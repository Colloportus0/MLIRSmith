        -:    0:Source:/data/xcy/llvm-project-fdbc55a5-2/mlir/lib/Dialect/Linalg/Transforms/SplitReduction.cpp
        -:    0:Graph:../tools/mlir/lib/Dialect/Linalg/Transforms/CMakeFiles/obj.MLIRLinalgTransforms.dir/SplitReduction.cpp.gcno
        -:    0:Data:../tools/mlir/lib/Dialect/Linalg/Transforms/CMakeFiles/obj.MLIRLinalgTransforms.dir/SplitReduction.cpp.gcda
        -:    0:Runs:128628
        -:    1://===-------- SplitReduction.cpp - Split reduction dimesion ---------------===//
        -:    2://
        -:    3:// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
        -:    4:// See https://llvm.org/LICENSE.txt for license information.
        -:    5:// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
        -:    6://
        -:    7://===----------------------------------------------------------------------===//
        -:    8://
        -:    9:// This file implements linalg transformation to break a reduction dimension
        -:   10:// between a parallel and a reduction dimension.
        -:   11://
        -:   12://===----------------------------------------------------------------------===//
        -:   13:
        -:   14:#include <utility>
        -:   15:
        -:   16:#include "mlir/Analysis/SliceAnalysis.h"
        -:   17:#include "mlir/Dialect/Arith/IR/Arith.h"
        -:   18:#include "mlir/Dialect/Bufferization/IR/Bufferization.h"
        -:   19:#include "mlir/Dialect/Linalg/IR/Linalg.h"
        -:   20:#include "mlir/Dialect/Linalg/Transforms/Transforms.h"
        -:   21:#include "mlir/Dialect/Linalg/Utils/Utils.h"
        -:   22:#include "mlir/Dialect/Tensor/IR/Tensor.h"
        -:   23:#include "mlir/Dialect/Tensor/Utils/Utils.h"
        -:   24:#include "mlir/IR/PatternMatch.h"
        -:   25:
        -:   26:using namespace mlir;
        -:   27:using namespace mlir::linalg;
        -:   28:
        -:   29:/// Return the identity numeric value associated to the give op.
function _ZL17getNeutralElementPN4mlir9OperationE called 0 returned 0% blocks executed 0%
    #####:   30:static Attribute getNeutralElement(Operation *op) {
        -:   31:  // Builder only used as helper for attribute creation.
    #####:   32:  OpBuilder b(op->getContext());
call    0 never executed
call    1 never executed
    #####:   33:  Type resultType = op->getResult(0).getType();
call    0 never executed
    #####:   34:  if (auto floatType = resultType.dyn_cast<FloatType>()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:   35:    const llvm::fltSemantics &semantic = floatType.getFloatSemantics();
call    0 never executed
    #####:   36:    if (isa<arith::AddFOp>(op))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:   37:      return b.getFloatAttr(resultType, llvm::APFloat::getZero(semantic));
call    0 never executed
call    1 never executed
call    2 never executed
    #####:   38:    if (isa<arith::MulFOp>(op))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:   39:      return b.getFloatAttr(resultType, llvm::APFloat(semantic, 1));
call    0 never executed
call    1 never executed
call    2 never executed
    #####:   40:    if (isa<arith::MaxFOp>(op))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:   41:      return b.getFloatAttr(resultType,
call    0 never executed
    #####:   42:                            llvm::APFloat::getLargest(semantic, true));
call    0 never executed
call    1 never executed
    #####:   43:    if (isa<arith::MinFOp>(op))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:   44:      return b.getFloatAttr(resultType,
call    0 never executed
    #####:   45:                            llvm::APFloat::getLargest(semantic, true));
call    0 never executed
call    1 never executed
    #####:   46:    return Attribute();
        -:   47:  }
    #####:   48:  if (isa<arith::AddIOp, arith::OrIOp, arith::XOrIOp>(op))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:   49:    return b.getIntegerAttr(resultType, 0);
call    0 never executed
    #####:   50:  if (isa<arith::AndIOp>(op))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:   51:    return b.getIntegerAttr(resultType, -1);
call    0 never executed
    #####:   52:  if (isa<arith::MaxSIOp>(op))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:   53:    return b.getIntegerAttr(resultType, std::numeric_limits<int64_t>::min());
call    0 never executed
    #####:   54:  if (isa<arith::MinSIOp>(op))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:   55:    return b.getIntegerAttr(resultType, std::numeric_limits<int64_t>::max());
call    0 never executed
    #####:   56:  if (isa<arith::MulIOp>(op))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:   57:    return b.getIntegerAttr(resultType, 1);
call    0 never executed
    #####:   58:  return Attribute();
        -:   59:}
        -:   60:
function _ZN4mlir6linalg14splitReductionERNS_15PatternRewriterENS0_8LinalgOpERKSt8functionIFNS0_21SplitReductionOptionsES3_EEb called 0 returned 0% blocks executed 0%
    #####:   61:FailureOr<SplitReductionResult> mlir::linalg::splitReduction(
        -:   62:    PatternRewriter &b, LinalgOp op,
        -:   63:    const ControlSplitReductionFn &controlSplitReductionFn, bool useAlloc) {
    #####:   64:  OpBuilder::InsertionGuard guard(b);
call    0 never executed
    #####:   65:  b.setInsertionPoint(op);
call    0 never executed
        -:   66:
    #####:   67:  SplitReductionOptions control = controlSplitReductionFn(op);
branch  0 never executed
branch  1 never executed
    #####:   68:  int64_t ratio = control.ratio;
    #####:   69:  unsigned insertSplitDimension = control.index;
    #####:   70:  if (ratio <= 1)
branch  0 never executed
branch  1 never executed
    #####:   71:    return b.notifyMatchFailure(op, "split ratio needs to be greater than 1");
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:   72:
    #####:   73:  SmallVector<unsigned> dims;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:   74:  op.getReductionDims(dims);
call    0 never executed
    #####:   75:  assert(dims.size() == 1);
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:   76:  unsigned reductionDim = dims[0];
call    0 never executed
    #####:   77:  SmallVector<int64_t, 4> loopRanges = op.getStaticLoopRanges();
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:   78:  int64_t reductionDimSize = loopRanges[reductionDim];
branch  0 never executed
branch  1 never executed
    #####:   79:  if (reductionDimSize == ShapedType::kDynamicSize ||
    #####:   80:      reductionDimSize % ratio != 0 ||
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
    #####:   81:      insertSplitDimension >= loopRanges.size())
branch  0 never executed
branch  1 never executed
    #####:   82:    return b.notifyMatchFailure(
    #####:   83:        op, "Reduction dimension not divisible by split ratio");
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:   84:
    #####:   85:  SmallVector<Operation *, 4> combinerOps;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:   86:  if (!matchReduction(op.getRegionOutputArgs(), 0, combinerOps) ||
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
    #####:   87:      combinerOps.size() != 1)
branch  0 never executed
branch  1 never executed
    #####:   88:    return b.notifyMatchFailure(op, "Cannot match the reduction pattern");
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:   89:
    #####:   90:  Operation *reductionOp = combinerOps[0];
call    0 never executed
    #####:   91:  Attribute identity = getNeutralElement(reductionOp);
call    0 never executed
    #####:   92:  if (!identity)
branch  0 never executed
branch  1 never executed
    #####:   93:    return b.notifyMatchFailure(op, "Unknown identity value for the reduction");
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:   94:
    #####:   95:  Location loc = op->getLoc();
call    0 never executed
    #####:   96:  SmallVector<Value> newInputs;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:   97:  SmallVector<AffineMap> newMaps;
branch  0 never executed
branch  1 never executed
        -:   98:  // Calculate the new shapes and indexing maps of the input operands.
    #####:   99:  for (OpOperand *operand : op.getDpsInputOperands()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  100:    AffineMap map = op.getMatchingIndexingMap(operand);
call    0 never executed
    #####:  101:    SmallVector<int64_t> newShape;
call    0 never executed
    #####:  102:    SmallVector<AffineExpr> exprs;
branch  0 never executed
branch  1 never executed
    #####:  103:    SmallVector<ReassociationIndices> reassociation;
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  104:    unsigned index = 0;
    #####:  105:    for (unsigned idx : llvm::seq<unsigned>(0, map.getNumResults())) {
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
call    4 never executed
    #####:  106:      unsigned dim = map.getDimPosition(idx);
call    0 never executed
    #####:  107:      if (reductionDim == dim) {
branch  0 never executed
branch  1 never executed
    #####:  108:        if (control.innerParallel) {
branch  0 never executed
branch  1 never executed
    #####:  109:          newShape.push_back(op.getShape(operand)[idx] / ratio);
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
    #####:  110:          newShape.push_back(ratio);
call    0 never executed
        -:  111:        } else {
    #####:  112:          newShape.push_back(ratio);
call    0 never executed
    #####:  113:          newShape.push_back(op.getShape(operand)[idx] / ratio);
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
        -:  114:        }
    #####:  115:        reassociation.push_back({index++, index++});
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  116:        if (control.innerParallel) {
branch  0 never executed
branch  1 never executed
    #####:  117:          exprs.push_back(b.getAffineDimExpr(reductionDim));
call    0 never executed
call    1 never executed
    #####:  118:          exprs.push_back(b.getAffineDimExpr(reductionDim + 1));
call    0 never executed
call    1 never executed
        -:  119:        } else {
    #####:  120:          exprs.push_back(b.getAffineDimExpr(insertSplitDimension));
call    0 never executed
call    1 never executed
    #####:  121:          exprs.push_back(
branch  0 never executed
branch  1 never executed
call    2 never executed
call    3 never executed
        -:  122:              b.getAffineDimExpr(dim < insertSplitDimension ? dim : dim + 1));
        -:  123:        }
    #####:  124:        continue;
        -:  125:      }
    #####:  126:      newShape.push_back(op.getShape(operand)[idx]);
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
    #####:  127:      if (control.innerParallel) {
branch  0 never executed
branch  1 never executed
    #####:  128:        exprs.push_back(
branch  0 never executed
branch  1 never executed
call    2 never executed
call    3 never executed
        -:  129:            b.getAffineDimExpr(dim <= reductionDim ? dim : dim + 1));
        -:  130:      } else {
    #####:  131:        exprs.push_back(
branch  0 never executed
branch  1 never executed
call    2 never executed
call    3 never executed
        -:  132:            b.getAffineDimExpr(dim < insertSplitDimension ? dim : dim + 1));
        -:  133:      }
    #####:  134:      reassociation.push_back({index++});
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
        -:  135:    }
    #####:  136:    newMaps.push_back(
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:  137:        AffineMap::get(map.getNumDims() + 1, 0, exprs, op.getContext()));
call    0 never executed
        -:  138:    // If the shape is unchanged the input doesn't change.
    #####:  139:    if (newShape == op.getShape(operand)) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  140:      newInputs.push_back(operand->get());
call    0 never executed
    #####:  141:      continue;
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  142:    }
    #####:  143:    Type newType = RankedTensorType::get(
        -:  144:        newShape,
    #####:  145:        operand->get().getType().cast<RankedTensorType>().getElementType());
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  146:    Value newInput = b.create<tensor::ExpandShapeOp>(
    #####:  147:        loc, newType, operand->get(), reassociation);
call    0 never executed
call    1 never executed
    #####:  148:    newInputs.push_back(newInput);
call    0 never executed
        -:  149:  }
        -:  150:
        -:  151:  // Calculate the new output map and shape, we insert the new dimension based
        -:  152:  // on the index returned by `controlSplitReductionFn`.
    #####:  153:  SmallVector<int64_t> newOutputShape;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  154:  AffineMap oldOutputMap = op.getMatchingIndexingMap(op.getDpsInitOperand(0));
call    0 never executed
call    1 never executed
    #####:  155:  ArrayRef<int64_t> oldShape = op.getShape(op.getDpsInitOperand(0));
call    0 never executed
call    1 never executed
    #####:  156:  SmallVector<AffineExpr> outputExpr;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  157:  for (unsigned idx :
    #####:  158:       llvm::seq<unsigned>(0, oldOutputMap.getNumResults() + 1)) {
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
call    4 never executed
    #####:  159:    if (idx == insertSplitDimension) {
branch  0 never executed
branch  1 never executed
    #####:  160:      newOutputShape.push_back(ratio);
call    0 never executed
    #####:  161:      if (control.innerParallel) {
branch  0 never executed
branch  1 never executed
    #####:  162:        outputExpr.push_back(b.getAffineDimExpr(reductionDim + 1));
call    0 never executed
call    1 never executed
        -:  163:      } else {
    #####:  164:        outputExpr.push_back(b.getAffineDimExpr(insertSplitDimension));
call    0 never executed
call    1 never executed
        -:  165:      }
    #####:  166:      continue;
        -:  167:    }
    #####:  168:    unsigned oldIdx = idx < insertSplitDimension ? idx : idx - 1;
branch  0 never executed
branch  1 never executed
    #####:  169:    newOutputShape.push_back(oldShape[oldIdx]);
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  170:    unsigned dim = oldOutputMap.getDimPosition(oldIdx);
call    0 never executed
    #####:  171:    if (control.innerParallel) {
branch  0 never executed
branch  1 never executed
    #####:  172:      outputExpr.push_back(
branch  0 never executed
branch  1 never executed
call    2 never executed
call    3 never executed
        -:  173:          b.getAffineDimExpr(dim <= reductionDim ? dim : dim + 1));
        -:  174:    } else {
    #####:  175:      outputExpr.push_back(
branch  0 never executed
branch  1 never executed
call    2 never executed
call    3 never executed
        -:  176:          b.getAffineDimExpr(dim < insertSplitDimension ? dim : dim + 1));
        -:  177:    }
        -:  178:  }
    #####:  179:  Value emptyOrAllocTensor;
    #####:  180:  if (useAlloc) {
branch  0 never executed
branch  1 never executed
    #####:  181:    emptyOrAllocTensor = b.create<bufferization::AllocTensorOp>(
        -:  182:        loc,
    #####:  183:        RankedTensorType::get(newOutputShape,
    #####:  184:                              op.getRegionOutputArgs()[0].getType()),
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
    #####:  185:        ValueRange{});
call    0 never executed
call    1 never executed
        -:  186:  } else {
    #####:  187:    emptyOrAllocTensor = b.create<tensor::EmptyOp>(
    #####:  188:        loc, newOutputShape, op.getRegionOutputArgs()[0].getType());
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
        -:  189:  }
    #####:  190:  Value constantOp = b.create<arith::ConstantOp>(loc, identity);
call    0 never executed
call    1 never executed
    #####:  191:  Value identityTensor =
    #####:  192:      b.create<linalg::FillOp>(op->getLoc(), constantOp, emptyOrAllocTensor)
call    0 never executed
call    1 never executed
    #####:  193:          .getResult(0);
        -:  194:
    #####:  195:  newMaps.push_back(AffineMap::get(oldOutputMap.getNumDims() + 1, 0, outputExpr,
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
        -:  196:                                   op.getContext()));
    #####:  197:  SmallVector<StringRef> newIteratorTypes;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  198:  for (auto &it : llvm::enumerate(op.getIteratorTypesArray())) {
call    0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
branch  6 never executed
call    7 never executed
    #####:  199:    if (insertSplitDimension == it.index() && !control.innerParallel)
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####:  200:      newIteratorTypes.push_back(getParallelIteratorTypeName());
call    0 never executed
    #####:  201:    newIteratorTypes.push_back(it.value());
call    0 never executed
    #####:  202:    if (insertSplitDimension == it.index() && control.innerParallel)
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####:  203:      newIteratorTypes.push_back(getParallelIteratorTypeName());
call    0 never executed
        -:  204:  }
        -:  205:  // Create the new op matching the original op with an extra parallel
        -:  206:  // dimension.
    #####:  207:  GenericOp genericOp = b.create<GenericOp>(
    #####:  208:      loc, TypeRange({emptyOrAllocTensor.getType()}), newInputs,
    #####:  209:      ValueRange({identityTensor}), newMaps, newIteratorTypes);
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  210:  b.inlineRegionBefore(op->getRegion(0), genericOp.getRegion(),
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  211:                       genericOp.getRegion().begin());
call    0 never executed
call    1 never executed
        -:  212:
        -:  213:  // Then create a new reduction that only reduce the newly added dimension
        -:  214:  // from the previous op.
    #####:  215:  unsigned intermRank = newOutputShape.size();
call    0 never executed
    #####:  216:  AffineMap inputMap = b.getMultiDimIdentityMap(intermRank);
call    0 never executed
    #####:  217:  SmallVector<StringRef> reductionIteratorTypes;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  218:  SmallVector<AffineExpr> exprs;
branch  0 never executed
branch  1 never executed
    #####:  219:  for (unsigned i : llvm::seq<unsigned>(0, intermRank)) {
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
    #####:  220:    if (insertSplitDimension == i) {
branch  0 never executed
branch  1 never executed
    #####:  221:      reductionIteratorTypes.push_back(getReductionIteratorTypeName());
call    0 never executed
        -:  222:    } else {
    #####:  223:      exprs.push_back(b.getAffineDimExpr(i));
call    0 never executed
call    1 never executed
    #####:  224:      reductionIteratorTypes.push_back(getParallelIteratorTypeName());
call    0 never executed
        -:  225:    }
        -:  226:  }
    #####:  227:  AffineMap outputMap = AffineMap::get(intermRank, 0, exprs, op.getContext());
call    0 never executed
call    1 never executed
    #####:  228:  SmallVector<AffineMap> reductionMaps = {inputMap, outputMap};
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  229:
    #####:  230:  auto reduction = b.create<GenericOp>(
    #####:  231:      loc, op->getResultTypes(), ValueRange({genericOp.getResult(0)}),
call    0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
    #####:  232:      SmallVector<Value>{op.getDpsInitOperands()}, reductionMaps,
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
        -:  233:      reductionIteratorTypes,
function _ZZN4mlir6linalg14splitReductionERNS_15PatternRewriterENS0_8LinalgOpERKSt8functionIFNS0_21SplitReductionOptionsES3_EEbENKUlRNS_9OpBuilderENS_8LocationENS_10ValueRangeEE_clESB_SC_SD_.isra.0 called 0 returned 0% blocks executed 0%
    #####:  234:      [reductionOp](OpBuilder &b, Location loc, ValueRange inputs) {
    #####:  235:        Operation *clonedReductionOp = b.clone(*reductionOp);
call    0 never executed
    #####:  236:        clonedReductionOp->setOperand(0, inputs[0]);
call    0 never executed
call    1 never executed
    #####:  237:        clonedReductionOp->setOperand(1, inputs[1]);
call    0 never executed
call    1 never executed
    #####:  238:        b.create<linalg::YieldOp>(loc, clonedReductionOp->getResult(0));
call    0 never executed
    #####:  239:      });
call    0 never executed
call    1 never executed
    #####:  240:  b.replaceOp(op, reduction.getResults());
branch  0 never executed
branch  1 never executed
call    2 never executed
call    3 never executed
        -:  241:
    #####:  242:  return SplitReductionResult{emptyOrAllocTensor.getDefiningOp(),
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  243:                              identityTensor.getDefiningOp<FillOp>(),
call    0 never executed
    #####:  244:                              cast<LinalgOp>(genericOp.getOperation()),
call    0 never executed
call    1 never executed
    #####:  245:                              reduction};
branch  0 never executed
branch  1 never executed
        -:  246:}
        -:  247:
        -:  248:/// Rewrite f(i, j, k, ...) into f(i, j, k * ratio + kk, ...)
        -:  249:/// TODO: Additional pattern to rewrite f(i, j, k * ratio + kk, ...) into
        -:  250:/// f(i, j, k, kk, ...) with a proper ExpandShapeOp. This is probably better
        -:  251:/// done as a transform to enable better vectorization.
function _ZL17scaleReductionDimN4mlir6linalg8LinalgOpERNS_9OpOperandEjl called 0 returned 0% blocks executed 0%
    #####:  252:static AffineMap scaleReductionDim(LinalgOp op, OpOperand &opOperand,
        -:  253:                                   unsigned reductionDimPos,
        -:  254:                                   int64_t reductionRatio) {
    #####:  255:  auto reductionDim = getAffineDimExpr(reductionDimPos, op.getContext());
call    0 never executed
call    1 never executed
    #####:  256:  auto reductionDimP1 = getAffineDimExpr(reductionDimPos + 1, op.getContext());
call    0 never executed
call    1 never executed
    #####:  257:  AffineMap map = op.getMatchingIndexingMap(&opOperand);
call    0 never executed
    #####:  258:  AffineMap idMap =
call    0 never executed
    #####:  259:      AffineMap::getMultiDimIdentityMap(map.getNumDims(), op.getContext());
call    0 never executed
call    1 never executed
    #####:  260:  AffineMap shiftedIdMap = idMap.shiftDims(1, /*offset=*/reductionDimPos + 1);
call    0 never executed
    #####:  261:  AffineMap composeMap = shiftedIdMap.replace(
    #####:  262:      reductionDim, reductionDim * reductionRatio + reductionDimP1,
call    0 never executed
    #####:  263:      shiftedIdMap.getNumDims(), /*numSymbols=*/0);
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  264:  return map.compose(composeMap);
call    0 never executed
        -:  265:}
        -:  266:
        -:  267:static AffineMap insertParallelDim(LinalgOp op, OpOperand &opOperand,
        -:  268:                                   unsigned reductionDimPos, int64_t size) {
        -:  269:  auto reductionDim = getAffineDimExpr(reductionDimPos, op.getContext());
        -:  270:  AffineMap map = op.getMatchingIndexingMap(&opOperand);
        -:  271:  AffineMap idMap =
        -:  272:      AffineMap::getMultiDimIdentityMap(map.getNumDims(), op.getContext());
        -:  273:  AffineMap shiftedIdMap = idMap.shiftDims(1, /*offset=*/reductionDimPos + 1);
        -:  274:  return map.compose(shiftedIdMap).insertResult(reductionDim, reductionDimPos);
        -:  275:}
        -:  276:
        -:  277:/// Core rewrite implementation.
function _ZN4mlir6linalg23splitReductionByScalingERNS_15PatternRewriterENS0_8LinalgOpERKSt8functionIFNS0_21SplitReductionOptionsES3_EEb called 0 returned 0% blocks executed 0%
    #####:  278:FailureOr<SplitReductionResult> mlir::linalg::splitReductionByScaling(
        -:  279:    PatternRewriter &b, LinalgOp op,
        -:  280:    const ControlSplitReductionFn &controlSplitReductionFn, bool useAlloc) {
    #####:  281:  OpBuilder::InsertionGuard guard(b);
call    0 never executed
    #####:  282:  b.setInsertionPoint(op);
call    0 never executed
        -:  283:
        -:  284:  // Matcher part, enforce preconditions.
    #####:  285:  SplitReductionOptions control = controlSplitReductionFn(op);
branch  0 never executed
branch  1 never executed
    #####:  286:  if (control.innerParallel)
branch  0 never executed
branch  1 never executed
    #####:  287:    return b.notifyMatchFailure(op, "innerParallel not supported");
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  288:
    #####:  289:  int64_t splitFactor = control.ratio;
    #####:  290:  unsigned insertSplitDimension = control.index;
    #####:  291:  if (splitFactor <= 1)
branch  0 never executed
branch  1 never executed
    #####:  292:    return b.notifyMatchFailure(op, "split factor needs to be greater than 1");
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  293:
    #####:  294:  SmallVector<unsigned> dims;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  295:  op.getReductionDims(dims);
call    0 never executed
    #####:  296:  if (dims.empty())
branch  0 never executed
branch  1 never executed
    #####:  297:    return b.notifyMatchFailure(op, "needs at least 1 reduction dimension");
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  298:
    #####:  299:  unsigned reductionDimPos = dims[0];
call    0 never executed
    #####:  300:  SmallVector<int64_t> loopRanges = op.getStaticLoopRanges();
call    0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
branch  6 never executed
    #####:  301:  int64_t reductionDimSize = loopRanges[reductionDimPos];
branch  0 never executed
branch  1 never executed
    #####:  302:  if (reductionDimSize == ShapedType::kDynamicSize ||
    #####:  303:      reductionDimSize % splitFactor != 0 ||
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
    #####:  304:      insertSplitDimension >= loopRanges.size())
branch  0 never executed
branch  1 never executed
    #####:  305:    return b.notifyMatchFailure(
    #####:  306:        op, "first reduction dimension not divisible by split factor");
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  307:
    #####:  308:  SmallVector<Operation *> combinerOps;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  309:  if (!matchReduction(op.getRegionOutputArgs(), 0, combinerOps))
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  310:    return b.notifyMatchFailure(op, "cannot match a reduction pattern");
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  311:
    #####:  312:  SmallVector<Attribute> neutralElements = llvm::to_vector<4>(
branch  0 never executed
branch  1 never executed
    #####:  313:      llvm::map_range(combinerOps, [&](Operation *reductionOp) {
        -:  314:        return getNeutralElement(reductionOp);
    #####:  315:      }));
call    0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
    #####:  316:  if (!llvm::all_of(neutralElements, [](Attribute attr) { return attr; }))
branch  0 never executed
branch  1 never executed
    #####:  317:    return b.notifyMatchFailure(op, "unknown reduction neutral");
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  318:
        -:  319:  // TODO: relax this when multi-reduction support is available.
    #####:  320:  if (op.getNumDpsInits() != static_cast<int64_t>(neutralElements.size()))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  321:    return b.notifyMatchFailure(op, "expect one reduction per output");
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  322:
        -:  323:  // Rewrite part.
        -:  324:  // Step 1. Build the intermediate outputs filled with the proper
        -:  325:  // neutralElements. Such outputs are of the same shape with an extra dimension
        -:  326:  // inserted at `insertSplitDimension`.
        -:  327:  //
        -:  328:  // Consider a minimal example where `k` is reduced:
        -:  329:  //     O(i, j) += I(i, j, k)
        -:  330:  // Assume i=3, j=5, k=128, splitFactor=16 and insertSplitDimension=0.
        -:  331:  // The compute is rewritten as:
        -:  332:  //   a. O_i(kk, i, j) += I(i, j, 16 * k + kk)
        -:  333:  //   b. O(i, j) += O_i(kk, i, j)
        -:  334:  // The intermediate tensor O_i is of shape (128/16)x3x5 == 8x3x5.
    #####:  335:  Location loc = op->getLoc();
call    0 never executed
    #####:  336:  MLIRContext *context = op.getContext();
call    0 never executed
        -:  337:  // For now assume outputs are 1-1 with reduction neutralElements.
        -:  338:  // TODO: generalize when multi-reduction support is available.
    #####:  339:  SmallVector<Value> newOutputs;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  340:  newOutputs.reserve(op.getNumDpsInits());
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  341:  SmallVector<Operation *> emptyOrAllocTensorOps;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  342:  SmallVector<linalg::FillOp> fillOps;
branch  0 never executed
branch  1 never executed
    #####:  343:  fillOps.reserve(op.getNumDpsInits());
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  344:  for (auto it : llvm::zip(op.getDpsInitOperands(), neutralElements)) {
call    0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
branch  6 never executed
    #####:  345:    Value rankedTensor = std::get<0>(it)->get();
call    0 never executed
    #####:  346:    auto t = rankedTensor.getType().cast<RankedTensorType>();
call    0 never executed
    #####:  347:    RankedTensorType newT = RankedTensorType::Builder(t).insertDim(
call    0 never executed
    #####:  348:        reductionDimSize / splitFactor, insertSplitDimension);
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  349:    SmallVector<Value> dims =
    #####:  350:        tensor::createDynamicDimValues(b, loc, rankedTensor);
call    0 never executed
    #####:  351:    Value emptyOrAllocTensor;
    #####:  352:    if (useAlloc) {
branch  0 never executed
branch  1 never executed
    #####:  353:      emptyOrAllocTensor =
    #####:  354:          b.create<bufferization::AllocTensorOp>(loc, newT, dims);
call    0 never executed
        -:  355:    } else {
    #####:  356:      emptyOrAllocTensor = b.create<tensor::EmptyOp>(loc, newT.getShape(),
call    0 never executed
    #####:  357:                                                     t.getElementType(), dims);
call    0 never executed
call    1 never executed
        -:  358:    }
    #####:  359:    Value constantOp = b.create<arith::ConstantOp>(loc, std::get<1>(it));
call    0 never executed
call    1 never executed
    #####:  360:    fillOps.push_back(
call    0 never executed
call    1 never executed
        -:  361:        b.create<linalg::FillOp>(op->getLoc(), constantOp, emptyOrAllocTensor));
    #####:  362:    newOutputs.push_back(fillOps.back().getResult(0));
call    0 never executed
call    1 never executed
    #####:  363:    emptyOrAllocTensorOps.push_back(emptyOrAllocTensor.getDefiningOp());
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
        -:  364:  }
        -:  365:
        -:  366:  // Step 2. Reindex / expand indexing maps.
        -:  367:  // Reindex existing input indexings: k -> k * splitFactor + k'.
    #####:  368:  SmallVector<AffineMap> newMaps;
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####:  369:  newMaps.reserve(op->getNumOperands() + 1);
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####:  370:  for (OpOperand *o : op.getDpsInputOperands())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  371:    newMaps.push_back(scaleReductionDim(op, *o, reductionDimPos, splitFactor));
call    0 never executed
call    1 never executed
        -:  372:  // Provision a new indexing for the shape-only tensor.
    #####:  373:  auto nDims = op.getNumLoops() + 1;
call    0 never executed
    #####:  374:  auto redDim = getAffineDimExpr(reductionDimPos, context);
call    0 never executed
    #####:  375:  auto redDimP1 = getAffineDimExpr(reductionDimPos + 1, context);
call    0 never executed
    #####:  376:  newMaps.push_back(AffineMap::get(nDims, 0, {redDim, redDimP1}, context));
call    0 never executed
call    1 never executed
        -:  377:  // Expand existing output indexings.
        -:  378:  // TODO: a subset of these may not reduce along reducePos and should be
        -:  379:  // reindexed: k -> k * splitFactor + k', when multi-reduction support is
        -:  380:  // available.
    #####:  381:  for (OpOperand *o : op.getDpsInitOperands())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  382:    newMaps.push_back(insertParallelDim(op, *o, reductionDimPos,
call    0 never executed
call    1 never executed
        -:  383:                                        reductionDimSize / splitFactor));
        -:  384:
        -:  385:  // Step 3. Handle operands.
        -:  386:  // Compute the new input tensors.
    #####:  387:  SmallVector<Value> newInputs(op.getDpsInputOperands());
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
        -:  388:  // Add a single shape-only tensor to carry the dimensions without resorting to
        -:  389:  // more complex inversions.
    #####:  390:  newInputs.push_back(b.create<tensor::EmptyOp>(
call    0 never executed
    #####:  391:      loc, ArrayRef<int64_t>{reductionDimSize / splitFactor, splitFactor},
call    0 never executed
    #####:  392:      b.getIntegerType(1)));
call    0 never executed
call    1 never executed
call    2 never executed
        -:  393:  // Output tensors are already good to go.
        -:  394:
        -:  395:  // Step 4. Create the new op matching the original op with an extra parallel
        -:  396:  // dimension.
    #####:  397:  auto iteratorTypes = op.getIteratorTypesArray();
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  398:  iteratorTypes.insert(iteratorTypes.begin() + reductionDimPos,
call    0 never executed
        -:  399:                       getParallelIteratorTypeName());
    #####:  400:  GenericOp genericOp =
    #####:  401:      b.create<GenericOp>(loc, ValueRange(newOutputs).getTypes(), newInputs,
call    0 never executed
    #####:  402:                          newOutputs, newMaps, iteratorTypes);
call    0 never executed
call    1 never executed
    #####:  403:  b.inlineRegionBefore(op->getRegion(0), genericOp.getRegion(),
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  404:                       genericOp.getRegion().begin());
call    0 never executed
call    1 never executed
    #####:  405:  genericOp.getRegion().front().insertArgument(reductionDimPos,
call    0 never executed
call    1 never executed
    #####:  406:                                               b.getIntegerType(1), loc);
call    0 never executed
call    1 never executed
        -:  407:
        -:  408:  // Step 5. Create new reduction ops that only reduce the newly added
        -:  409:  // dimensions from the previous op.
        -:  410:  // For now assume outputs are 1-1 with reduction ops.
        -:  411:  // TODO: a subset of these may not reduce in the first place and do not
        -:  412:  // require a new op, when multi-reduction support is available.
        -:  413:  // TODO: all results can be handled in a single GenericOp, when
        -:  414:  // multi-reduction support is available.
    #####:  415:  SmallVector<LinalgOp> results;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  416:  for (auto it : llvm::zip(genericOp->getResults(), op.getDpsInitOperands(),
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  417:                           combinerOps)) {
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
    #####:  418:    Value reindexedOutput = std::get<0>(it);
call    0 never executed
    #####:  419:    Value originalOutput = std::get<1>(it)->get();
call    0 never executed
    #####:  420:    auto originalOutputType = originalOutput.getType().cast<RankedTensorType>();
call    0 never executed
    #####:  421:    Operation *combinerOp = std::get<2>(it);
call    0 never executed
        -:  422:
    #####:  423:    AffineMap map = b.getMultiDimIdentityMap(originalOutputType.getRank() + 1);
call    0 never executed
call    1 never executed
    #####:  424:    SmallVector<AffineMap> indexingMaps = {
    #####:  425:        map, map.dropResult(insertSplitDimension)};
call    0 never executed
call    1 never executed
    #####:  426:    SmallVector<StringRef> reductionIteratorTypes(
call    0 never executed
    #####:  427:        originalOutputType.getRank() + 1, getParallelIteratorTypeName());
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  428:    reductionIteratorTypes[insertSplitDimension] =
branch  0 never executed
branch  1 never executed
        -:  429:        getReductionIteratorTypeName();
        -:  430:
        -:  431:    // clang-format off
    #####:  432:    auto reductionOp = b.create<GenericOp>(
        -:  433:        loc,
        -:  434:        originalOutputType,
        -:  435:        reindexedOutput,
        -:  436:        originalOutput,
        -:  437:        indexingMaps,
        -:  438:        reductionIteratorTypes,
function _ZZN4mlir6linalg23splitReductionByScalingERNS_15PatternRewriterENS0_8LinalgOpERKSt8functionIFNS0_21SplitReductionOptionsES3_EEbENKUlRNS_9OpBuilderENS_8LocationENS_10ValueRangeEE1_clESB_SC_SD_.isra.0 called 0 returned 0% blocks executed 0%
    #####:  439:        [combinerOp](OpBuilder &b, Location loc, ValueRange bbArgs) {
    #####:  440:          Operation *clonedReductionOp = b.clone(*combinerOp);
call    0 never executed
    #####:  441:          clonedReductionOp->setOperand(0, bbArgs[0]);
call    0 never executed
call    1 never executed
    #####:  442:          clonedReductionOp->setOperand(1, bbArgs[1]);
call    0 never executed
call    1 never executed
    #####:  443:          b.create<linalg::YieldOp>(loc, clonedReductionOp->getResult(0));
call    0 never executed
    #####:  444:        });
call    0 never executed
        -:  445:    // clang-format on
        -:  446:
    #####:  447:    results.push_back(reductionOp);
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
        -:  448:  }
        -:  449:
        -:  450:  // TODO: extend when multi-reduction support is available.
    #####:  451:  assert(fillOps.size() == results.size() && results.size() == 1);
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
call    4 never executed
    #####:  452:  b.replaceOp(op, results.front()->getResults());
branch  0 never executed
branch  1 never executed
call    2 never executed
call    3 never executed
    #####:  453:  return SplitReductionResult{emptyOrAllocTensorOps.front(), fillOps.front(),
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####:  454:                              cast<LinalgOp>(genericOp.getOperation()),
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  455:                              results.front()};
branch  0 never executed
branch  1 never executed
        -:  456:}
        -:  457:
        -:  458:namespace {
        -:  459:
        -:  460:struct LinalgSplitReduction : public OpInterfaceRewritePattern<LinalgOp> {
        -:  461:  /// Construct a generic pattern applied to all LinalgOp that verify `filter`.
function _ZN12_GLOBAL__N_120LinalgSplitReductionC2EPN4mlir11MLIRContextESt8functionIFNS1_6linalg21SplitReductionOptionsENS5_8LinalgOpEEEbNS1_14PatternBenefitE called 0 returned 0% blocks executed 0%
    #####:  462:  LinalgSplitReduction(MLIRContext *context,
        -:  463:                       ControlSplitReductionFn controlSplitReductionFn,
        -:  464:                       bool useAlloc = false, PatternBenefit benefit = 1)
    #####:  465:      : OpInterfaceRewritePattern<LinalgOp>(context, benefit),
    #####:  466:        controlSplitReductionFn(std::move(controlSplitReductionFn)),
    #####:  467:        useAlloc(useAlloc) {}
call    0 never executed
        -:  468:
function _ZNK12_GLOBAL__N_120LinalgSplitReduction15matchAndRewriteEN4mlir6linalg8LinalgOpERNS1_15PatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  469:  LogicalResult matchAndRewrite(LinalgOp op,
        -:  470:                                PatternRewriter &rewriter) const override {
    #####:  471:    return splitReduction(rewriter, op, controlSplitReductionFn, useAlloc);
call    0 never executed
        -:  472:  }
        -:  473:
        -:  474:private:
        -:  475:  ControlSplitReductionFn controlSplitReductionFn;
        -:  476:  bool useAlloc;
        -:  477:};
        -:  478:
        -:  479:} // namespace
        -:  480:
function _ZN4mlir6linalg29populateSplitReductionPatternERNS_17RewritePatternSetERKSt8functionIFNS0_21SplitReductionOptionsENS0_8LinalgOpEEEb called 0 returned 0% blocks executed 0%
    #####:  481:void linalg::populateSplitReductionPattern(
        -:  482:    RewritePatternSet &patterns,
        -:  483:    const ControlSplitReductionFn &controlSplitReductionFn, bool useAlloc) {
    #####:  484:  patterns.add<LinalgSplitReduction>(patterns.getContext(),
call    0 never executed
    #####:  485:                                     controlSplitReductionFn, useAlloc);
call    0 never executed
    #####:  486:}
