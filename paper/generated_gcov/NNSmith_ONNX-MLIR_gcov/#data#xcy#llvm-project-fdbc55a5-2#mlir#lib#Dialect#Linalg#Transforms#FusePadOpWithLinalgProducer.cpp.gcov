        -:    0:Source:/data/xcy/llvm-project-fdbc55a5-2/mlir/lib/Dialect/Linalg/Transforms/FusePadOpWithLinalgProducer.cpp
        -:    0:Graph:../tools/mlir/lib/Dialect/Linalg/Transforms/CMakeFiles/obj.MLIRLinalgTransforms.dir/FusePadOpWithLinalgProducer.cpp.gcno
        -:    0:Data:../tools/mlir/lib/Dialect/Linalg/Transforms/CMakeFiles/obj.MLIRLinalgTransforms.dir/FusePadOpWithLinalgProducer.cpp.gcda
        -:    0:Runs:128649
        -:    1://===- FusePadOpWithLinalgProducer.cpp ---- Fuse pad with linalg producer -===//
        -:    2://
        -:    3:// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
        -:    4:// See https://llvm.org/LICENSE.txt for license information.
        -:    5:// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
        -:    6://
        -:    7://===----------------------------------------------------------------------===//
        -:    8://
        -:    9:// This file implements patterns that fuses a linalg.generic -> tensor.pad op
        -:   10:// chain into a tensor.extract_slice -> linalg.generic -> tensor.insert_slice
        -:   11:// op chain.
        -:   12://
        -:   13://===----------------------------------------------------------------------===//
        -:   14:
        -:   15:#include "mlir/Dialect/Linalg/Transforms/Transforms.h"
        -:   16:
        -:   17:#include "mlir/Dialect/Linalg/IR/Linalg.h"
        -:   18:#include "mlir/Transforms/GreedyPatternRewriteDriver.h"
        -:   19:
        -:   20:using namespace mlir;
        -:   21:
        -:   22:namespace {
        -:   23:
        -:   24:/// A sequence of operations
        -:   25:///
        -:   26:/// ```mlir
        -:   27:/// %0 = linalg. ...
        -:   28:/// %1 = tensor.pad %0 ...
        -:   29:/// ```
        -:   30:///
        -:   31:/// can be replaced with
        -:   32:///
        -:   33:/// ```mlir
        -:   34:/// %0 = linalg.fill
        -:   35:/// %1 = tensor.extract_slice %0 ...
        -:   36:/// %2 = linalg. .... outs(..., %1, ....) ....
        -:   37:/// %3 = tensor.insert_slice %2 into %1 ...
        -:   38:/// ```
        -:   39:///
        -:   40:/// if the `linalg.generic` has all parallel iterator types.
        -:   41:struct FusePadOp : OpRewritePattern<tensor::PadOp> {
        -:   42:  using OpRewritePattern<tensor::PadOp>::OpRewritePattern;
        -:   43:
function _ZNK12_GLOBAL__N_19FusePadOp15matchAndRewriteEN4mlir6tensor5PadOpERNS1_15PatternRewriterE called 0 returned 0% blocks executed 0%
    #####:   44:  LogicalResult matchAndRewrite(tensor::PadOp padOp,
        -:   45:                                PatternRewriter &rewriter) const override {
        -:   46:    // Only works on padding op that sets the padded value to a constant.
    #####:   47:    Value padValue = padOp.getConstantPaddingValue();
call    0 never executed
    #####:   48:    if (!padValue)
branch  0 never executed
branch  1 never executed
    #####:   49:      return rewriter.notifyMatchFailure(padOp, "non constant padding");
call    0 never executed
        -:   50:
        -:   51:    // This pattern could work for any Linalg op. For now restrict it to generic
        -:   52:    // ops.
    #####:   53:    Value source = padOp.getSource();
call    0 never executed
    #####:   54:    auto linalgOp = source.getDefiningOp<linalg::GenericOp>();
call    0 never executed
    #####:   55:    if (!linalgOp) {
branch  0 never executed
branch  1 never executed
    #####:   56:      return rewriter.notifyMatchFailure(
    #####:   57:          padOp, "expected source to be linalg.generic op");
call    0 never executed
        -:   58:    }
        -:   59:    // All iterator types need to be parallel.
    #####:   60:    if (linalgOp.getNumLoops() != linalgOp.getNumParallelLoops()) {
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:   61:      return rewriter.notifyMatchFailure(
    #####:   62:          padOp, "only supported for ops with all parallel iterator types");
call    0 never executed
        -:   63:    }
    #####:   64:    ReifiedRankedShapedTypeDims resultShape;
call    0 never executed
    #####:   65:    ReifyRankedShapedTypeOpInterface reifyShapedTypeInterface =
    #####:   66:        dyn_cast<ReifyRankedShapedTypeOpInterface>(padOp.getOperation());
call    0 never executed
    #####:   67:    if (failed(reifyShapedTypeInterface.reifyResultShapes(rewriter,
call    0 never executed
    #####:   68:                                                          resultShape)) ||
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####:   69:        resultShape.size() != 1) {
branch  0 never executed
branch  1 never executed
    #####:   70:      return rewriter.notifyMatchFailure(
    #####:   71:          padOp, "failed to get shape of pad op result");
call    0 never executed
        -:   72:    }
        -:   73:
    #####:   74:    Location loc = padOp.getLoc();
call    0 never executed
        -:   75:
        -:   76:    // Create the tensor of same size as output of the pad op.
    #####:   77:    RankedTensorType padResultType = padOp.getResultType();
call    0 never executed
    #####:   78:    auto resultSizes = getAsOpFoldResult(resultShape[0]);
branch  0 never executed
branch  1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
    #####:   79:    auto emptyTensor = rewriter.create<tensor::EmptyOp>(
    #####:   80:        loc, resultSizes, padResultType.getElementType());
call    0 never executed
call    1 never executed
        -:   81:
        -:   82:    // Fill the tensor with the pad value.
        -:   83:    // TODO: There is an option to fill only the boundaries. For now just
        -:   84:    // filling the whole tensor.
    #####:   85:    auto fillTensor =
    #####:   86:        rewriter.create<linalg::FillOp>(loc, padValue, emptyTensor.getResult());
call    0 never executed
call    1 never executed
        -:   87:
        -:   88:    // Construct a slice of the fill result that is to be replaced with the
        -:   89:    // result of the generic op. The low pad values are the offsets, the size of
        -:   90:    // the source is the size of the slice.
        -:   91:    // TODO: This insert/extract could be potentially made a utility method.
    #####:   92:    unsigned resultNumber = source.cast<OpResult>().getResultNumber();
call    0 never executed
call    1 never executed
    #####:   93:    SmallVector<OpFoldResult> offsets = padOp.getMixedLowPad();
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:   94:    SmallVector<OpFoldResult> sizes;
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####:   95:    sizes.reserve(offsets.size());
branch  0 never executed
branch  1 never executed
    #####:   96:    for (const auto &shape : llvm::enumerate(
    #####:   97:             source.getType().cast<RankedTensorType>().getShape())) {
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
call    4 never executed
    #####:   98:      if (ShapedType::isDynamic(shape.value())) {
branch  0 never executed
branch  1 never executed
    #####:   99:        sizes.push_back(
call    0 never executed
    #####:  100:            rewriter.create<tensor::DimOp>(loc, source, shape.index())
call    0 never executed
    #####:  101:                .getResult());
call    0 never executed
call    1 never executed
        -:  102:      } else {
    #####:  103:        sizes.push_back(rewriter.getIndexAttr(shape.value()));
call    0 never executed
call    1 never executed
call    2 never executed
        -:  104:      }
        -:  105:    }
    #####:  106:    SmallVector<OpFoldResult> strides(offsets.size(), rewriter.getIndexAttr(1));
call    0 never executed
call    1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
    #####:  107:    auto slice = rewriter.create<tensor::ExtractSliceOp>(
    #####:  108:        loc, fillTensor.getResult(0), offsets, sizes, strides);
call    0 never executed
        -:  109:
        -:  110:    // Clone the generic op.
    #####:  111:    auto clonedOp =
    #####:  112:        cast<linalg::GenericOp>(rewriter.clone(*linalgOp.getOperation()));
call    0 never executed
call    1 never executed
    #####:  113:    clonedOp.setDpsInitOperand(resultNumber, slice.getResult());
call    0 never executed
call    1 never executed
        -:  114:
        -:  115:    // Insert it back into the result of the fill.
    #####:  116:    rewriter.replaceOpWithNewOp<tensor::InsertSliceOp>(
    #####:  117:        padOp, clonedOp.getResult(resultNumber), fillTensor.getResult(0),
branch  0 never executed
branch  1 never executed
    #####:  118:        offsets, sizes, strides);
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  119:    return success();
branch  0 never executed
branch  1 never executed
        -:  120:  }
        -:  121:};
        -:  122:} // namespace
        -:  123:
function _ZN4mlir6linalg49populateFuseTensorPadWithProducerLinalgOpPatternsERNS_17RewritePatternSetE called 511 returned 100% blocks executed 100%
      511:  124:void mlir::linalg::populateFuseTensorPadWithProducerLinalgOpPatterns(
        -:  125:    RewritePatternSet &patterns) {
      511:  126:  patterns.add<FusePadOp>(patterns.getContext());
call    0 returned 100%
      511:  127:}
