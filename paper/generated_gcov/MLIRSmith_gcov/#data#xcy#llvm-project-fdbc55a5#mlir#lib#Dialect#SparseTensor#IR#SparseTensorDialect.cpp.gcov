        -:    0:Source:/data/xcy/llvm-project-fdbc55a5/mlir/lib/Dialect/SparseTensor/IR/SparseTensorDialect.cpp
        -:    0:Graph:../tools/mlir/lib/Dialect/SparseTensor/IR/CMakeFiles/obj.MLIRSparseTensorDialect.dir/SparseTensorDialect.cpp.gcno
        -:    0:Data:../tools/mlir/lib/Dialect/SparseTensor/IR/CMakeFiles/obj.MLIRSparseTensorDialect.dir/SparseTensorDialect.cpp.gcda
        -:    0:Runs:116161
        -:    1://===- SparseTensorDialect.cpp - Sparse tensor dialect implementation -----===//
        -:    2://
        -:    3:// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
        -:    4:// See https://llvm.org/LICENSE.txt for license information.
        -:    5:// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
        -:    6://
        -:    7://===----------------------------------------------------------------------===//
        -:    8:
        -:    9:#include "mlir/Dialect/SparseTensor/IR/SparseTensor.h"
        -:   10:
        -:   11:#include "mlir/Dialect/Arith/IR/Arith.h"
        -:   12:#include "mlir/IR/Builders.h"
        -:   13:#include "mlir/IR/DialectImplementation.h"
        -:   14:#include "mlir/IR/Matchers.h"
        -:   15:#include "mlir/IR/OpImplementation.h"
        -:   16:#include "llvm/ADT/TypeSwitch.h"
        -:   17:#include "llvm/Support/FormatVariadic.h"
        -:   18:
        -:   19:using namespace mlir;
        -:   20:using namespace mlir::sparse_tensor;
        -:   21:
        -:   22://===----------------------------------------------------------------------===//
        -:   23:// TensorDialect Attribute Methods.
        -:   24://===----------------------------------------------------------------------===//
        -:   25:
        -:   26:#define GET_ATTRDEF_CLASSES
        -:   27:#include "mlir/Dialect/SparseTensor/IR/SparseTensorAttrDefs.cpp.inc"
        -:   28:
    #####:   29:static bool acceptBitWidth(unsigned bitWidth) {
    #####:   30:  switch (bitWidth) {
        -:   31:  case 0:
        -:   32:  case 8:
        -:   33:  case 16:
        -:   34:  case 32:
        -:   35:  case 64:
        -:   36:    return true;
    #####:   37:  default:
    #####:   38:    return false;
        -:   39:  }
        -:   40:}
        -:   41:
function _ZN4mlir13sparse_tensor24SparseTensorEncodingAttr5parseERNS_9AsmParserENS_4TypeE called 0 returned 0% blocks executed 0%
    #####:   42:Attribute SparseTensorEncodingAttr::parse(AsmParser &parser, Type type) {
    #####:   43:  if (failed(parser.parseLess()))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:   44:    return {};
        -:   45:  // Parse the data as a dictionary.
    #####:   46:  DictionaryAttr dict;
    #####:   47:  if (failed(parser.parseAttribute(dict)))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:   48:    return {};
    #####:   49:  if (failed(parser.parseGreater()))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:   50:    return {};
        -:   51:  // Process the data from the parsed dictionary value into struct-like data.
    #####:   52:  SmallVector<DimLevelType, 4> dlt;
call    0 never executed
    #####:   53:  AffineMap dimOrd = {};
    #####:   54:  AffineMap higherOrd = {};
    #####:   55:  unsigned ptr = 0;
    #####:   56:  unsigned ind = 0;
    #####:   57:  for (const NamedAttribute &attr : dict) {
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:   58:    if (attr.getName() == "dimLevelType") {
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:   59:      auto arrayAttr = attr.getValue().dyn_cast<ArrayAttr>();
call    0 never executed
    #####:   60:      if (!arrayAttr) {
branch  0 never executed
branch  1 never executed
    #####:   61:        parser.emitError(parser.getNameLoc(),
call    0 never executed
call    1 never executed
call    2 never executed
    #####:   62:                         "expected an array for dimension level types");
call    0 never executed
    #####:   63:        return {};
        -:   64:      }
    #####:   65:      for (auto i : arrayAttr) {
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:   66:        auto strAttr = i.dyn_cast<StringAttr>();
call    0 never executed
    #####:   67:        if (!strAttr) {
branch  0 never executed
branch  1 never executed
    #####:   68:          parser.emitError(parser.getNameLoc(),
call    0 never executed
call    1 never executed
call    2 never executed
    #####:   69:                           "expected a string value in dimension level types");
call    0 never executed
    #####:   70:          return {};
        -:   71:        }
    #####:   72:        auto strVal = strAttr.getValue();
call    0 never executed
    #####:   73:        if (strVal == "dense") {
branch  0 never executed
branch  1 never executed
    #####:   74:          dlt.push_back(DimLevelType::Dense);
call    0 never executed
    #####:   75:        } else if (strVal == "compressed") {
branch  0 never executed
branch  1 never executed
    #####:   76:          dlt.push_back(DimLevelType::Compressed);
call    0 never executed
    #####:   77:        } else if (strVal == "compressed-nu") {
branch  0 never executed
branch  1 never executed
    #####:   78:          dlt.push_back(DimLevelType::CompressedNu);
call    0 never executed
    #####:   79:        } else if (strVal == "compressed-no") {
branch  0 never executed
branch  1 never executed
    #####:   80:          dlt.push_back(DimLevelType::CompressedNo);
call    0 never executed
    #####:   81:        } else if (strVal == "compressed-nu-no") {
branch  0 never executed
branch  1 never executed
    #####:   82:          dlt.push_back(DimLevelType::CompressedNuNo);
call    0 never executed
    #####:   83:        } else if (strVal == "singleton") {
branch  0 never executed
branch  1 never executed
    #####:   84:          dlt.push_back(DimLevelType::Singleton);
call    0 never executed
    #####:   85:        } else if (strVal == "singleton-nu") {
branch  0 never executed
branch  1 never executed
    #####:   86:          dlt.push_back(DimLevelType::SingletonNu);
call    0 never executed
    #####:   87:        } else if (strVal == "singleton-no") {
branch  0 never executed
branch  1 never executed
    #####:   88:          dlt.push_back(DimLevelType::SingletonNo);
call    0 never executed
    #####:   89:        } else if (strVal == "singleton-nu-no") {
branch  0 never executed
branch  1 never executed
    #####:   90:          dlt.push_back(DimLevelType::SingletonNuNo);
call    0 never executed
        -:   91:        } else {
    #####:   92:          parser.emitError(parser.getNameLoc(),
call    0 never executed
call    1 never executed
call    2 never executed
    #####:   93:                           "unexpected dimension level type: ")
call    0 never executed
    #####:   94:              << strVal;
call    0 never executed
    #####:   95:          return {};
        -:   96:        }
        -:   97:      }
    #####:   98:    } else if (attr.getName() == "dimOrdering") {
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:   99:      auto affineAttr = attr.getValue().dyn_cast<AffineMapAttr>();
call    0 never executed
    #####:  100:      if (!affineAttr) {
branch  0 never executed
branch  1 never executed
    #####:  101:        parser.emitError(parser.getNameLoc(),
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  102:                         "expected an affine map for dimension ordering");
call    0 never executed
    #####:  103:        return {};
        -:  104:      }
    #####:  105:      dimOrd = affineAttr.getValue();
call    0 never executed
    #####:  106:    } else if (attr.getName() == "higherOrdering") {
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  107:      auto affineAttr = attr.getValue().dyn_cast<AffineMapAttr>();
call    0 never executed
    #####:  108:      if (!affineAttr) {
branch  0 never executed
branch  1 never executed
    #####:  109:        parser.emitError(parser.getNameLoc(),
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  110:                         "expected an affine map for higher ordering");
call    0 never executed
    #####:  111:        return {};
        -:  112:      }
    #####:  113:      higherOrd = affineAttr.getValue();
call    0 never executed
    #####:  114:    } else if (attr.getName() == "pointerBitWidth") {
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  115:      auto intAttr = attr.getValue().dyn_cast<IntegerAttr>();
call    0 never executed
    #####:  116:      if (!intAttr) {
branch  0 never executed
branch  1 never executed
    #####:  117:        parser.emitError(parser.getNameLoc(),
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  118:                         "expected an integral pointer bitwidth");
call    0 never executed
    #####:  119:        return {};
        -:  120:      }
    #####:  121:      ptr = intAttr.getInt();
call    0 never executed
    #####:  122:    } else if (attr.getName() == "indexBitWidth") {
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  123:      auto intAttr = attr.getValue().dyn_cast<IntegerAttr>();
call    0 never executed
    #####:  124:      if (!intAttr) {
branch  0 never executed
branch  1 never executed
    #####:  125:        parser.emitError(parser.getNameLoc(),
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  126:                         "expected an integral index bitwidth");
call    0 never executed
    #####:  127:        return {};
        -:  128:      }
    #####:  129:      ind = intAttr.getInt();
call    0 never executed
        -:  130:    } else {
    #####:  131:      parser.emitError(parser.getNameLoc(), "unexpected key: ")
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  132:          << attr.getName().strref();
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:  133:      return {};
        -:  134:    }
        -:  135:  }
        -:  136:  // Construct struct-like storage for attribute.
    #####:  137:  return parser.getChecked<SparseTensorEncodingAttr>(
    #####:  138:      parser.getContext(), dlt, dimOrd, higherOrd, ptr, ind);
call    0 never executed
call    1 never executed
        -:  139:}
        -:  140:
function _ZNK4mlir13sparse_tensor24SparseTensorEncodingAttr5printERNS_10AsmPrinterE called 0 returned 0% blocks executed 0%
    #####:  141:void SparseTensorEncodingAttr::print(AsmPrinter &printer) const {
        -:  142:  // Print the struct-like storage in dictionary fashion.
    #####:  143:  printer << "<{ dimLevelType = [ ";
call    0 never executed
    #####:  144:  for (unsigned i = 0, e = getDimLevelType().size(); i < e; i++) {
branch  0 never executed
branch  1 never executed
    #####:  145:    switch (getDimLevelType()[i]) {
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
branch  6 never executed
branch  7 never executed
branch  8 never executed
branch  9 never executed
branch 10 never executed
branch 11 never executed
branch 12 never executed
    #####:  146:    case DimLevelType::Undef:
        -:  147:      // TODO: should probably raise an error instead of printing it...
    #####:  148:      printer << "\"undef\"";
call    0 never executed
        -:  149:      break;
    #####:  150:    case DimLevelType::Dense:
    #####:  151:      printer << "\"dense\"";
call    0 never executed
        -:  152:      break;
    #####:  153:    case DimLevelType::Compressed:
    #####:  154:      printer << "\"compressed\"";
call    0 never executed
        -:  155:      break;
    #####:  156:    case DimLevelType::CompressedNu:
    #####:  157:      printer << "\"compressed-nu\"";
call    0 never executed
        -:  158:      break;
    #####:  159:    case DimLevelType::CompressedNo:
    #####:  160:      printer << "\"compressed-no\"";
call    0 never executed
        -:  161:      break;
    #####:  162:    case DimLevelType::CompressedNuNo:
    #####:  163:      printer << "\"compressed-nu-no\"";
call    0 never executed
        -:  164:      break;
    #####:  165:    case DimLevelType::Singleton:
    #####:  166:      printer << "\"singleton\"";
call    0 never executed
        -:  167:      break;
    #####:  168:    case DimLevelType::SingletonNu:
    #####:  169:      printer << "\"singleton-nu\"";
call    0 never executed
        -:  170:      break;
    #####:  171:    case DimLevelType::SingletonNo:
    #####:  172:      printer << "\"singleton-no\"";
call    0 never executed
        -:  173:      break;
    #####:  174:    case DimLevelType::SingletonNuNo:
    #####:  175:      printer << "\"singleton-nu-no\"";
call    0 never executed
        -:  176:      break;
        -:  177:    }
    #####:  178:    if (i != e - 1)
branch  0 never executed
branch  1 never executed
    #####:  179:      printer << ", ";
call    0 never executed
        -:  180:  }
    #####:  181:  printer << " ]";
call    0 never executed
        -:  182:  // Print remaining members only for non-default values.
    #####:  183:  if (getDimOrdering() && !getDimOrdering().isIdentity())
branch  0 never executed
branch  1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
    #####:  184:    printer << ", dimOrdering = affine_map<" << getDimOrdering() << ">";
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  185:  if (getHigherOrdering())
branch  0 never executed
branch  1 never executed
    #####:  186:    printer << ", higherOrdering = affine_map<" << getHigherOrdering() << ">";
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  187:  if (getPointerBitWidth())
branch  0 never executed
branch  1 never executed
    #####:  188:    printer << ", pointerBitWidth = " << getPointerBitWidth();
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  189:  if (getIndexBitWidth())
branch  0 never executed
branch  1 never executed
    #####:  190:    printer << ", indexBitWidth = " << getIndexBitWidth();
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  191:  printer << " }>";
call    0 never executed
    #####:  192:}
        -:  193:
function _ZN4mlir13sparse_tensor24SparseTensorEncodingAttr6verifyEN4llvm12function_refIFNS_18InFlightDiagnosticEvEEENS2_8ArrayRefINS0_12DimLevelTypeEEENS_9AffineMapESA_jj called 0 returned 0% blocks executed 0%
    #####:  194:LogicalResult SparseTensorEncodingAttr::verify(
        -:  195:    function_ref<InFlightDiagnostic()> emitError,
        -:  196:    ArrayRef<DimLevelType> dimLevelType, AffineMap dimOrdering,
        -:  197:    AffineMap higherOrdering, unsigned pointerBitWidth,
        -:  198:    unsigned indexBitWidth) {
    #####:  199:  if (!acceptBitWidth(pointerBitWidth))
branch  0 never executed
branch  1 never executed
    #####:  200:    return emitError() << "unexpected pointer bitwidth: " << pointerBitWidth;
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
    #####:  201:  if (!acceptBitWidth(indexBitWidth))
branch  0 never executed
branch  1 never executed
    #####:  202:    return emitError() << "unexpected index bitwidth: " << indexBitWidth;
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
    #####:  203:  if (dimOrdering) {
branch  0 never executed
branch  1 never executed
    #####:  204:    if (!dimOrdering.isPermutation())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  205:      return emitError()
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  206:             << "expected a permutation affine map for dimension ordering";
call    0 never executed
    #####:  207:    if (dimOrdering.getNumResults() != dimLevelType.size())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  208:      return emitError() << "unexpected mismatch in ordering and dimension "
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  209:                            "level types size";
call    0 never executed
        -:  210:  }
    #####:  211:  if (higherOrdering) {
branch  0 never executed
branch  1 never executed
    #####:  212:    if (higherOrdering.getNumDims() >= higherOrdering.getNumResults())
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  213:      return emitError() << "unexpected higher ordering mapping from "
call    0 never executed
call    1 never executed
    #####:  214:                         << higherOrdering.getNumDims() << " to "
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  215:                         << higherOrdering.getNumResults();
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:  216:    if (higherOrdering.getNumResults() != dimLevelType.size())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  217:      return emitError() << "unexpected mismatch in higher ordering and "
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  218:                            "dimension level types size";
call    0 never executed
        -:  219:  }
    #####:  220:  return success();
        -:  221:}
        -:  222:
function _ZNK4mlir13sparse_tensor24SparseTensorEncodingAttr14verifyEncodingEN4llvm8ArrayRefIlEENS_4TypeENS2_12function_refIFNS_18InFlightDiagnosticEvEEE called 0 returned 0% blocks executed 0%
    #####:  223:LogicalResult SparseTensorEncodingAttr::verifyEncoding(
        -:  224:    ArrayRef<int64_t> shape, Type elementType,
        -:  225:    function_ref<InFlightDiagnostic()> emitError) const {
        -:  226:  // Check structural integrity.
    #####:  227:  if (failed(verify(emitError, getDimLevelType(), getDimOrdering(),
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  228:                    getHigherOrdering(), getPointerBitWidth(),
        -:  229:                    getIndexBitWidth())))
    #####:  230:    return failure();
        -:  231:  // Check integrity with tensor type specifics. Dimension ordering is optional,
        -:  232:  // but we always should have dimension level types for the full rank.
    #####:  233:  unsigned size = shape.size();
branch  0 never executed
branch  1 never executed
    #####:  234:  if (size == 0)
branch  0 never executed
branch  1 never executed
    #####:  235:    return emitError() << "expected non-scalar sparse tensor";
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:  236:  if (getHigherOrdering()) {
branch  0 never executed
branch  1 never executed
    #####:  237:    if (getHigherOrdering().getNumDims() != size)
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  238:      return emitError() << "expected an affine map of size " << size
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
    #####:  239:                         << " for higher ordering";
call    0 never executed
        -:  240:
        -:  241:    // TODO: verification of higher ordering contents
        -:  242:
    #####:  243:    size = getHigherOrdering().getNumResults(); // higher-order size!
call    0 never executed
        -:  244:  }
    #####:  245:  if (getDimOrdering() && getDimOrdering().getNumResults() != size)
branch  0 never executed
branch  1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
    #####:  246:    return emitError() << "expected an affine map of size " << size
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
    #####:  247:                       << " for dimension ordering";
call    0 never executed
    #####:  248:  if (getDimLevelType().size() != size)
branch  0 never executed
branch  1 never executed
    #####:  249:    return emitError() << "expected an array of size " << size
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
    #####:  250:                       << " for dimension level types";
call    0 never executed
    #####:  251:  return success();
        -:  252:}
        -:  253:
        -:  254://===----------------------------------------------------------------------===//
        -:  255:// Convenience Methods.
        -:  256://===----------------------------------------------------------------------===//
        -:  257:
        -:  258:SparseTensorEncodingAttr
function _ZN4mlir13sparse_tensor23getSparseTensorEncodingENS_4TypeE called 72500 returned 100% blocks executed 78%
    72500:  259:mlir::sparse_tensor::getSparseTensorEncoding(Type type) {
    72500:  260:  if (auto ttp = type.dyn_cast<RankedTensorType>())
call    0 returned 100%
branch  1 taken 86% (fallthrough)
branch  2 taken 14%
    62086:  261:    return ttp.getEncoding().dyn_cast_or_null<SparseTensorEncodingAttr>();
call    0 returned 100%
branch  1 taken 0% (fallthrough)
branch  2 taken 100%
    10414:  262:  return nullptr;
        -:  263:}
        -:  264:
function _ZN4mlir13sparse_tensor15isUniqueCOOTypeENS_16RankedTensorTypeE called 0 returned 0% blocks executed 0%
    #####:  265:bool mlir::sparse_tensor::isUniqueCOOType(RankedTensorType tp) {
    #####:  266:  SparseTensorEncodingAttr enc = getSparseTensorEncoding(tp);
call    0 never executed
        -:  267:
    #####:  268:  if (!enc)
branch  0 never executed
branch  1 never executed
        -:  269:    return false;
        -:  270:
    #####:  271:  if (!isCompressedDim(tp, 0))
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  272:    return false;
        -:  273:
    #####:  274:  for (uint64_t i = 1, e = tp.getRank(); i < e; ++i)
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  275:    if (!isSingletonDim(tp, i))
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  276:      return false;
        -:  277:
        -:  278:  // This works for rank == 1 (unique the only compressed) and rank > 1 (unique
        -:  279:  // on the last singleton).
    #####:  280:  return isUniqueDim(tp, tp.getRank() - 1);
call    0 never executed
call    1 never executed
        -:  281:}
        -:  282:
function _ZN4mlir13sparse_tensor9toOrigDimERKNS0_24SparseTensorEncodingAttrEm called 1874 returned 100% blocks executed 22%
     1874:  283:uint64_t mlir::sparse_tensor::toOrigDim(const SparseTensorEncodingAttr &enc,
        -:  284:                                        uint64_t d) {
     1874:  285:  if (enc) {
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
    #####:  286:    auto order = enc.getDimOrdering();
branch  0 never executed
branch  1 never executed
    #####:  287:    if (order) {
branch  0 never executed
branch  1 never executed
    #####:  288:      assert(order.isPermutation());
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
    #####:  289:      return order.getDimPosition(d);
call    0 never executed
        -:  290:    }
        -:  291:  }
        -:  292:  return d;
        -:  293:}
        -:  294:
function _ZN4mlir13sparse_tensor11toStoredDimERKNS0_24SparseTensorEncodingAttrEm called 0 returned 0% blocks executed 0%
    #####:  295:uint64_t mlir::sparse_tensor::toStoredDim(const SparseTensorEncodingAttr &enc,
        -:  296:                                          uint64_t d) {
    #####:  297:  if (enc) {
branch  0 never executed
branch  1 never executed
    #####:  298:    auto order = enc.getDimOrdering();
branch  0 never executed
branch  1 never executed
    #####:  299:    if (order) {
branch  0 never executed
branch  1 never executed
    #####:  300:      assert(order.isPermutation());
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
    #####:  301:      return order.getPermutedPosition(d);
call    0 never executed
        -:  302:    }
        -:  303:  }
        -:  304:  return d;
        -:  305:}
        -:  306:
function _ZN4mlir13sparse_tensor9toOrigDimENS_16RankedTensorTypeEm called 0 returned 0% blocks executed 0%
    #####:  307:uint64_t mlir::sparse_tensor::toOrigDim(RankedTensorType type, uint64_t d) {
    #####:  308:  assert(d < static_cast<uint64_t>(type.getRank()));
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
    #####:  309:  return toOrigDim(getSparseTensorEncoding(type), d);
call    0 never executed
call    1 never executed
        -:  310:}
        -:  311:
function _ZN4mlir13sparse_tensor11toStoredDimENS_16RankedTensorTypeEm called 0 returned 0% blocks executed 0%
    #####:  312:uint64_t mlir::sparse_tensor::toStoredDim(RankedTensorType type, uint64_t d) {
    #####:  313:  assert(d < static_cast<uint64_t>(type.getRank()));
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
    #####:  314:  return toStoredDim(getSparseTensorEncoding(type), d);
call    0 never executed
call    1 never executed
        -:  315:}
        -:  316:
        -:  317://===----------------------------------------------------------------------===//
        -:  318:// TensorDialect Operations.
        -:  319://===----------------------------------------------------------------------===//
        -:  320:
function _ZL10isInBoundsmN4mlir5ValueE called 0 returned 0% blocks executed 0%
    #####:  321:static LogicalResult isInBounds(uint64_t dim, Value tensor) {
    #####:  322:  uint64_t rank = tensor.getType().cast<RankedTensorType>().getRank();
call    0 never executed
call    1 never executed
    #####:  323:  if (dim >= rank)
branch  0 never executed
branch  1 never executed
    #####:  324:    return failure();
    #####:  325:  return success(); // in bounds
        -:  326:}
        -:  327:
function _ZL15isMatchingWidthN4mlir5ValueEj called 0 returned 0% blocks executed 0%
    #####:  328:static LogicalResult isMatchingWidth(Value result, unsigned width) {
    #####:  329:  Type etp = result.getType().cast<MemRefType>().getElementType();
call    0 never executed
call    1 never executed
    #####:  330:  if ((width == 0 && etp.isIndex()) || (width > 0 && etp.isInteger(width)))
branch  0 never executed
branch  1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
branch  6 never executed
call    7 never executed
branch  8 never executed
branch  9 never executed
    #####:  331:    return success();
    #####:  332:  return failure();
        -:  333:}
        -:  334:
function _ZN4mlir13sparse_tensor9ConvertOp6verifyEv called 0 returned 0% blocks executed 0%
    #####:  335:LogicalResult ConvertOp::verify() {
    #####:  336:  if (auto tp1 = getSource().getType().dyn_cast<RankedTensorType>()) {
call    0 never executed
call    1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
    #####:  337:    if (auto tp2 = getDest().getType().dyn_cast<RankedTensorType>()) {
call    0 never executed
call    1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
    #####:  338:      if (tp1.getRank() != tp2.getRank())
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  339:        return emitError("unexpected conversion mismatch in rank");
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:  340:      auto shape1 = tp1.getShape();
call    0 never executed
    #####:  341:      auto shape2 = tp2.getShape();
call    0 never executed
        -:  342:      // Accept size matches between the source and the destination type
        -:  343:      // (e.g. 10 vs. 10, 10 vs. ?, or ? vs. ?), but reject direct mismatches or
        -:  344:      // matches that would need a runtime assert (e.g. 10 vs. 20 or ? vs. 10).
    #####:  345:      for (unsigned d = 0, rank = tp1.getRank(); d < rank; d++)
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  346:        if (shape1[d] != shape2[d] && shape2[d] != ShapedType::kDynamicSize)
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
branch  6 never executed
branch  7 never executed
    #####:  347:          return emitError("unexpected conversion mismatch in dimension ") << d;
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
    #####:  348:      return success();
        -:  349:    }
        -:  350:  }
    #####:  351:  return emitError("unexpected type in convert");
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
        -:  352:}
        -:  353:
function _ZN4mlir13sparse_tensor9ConvertOp4foldEN4llvm8ArrayRefINS_9AttributeEEE called 0 returned 0% blocks executed 0%
    #####:  354:OpFoldResult ConvertOp::fold(ArrayRef<Attribute> operands) {
    #####:  355:  Type dstType = getType();
call    0 never executed
        -:  356:  // Fold trivial dense-to-dense convert and leave trivial sparse-to-sparse
        -:  357:  // convert for codegen to remove. This is because we use trivial
        -:  358:  // sparse-to-sparse convert to tell bufferization that the sparse codegen
        -:  359:  // will expand the tensor buffer into sparse tensor storage.
    #####:  360:  if (!getSparseTensorEncoding(dstType) && dstType == getSource().getType())
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
call    4 never executed
branch  5 never executed
branch  6 never executed
    #####:  361:    return getSource();
call    0 never executed
call    1 never executed
    #####:  362:  return {};
        -:  363:}
        -:  364:
function _ZN4mlir13sparse_tensor12ToPointersOp6verifyEv called 0 returned 0% blocks executed 0%
    #####:  365:LogicalResult ToPointersOp::verify() {
    #####:  366:  auto e = getSparseTensorEncoding(getTensor().getType());
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  367:  if (failed(isInBounds(getDimension().getZExtValue(), getTensor())))
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
branch  4 never executed
branch  5 never executed
branch  6 never executed
branch  7 never executed
    #####:  368:    return emitError("requested pointers dimension out of bounds");
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:  369:  if (failed(isMatchingWidth(getResult(), e.getPointerBitWidth())))
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  370:    return emitError("unexpected type for pointers");
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:  371:  return success();
        -:  372:}
        -:  373:
function _ZN4mlir13sparse_tensor11ToIndicesOp6verifyEv called 0 returned 0% blocks executed 0%
    #####:  374:LogicalResult ToIndicesOp::verify() {
    #####:  375:  auto e = getSparseTensorEncoding(getTensor().getType());
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  376:  if (failed(isInBounds(getDimension().getZExtValue(), getTensor())))
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
branch  4 never executed
branch  5 never executed
branch  6 never executed
branch  7 never executed
    #####:  377:    return emitError("requested indices dimension out of bounds");
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:  378:  if (failed(isMatchingWidth(getResult(), e.getIndexBitWidth())))
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  379:    return emitError("unexpected type for indices");
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:  380:  return success();
        -:  381:}
        -:  382:
function _ZN4mlir13sparse_tensor10ToValuesOp6verifyEv called 0 returned 0% blocks executed 0%
    #####:  383:LogicalResult ToValuesOp::verify() {
    #####:  384:  RankedTensorType ttp = getTensor().getType().cast<RankedTensorType>();
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  385:  MemRefType mtp = getResult().getType().cast<MemRefType>();
call    0 never executed
call    1 never executed
    #####:  386:  if (ttp.getElementType() != mtp.getElementType())
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  387:    return emitError("unexpected mismatch in element types");
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:  388:  return success();
        -:  389:}
        -:  390:
        -:  391://===----------------------------------------------------------------------===//
        -:  392:// TensorDialect Linalg.Generic Operations.
        -:  393://===----------------------------------------------------------------------===//
        -:  394:
        -:  395:template <class T>
    #####:  396:static LogicalResult verifyNumBlockArgs(T *op, Region &region,
        -:  397:                                        const char *regionName,
        -:  398:                                        TypeRange inputTypes, Type outputType) {
    #####:  399:  unsigned numArgs = region.getNumArguments();
    #####:  400:  unsigned expectedNum = inputTypes.size();
    #####:  401:  if (numArgs != expectedNum)
    #####:  402:    return op->emitError() << regionName << " region must have exactly "
    #####:  403:                           << expectedNum << " arguments";
        -:  404:
    #####:  405:  for (unsigned i = 0; i < numArgs; i++) {
    #####:  406:    Type typ = region.getArgument(i).getType();
    #####:  407:    if (typ != inputTypes[i])
    #####:  408:      return op->emitError() << regionName << " region argument " << (i + 1)
    #####:  409:                             << " type mismatch";
        -:  410:  }
    #####:  411:  Operation *term = region.front().getTerminator();
    #####:  412:  YieldOp yield = dyn_cast<YieldOp>(term);
    #####:  413:  if (!yield)
    #####:  414:    return op->emitError() << regionName
    #####:  415:                           << " region must end with sparse_tensor.yield";
    #####:  416:  if (!yield.getResult() || yield.getResult().getType() != outputType)
    #####:  417:    return op->emitError() << regionName << " region yield type mismatch";
        -:  418:
    #####:  419:  return success();
        -:  420:}
------------------
_Z18verifyNumBlockArgsIN4mlir13sparse_tensor8SelectOpEENS0_13LogicalResultEPT_RNS0_6RegionEPKcNS0_9TypeRangeENS0_4TypeE:
function _Z18verifyNumBlockArgsIN4mlir13sparse_tensor8SelectOpEENS0_13LogicalResultEPT_RNS0_6RegionEPKcNS0_9TypeRangeENS0_4TypeE called 0 returned 0% blocks executed 0%
    #####:  396:static LogicalResult verifyNumBlockArgs(T *op, Region &region,
call    0 never executed
        -:  397:                                        const char *regionName,
        -:  398:                                        TypeRange inputTypes, Type outputType) {
    #####:  399:  unsigned numArgs = region.getNumArguments();
    #####:  400:  unsigned expectedNum = inputTypes.size();
branch  0 never executed
branch  1 never executed
    #####:  401:  if (numArgs != expectedNum)
branch  0 never executed
branch  1 never executed
    #####:  402:    return op->emitError() << regionName << " region must have exactly "
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
call    5 never executed
    #####:  403:                           << expectedNum << " arguments";
call    0 never executed
call    1 never executed
        -:  404:
    #####:  405:  for (unsigned i = 0; i < numArgs; i++) {
branch  0 never executed
branch  1 never executed
    #####:  406:    Type typ = region.getArgument(i).getType();
call    0 never executed
call    1 never executed
    #####:  407:    if (typ != inputTypes[i])
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  408:      return op->emitError() << regionName << " region argument " << (i + 1)
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
call    5 never executed
call    6 never executed
    #####:  409:                             << " type mismatch";
call    0 never executed
        -:  410:  }
    #####:  411:  Operation *term = region.front().getTerminator();
call    0 never executed
    #####:  412:  YieldOp yield = dyn_cast<YieldOp>(term);
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  413:  if (!yield)
branch  0 never executed
branch  1 never executed
    #####:  414:    return op->emitError() << regionName
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
    #####:  415:                           << " region must end with sparse_tensor.yield";
call    0 never executed
    #####:  416:  if (!yield.getResult() || yield.getResult().getType() != outputType)
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
branch  4 never executed
branch  5 never executed
    #####:  417:    return op->emitError() << regionName << " region yield type mismatch";
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
call    5 never executed
        -:  418:
    #####:  419:  return success();
        -:  420:}
------------------
_Z18verifyNumBlockArgsIN4mlir13sparse_tensor8ReduceOpEENS0_13LogicalResultEPT_RNS0_6RegionEPKcNS0_9TypeRangeENS0_4TypeE:
function _Z18verifyNumBlockArgsIN4mlir13sparse_tensor8ReduceOpEENS0_13LogicalResultEPT_RNS0_6RegionEPKcNS0_9TypeRangeENS0_4TypeE called 0 returned 0% blocks executed 0%
    #####:  396:static LogicalResult verifyNumBlockArgs(T *op, Region &region,
call    0 never executed
        -:  397:                                        const char *regionName,
        -:  398:                                        TypeRange inputTypes, Type outputType) {
    #####:  399:  unsigned numArgs = region.getNumArguments();
    #####:  400:  unsigned expectedNum = inputTypes.size();
branch  0 never executed
branch  1 never executed
    #####:  401:  if (numArgs != expectedNum)
branch  0 never executed
branch  1 never executed
    #####:  402:    return op->emitError() << regionName << " region must have exactly "
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
call    5 never executed
    #####:  403:                           << expectedNum << " arguments";
call    0 never executed
call    1 never executed
        -:  404:
    #####:  405:  for (unsigned i = 0; i < numArgs; i++) {
branch  0 never executed
branch  1 never executed
    #####:  406:    Type typ = region.getArgument(i).getType();
call    0 never executed
call    1 never executed
    #####:  407:    if (typ != inputTypes[i])
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  408:      return op->emitError() << regionName << " region argument " << (i + 1)
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
call    5 never executed
call    6 never executed
    #####:  409:                             << " type mismatch";
call    0 never executed
        -:  410:  }
    #####:  411:  Operation *term = region.front().getTerminator();
call    0 never executed
    #####:  412:  YieldOp yield = dyn_cast<YieldOp>(term);
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  413:  if (!yield)
branch  0 never executed
branch  1 never executed
    #####:  414:    return op->emitError() << regionName
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
    #####:  415:                           << " region must end with sparse_tensor.yield";
call    0 never executed
    #####:  416:  if (!yield.getResult() || yield.getResult().getType() != outputType)
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
branch  4 never executed
branch  5 never executed
    #####:  417:    return op->emitError() << regionName << " region yield type mismatch";
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
call    5 never executed
        -:  418:
    #####:  419:  return success();
        -:  420:}
------------------
_Z18verifyNumBlockArgsIN4mlir13sparse_tensor7UnaryOpEENS0_13LogicalResultEPT_RNS0_6RegionEPKcNS0_9TypeRangeENS0_4TypeE:
function _Z18verifyNumBlockArgsIN4mlir13sparse_tensor7UnaryOpEENS0_13LogicalResultEPT_RNS0_6RegionEPKcNS0_9TypeRangeENS0_4TypeE called 0 returned 0% blocks executed 0%
    #####:  396:static LogicalResult verifyNumBlockArgs(T *op, Region &region,
call    0 never executed
        -:  397:                                        const char *regionName,
        -:  398:                                        TypeRange inputTypes, Type outputType) {
    #####:  399:  unsigned numArgs = region.getNumArguments();
    #####:  400:  unsigned expectedNum = inputTypes.size();
branch  0 never executed
branch  1 never executed
    #####:  401:  if (numArgs != expectedNum)
branch  0 never executed
branch  1 never executed
    #####:  402:    return op->emitError() << regionName << " region must have exactly "
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
call    5 never executed
    #####:  403:                           << expectedNum << " arguments";
call    0 never executed
call    1 never executed
        -:  404:
    #####:  405:  for (unsigned i = 0; i < numArgs; i++) {
branch  0 never executed
branch  1 never executed
    #####:  406:    Type typ = region.getArgument(i).getType();
call    0 never executed
call    1 never executed
    #####:  407:    if (typ != inputTypes[i])
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  408:      return op->emitError() << regionName << " region argument " << (i + 1)
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
call    5 never executed
call    6 never executed
    #####:  409:                             << " type mismatch";
call    0 never executed
        -:  410:  }
    #####:  411:  Operation *term = region.front().getTerminator();
call    0 never executed
    #####:  412:  YieldOp yield = dyn_cast<YieldOp>(term);
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  413:  if (!yield)
branch  0 never executed
branch  1 never executed
    #####:  414:    return op->emitError() << regionName
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
    #####:  415:                           << " region must end with sparse_tensor.yield";
call    0 never executed
    #####:  416:  if (!yield.getResult() || yield.getResult().getType() != outputType)
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
branch  4 never executed
branch  5 never executed
    #####:  417:    return op->emitError() << regionName << " region yield type mismatch";
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
call    5 never executed
        -:  418:
    #####:  419:  return success();
        -:  420:}
------------------
_Z18verifyNumBlockArgsIN4mlir13sparse_tensor8BinaryOpEENS0_13LogicalResultEPT_RNS0_6RegionEPKcNS0_9TypeRangeENS0_4TypeE:
function _Z18verifyNumBlockArgsIN4mlir13sparse_tensor8BinaryOpEENS0_13LogicalResultEPT_RNS0_6RegionEPKcNS0_9TypeRangeENS0_4TypeE called 0 returned 0% blocks executed 0%
    #####:  396:static LogicalResult verifyNumBlockArgs(T *op, Region &region,
call    0 never executed
        -:  397:                                        const char *regionName,
        -:  398:                                        TypeRange inputTypes, Type outputType) {
    #####:  399:  unsigned numArgs = region.getNumArguments();
    #####:  400:  unsigned expectedNum = inputTypes.size();
branch  0 never executed
branch  1 never executed
    #####:  401:  if (numArgs != expectedNum)
branch  0 never executed
branch  1 never executed
    #####:  402:    return op->emitError() << regionName << " region must have exactly "
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
call    5 never executed
    #####:  403:                           << expectedNum << " arguments";
call    0 never executed
call    1 never executed
        -:  404:
    #####:  405:  for (unsigned i = 0; i < numArgs; i++) {
branch  0 never executed
branch  1 never executed
    #####:  406:    Type typ = region.getArgument(i).getType();
call    0 never executed
call    1 never executed
    #####:  407:    if (typ != inputTypes[i])
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  408:      return op->emitError() << regionName << " region argument " << (i + 1)
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
call    5 never executed
call    6 never executed
    #####:  409:                             << " type mismatch";
call    0 never executed
        -:  410:  }
    #####:  411:  Operation *term = region.front().getTerminator();
call    0 never executed
    #####:  412:  YieldOp yield = dyn_cast<YieldOp>(term);
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  413:  if (!yield)
branch  0 never executed
branch  1 never executed
    #####:  414:    return op->emitError() << regionName
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
    #####:  415:                           << " region must end with sparse_tensor.yield";
call    0 never executed
    #####:  416:  if (!yield.getResult() || yield.getResult().getType() != outputType)
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
branch  4 never executed
branch  5 never executed
    #####:  417:    return op->emitError() << regionName << " region yield type mismatch";
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
call    5 never executed
        -:  418:
    #####:  419:  return success();
        -:  420:}
------------------
        -:  421:
function _ZN4mlir13sparse_tensor8BinaryOp6verifyEv called 0 returned 0% blocks executed 0%
    #####:  422:LogicalResult BinaryOp::verify() {
    #####:  423:  NamedAttrList attrs = (*this)->getAttrs();
call    0 never executed
call    1 never executed
    #####:  424:  Type leftType = getX().getType();
call    0 never executed
call    1 never executed
    #####:  425:  Type rightType = getY().getType();
call    0 never executed
call    1 never executed
    #####:  426:  Type outputType = getOutput().getType();
call    0 never executed
call    1 never executed
    #####:  427:  Region &overlap = getOverlapRegion();
call    0 never executed
    #####:  428:  Region &left = getLeftRegion();
call    0 never executed
    #####:  429:  Region &right = getRightRegion();
call    0 never executed
        -:  430:
        -:  431:  // Check correct number of block arguments and return type for each
        -:  432:  // non-empty region.
    #####:  433:  LogicalResult regionResult = success();
branch  0 never executed
branch  1 never executed
    #####:  434:  if (!overlap.empty()) {
branch  0 never executed
branch  1 never executed
    #####:  435:    regionResult = verifyNumBlockArgs(
    #####:  436:        this, overlap, "overlap", TypeRange{leftType, rightType}, outputType);
call    0 never executed
call    1 never executed
    #####:  437:    if (failed(regionResult))
branch  0 never executed
branch  1 never executed
    #####:  438:      return regionResult;
        -:  439:  }
    #####:  440:  if (!left.empty()) {
branch  0 never executed
branch  1 never executed
    #####:  441:    regionResult =
    #####:  442:        verifyNumBlockArgs(this, left, "left", TypeRange{leftType}, outputType);
call    0 never executed
call    1 never executed
    #####:  443:    if (failed(regionResult))
branch  0 never executed
branch  1 never executed
    #####:  444:      return regionResult;
    #####:  445:  } else if (getLeftIdentity()) {
call    0 never executed
    #####:  446:    if (leftType != outputType)
branch  0 never executed
branch  1 never executed
    #####:  447:      return emitError("left=identity requires first argument to have the same "
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  448:                       "type as the output");
call    0 never executed
        -:  449:  }
    #####:  450:  if (!right.empty()) {
branch  0 never executed
branch  1 never executed
    #####:  451:    regionResult = verifyNumBlockArgs(this, right, "right",
    #####:  452:                                      TypeRange{rightType}, outputType);
call    0 never executed
call    1 never executed
    #####:  453:    if (failed(regionResult))
branch  0 never executed
branch  1 never executed
    #####:  454:      return regionResult;
    #####:  455:  } else if (getRightIdentity()) {
call    0 never executed
    #####:  456:    if (rightType != outputType)
branch  0 never executed
branch  1 never executed
    #####:  457:      return emitError("right=identity requires second argument to have the "
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  458:                       "same type as the output");
call    0 never executed
        -:  459:  }
        -:  460:
    #####:  461:  return success();
branch  0 never executed
branch  1 never executed
        -:  462:}
        -:  463:
function _ZN4mlir13sparse_tensor7UnaryOp6verifyEv called 0 returned 0% blocks executed 0%
    #####:  464:LogicalResult UnaryOp::verify() {
    #####:  465:  Type inputType = getX().getType();
call    0 never executed
call    1 never executed
    #####:  466:  Type outputType = getOutput().getType();
call    0 never executed
call    1 never executed
    #####:  467:  LogicalResult regionResult = success();
call    0 never executed
        -:  468:
        -:  469:  // Check correct number of block arguments and return type for each
        -:  470:  // non-empty region.
    #####:  471:  Region &present = getPresentRegion();
call    0 never executed
    #####:  472:  if (!present.empty()) {
branch  0 never executed
branch  1 never executed
    #####:  473:    regionResult = verifyNumBlockArgs(this, present, "present",
    #####:  474:                                      TypeRange{inputType}, outputType);
call    0 never executed
call    1 never executed
    #####:  475:    if (failed(regionResult))
branch  0 never executed
branch  1 never executed
    #####:  476:      return regionResult;
        -:  477:  }
    #####:  478:  Region &absent = getAbsentRegion();
call    0 never executed
    #####:  479:  if (!absent.empty()) {
branch  0 never executed
branch  1 never executed
    #####:  480:    regionResult =
call    0 never executed
    #####:  481:        verifyNumBlockArgs(this, absent, "absent", TypeRange{}, outputType);
call    0 never executed
call    1 never executed
    #####:  482:    if (failed(regionResult))
branch  0 never executed
branch  1 never executed
    #####:  483:      return regionResult;
        -:  484:  }
        -:  485:
    #####:  486:  return success();
        -:  487:}
        -:  488:
function _ZN4mlir13sparse_tensor13ConcatenateOp6verifyEv called 0 returned 0% blocks executed 0%
    #####:  489:LogicalResult ConcatenateOp::verify() {
    #####:  490:  auto dstTp = getType().cast<RankedTensorType>();
call    0 never executed
call    1 never executed
    #####:  491:  uint64_t concatDim = getDimension().getZExtValue();
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  492:  unsigned rank = dstTp.getRank();
call    0 never executed
        -:  493:
    #####:  494:  if (getInputs().size() <= 1)
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  495:    return emitError("Need at least two tensors to concatenate.");
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
        -:  496:
    #####:  497:  for (auto type : getInputs().getTypes()) {
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
call    4 never executed
    #####:  498:    auto shape = type.cast<RankedTensorType>().getShape();
call    0 never executed
call    1 never executed
    #####:  499:    for (auto dim : shape) {
branch  0 never executed
branch  1 never executed
    #####:  500:      if (dim == ShapedType::kDynamicSize)
branch  0 never executed
branch  1 never executed
    #####:  501:        return emitError("Only statically-sized input tensors are supported.");
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
        -:  502:    }
        -:  503:  }
        -:  504:
    #####:  505:  if (concatDim >= rank)
branch  0 never executed
branch  1 never executed
    #####:  506:    return emitError(llvm::formatv(
call    0 never executed
call    1 never executed
call    2 never executed
        -:  507:        "Failed to concatentate tensors with rank={0} on dimension={1}.", rank,
    #####:  508:        concatDim));
call    0 never executed
        -:  509:
    #####:  510:  for (size_t i = 0, e = getInputs().size(); i < e; i++) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  511:    Value input = getInputs()[i];
call    0 never executed
call    1 never executed
    #####:  512:    auto inputRank = input.getType().cast<RankedTensorType>().getRank();
call    0 never executed
call    1 never executed
    #####:  513:    if (inputRank != rank)
branch  0 never executed
branch  1 never executed
    #####:  514:      return emitError(
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  515:          llvm::formatv("The input tensor ${0} has a different rank (rank={1}) "
call    0 never executed
        -:  516:                        "from the output tensor (rank={2}).",
    #####:  517:                        i, inputRank, rank));
call    0 never executed
        -:  518:  }
        -:  519:
    #####:  520:  for (unsigned i = 0; i < rank; i++) {
branch  0 never executed
branch  1 never executed
    #####:  521:    auto dstDim = dstTp.getShape()[i];
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  522:    if (i == concatDim) {
branch  0 never executed
branch  1 never executed
    #####:  523:      if (dstDim != ShapedType::kDynamicSize) {
branch  0 never executed
branch  1 never executed
    #####:  524:        unsigned sumDim = 0;
    #####:  525:        for (auto src : getInputs()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
        -:  526:          // If we reach here, all inputs should have static shapes.
    #####:  527:          auto d = src.getType().cast<RankedTensorType>().getShape()[i];
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  528:          sumDim += d;
        -:  529:        }
        -:  530:        // If all dimension are statically known, the sum of all the input
        -:  531:        // dimensions should be equal to the output dimension.
    #####:  532:        if (sumDim != dstDim)
branch  0 never executed
branch  1 never executed
    #####:  533:          return emitError(
call    0 never executed
call    1 never executed
call    2 never executed
        -:  534:              "The concatenation dimension of the output tensor should be the "
    #####:  535:              "sum of all the concatenation dimensions of the input tensors.");
call    0 never executed
        -:  536:      }
        -:  537:    } else {
    #####:  538:      int64_t prev = dstDim;
    #####:  539:      for (auto src : getInputs()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
    #####:  540:        auto d = src.getType().cast<RankedTensorType>().getShape()[i];
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  541:        if (prev != ShapedType::kDynamicSize && d != prev)
branch  0 never executed
branch  1 never executed
    #####:  542:          return emitError("All dimensions (expect for the concatenating one) "
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  543:                           "should be equal.");
call    0 never executed
    #####:  544:        prev = d;
        -:  545:      }
        -:  546:    }
        -:  547:  }
        -:  548:
    #####:  549:  return success();
        -:  550:}
        -:  551:
function _ZN4mlir13sparse_tensor8InsertOp6verifyEv called 0 returned 0% blocks executed 0%
    #####:  552:LogicalResult InsertOp::verify() {
    #####:  553:  RankedTensorType ttp = getTensor().getType().cast<RankedTensorType>();
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  554:  if (ttp.getRank() != static_cast<int64_t>(getIndices().size()))
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  555:    return emitOpError("incorrect number of indices");
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:  556:  return success();
        -:  557:}
        -:  558:
function _ZN4mlir13sparse_tensor10PushBackOp5buildERNS_9OpBuilderERNS_14OperationStateENS_4TypeENS_5ValueES7_S7_N4llvm5APIntE called 0 returned 0% blocks executed 0%
    #####:  559:void PushBackOp::build(OpBuilder &builder, OperationState &result,
        -:  560:                       Type outBuffer, Value bufferSizes, Value inBuffer,
        -:  561:                       Value value, APInt idx) {
    #####:  562:  build(builder, result, outBuffer, bufferSizes, inBuffer, value, idx, Value());
branch  0 never executed
branch  1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
    #####:  563:}
        -:  564:
function _ZN4mlir13sparse_tensor10PushBackOp6verifyEv called 0 returned 0% blocks executed 0%
    #####:  565:LogicalResult PushBackOp::verify() {
    #####:  566:  Value n = getN();
call    0 never executed
    #####:  567:  if (n) {
branch  0 never executed
branch  1 never executed
    #####:  568:    auto nValue = dyn_cast_or_null<arith::ConstantIndexOp>(n.getDefiningOp());
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  569:    if (nValue && nValue.value() < 1)
branch  0 never executed
branch  1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
    #####:  570:      return emitOpError("n must be not less than 1");
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
        -:  571:  }
    #####:  572:  return success();
        -:  573:}
        -:  574:
function _ZN4mlir13sparse_tensor10CompressOp6verifyEv called 0 returned 0% blocks executed 0%
    #####:  575:LogicalResult CompressOp::verify() {
    #####:  576:  RankedTensorType ttp = getTensor().getType().cast<RankedTensorType>();
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  577:  if (ttp.getRank() != 1 + static_cast<int64_t>(getIndices().size()))
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  578:    return emitOpError("incorrect number of indices");
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:  579:  return success();
        -:  580:}
        -:  581:
function _ZN4mlir13sparse_tensor9ForeachOp5buildERNS_9OpBuilderERNS_14OperationStateENS_5ValueEN4llvm12function_refIFvS3_NS_8LocationENS_10ValueRangeEEEE called 0 returned 0% blocks executed 0%
    #####:  582:void ForeachOp::build(
        -:  583:    OpBuilder &builder, OperationState &result, Value tensor,
        -:  584:    function_ref<void(OpBuilder &, Location, ValueRange)> bodyBuilder) {
    #####:  585:  build(builder, result, tensor);
call    0 never executed
    #####:  586:  if (!bodyBuilder)
branch  0 never executed
branch  1 never executed
    #####:  587:    return;
        -:  588:
    #####:  589:  auto rtp = tensor.getType().cast<RankedTensorType>();
call    0 never executed
    #####:  590:  int64_t rank = rtp.getRank();
call    0 never executed
        -:  591:
    #####:  592:  SmallVector<Type, 4> blockArgTypes;
call    0 never executed
        -:  593:  // Starts with n index.
    #####:  594:  std::fill_n(std::back_inserter(blockArgTypes), rank, builder.getIndexType());
call    0 never executed
        -:  595:  // Followed by one value.
    #####:  596:  blockArgTypes.push_back(rtp.getElementType());
call    0 never executed
call    1 never executed
        -:  597:
    #####:  598:  SmallVector<Location, 4> blockArgLocs;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  599:  std::fill_n(std::back_inserter(blockArgLocs), rank + 1, tensor.getLoc());
call    0 never executed
        -:  600:
    #####:  601:  OpBuilder::InsertionGuard guard(builder);
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####:  602:  auto &region = *result.regions.front();
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  603:  Block *bodyBlock =
call    0 never executed
    #####:  604:      builder.createBlock(&region, region.end(), blockArgTypes, blockArgLocs);
call    0 never executed
call    1 never executed
    #####:  605:  bodyBuilder(builder, result.location, bodyBlock->getArguments());
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
        -:  606:}
        -:  607:
function _ZN4mlir13sparse_tensor9ForeachOp6verifyEv called 0 returned 0% blocks executed 0%
    #####:  608:LogicalResult ForeachOp::verify() {
    #####:  609:  auto t = getTensor().getType().cast<RankedTensorType>();
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  610:  auto args = getBody()->getArguments();
call    0 never executed
call    1 never executed
        -:  611:
    #####:  612:  if (static_cast<size_t>(t.getRank()) + 1 != args.size())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  613:    return emitError("Unmatched number of arguments in the block");
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
        -:  614:
    #####:  615:  for (int64_t i = 0, e = t.getRank(); i < e; i++)
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  616:    if (args[i].getType() != IndexType::get(getContext()))
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
    #####:  617:      emitError(
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  618:          llvm::formatv("Expecting Index type for argument at index {0}", i));
call    0 never executed
        -:  619:
    #####:  620:  auto elemTp = t.getElementType();
call    0 never executed
    #####:  621:  auto valueTp = args.back().getType();
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  622:  if (elemTp != valueTp)
branch  0 never executed
branch  1 never executed
    #####:  623:    emitError(llvm::formatv("Unmatched element type between input tensor and "
call    0 never executed
call    1 never executed
call    2 never executed
        -:  624:                            "block argument, expected:{0}, got: {1}",
        -:  625:                            elemTp, valueTp));
    #####:  626:  return success();
        -:  627:}
        -:  628:
function _ZN4mlir13sparse_tensor8ReduceOp6verifyEv called 0 returned 0% blocks executed 0%
    #####:  629:LogicalResult ReduceOp::verify() {
    #####:  630:  Type inputType = getX().getType();
call    0 never executed
call    1 never executed
    #####:  631:  LogicalResult regionResult = success();
call    0 never executed
        -:  632:
        -:  633:  // Check correct number of block arguments and return type.
    #####:  634:  Region &formula = getRegion();
call    0 never executed
    #####:  635:  regionResult = verifyNumBlockArgs(this, formula, "reduce",
    #####:  636:                                    TypeRange{inputType, inputType}, inputType);
call    0 never executed
call    1 never executed
    #####:  637:  if (failed(regionResult))
branch  0 never executed
branch  1 never executed
    #####:  638:    return regionResult;
        -:  639:
    #####:  640:  return success();
        -:  641:}
        -:  642:
function _ZN4mlir13sparse_tensor8SelectOp6verifyEv called 0 returned 0% blocks executed 0%
    #####:  643:LogicalResult SelectOp::verify() {
    #####:  644:  Builder b(getContext());
call    0 never executed
call    1 never executed
        -:  645:
    #####:  646:  Type inputType = getX().getType();
call    0 never executed
call    1 never executed
    #####:  647:  Type boolType = b.getI1Type();
call    0 never executed
    #####:  648:  LogicalResult regionResult = success();
call    0 never executed
        -:  649:
        -:  650:  // Check correct number of block arguments and return type.
    #####:  651:  Region &formula = getRegion();
call    0 never executed
    #####:  652:  regionResult = verifyNumBlockArgs(this, formula, "select",
    #####:  653:                                    TypeRange{inputType}, boolType);
call    0 never executed
call    1 never executed
    #####:  654:  if (failed(regionResult))
branch  0 never executed
branch  1 never executed
    #####:  655:    return regionResult;
        -:  656:
    #####:  657:  return success();
        -:  658:}
        -:  659:
function _ZN4mlir13sparse_tensor6SortOp6verifyEv called 0 returned 0% blocks executed 0%
    #####:  660:LogicalResult SortOp::verify() {
    #####:  661:  if (getXs().empty())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  662:    return emitError("need at least one xs buffer.");
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
        -:  663:
    #####:  664:  auto n = getN().getDefiningOp<arith::ConstantIndexOp>();
call    0 never executed
call    1 never executed
        -:  665:
    #####:  666:  Type xtp = getXs().front().getType().cast<MemRefType>().getElementType();
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
call    4 never executed
function _ZZN4mlir13sparse_tensor6SortOp6verifyEvENKUlNS_10ValueRangeEbE_clES2_b called 0 returned 0% blocks executed 0%
    #####:  667:  auto checkTypes = [&](ValueRange operands,
        -:  668:                        bool checkEleType = true) -> LogicalResult {
    #####:  669:    for (Value opnd : operands) {
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  670:      MemRefType mtp = opnd.getType().cast<MemRefType>();
call    0 never executed
    #####:  671:      int64_t dim = mtp.getShape()[0];
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  672:      // We can't check the size of dynamic dimension at compile-time, but all
        -:  673:      // xs and ys should have a dimension not less than n at runtime.
    #####:  674:      if (n && dim != ShapedType::kDynamicSize && dim < n.value())
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
call    4 never executed
branch  5 never executed
branch  6 never executed
    #####:  675:        return emitError(llvm::formatv("xs and ys need to have a dimension >= n"
call    0 never executed
call    1 never executed
call    2 never executed
        -:  676:                                       ": {0} < {1}",
    #####:  677:                                       dim, n.value()));
call    0 never executed
call    1 never executed
        -:  678:
    #####:  679:      if (checkEleType && xtp != mtp.getElementType())
branch  0 never executed
branch  1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
    #####:  680:        return emitError("mismatch xs element types");
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
        -:  681:    }
    #####:  682:    return success();
    #####:  683:  };
        -:  684:
    #####:  685:  LogicalResult result = checkTypes(getXs());
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  686:  if (failed(result))
branch  0 never executed
branch  1 never executed
    #####:  687:    return result;
        -:  688:
    #####:  689:  if (n)
branch  0 never executed
branch  1 never executed
    #####:  690:    return checkTypes(getYs(), false);
call    0 never executed
call    1 never executed
call    2 never executed
        -:  691:
    #####:  692:  return success();
        -:  693:}
        -:  694:
function _ZN4mlir13sparse_tensor7YieldOp6verifyEv called 0 returned 0% blocks executed 0%
    #####:  695:LogicalResult YieldOp::verify() {
        -:  696:  // Check for compatible parent.
    #####:  697:  auto *parentOp = (*this)->getParentOp();
branch  0 never executed
branch  1 never executed
    #####:  698:  if (isa<BinaryOp>(parentOp) || isa<UnaryOp>(parentOp) ||
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
    #####:  699:      isa<ReduceOp>(parentOp) || isa<SelectOp>(parentOp) ||
branch  0 never executed
branch  1 never executed
call    2 never executed
call    3 never executed
branch  4 never executed
branch  5 never executed
branch  6 never executed
branch  7 never executed
    #####:  700:      isa<ForeachOp>(parentOp))
call    0 never executed
    #####:  701:    return success();
        -:  702:
    #####:  703:  return emitOpError("expected parent op to be sparse_tensor unary, binary, "
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  704:                     "reduce, select or foreach");
call    0 never executed
        -:  705:}
        -:  706:
        -:  707://===----------------------------------------------------------------------===//
        -:  708:// TensorDialect Methods.
        -:  709://===----------------------------------------------------------------------===//
        -:  710:
function _ZN4mlir13sparse_tensor19SparseTensorDialect10initializeEv called 0 returned 0% blocks executed 0%
    2434*:  711:void SparseTensorDialect::initialize() {
    2434*:  712:  addAttributes<
        -:  713:#define GET_ATTRDEF_LIST
        -:  714:#include "mlir/Dialect/SparseTensor/IR/SparseTensorAttrDefs.cpp.inc"
    2434*:  715:      >();
call    0 returned 100%
call    1 never executed
    2434*:  716:  addOperations<
        -:  717:#define GET_OP_LIST
        -:  718:#include "mlir/Dialect/SparseTensor/IR/SparseTensorOps.cpp.inc"
    2434*:  719:      >();
call    0 returned 100%
call    1 never executed
    #####:  720:}
        -:  721:
        -:  722:#define GET_OP_CLASSES
        -:  723:#include "mlir/Dialect/SparseTensor/IR/SparseTensorOps.cpp.inc"
        -:  724:
        -:  725:#include "mlir/Dialect/SparseTensor/IR/SparseTensorOpsDialect.cpp.inc"
