        -:    0:Source:/data/xcy/llvm-project-fdbc55a5/mlir/lib/Conversion/ShapeToStandard/ShapeToStandard.cpp
        -:    0:Graph:../tools/mlir/lib/Conversion/ShapeToStandard/CMakeFiles/obj.MLIRShapeToStandard.dir/ShapeToStandard.cpp.gcno
        -:    0:Data:../tools/mlir/lib/Conversion/ShapeToStandard/CMakeFiles/obj.MLIRShapeToStandard.dir/ShapeToStandard.cpp.gcda
        -:    0:Runs:116161
        -:    1://===- ShapeToStandard.cpp - conversion from Shape to Standard dialect ----===//
        -:    2://
        -:    3:// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
        -:    4:// See https://llvm.org/LICENSE.txt for license information.
        -:    5:// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
        -:    6://
        -:    7://===----------------------------------------------------------------------===//
        -:    8:
        -:    9:#include "mlir/Conversion/ShapeToStandard/ShapeToStandard.h"
        -:   10:
        -:   11:#include "mlir/Dialect/Arith/IR/Arith.h"
        -:   12:#include "mlir/Dialect/Func/IR/FuncOps.h"
        -:   13:#include "mlir/Dialect/SCF/IR/SCF.h"
        -:   14:#include "mlir/Dialect/Shape/IR/Shape.h"
        -:   15:#include "mlir/Dialect/Tensor/IR/Tensor.h"
        -:   16:#include "mlir/IR/BlockAndValueMapping.h"
        -:   17:#include "mlir/IR/ImplicitLocOpBuilder.h"
        -:   18:#include "mlir/Pass/Pass.h"
        -:   19:#include "mlir/Transforms/DialectConversion.h"
        -:   20:#include "llvm/ADT/STLExtras.h"
        -:   21:
        -:   22:namespace mlir {
        -:   23:#define GEN_PASS_DEF_CONVERTSHAPETOSTANDARD
        -:   24:#include "mlir/Conversion/Passes.h.inc"
        -:   25:} // namespace mlir
        -:   26:
        -:   27:using namespace mlir;
        -:   28:using namespace mlir::shape;
        -:   29:using namespace mlir::scf;
        -:   30:
        -:   31:/// Conversion patterns.
        -:   32:namespace {
        -:   33:class AnyOpConversion : public OpConversionPattern<AnyOp> {
        -:   34:public:
        -:   35:  using OpConversionPattern<AnyOp>::OpConversionPattern;
        -:   36:
        -:   37:  LogicalResult
        -:   38:  matchAndRewrite(AnyOp op, OpAdaptor adaptor,
        -:   39:                  ConversionPatternRewriter &rewriter) const override;
        -:   40:};
        -:   41:} // namespace
        -:   42:
        -:   43:LogicalResult
function _ZNK12_GLOBAL__N_115AnyOpConversion15matchAndRewriteEN4mlir5shape5AnyOpENS2_12AnyOpAdaptorERNS1_25ConversionPatternRewriterE called 0 returned 0% blocks executed 0%
    #####:   44:AnyOpConversion::matchAndRewrite(AnyOp op, OpAdaptor adaptor,
        -:   45:                                 ConversionPatternRewriter &rewriter) const {
        -:   46:  // Replace `any` with its first operand.
        -:   47:  // Any operand would be a valid substitution.
    #####:   48:  rewriter.replaceOp(op, {adaptor.getInputs().front()});
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:   49:  return success();
        -:   50:}
        -:   51:
        -:   52:namespace {
        -:   53:template <typename SrcOpTy, typename DstOpTy>
        -:   54:class BinaryOpConversion : public OpConversionPattern<SrcOpTy> {
        -:   55:public:
        -:   56:  using OpConversionPattern<SrcOpTy>::OpConversionPattern;
        -:   57:
        -:   58:  LogicalResult
    #####:   59:  matchAndRewrite(SrcOpTy op, typename SrcOpTy::Adaptor adaptor,
        -:   60:                  ConversionPatternRewriter &rewriter) const override {
        -:   61:    // For now, only error-free types are supported by this lowering.
    #####:   62:    if (op.getType().template isa<SizeType>())
    #####:   63:      return failure();
        -:   64:
    #####:   65:    rewriter.replaceOpWithNewOp<DstOpTy>(op, adaptor.getLhs(),
        -:   66:                                         adaptor.getRhs());
    #####:   67:    return success();
        -:   68:  }
------------------
_ZNK12_GLOBAL__N_118BinaryOpConversionIN4mlir5shape5AddOpENS1_5arith6AddIOpEE15matchAndRewriteES3_NS2_12AddOpAdaptorERNS1_25ConversionPatternRewriterE:
function _ZNK12_GLOBAL__N_118BinaryOpConversionIN4mlir5shape5AddOpENS1_5arith6AddIOpEE15matchAndRewriteES3_NS2_12AddOpAdaptorERNS1_25ConversionPatternRewriterE called 0 returned 0% blocks executed 0%
    #####:   59:  matchAndRewrite(SrcOpTy op, typename SrcOpTy::Adaptor adaptor,
call    0 never executed
        -:   60:                  ConversionPatternRewriter &rewriter) const override {
        -:   61:    // For now, only error-free types are supported by this lowering.
    #####:   62:    if (op.getType().template isa<SizeType>())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:   63:      return failure();
        -:   64:
    #####:   65:    rewriter.replaceOpWithNewOp<DstOpTy>(op, adaptor.getLhs(),
call    0 never executed
call    1 never executed
call    2 never executed
        -:   66:                                         adaptor.getRhs());
    #####:   67:    return success();
        -:   68:  }
------------------
_ZNK12_GLOBAL__N_118BinaryOpConversionIN4mlir5shape5MulOpENS1_5arith6MulIOpEE15matchAndRewriteES3_NS2_12MulOpAdaptorERNS1_25ConversionPatternRewriterE:
function _ZNK12_GLOBAL__N_118BinaryOpConversionIN4mlir5shape5MulOpENS1_5arith6MulIOpEE15matchAndRewriteES3_NS2_12MulOpAdaptorERNS1_25ConversionPatternRewriterE called 0 returned 0% blocks executed 0%
    #####:   59:  matchAndRewrite(SrcOpTy op, typename SrcOpTy::Adaptor adaptor,
call    0 never executed
        -:   60:                  ConversionPatternRewriter &rewriter) const override {
        -:   61:    // For now, only error-free types are supported by this lowering.
    #####:   62:    if (op.getType().template isa<SizeType>())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:   63:      return failure();
        -:   64:
    #####:   65:    rewriter.replaceOpWithNewOp<DstOpTy>(op, adaptor.getLhs(),
call    0 never executed
call    1 never executed
call    2 never executed
        -:   66:                                         adaptor.getRhs());
    #####:   67:    return success();
        -:   68:  }
------------------
        -:   69:};
        -:   70:} // namespace
        -:   71:
        -:   72:namespace {
        -:   73:struct BroadcastOpConverter : public OpConversionPattern<BroadcastOp> {
        -:   74:  using OpConversionPattern<BroadcastOp>::OpConversionPattern;
        -:   75:
        -:   76:  LogicalResult
        -:   77:  matchAndRewrite(BroadcastOp op, OpAdaptor adaptor,
        -:   78:                  ConversionPatternRewriter &rewriter) const override;
        -:   79:};
        -:   80:
        -:   81:// Get the resulting extent in a given dimension. This is computed with any
        -:   82:// number of extent tensors and shifted offsets into them.
function _ZN12_GLOBAL__N_117getBroadcastedDimEN4mlir20ImplicitLocOpBuilderENS0_10ValueRangeES2_NS0_5ValueE called 0 returned 0% blocks executed 0%
    #####:   83:Value getBroadcastedDim(ImplicitLocOpBuilder lb, ValueRange extentTensors,
        -:   84:                        ValueRange rankDiffs, Value outputDimension) {
    #####:   85:  Value one = lb.create<arith::ConstantIndexOp>(1);
call    0 never executed
    #####:   86:  Value broadcastedDim = one;
    #####:   87:  for (auto tup : llvm::zip(extentTensors, rankDiffs)) {
branch  0 never executed
branch  1 never executed
    #####:   88:    Value shape = std::get<0>(tup);
call    0 never executed
    #####:   89:    Value rankDiff = std::get<1>(tup);
call    0 never executed
    #####:   90:    Value outOfBounds = lb.create<arith::CmpIOp>(arith::CmpIPredicate::ult,
call    0 never executed
    #####:   91:                                                 outputDimension, rankDiff);
call    0 never executed
    #####:   92:    Type indexTy = lb.getIndexType();
call    0 never executed
    #####:   93:    broadcastedDim =
        -:   94:        lb.create<IfOp>(
    #####:   95:              TypeRange{indexTy}, outOfBounds,
call    0 never executed
    #####:   96:              [&](OpBuilder &b, Location loc) {
    #####:   97:                b.create<scf::YieldOp>(loc, broadcastedDim);
call    0 never executed
        -:   98:              },
function _ZZN12_GLOBAL__N_117getBroadcastedDimEN4mlir20ImplicitLocOpBuilderENS0_10ValueRangeES2_NS0_5ValueEENKUlRNS0_9OpBuilderENS0_8LocationEE0_clES5_S6_ called 0 returned 0% blocks executed 0%
    #####:   99:              [&](OpBuilder &b, Location loc) {
        -:  100:                // The broadcasting logic is:
        -:  101:                // - if one extent (here we arbitrarily choose the
        -:  102:                // extent from the greater-rank operand) is equal to 1,
        -:  103:                // then take the extent from the other operand
        -:  104:                // - otherwise, take the extent as-is.
        -:  105:                // Note that this logic remains correct in the presence
        -:  106:                // of dimensions of zero extent.
    #####:  107:                Value lesserRankOperandDimension = b.create<arith::SubIOp>(
    #####:  108:                    loc, indexTy, outputDimension, rankDiff);
call    0 never executed
call    1 never executed
    #####:  109:                Value lesserRankOperandExtent = b.create<tensor::ExtractOp>(
    #####:  110:                    loc, shape, ValueRange{lesserRankOperandDimension});
call    0 never executed
call    1 never executed
call    2 never executed
        -:  111:
    #####:  112:                Value dimIsOne =
    #####:  113:                    b.create<arith::CmpIOp>(loc, arith::CmpIPredicate::eq,
    #####:  114:                                            lesserRankOperandExtent, one);
call    0 never executed
call    1 never executed
    #####:  115:                Value dim = b.create<arith::SelectOp>(
    #####:  116:                    loc, dimIsOne, broadcastedDim, lesserRankOperandExtent);
call    0 never executed
call    1 never executed
    #####:  117:                b.create<scf::YieldOp>(loc, dim);
call    0 never executed
    #####:  118:              })
call    0 never executed
    #####:  119:            .getResult(0);
        -:  120:  }
    #####:  121:  return broadcastedDim;
        -:  122:}
        -:  123:} // namespace
        -:  124:
function _ZNK12_GLOBAL__N_120BroadcastOpConverter15matchAndRewriteEN4mlir5shape11BroadcastOpENS2_18BroadcastOpAdaptorERNS1_25ConversionPatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  125:LogicalResult BroadcastOpConverter::matchAndRewrite(
        -:  126:    BroadcastOp op, OpAdaptor adaptor,
        -:  127:    ConversionPatternRewriter &rewriter) const {
        -:  128:  // For now, this lowering is only defined on `tensor<?xindex>` operands, not
        -:  129:  // on shapes.
    #####:  130:  if (op.getType().isa<ShapeType>())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  131:    return failure();
        -:  132:
    #####:  133:  auto loc = op.getLoc();
call    0 never executed
    #####:  134:  ImplicitLocOpBuilder lb(loc, rewriter);
call    0 never executed
        -:  135:
    #####:  136:  Value zero = lb.create<arith::ConstantIndexOp>(0);
call    0 never executed
call    1 never executed
    #####:  137:  Type indexTy = lb.getIndexType();
call    0 never executed
        -:  138:
        -:  139:  // Save all the ranks for bounds checking. Because this is a tensor
        -:  140:  // representing the shape extents, the rank is the extent of the only
        -:  141:  // dimension in the tensor.
    #####:  142:  SmallVector<Value> ranks, rankDiffs;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  143:  llvm::append_range(ranks, llvm::map_range(adaptor.getShapes(), [&](Value v) {
call    0 never executed
call    1 never executed
    #####:  144:                       return lb.create<tensor::DimOp>(v, zero);
call    0 never executed
    #####:  145:                     }));
call    0 never executed
        -:  146:
        -:  147:  // Find the maximum rank
    #####:  148:  Value maxRank = ranks.front();
branch  0 never executed
branch  1 never executed
    #####:  149:  for (Value v : llvm::drop_begin(ranks, 1)) {
branch  0 never executed
branch  1 never executed
    #####:  150:    Value rankIsGreater =
    #####:  151:        lb.create<arith::CmpIOp>(arith::CmpIPredicate::ugt, v, maxRank);
call    0 never executed
call    1 never executed
    #####:  152:    maxRank = lb.create<arith::SelectOp>(rankIsGreater, v, maxRank);
call    0 never executed
        -:  153:  }
        -:  154:
        -:  155:  // Calculate the difference of ranks and the maximum rank for later offsets.
    #####:  156:  llvm::append_range(rankDiffs, llvm::map_range(ranks, [&](Value v) {
        -:  157:                       return lb.create<arith::SubIOp>(indexTy, maxRank, v);
    #####:  158:                     }));
call    0 never executed
        -:  159:
    #####:  160:  Value replacement = lb.create<tensor::GenerateOp>(
    #####:  161:      getExtentTensorType(lb.getContext()), ValueRange{maxRank},
call    0 never executed
call    1 never executed
function _ZZNK12_GLOBAL__N_120BroadcastOpConverter15matchAndRewriteEN4mlir5shape11BroadcastOpENS2_18BroadcastOpAdaptorERNS1_25ConversionPatternRewriterEENKUlRNS1_9OpBuilderENS1_8LocationENS1_10ValueRangeEE1_clES8_S9_SA_.isra.0 called 0 returned 0% blocks executed 0%
    #####:  162:      [&](OpBuilder &b, Location loc, ValueRange args) {
    #####:  163:        Value broadcastedDim =
    #####:  164:            getBroadcastedDim(ImplicitLocOpBuilder(loc, b), adaptor.getShapes(),
    #####:  165:                              rankDiffs, args[0]);
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
        -:  166:
    #####:  167:        b.create<tensor::YieldOp>(loc, broadcastedDim);
call    0 never executed
    #####:  168:      });
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  169:  if (replacement.getType() != op.getType())
branch  0 never executed
branch  1 never executed
    #####:  170:    replacement = lb.create<tensor::CastOp>(op.getType(), replacement);
call    0 never executed
    #####:  171:  rewriter.replaceOp(op, replacement);
call    0 never executed
call    1 never executed
    #####:  172:  return success();
branch  0 never executed
branch  1 never executed
        -:  173:}
        -:  174:
        -:  175:namespace {
        -:  176:class ConstShapeOpConverter : public OpConversionPattern<ConstShapeOp> {
        -:  177:public:
        -:  178:  using OpConversionPattern<ConstShapeOp>::OpConversionPattern;
        -:  179:
        -:  180:  LogicalResult
        -:  181:  matchAndRewrite(ConstShapeOp op, OpAdaptor adaptor,
        -:  182:                  ConversionPatternRewriter &rewriter) const override;
        -:  183:};
        -:  184:} // namespace
        -:  185:
function _ZNK12_GLOBAL__N_121ConstShapeOpConverter15matchAndRewriteEN4mlir5shape12ConstShapeOpENS2_19ConstShapeOpAdaptorERNS1_25ConversionPatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  186:LogicalResult ConstShapeOpConverter::matchAndRewrite(
        -:  187:    ConstShapeOp op, OpAdaptor adaptor,
        -:  188:    ConversionPatternRewriter &rewriter) const {
        -:  189:
        -:  190:  // For now, this lowering supports only extent tensors, not `shape.shape`
        -:  191:  // types.
    #####:  192:  if (op.getType().isa<ShapeType>())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  193:    return failure();
        -:  194:
    #####:  195:  auto loc = op.getLoc();
call    0 never executed
    #####:  196:  SmallVector<Value, 4> extentOperands;
call    0 never executed
    #####:  197:  for (auto extent : op.getShape()) {
call    0 never executed
call    1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
call    5 never executed
    #####:  198:    extentOperands.push_back(
call    0 never executed
    #####:  199:        rewriter.create<arith::ConstantIndexOp>(loc, extent.getLimitedValue()));
call    0 never executed
call    1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
        -:  200:  }
    #####:  201:  Type resultTy =
    #####:  202:      RankedTensorType::get({op.getShape().size()}, rewriter.getIndexType());
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:  203:  Value tensor =
    #####:  204:      rewriter.create<tensor::FromElementsOp>(loc, resultTy, extentOperands);
call    0 never executed
call    1 never executed
    #####:  205:  rewriter.replaceOpWithNewOp<tensor::CastOp>(op, resultTy, tensor);
call    0 never executed
    #####:  206:  return success();
branch  0 never executed
branch  1 never executed
        -:  207:}
        -:  208:
        -:  209:namespace {
        -:  210:class ConstSizeOpConversion : public OpConversionPattern<ConstSizeOp> {
        -:  211:public:
        -:  212:  using OpConversionPattern<ConstSizeOp>::OpConversionPattern;
        -:  213:
        -:  214:  LogicalResult
        -:  215:  matchAndRewrite(ConstSizeOp op, OpAdaptor adaptor,
        -:  216:                  ConversionPatternRewriter &rewriter) const override;
        -:  217:};
        -:  218:} // namespace
        -:  219:
function _ZNK12_GLOBAL__N_121ConstSizeOpConversion15matchAndRewriteEN4mlir5shape11ConstSizeOpENS2_18ConstSizeOpAdaptorERNS1_25ConversionPatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  220:LogicalResult ConstSizeOpConversion::matchAndRewrite(
        -:  221:    ConstSizeOp op, OpAdaptor adaptor,
        -:  222:    ConversionPatternRewriter &rewriter) const {
    #####:  223:  rewriter.replaceOpWithNewOp<arith::ConstantIndexOp>(
    #####:  224:      op, op.getValue().getSExtValue());
call    0 never executed
call    1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
    #####:  225:  return success();
        -:  226:}
        -:  227:
        -:  228:namespace {
        -:  229:struct IsBroadcastableOpConverter
        -:  230:    : public OpConversionPattern<IsBroadcastableOp> {
        -:  231:  using OpConversionPattern<IsBroadcastableOp>::OpConversionPattern;
        -:  232:
        -:  233:  LogicalResult
        -:  234:  matchAndRewrite(IsBroadcastableOp op, OpAdaptor adaptor,
        -:  235:                  ConversionPatternRewriter &rewriter) const override;
        -:  236:};
        -:  237:} // namespace
        -:  238:
function _ZNK12_GLOBAL__N_126IsBroadcastableOpConverter15matchAndRewriteEN4mlir5shape17IsBroadcastableOpENS2_24IsBroadcastableOpAdaptorERNS1_25ConversionPatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  239:LogicalResult IsBroadcastableOpConverter::matchAndRewrite(
        -:  240:    IsBroadcastableOp op, OpAdaptor adaptor,
        -:  241:    ConversionPatternRewriter &rewriter) const {
        -:  242:  // For now, this lowering is only defined on `tensor<?xindex>` operands, not
        -:  243:  // on shapes.
    #####:  244:  if (!llvm::all_of(op.getShapes(),
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
        -:  245:                    [](Value v) { return !v.getType().isa<ShapeType>(); }))
    #####:  246:    return failure();
        -:  247:
    #####:  248:  auto loc = op.getLoc();
call    0 never executed
    #####:  249:  ImplicitLocOpBuilder lb(loc, rewriter);
call    0 never executed
    #####:  250:  Value zero = lb.create<arith::ConstantIndexOp>(0);
call    0 never executed
call    1 never executed
    #####:  251:  Value one = lb.create<arith::ConstantIndexOp>(1);
call    0 never executed
call    1 never executed
    #####:  252:  Type indexTy = lb.getIndexType();
call    0 never executed
        -:  253:
        -:  254:  // Save all the ranks for bounds checking. Because this is a tensor
        -:  255:  // representing the shape extents, the rank is the extent of the only
        -:  256:  // dimension in the tensor.
    #####:  257:  SmallVector<Value> ranks, rankDiffs;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  258:  llvm::append_range(ranks, llvm::map_range(adaptor.getShapes(), [&](Value v) {
call    0 never executed
call    1 never executed
    #####:  259:                       return lb.create<tensor::DimOp>(v, zero);
call    0 never executed
    #####:  260:                     }));
call    0 never executed
        -:  261:
        -:  262:  // Find the maximum rank
    #####:  263:  Value maxRank = ranks.front();
branch  0 never executed
branch  1 never executed
    #####:  264:  for (Value v : llvm::drop_begin(ranks, 1)) {
branch  0 never executed
branch  1 never executed
    #####:  265:    Value rankIsGreater =
    #####:  266:        lb.create<arith::CmpIOp>(arith::CmpIPredicate::ugt, v, maxRank);
call    0 never executed
call    1 never executed
    #####:  267:    maxRank = lb.create<arith::SelectOp>(rankIsGreater, v, maxRank);
call    0 never executed
        -:  268:  }
        -:  269:
        -:  270:  // Calculate the difference of ranks and the maximum rank for later offsets.
    #####:  271:  llvm::append_range(rankDiffs, llvm::map_range(ranks, [&](Value v) {
        -:  272:                       return lb.create<arith::SubIOp>(indexTy, maxRank, v);
    #####:  273:                     }));
call    0 never executed
        -:  274:
    #####:  275:  Type i1Ty = rewriter.getI1Type();
call    0 never executed
    #####:  276:  Value trueVal =
    #####:  277:      rewriter.create<arith::ConstantOp>(loc, i1Ty, rewriter.getBoolAttr(true));
call    0 never executed
call    1 never executed
call    2 never executed
        -:  278:
    #####:  279:  auto reduceResult = lb.create<ForOp>(
    #####:  280:      loc, zero, maxRank, one, ValueRange{trueVal},
function _ZZNK12_GLOBAL__N_126IsBroadcastableOpConverter15matchAndRewriteEN4mlir5shape17IsBroadcastableOpENS2_24IsBroadcastableOpAdaptorERNS1_25ConversionPatternRewriterEENKUlRNS1_9OpBuilderENS1_8LocationENS1_5ValueENS1_10ValueRangeEE2_clES8_S9_SA_SB_ called 0 returned 0% blocks executed 0%
    #####:  281:      [&](OpBuilder &b, Location loc, Value iv, ValueRange iterArgs) {
        -:  282:        // Find a non-1 dim, if it exists. Note that the first part of this
        -:  283:        // could reuse the Broadcast lowering entirely, but we redo the work
        -:  284:        // here to make optimizations easier between the two loops.
    #####:  285:        Value broadcastedDim = getBroadcastedDim(
    #####:  286:            ImplicitLocOpBuilder(loc, b), adaptor.getShapes(), rankDiffs, iv);
call    0 never executed
call    1 never executed
call    2 never executed
        -:  287:
    #####:  288:        Value broadcastable = iterArgs[0];
call    0 never executed
    #####:  289:        for (auto tup : llvm::zip(adaptor.getShapes(), rankDiffs)) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  290:          Value shape, rankDiff;
    #####:  291:          std::tie(shape, rankDiff) = tup;
call    0 never executed
    #####:  292:          Value outOfBounds = b.create<arith::CmpIOp>(
    #####:  293:              loc, arith::CmpIPredicate::ult, iv, rankDiff);
call    0 never executed
call    1 never executed
    #####:  294:          broadcastable =
    #####:  295:              b.create<IfOp>(
    #####:  296:                   loc, TypeRange{i1Ty}, outOfBounds,
    #####:  297:                   [&](OpBuilder &b, Location loc) {
        -:  298:                     // Non existent dimensions are always broadcastable
    #####:  299:                     b.create<scf::YieldOp>(loc, broadcastable);
call    0 never executed
        -:  300:                   },
function _ZZZNK12_GLOBAL__N_126IsBroadcastableOpConverter15matchAndRewriteEN4mlir5shape17IsBroadcastableOpENS2_24IsBroadcastableOpAdaptorERNS1_25ConversionPatternRewriterEENKUlRNS1_9OpBuilderENS1_8LocationENS1_5ValueENS1_10ValueRangeEE2_clES8_S9_SA_SB_ENKUlS8_S9_E0_clES8_S9_ called 0 returned 0% blocks executed 0%
    #####:  301:                   [&](OpBuilder &b, Location loc) {
        -:  302:                     // Every value needs to be either 1, or the same non-1
        -:  303:                     // value to be broadcastable in this dim.
    #####:  304:                     Value operandDimension =
    #####:  305:                         b.create<arith::SubIOp>(loc, indexTy, iv, rankDiff);
call    0 never executed
call    1 never executed
    #####:  306:                     Value dimensionExtent = b.create<tensor::ExtractOp>(
    #####:  307:                         loc, shape, ValueRange{operandDimension});
call    0 never executed
call    1 never executed
call    2 never executed
        -:  308:
    #####:  309:                     Value equalOne = b.create<arith::CmpIOp>(
    #####:  310:                         loc, arith::CmpIPredicate::eq, dimensionExtent, one);
call    0 never executed
call    1 never executed
    #####:  311:                     Value equalBroadcasted = b.create<arith::CmpIOp>(
    #####:  312:                         loc, arith::CmpIPredicate::eq, dimensionExtent,
    #####:  313:                         broadcastedDim);
call    0 never executed
call    1 never executed
    #####:  314:                     Value result = b.create<arith::AndIOp>(
    #####:  315:                         loc, broadcastable,
    #####:  316:                         b.create<arith::OrIOp>(loc, equalOne,
    #####:  317:                                                equalBroadcasted));
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  318:                     b.create<scf::YieldOp>(loc, result);
call    0 never executed
    #####:  319:                   })
call    0 never executed
call    1 never executed
    #####:  320:                  .getResult(0);
        -:  321:        }
        -:  322:
    #####:  323:        b.create<scf::YieldOp>(loc, broadcastable);
call    0 never executed
    #####:  324:      });
call    0 never executed
call    1 never executed
        -:  325:
    #####:  326:  rewriter.replaceOp(op, reduceResult.getResults().front());
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:  327:  return success();
branch  0 never executed
branch  1 never executed
        -:  328:}
        -:  329:
        -:  330:namespace {
        -:  331:class DimOpConverter : public OpConversionPattern<DimOp> {
        -:  332:  using OpConversionPattern<DimOp>::OpConversionPattern;
        -:  333:
        -:  334:  LogicalResult
        -:  335:  matchAndRewrite(DimOp op, OpAdaptor adaptor,
        -:  336:                  ConversionPatternRewriter &rewriter) const override;
        -:  337:};
        -:  338:} // namespace
        -:  339:
        -:  340:LogicalResult
function _ZNK12_GLOBAL__N_114DimOpConverter15matchAndRewriteEN4mlir5shape5DimOpENS2_12DimOpAdaptorERNS1_25ConversionPatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  341:DimOpConverter::matchAndRewrite(DimOp op, OpAdaptor adaptor,
        -:  342:                                ConversionPatternRewriter &rewriter) const {
        -:  343:  // Lower to dim(X, i) to get_extent(shape_of(X), i) and rely on further
        -:  344:  // lowerings. This can be further optimized if needed to avoid intermediate
        -:  345:  // steps.
    #####:  346:  auto shapeOf = rewriter.create<shape::ShapeOfOp>(op.getLoc(), op.getValue());
call    0 never executed
call    1 never executed
    #####:  347:  rewriter.replaceOpWithNewOp<shape::GetExtentOp>(op, op.getType(), shapeOf,
call    0 never executed
    #####:  348:                                                  op.getIndex());
call    0 never executed
call    1 never executed
    #####:  349:  return success();
        -:  350:}
        -:  351:
        -:  352:namespace {
        -:  353:class GetExtentOpConverter : public OpConversionPattern<GetExtentOp> {
        -:  354:  using OpConversionPattern<GetExtentOp>::OpConversionPattern;
        -:  355:
        -:  356:  LogicalResult
        -:  357:  matchAndRewrite(GetExtentOp op, OpAdaptor adaptor,
        -:  358:                  ConversionPatternRewriter &rewriter) const override;
        -:  359:};
        -:  360:} // namespace
        -:  361:
function _ZNK12_GLOBAL__N_120GetExtentOpConverter15matchAndRewriteEN4mlir5shape11GetExtentOpENS2_18GetExtentOpAdaptorERNS1_25ConversionPatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  362:LogicalResult GetExtentOpConverter::matchAndRewrite(
        -:  363:    GetExtentOp op, OpAdaptor adaptor,
        -:  364:    ConversionPatternRewriter &rewriter) const {
        -:  365:  // For now, only error-free types are supported by this lowering.
    #####:  366:  if (op.getType().isa<SizeType>())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  367:    return failure();
        -:  368:
        -:  369:  // Derive shape extent directly from shape origin if possible. This
        -:  370:  // circumvents the necessity to materialize the shape in memory.
    #####:  371:  if (auto shapeOfOp = op.getShape().getDefiningOp<ShapeOfOp>()) {
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  372:    if (shapeOfOp.getArg().getType().isa<ShapedType>()) {
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  373:      rewriter.replaceOpWithNewOp<tensor::DimOp>(op, shapeOfOp.getArg(),
call    0 never executed
    #####:  374:                                                 adaptor.getDim());
call    0 never executed
call    1 never executed
    #####:  375:      return success();
        -:  376:    }
        -:  377:  }
        -:  378:
    #####:  379:  rewriter.replaceOpWithNewOp<tensor::ExtractOp>(op, rewriter.getIndexType(),
call    0 never executed
    #####:  380:                                                 adaptor.getShape(),
    #####:  381:                                                 ValueRange{adaptor.getDim()});
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:  382:  return success();
        -:  383:}
        -:  384:
        -:  385:namespace {
        -:  386:class RankOpConverter : public OpConversionPattern<shape::RankOp> {
        -:  387:public:
        -:  388:  using OpConversionPattern<shape::RankOp>::OpConversionPattern;
        -:  389:
        -:  390:  LogicalResult
        -:  391:  matchAndRewrite(shape::RankOp op, OpAdaptor adaptor,
        -:  392:                  ConversionPatternRewriter &rewriter) const override;
        -:  393:};
        -:  394:} // namespace
        -:  395:
        -:  396:LogicalResult
function _ZNK12_GLOBAL__N_115RankOpConverter15matchAndRewriteEN4mlir5shape6RankOpENS2_13RankOpAdaptorERNS1_25ConversionPatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  397:RankOpConverter::matchAndRewrite(shape::RankOp op, OpAdaptor adaptor,
        -:  398:                                 ConversionPatternRewriter &rewriter) const {
        -:  399:  // For now, this lowering supports only error-free types.
    #####:  400:  if (op.getType().isa<SizeType>())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  401:    return failure();
        -:  402:
    #####:  403:  rewriter.replaceOpWithNewOp<tensor::DimOp>(op, adaptor.getShape(), 0);
call    0 never executed
call    1 never executed
    #####:  404:  return success();
        -:  405:}
        -:  406:
        -:  407:namespace {
        -:  408:/// Converts `shape.reduce` to `scf.for`.
        -:  409:struct ReduceOpConverter : public OpConversionPattern<shape::ReduceOp> {
        -:  410:public:
        -:  411:  using OpConversionPattern::OpConversionPattern;
        -:  412:
        -:  413:  LogicalResult
        -:  414:  matchAndRewrite(shape::ReduceOp op, OpAdaptor adaptor,
        -:  415:                  ConversionPatternRewriter &rewriter) const final;
        -:  416:};
        -:  417:} // namespace
        -:  418:
        -:  419:LogicalResult
function _ZNK12_GLOBAL__N_117ReduceOpConverter15matchAndRewriteEN4mlir5shape8ReduceOpENS2_15ReduceOpAdaptorERNS1_25ConversionPatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  420:ReduceOpConverter::matchAndRewrite(shape::ReduceOp op, OpAdaptor adaptor,
        -:  421:                                   ConversionPatternRewriter &rewriter) const {
        -:  422:  // For now, this lowering is only defined on `tensor<?xindex>` operands.
    #####:  423:  if (op.getShape().getType().isa<ShapeType>())
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  424:    return failure();
        -:  425:
    #####:  426:  auto loc = op.getLoc();
call    0 never executed
        -:  427:
    #####:  428:  Value zero = rewriter.create<arith::ConstantIndexOp>(loc, 0);
call    0 never executed
call    1 never executed
    #####:  429:  Value one = rewriter.create<arith::ConstantIndexOp>(loc, 1);
call    0 never executed
call    1 never executed
    #####:  430:  Type indexTy = rewriter.getIndexType();
call    0 never executed
    #####:  431:  Value rank =
    #####:  432:      rewriter.create<tensor::DimOp>(loc, indexTy, adaptor.getShape(), zero);
call    0 never executed
call    1 never executed
call    2 never executed
        -:  433:
    #####:  434:  auto loop = rewriter.create<scf::ForOp>(
    #####:  435:      loc, zero, rank, one, op.getInitVals(),
function _ZZNK12_GLOBAL__N_117ReduceOpConverter15matchAndRewriteEN4mlir5shape8ReduceOpENS2_15ReduceOpAdaptorERNS1_25ConversionPatternRewriterEENKUlRNS1_9OpBuilderENS1_8LocationENS1_5ValueENS1_10ValueRangeEE_clES8_S9_SA_SB_.isra.0 called 0 returned 0% blocks executed 0%
    #####:  436:      [&](OpBuilder &b, Location loc, Value iv, ValueRange args) {
    #####:  437:        Value extent = b.create<tensor::ExtractOp>(loc, adaptor.getShape(), iv);
call    0 never executed
call    1 never executed
call    2 never executed
        -:  438:
    #####:  439:        SmallVector<Value, 2> mappedValues{iv, extent};
call    0 never executed
    #####:  440:        mappedValues.append(args.begin(), args.end());
call    0 never executed
        -:  441:
    #####:  442:        BlockAndValueMapping mapping;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  443:        Block *reduceBody = op.getBody();
call    0 never executed
    #####:  444:        mapping.map(reduceBody->getArguments(), mappedValues);
call    0 never executed
    #####:  445:        for (auto &nested : reduceBody->without_terminator())
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
call    4 never executed
    #####:  446:          b.clone(nested, mapping);
call    0 never executed
        -:  447:
    #####:  448:        SmallVector<Value, 2> mappedResults;
call    0 never executed
call    1 never executed
    #####:  449:        for (auto result : reduceBody->getTerminator()->getOperands())
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
call    4 never executed
    #####:  450:          mappedResults.push_back(mapping.lookup(result));
call    0 never executed
call    1 never executed
    #####:  451:        b.create<scf::YieldOp>(loc, mappedResults);
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  452:      });
call    0 never executed
call    1 never executed
        -:  453:
    #####:  454:  rewriter.replaceOp(op, loop.getResults());
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  455:  return success();
        -:  456:}
        -:  457:
        -:  458:namespace {
        -:  459:/// Converts `shape.shape_eq` to an `scf.for` loop. For now, the lowering is
        -:  460:/// only defined on `tensor<?xindex>` operands. The test for equality first
        -:  461:/// compares their size and, if equal, checks every extent for equality.
        -:  462:///
        -:  463:/// Example:
        -:  464:///
        -:  465:/// %result = shape.shape_eq %a, %b : tensor<?xindex>, tensor<?xindex>
        -:  466:///
        -:  467:/// becomes
        -:  468:///
        -:  469:/// %c0 = arith.constant 0 : index
        -:  470:/// %0 = dim %arg0, %c0 : tensor<?xindex>
        -:  471:/// %1 = dim %arg1, %c0 : tensor<?xindex>
        -:  472:/// %2 = arith.cmpi "eq", %0, %1 : index
        -:  473:/// %result = scf.if %2 -> (i1) {
        -:  474:///   %c1 = arith.constant 1 : index
        -:  475:///   %true = arith.constant true
        -:  476:///   %4 = scf.for %arg2 = %c0 to %0 step %c1 iter_args(%arg3 = %true) -> (i1) {
        -:  477:///     %5 = tensor.extract %arg0[%arg2] : tensor<?xindex>
        -:  478:///     %6 = tensor.extract %arg1[%arg2] : tensor<?xindex>
        -:  479:///     %7 = arith.cmpi "eq", %5, %6 : index
        -:  480:///     %8 = arith.andi %arg3, %7 : i1
        -:  481:///     scf.yield %8 : i1
        -:  482:///   }
        -:  483:///   scf.yield %4 : i1
        -:  484:/// } else {
        -:  485:///   %false = arith.constant false
        -:  486:///   scf.yield %false : i1
        -:  487:/// }
        -:  488:///
        -:  489:struct ShapeEqOpConverter : public OpConversionPattern<ShapeEqOp> {
        -:  490:  using OpConversionPattern<ShapeEqOp>::OpConversionPattern;
        -:  491:
        -:  492:  LogicalResult
        -:  493:  matchAndRewrite(ShapeEqOp op, OpAdaptor adaptor,
        -:  494:                  ConversionPatternRewriter &rewriter) const override;
        -:  495:};
        -:  496:} // namespace
        -:  497:
        -:  498:LogicalResult
function _ZNK12_GLOBAL__N_118ShapeEqOpConverter15matchAndRewriteEN4mlir5shape9ShapeEqOpENS2_16ShapeEqOpAdaptorERNS1_25ConversionPatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  499:ShapeEqOpConverter::matchAndRewrite(ShapeEqOp op, OpAdaptor adaptor,
        -:  500:                                    ConversionPatternRewriter &rewriter) const {
    #####:  501:  if (!llvm::all_of(op.getShapes(),
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
        -:  502:                    [](Value v) { return !v.getType().isa<ShapeType>(); }))
    #####:  503:    return failure();
        -:  504:
    #####:  505:  Type i1Ty = rewriter.getI1Type();
call    0 never executed
    #####:  506:  if (op.getShapes().size() <= 1) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  507:    rewriter.replaceOpWithNewOp<arith::ConstantOp>(op, i1Ty,
    #####:  508:                                                   rewriter.getBoolAttr(true));
call    0 never executed
call    1 never executed
    #####:  509:    return success();
        -:  510:  }
        -:  511:
    #####:  512:  auto loc = op.getLoc();
call    0 never executed
    #####:  513:  Type indexTy = rewriter.getIndexType();
call    0 never executed
    #####:  514:  Value zero = rewriter.create<arith::ConstantIndexOp>(loc, 0);
call    0 never executed
call    1 never executed
    #####:  515:  Value firstShape = adaptor.getShapes().front();
call    0 never executed
call    1 never executed
    #####:  516:  Value firstRank =
    #####:  517:      rewriter.create<tensor::DimOp>(loc, indexTy, firstShape, zero);
call    0 never executed
call    1 never executed
    #####:  518:  Value result = nullptr;
        -:  519:  // Generate a linear sequence of compares, all with firstShape as lhs.
    #####:  520:  for (Value shape : adaptor.getShapes().drop_front(1)) {
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
call    4 never executed
    #####:  521:    Value rank = rewriter.create<tensor::DimOp>(loc, indexTy, shape, zero);
call    0 never executed
call    1 never executed
    #####:  522:    Value eqRank = rewriter.create<arith::CmpIOp>(loc, arith::CmpIPredicate::eq,
    #####:  523:                                                  firstRank, rank);
call    0 never executed
call    1 never executed
    #####:  524:    auto same = rewriter.create<IfOp>(
        -:  525:        loc, i1Ty, eqRank,
function _ZZNK12_GLOBAL__N_118ShapeEqOpConverter15matchAndRewriteEN4mlir5shape9ShapeEqOpENS2_16ShapeEqOpAdaptorERNS1_25ConversionPatternRewriterEENKUlRNS1_9OpBuilderENS1_8LocationEE0_clES8_S9_ called 0 returned 0% blocks executed 0%
    #####:  526:        [&](OpBuilder &b, Location loc) {
    #####:  527:          Value one = b.create<arith::ConstantIndexOp>(loc, 1);
call    0 never executed
call    1 never executed
    #####:  528:          Value init =
    #####:  529:              b.create<arith::ConstantOp>(loc, i1Ty, b.getBoolAttr(true));
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  530:          auto loop = b.create<scf::ForOp>(
    #####:  531:              loc, zero, firstRank, one, ValueRange{init},
function _ZZZNK12_GLOBAL__N_118ShapeEqOpConverter15matchAndRewriteEN4mlir5shape9ShapeEqOpENS2_16ShapeEqOpAdaptorERNS1_25ConversionPatternRewriterEENKUlRNS1_9OpBuilderENS1_8LocationEE0_clES8_S9_ENKUlS8_S9_NS1_5ValueENS1_10ValueRangeEE_clES8_S9_SB_SC_.isra.0 called 0 returned 0% blocks executed 0%
    #####:  532:              [&](OpBuilder &b, Location nestedLoc, Value iv, ValueRange args) {
    #####:  533:                Value conj = args[0];
call    0 never executed
    #####:  534:                Value lhsExtent =
    #####:  535:                    b.create<tensor::ExtractOp>(loc, firstShape, iv);
call    0 never executed
call    1 never executed
    #####:  536:                Value rhsExtent = b.create<tensor::ExtractOp>(loc, shape, iv);
call    0 never executed
call    1 never executed
    #####:  537:                Value eqExtent = b.create<arith::CmpIOp>(
    #####:  538:                    loc, arith::CmpIPredicate::eq, lhsExtent, rhsExtent);
call    0 never executed
call    1 never executed
    #####:  539:                Value conjNext = b.create<arith::AndIOp>(loc, conj, eqExtent);
call    0 never executed
call    1 never executed
    #####:  540:                b.create<scf::YieldOp>(loc, ValueRange({conjNext}));
call    0 never executed
call    1 never executed
    #####:  541:              });
call    0 never executed
call    1 never executed
    #####:  542:          b.create<scf::YieldOp>(loc, loop.getResults());
call    0 never executed
call    1 never executed
    #####:  543:        },
function _ZZNK12_GLOBAL__N_118ShapeEqOpConverter15matchAndRewriteEN4mlir5shape9ShapeEqOpENS2_16ShapeEqOpAdaptorERNS1_25ConversionPatternRewriterEENKUlRNS1_9OpBuilderENS1_8LocationEE1_clES8_S9_.isra.0 called 0 returned 0% blocks executed 0%
    #####:  544:        [&](OpBuilder &b, Location loc) {
    #####:  545:          Value result =
    #####:  546:              b.create<arith::ConstantOp>(loc, i1Ty, b.getBoolAttr(false));
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  547:          b.create<scf::YieldOp>(loc, result);
call    0 never executed
    #####:  548:        });
call    0 never executed
    #####:  549:    result = !result ? same.getResult(0)
branch  0 never executed
branch  1 never executed
    #####:  550:                     : rewriter.create<arith::AndIOp>(loc, result,
    #####:  551:                                                      same.getResult(0));
call    0 never executed
        -:  552:  }
    #####:  553:  rewriter.replaceOp(op, result);
call    0 never executed
call    1 never executed
    #####:  554:  return success();
        -:  555:}
        -:  556:
        -:  557:namespace {
        -:  558:class ShapeOfOpConversion : public OpConversionPattern<ShapeOfOp> {
        -:  559:public:
        -:  560:  using OpConversionPattern<ShapeOfOp>::OpConversionPattern;
        -:  561:
        -:  562:  LogicalResult
        -:  563:  matchAndRewrite(ShapeOfOp op, OpAdaptor adaptor,
        -:  564:                  ConversionPatternRewriter &rewriter) const override;
        -:  565:};
        -:  566:} // namespace
        -:  567:
function _ZNK12_GLOBAL__N_119ShapeOfOpConversion15matchAndRewriteEN4mlir5shape9ShapeOfOpENS2_16ShapeOfOpAdaptorERNS1_25ConversionPatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  568:LogicalResult ShapeOfOpConversion::matchAndRewrite(
        -:  569:    ShapeOfOp op, OpAdaptor adaptor,
        -:  570:    ConversionPatternRewriter &rewriter) const {
        -:  571:
        -:  572:  // For now, only error-free types are supported by this lowering.
    #####:  573:  if (op.getType().isa<ShapeType>())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  574:    return failure();
        -:  575:
        -:  576:  // For ranked tensor arguments, lower to `tensor.from_elements`.
    #####:  577:  auto loc = op.getLoc();
call    0 never executed
    #####:  578:  Value tensor = adaptor.getArg();
call    0 never executed
    #####:  579:  Type tensorTy = tensor.getType();
call    0 never executed
    #####:  580:  if (tensorTy.isa<RankedTensorType>()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  581:
        -:  582:    // Build values for individual extents.
    #####:  583:    SmallVector<Value, 8> extentValues;
call    0 never executed
    #####:  584:    RankedTensorType rankedTensorTy = tensorTy.cast<RankedTensorType>();
call    0 never executed
    #####:  585:    int64_t rank = rankedTensorTy.getRank();
call    0 never executed
    #####:  586:    for (int64_t i = 0; i < rank; i++) {
branch  0 never executed
branch  1 never executed
    #####:  587:      if (rankedTensorTy.isDynamicDim(i)) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  588:        Value extent = rewriter.create<tensor::DimOp>(loc, tensor, i);
call    0 never executed
call    1 never executed
    #####:  589:        extentValues.push_back(extent);
call    0 never executed
        -:  590:      } else {
    #####:  591:        Value extent = rewriter.create<arith::ConstantIndexOp>(
    #####:  592:            loc, rankedTensorTy.getDimSize(i));
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  593:        extentValues.push_back(extent);
call    0 never executed
        -:  594:      }
        -:  595:    }
        -:  596:
        -:  597:    // Materialize extent tensor.
    #####:  598:    Value staticExtentTensor = rewriter.create<tensor::FromElementsOp>(
    #####:  599:        loc, RankedTensorType::get({rank}, rewriter.getIndexType()),
call    0 never executed
    #####:  600:        extentValues);
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  601:    rewriter.replaceOpWithNewOp<tensor::CastOp>(op, op.getType(),
    #####:  602:                                                staticExtentTensor);
call    0 never executed
    #####:  603:    return success();
branch  0 never executed
branch  1 never executed
        -:  604:  }
        -:  605:
        -:  606:  // Lower to `tensor.generate` otherwise.
    #####:  607:  auto *ctx = rewriter.getContext();
call    0 never executed
    #####:  608:  Value rank = rewriter.create<tensor::RankOp>(loc, tensor);
call    0 never executed
call    1 never executed
    #####:  609:  rewriter.replaceOpWithNewOp<tensor::GenerateOp>(
    #####:  610:      op, getExtentTensorType(ctx), ValueRange{rank},
call    0 never executed
function _ZZNK12_GLOBAL__N_119ShapeOfOpConversion15matchAndRewriteEN4mlir5shape9ShapeOfOpENS2_16ShapeOfOpAdaptorERNS1_25ConversionPatternRewriterEENKUlRNS1_9OpBuilderENS1_8LocationENS1_10ValueRangeEE_clES8_S9_SA_.isra.0 called 0 returned 0% blocks executed 0%
    #####:  611:      [&](OpBuilder &b, Location loc, ValueRange args) {
    #####:  612:        Value dim = args.front();
call    0 never executed
    #####:  613:        Value extent = b.create<tensor::DimOp>(loc, tensor, dim);
call    0 never executed
call    1 never executed
    #####:  614:        b.create<tensor::YieldOp>(loc, extent);
call    0 never executed
    #####:  615:      });
call    0 never executed
call    1 never executed
        -:  616:
    #####:  617:  return success();
        -:  618:}
        -:  619:
        -:  620:namespace {
        -:  621:class SplitAtOpConversion : public OpConversionPattern<SplitAtOp> {
        -:  622:public:
        -:  623:  using OpConversionPattern<SplitAtOp>::OpConversionPattern;
        -:  624:
        -:  625:  LogicalResult
        -:  626:  matchAndRewrite(SplitAtOp op, OpAdaptor adaptor,
        -:  627:                  ConversionPatternRewriter &rewriter) const override;
        -:  628:};
        -:  629:} // namespace
        -:  630:
function _ZNK12_GLOBAL__N_119SplitAtOpConversion15matchAndRewriteEN4mlir5shape9SplitAtOpENS2_16SplitAtOpAdaptorERNS1_25ConversionPatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  631:LogicalResult SplitAtOpConversion::matchAndRewrite(
        -:  632:    SplitAtOp op, OpAdaptor adaptor,
        -:  633:    ConversionPatternRewriter &rewriter) const {
        -:  634:  // Error conditions are not implemented, only lower if all operands and
        -:  635:  // results are extent tensors.
    #####:  636:  if (llvm::any_of(ValueRange{op.getOperand(), op.getHead(), op.getTail()},
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
branch  5 never executed
branch  6 never executed
        -:  637:                   [](Value v) { return v.getType().isa<ShapeType>(); }))
    #####:  638:    return failure();
        -:  639:
    #####:  640:  ImplicitLocOpBuilder b(op.getLoc(), rewriter);
call    0 never executed
    #####:  641:  Value zero = b.create<arith::ConstantIndexOp>(0);
call    0 never executed
call    1 never executed
    #####:  642:  Value rank = b.create<tensor::DimOp>(adaptor.getOperand(), zero);
call    0 never executed
call    1 never executed
call    2 never executed
        -:  643:
        -:  644:  // index < 0 ? index + rank : index
    #####:  645:  Value originalIndex = adaptor.getIndex();
call    0 never executed
    #####:  646:  Value add = b.create<arith::AddIOp>(originalIndex, rank);
call    0 never executed
call    1 never executed
    #####:  647:  Value indexIsNegative =
    #####:  648:      b.create<arith::CmpIOp>(arith::CmpIPredicate::slt, originalIndex, zero);
call    0 never executed
call    1 never executed
    #####:  649:  Value index = b.create<arith::SelectOp>(indexIsNegative, add, originalIndex);
call    0 never executed
call    1 never executed
        -:  650:
    #####:  651:  Value one = b.create<arith::ConstantIndexOp>(1);
call    0 never executed
call    1 never executed
    #####:  652:  Value head =
    #####:  653:      b.create<tensor::ExtractSliceOp>(adaptor.getOperand(), zero, index, one);
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  654:  Value tailSize = b.create<arith::SubIOp>(rank, index);
call    0 never executed
call    1 never executed
    #####:  655:  Value tail = b.create<tensor::ExtractSliceOp>(adaptor.getOperand(), index,
call    0 never executed
call    1 never executed
    #####:  656:                                                tailSize, one);
call    0 never executed
    #####:  657:  rewriter.replaceOp(op, {head, tail});
call    0 never executed
call    1 never executed
    #####:  658:  return success();
        -:  659:}
        -:  660:
        -:  661:namespace {
        -:  662:class ToExtentTensorOpConversion
        -:  663:    : public OpConversionPattern<ToExtentTensorOp> {
        -:  664:public:
        -:  665:  using OpConversionPattern<ToExtentTensorOp>::OpConversionPattern;
        -:  666:
        -:  667:  LogicalResult
function _ZNK12_GLOBAL__N_126ToExtentTensorOpConversion15matchAndRewriteEN4mlir5shape16ToExtentTensorOpENS2_23ToExtentTensorOpAdaptorERNS1_25ConversionPatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  668:  matchAndRewrite(ToExtentTensorOp op, OpAdaptor adaptor,
        -:  669:                  ConversionPatternRewriter &rewriter) const override {
    #####:  670:    if (!adaptor.getInput().getType().isa<RankedTensorType>())
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  671:      return rewriter.notifyMatchFailure(op, "input needs to be a tensor");
call    0 never executed
        -:  672:
    #####:  673:    rewriter.replaceOpWithNewOp<tensor::CastOp>(op, op.getType(),
    #####:  674:                                                adaptor.getInput());
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  675:    return success();
        -:  676:  }
        -:  677:};
        -:  678:} // namespace
        -:  679:
        -:  680:namespace {
        -:  681:/// Import the Shape Ops to Std Patterns.
        -:  682:#include "ShapeToStandard.cpp.inc"
        -:  683:} // namespace
        -:  684:
        -:  685:namespace {
        -:  686:/// Conversion pass.
  116709*:  687:class ConvertShapeToStandardPass
call    0 never executed
call    1 returned 100%
        -:  688:    : public impl::ConvertShapeToStandardBase<ConvertShapeToStandardPass> {
        -:  689:
        -:  690:  void runOnOperation() override;
        -:  691:};
        -:  692:} // namespace
        -:  693:
function _ZN12_GLOBAL__N_126ConvertShapeToStandardPass14runOnOperationEv called 416 returned 100% blocks executed 93%
      416:  694:void ConvertShapeToStandardPass::runOnOperation() {
        -:  695:  // Setup target legality.
      416:  696:  MLIRContext &ctx = getContext();
call    0 returned 100%
      416:  697:  ConversionTarget target(ctx);
call    0 returned 100%
      416:  698:  target.addLegalDialect<arith::ArithDialect, SCFDialect,
      416:  699:                         tensor::TensorDialect>();
call    0 returned 100%
      416:  700:  target.addLegalOp<CstrRequireOp, func::FuncOp, ModuleOp>();
call    0 returned 100%
        -:  701:
        -:  702:  // Setup conversion patterns.
      832:  703:  RewritePatternSet patterns(&ctx);
call    0 returned 100%
call    1 returned 100%
      416:  704:  populateShapeToStandardConversionPatterns(patterns);
call    0 returned 100%
        -:  705:
        -:  706:  // Apply conversion.
      416:  707:  auto module = getOperation();
call    0 returned 100%
      416:  708:  if (failed(applyPartialConversion(module, target, std::move(patterns))))
call    0 returned 100%
call    1 returned 100%
call    2 returned 100%
branch  3 taken 0% (fallthrough)
branch  4 taken 100%
    #####:  709:    signalPassFailure();
call    0 never executed
      416:  710:}
        -:  711:
function _ZN4mlir41populateShapeToStandardConversionPatternsERNS_17RewritePatternSetE called 416 returned 100% blocks executed 100%
      416:  712:void mlir::populateShapeToStandardConversionPatterns(
        -:  713:    RewritePatternSet &patterns) {
        -:  714:  // clang-format off
      416:  715:  populateWithGenerated(patterns);
call    0 returned 100%
      416:  716:  patterns.add<
        -:  717:      AnyOpConversion,
        -:  718:      BinaryOpConversion<AddOp, arith::AddIOp>,
        -:  719:      BinaryOpConversion<MulOp, arith::MulIOp>,
        -:  720:      BroadcastOpConverter,
        -:  721:      ConstShapeOpConverter,
        -:  722:      ConstSizeOpConversion,
        -:  723:      DimOpConverter,
        -:  724:      IsBroadcastableOpConverter,
        -:  725:      GetExtentOpConverter,
        -:  726:      RankOpConverter,
        -:  727:      ReduceOpConverter,
        -:  728:      ShapeEqOpConverter,
        -:  729:      ShapeOfOpConversion,
        -:  730:      SplitAtOpConversion,
      416:  731:      ToExtentTensorOpConversion>(patterns.getContext());
call    0 returned 100%
        -:  732:  // clang-format on
      416:  733:}
        -:  734:
        -:  735:std::unique_ptr<OperationPass<ModuleOp>>
function _ZN4mlir32createConvertShapeToStandardPassEv called 116709 returned 100% blocks executed 100%
   116709:  736:mlir::createConvertShapeToStandardPass() {
   116709:  737:  return std::make_unique<ConvertShapeToStandardPass>();
call    0 returned 100%
        -:  738:}
