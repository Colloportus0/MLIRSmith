        -:    0:Source:/data/xcy/llvm-project-fdbc55a5/mlir/lib/Dialect/Linalg/IR/LinalgInterfaces.cpp
        -:    0:Graph:../tools/mlir/lib/Dialect/Linalg/IR/CMakeFiles/obj.MLIRLinalgDialect.dir/LinalgInterfaces.cpp.gcno
        -:    0:Data:../tools/mlir/lib/Dialect/Linalg/IR/CMakeFiles/obj.MLIRLinalgDialect.dir/LinalgInterfaces.cpp.gcda
        -:    0:Runs:116158
        -:    1://===- LinalgInterfaces.cpp - Linalg interfaces implementation ------------===//
        -:    2://
        -:    3:// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
        -:    4:// See https://llvm.org/LICENSE.txt for license information.
        -:    5:// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
        -:    6://
        -:    7://===----------------------------------------------------------------------===//
        -:    8:
        -:    9:#include "mlir/Dialect/Linalg/IR/LinalgInterfaces.h"
        -:   10:
        -:   11:#include "mlir/Dialect/Affine/IR/AffineOps.h"
        -:   12:#include "mlir/Dialect/Arith/IR/Arith.h"
        -:   13:#include "mlir/Dialect/Arith/Utils/Utils.h"
        -:   14:#include "mlir/Dialect/Complex/IR/Complex.h"
        -:   15:#include "mlir/Dialect/MemRef/IR/MemRef.h"
        -:   16:#include "mlir/Dialect/Tensor/IR/Tensor.h"
        -:   17:#include "mlir/IR/AffineExprVisitor.h"
        -:   18:#include "mlir/IR/AffineMap.h"
        -:   19:#include "mlir/IR/TypeUtilities.h"
        -:   20:#include "llvm/ADT/SmallBitVector.h"
        -:   21:
        -:   22:using namespace mlir;
        -:   23:using namespace mlir::linalg;
        -:   24:
        -:   25:/// Include the definitions of the copy operation interface.
        -:   26:#include "mlir/Dialect/Linalg/IR/LinalgInterfaces.cpp.inc"
        -:   27:
        -:   28://===----------------------------------------------------------------------===//
        -:   29:// Interface utility functions
        -:   30://===----------------------------------------------------------------------===//
function _ZN4mlir6linalg6detail26canOpOperandsBeDroppedImplENS0_8LinalgOpEN4llvm8ArrayRefIPNS_9OpOperandEEE called 0 returned 0% blocks executed 0%
    #####:   31:bool linalg::detail::canOpOperandsBeDroppedImpl(
        -:   32:    linalg::LinalgOp linalgOp, ArrayRef<OpOperand *> droppedOperands) {
    #####:   33:  SmallVector<AffineMap> indexingMaps;
call    0 never executed
    #####:   34:  for (auto &opOperand : linalgOp->getOpOperands()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:   35:    if (llvm::is_contained(droppedOperands, &opOperand))
branch  0 never executed
branch  1 never executed
    #####:   36:      continue;
    #####:   37:    indexingMaps.push_back(linalgOp.getMatchingIndexingMap(&opOperand));
call    0 never executed
call    1 never executed
        -:   38:  }
    #####:   39:  return inversePermutation(concatAffineMaps(indexingMaps)) != AffineMap();
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
        -:   40:}
        -:   41:
        -:   42://===----------------------------------------------------------------------===//
        -:   43:// ContractionOpInterface implementation
        -:   44://===----------------------------------------------------------------------===//
        -:   45:
        -:   46:/// Return true if the use-def chain from `v` to `from` consists of 0 or more
        -:   47:/// unary single-operand operations.
        -:   48:// TODO: relax to multi-operands with constants, which are technically unary ops
        -:   49:// as needed (e.g. add5).
function _ZL21isChainOfUnaryOpsFromN4mlir5ValueES0_ called 296646110 returned 100% blocks executed 27%
296646110:   50:static bool isChainOfUnaryOpsFrom(Value v, Value from) {
296646110*:   51:  while (true) {
296646110:   52:    if (v == from)
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
        -:   53:      return true;
    #####:   54:    Operation *op = v.getDefiningOp();
call    0 never executed
    #####:   55:    if (!op || op->getNumOperands() != 1)
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
        -:   56:      return false;
    #####:   57:    v = op->getOperand(0);
call    0 never executed
    #####:   58:  };
        -:   59:}
        -:   60:
        -:   61:/// Return the unique instance of OpType in `block` if it is indeed unique.
        -:   62:/// Return null if none or more than 1 instances exist.
        -:   63:template <typename OpType>
251371910:   64:static OpType getSingleOpOfType(Block &block) {
251371910:   65:  OpType res = nullptr;
370030550*:   66:  block.walk([&](OpType op) {
118658640*:   67:    if (res) {
branch  0 taken 1% (fallthrough)
branch  1 taken 100%
branch  2 taken 1% (fallthrough)
branch  3 taken 100%
branch  4 never executed
branch  5 never executed
branch  6 never executed
branch  7 never executed
branch  8 taken 1% (fallthrough)
branch  9 taken 100%
branch 10 taken 1% (fallthrough)
branch 11 taken 100%
branch 12 taken 1% (fallthrough)
branch 13 taken 100%
branch 14 taken 1% (fallthrough)
branch 15 taken 100%
      98*:   68:      res = nullptr;
        -:   69:      return WalkResult::interrupt();
        -:   70:    }
118658542*:   71:    res = op;
        -:   72:    return WalkResult::advance();
        -:   73:  });
251371910:   74:  return res;
        -:   75:}
------------------
_Z17getSingleOpOfTypeIN4mlir5arith6AndIOpEET_RNS0_5BlockE:
function _Z17getSingleOpOfTypeIN4mlir5arith6AndIOpEET_RNS0_5BlockE called 11181653 returned 100% blocks executed 100%
 11181653:   64:static OpType getSingleOpOfType(Block &block) {
call    0 returned 100%
 11181653:   65:  OpType res = nullptr;
 11181653:   66:  block.walk([&](OpType op) {
call    0 returned 100%
        -:   67:    if (res) {
        -:   68:      res = nullptr;
        -:   69:      return WalkResult::interrupt();
        -:   70:    }
        -:   71:    res = op;
        -:   72:    return WalkResult::advance();
        -:   73:  });
 11181653:   74:  return res;
        -:   75:}
------------------
_Z17getSingleOpOfTypeIN4mlir5arith5OrIOpEET_RNS0_5BlockE:
function _Z17getSingleOpOfTypeIN4mlir5arith5OrIOpEET_RNS0_5BlockE called 11181653 returned 100% blocks executed 100%
 11181653:   64:static OpType getSingleOpOfType(Block &block) {
call    0 returned 100%
 11181653:   65:  OpType res = nullptr;
 11181653:   66:  block.walk([&](OpType op) {
call    0 returned 100%
        -:   67:    if (res) {
        -:   68:      res = nullptr;
        -:   69:      return WalkResult::interrupt();
        -:   70:    }
        -:   71:    res = op;
        -:   72:    return WalkResult::advance();
        -:   73:  });
 11181653:   74:  return res;
        -:   75:}
------------------
_Z17getSingleOpOfTypeIN4mlir7complex5MulOpEET_RNS0_5BlockE:
function _Z17getSingleOpOfTypeIN4mlir7complex5MulOpEET_RNS0_5BlockE called 11181653 returned 100% blocks executed 100%
 11181653:   64:static OpType getSingleOpOfType(Block &block) {
call    0 returned 100%
 11181653:   65:  OpType res = nullptr;
 11181653:   66:  block.walk([&](OpType op) {
call    0 returned 100%
        -:   67:    if (res) {
        -:   68:      res = nullptr;
        -:   69:      return WalkResult::interrupt();
        -:   70:    }
        -:   71:    res = op;
        -:   72:    return WalkResult::advance();
        -:   73:  });
 11181653:   74:  return res;
        -:   75:}
------------------
_Z17getSingleOpOfTypeIN4mlir7complex5AddOpEET_RNS0_5BlockE:
function _Z17getSingleOpOfTypeIN4mlir7complex5AddOpEET_RNS0_5BlockE called 11181653 returned 100% blocks executed 100%
 11181653:   64:static OpType getSingleOpOfType(Block &block) {
call    0 returned 100%
 11181653:   65:  OpType res = nullptr;
 11181653:   66:  block.walk([&](OpType op) {
call    0 returned 100%
        -:   67:    if (res) {
        -:   68:      res = nullptr;
        -:   69:      return WalkResult::interrupt();
        -:   70:    }
        -:   71:    res = op;
        -:   72:    return WalkResult::advance();
        -:   73:  });
 11181653:   74:  return res;
        -:   75:}
------------------
_Z17getSingleOpOfTypeIN4mlir5arith6MulIOpEET_RNS0_5BlockE:
function _Z17getSingleOpOfTypeIN4mlir5arith6MulIOpEET_RNS0_5BlockE called 43992179 returned 100% blocks executed 100%
 43992179:   64:static OpType getSingleOpOfType(Block &block) {
call    0 returned 100%
 43992179:   65:  OpType res = nullptr;
 43992179:   66:  block.walk([&](OpType op) {
call    0 returned 100%
        -:   67:    if (res) {
        -:   68:      res = nullptr;
        -:   69:      return WalkResult::interrupt();
        -:   70:    }
        -:   71:    res = op;
        -:   72:    return WalkResult::advance();
        -:   73:  });
 43992179:   74:  return res;
        -:   75:}
------------------
_Z17getSingleOpOfTypeIN4mlir5arith6AddIOpEET_RNS0_5BlockE:
function _Z17getSingleOpOfTypeIN4mlir5arith6AddIOpEET_RNS0_5BlockE called 43992179 returned 100% blocks executed 100%
 43992179:   64:static OpType getSingleOpOfType(Block &block) {
call    0 returned 100%
 43992179:   65:  OpType res = nullptr;
 43992179:   66:  block.walk([&](OpType op) {
call    0 returned 100%
        -:   67:    if (res) {
        -:   68:      res = nullptr;
        -:   69:      return WalkResult::interrupt();
        -:   70:    }
        -:   71:    res = op;
        -:   72:    return WalkResult::advance();
        -:   73:  });
 43992179:   74:  return res;
        -:   75:}
------------------
_Z17getSingleOpOfTypeIN4mlir5arith6MulFOpEET_RNS0_5BlockE:
function _Z17getSingleOpOfTypeIN4mlir5arith6MulFOpEET_RNS0_5BlockE called 59330470 returned 100% blocks executed 100%
 59330470:   64:static OpType getSingleOpOfType(Block &block) {
call    0 returned 100%
 59330470:   65:  OpType res = nullptr;
 59330470:   66:  block.walk([&](OpType op) {
call    0 returned 100%
        -:   67:    if (res) {
        -:   68:      res = nullptr;
        -:   69:      return WalkResult::interrupt();
        -:   70:    }
        -:   71:    res = op;
        -:   72:    return WalkResult::advance();
        -:   73:  });
 59330470:   74:  return res;
        -:   75:}
------------------
_Z17getSingleOpOfTypeIN4mlir5arith6AddFOpEET_RNS0_5BlockE:
function _Z17getSingleOpOfTypeIN4mlir5arith6AddFOpEET_RNS0_5BlockE called 59330470 returned 100% blocks executed 100%
 59330470:   64:static OpType getSingleOpOfType(Block &block) {
call    0 returned 100%
 59330470:   65:  OpType res = nullptr;
 59330470:   66:  block.walk([&](OpType op) {
call    0 returned 100%
        -:   67:    if (res) {
        -:   68:      res = nullptr;
        -:   69:      return WalkResult::interrupt();
        -:   70:    }
        -:   71:    res = op;
        -:   72:    return WalkResult::advance();
        -:   73:  });
 59330470:   74:  return res;
        -:   75:}
------------------
        -:   76:
        -:   77:/// Detect whether res is any permutation of `u5(u1(c) + u2(u3(a) * u4(b)))`
        -:   78:/// on the field (AddOpType, MulOpType), where u1, u2, u3, u4 and u5 represent
        -:   79:/// unary operations that may change the type.
        -:   80:template <typename AddOpType, typename MulOpType>
125685955:   81:static bool isAddMul(Block &block) {
125685955:   82:  if (block.getNumArguments() != 3)
        -:   83:    return false;
125685955:   84:  Operation *yieldOp = block.getTerminator();
125685955:   85:  if (yieldOp->getNumOperands() != 1)
        -:   86:    return false;
        -:   87:
125685955:   88:  AddOpType addOp = getSingleOpOfType<AddOpType>(block);
125685955:   89:  MulOpType mulOp = getSingleOpOfType<MulOpType>(block);
125685955*:   90:  if (!addOp || !mulOp)
        -:   91:    return false;
        -:   92:
59329222*:   93:  Value argA = block.getArgument(0), argB = block.getArgument(1);
118658444*:   94:  Value a = mulOp->getOperand(0), b = mulOp->getOperand(1);
59329222*:   95:  Value mul = mulOp->getResult(0);
59329222*:   96:  Value argC = block.getArgument(2);
59329222*:   97:  Value c1 = addOp->getOperand(0), c2 = addOp->getOperand(1);
59329222*:   98:  Value add = addOp->getResult(0);
59329222*:   99:  Value res = yieldOp->getOperand(0);
        -:  100:  // Result traces back to add.
59329222*:  101:  auto un = isChainOfUnaryOpsFrom;
59329222*:  102:  bool success = un(res, add);
        -:  103:  // One of the operands of add traces back to argC, the other to the mul.
59329222*:  104:  success |= (un(c1, argC) && un(c2, mul)) || ((un(c1, mul)) && un(c2, argC));
        -:  105:  // One of the operands of mul traces back to argA, the other to argB.
59329222*:  106:  success |= (un(a, argA) && un(b, argB)) || ((un(a, argB)) && un(b, argA));
59329222*:  107:  return success;
        -:  108:}
------------------
_Z8isAddMulIN4mlir5arith5OrIOpENS1_6AndIOpEEbRNS0_5BlockE:
function _Z8isAddMulIN4mlir5arith5OrIOpENS1_6AndIOpEEbRNS0_5BlockE called 11181653 returned 100% blocks executed 69%
 11181653:   81:static bool isAddMul(Block &block) {
branch  0 taken 100% (fallthrough)
branch  1 taken 0%
 11181653:   82:  if (block.getNumArguments() != 3)
branch  0 taken 100% (fallthrough)
branch  1 taken 0%
        -:   83:    return false;
 11181653:   84:  Operation *yieldOp = block.getTerminator();
call    0 returned 100%
branch  1 taken 100% (fallthrough)
branch  2 taken 0%
 11181653:   85:  if (yieldOp->getNumOperands() != 1)
branch  0 taken 100% (fallthrough)
branch  1 taken 0%
        -:   86:    return false;
        -:   87:
 11181653:   88:  AddOpType addOp = getSingleOpOfType<AddOpType>(block);
call    0 returned 100%
 11181653:   89:  MulOpType mulOp = getSingleOpOfType<MulOpType>(block);
call    0 returned 100%
branch  1 taken 100% (fallthrough)
branch  2 taken 1%
 11181653:   90:  if (!addOp || !mulOp)
branch  0 taken 100% (fallthrough)
branch  1 taken 1%
branch  2 taken 100% (fallthrough)
branch  3 taken 0%
        -:   91:    return false;
        -:   92:
 11180405:   93:  Value argA = block.getArgument(0), argB = block.getArgument(1);
 22360810:   94:  Value a = mulOp->getOperand(0), b = mulOp->getOperand(1);
call    0 returned 100%
call    1 returned 100%
call    2 returned 100%
call    3 returned 100%
 11180405:   95:  Value mul = mulOp->getResult(0);
call    0 returned 100%
 11180405:   96:  Value argC = block.getArgument(2);
 11180405:   97:  Value c1 = addOp->getOperand(0), c2 = addOp->getOperand(1);
call    0 returned 100%
call    1 returned 100%
 11180405:   98:  Value add = addOp->getResult(0);
call    0 returned 100%
 11180405:   99:  Value res = yieldOp->getOperand(0);
        -:  100:  // Result traces back to add.
 11180405:  101:  auto un = isChainOfUnaryOpsFrom;
 11180405:  102:  bool success = un(res, add);
call    0 returned 100%
        -:  103:  // One of the operands of add traces back to argC, the other to the mul.
11180405*:  104:  success |= (un(c1, argC) && un(c2, mul)) || ((un(c1, mul)) && un(c2, argC));
call    0 returned 100%
branch  1 taken 100% (fallthrough)
branch  2 taken 0%
call    3 returned 100%
branch  4 taken 0% (fallthrough)
branch  5 taken 100%
call    6 never executed
branch  7 never executed
branch  8 never executed
call    9 never executed
branch 10 never executed
branch 11 never executed
        -:  105:  // One of the operands of mul traces back to argA, the other to argB.
11180405*:  106:  success |= (un(a, argA) && un(b, argB)) || ((un(a, argB)) && un(b, argA));
call    0 returned 100%
branch  1 taken 100% (fallthrough)
branch  2 taken 0%
call    3 returned 100%
branch  4 taken 0% (fallthrough)
branch  5 taken 100%
call    6 never executed
branch  7 never executed
branch  8 never executed
call    9 never executed
branch 10 never executed
branch 11 never executed
 11180405:  107:  return success;
        -:  108:}
------------------
_Z8isAddMulIN4mlir7complex5AddOpENS1_5MulOpEEbRNS0_5BlockE:
function _Z8isAddMulIN4mlir7complex5AddOpENS1_5MulOpEEbRNS0_5BlockE called 11181653 returned 100% blocks executed 25%
 11181653:   81:static bool isAddMul(Block &block) {
branch  0 taken 100% (fallthrough)
branch  1 taken 0%
 11181653:   82:  if (block.getNumArguments() != 3)
branch  0 taken 100% (fallthrough)
branch  1 taken 0%
        -:   83:    return false;
 11181653:   84:  Operation *yieldOp = block.getTerminator();
call    0 returned 100%
branch  1 taken 100% (fallthrough)
branch  2 taken 0%
 11181653:   85:  if (yieldOp->getNumOperands() != 1)
branch  0 taken 100% (fallthrough)
branch  1 taken 0%
        -:   86:    return false;
        -:   87:
 11181653:   88:  AddOpType addOp = getSingleOpOfType<AddOpType>(block);
call    0 returned 100%
 11181653:   89:  MulOpType mulOp = getSingleOpOfType<MulOpType>(block);
call    0 returned 100%
branch  1 taken 0% (fallthrough)
branch  2 taken 100%
11181653*:   90:  if (!addOp || !mulOp)
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
branch  2 never executed
branch  3 never executed
        -:   91:    return false;
        -:   92:
    #####:   93:  Value argA = block.getArgument(0), argB = block.getArgument(1);
    #####:   94:  Value a = mulOp->getOperand(0), b = mulOp->getOperand(1);
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:   95:  Value mul = mulOp->getResult(0);
call    0 never executed
    #####:   96:  Value argC = block.getArgument(2);
    #####:   97:  Value c1 = addOp->getOperand(0), c2 = addOp->getOperand(1);
call    0 never executed
call    1 never executed
    #####:   98:  Value add = addOp->getResult(0);
call    0 never executed
    #####:   99:  Value res = yieldOp->getOperand(0);
        -:  100:  // Result traces back to add.
    #####:  101:  auto un = isChainOfUnaryOpsFrom;
    #####:  102:  bool success = un(res, add);
call    0 never executed
        -:  103:  // One of the operands of add traces back to argC, the other to the mul.
    #####:  104:  success |= (un(c1, argC) && un(c2, mul)) || ((un(c1, mul)) && un(c2, argC));
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
branch  4 never executed
branch  5 never executed
call    6 never executed
branch  7 never executed
branch  8 never executed
call    9 never executed
branch 10 never executed
branch 11 never executed
        -:  105:  // One of the operands of mul traces back to argA, the other to argB.
    #####:  106:  success |= (un(a, argA) && un(b, argB)) || ((un(a, argB)) && un(b, argA));
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
branch  4 never executed
branch  5 never executed
call    6 never executed
branch  7 never executed
branch  8 never executed
call    9 never executed
branch 10 never executed
branch 11 never executed
    #####:  107:  return success;
        -:  108:}
------------------
_Z8isAddMulIN4mlir5arith6AddIOpENS1_6MulIOpEEbRNS0_5BlockE:
function _Z8isAddMulIN4mlir5arith6AddIOpENS1_6MulIOpEEbRNS0_5BlockE called 43992179 returned 100% blocks executed 69%
 43992179:   81:static bool isAddMul(Block &block) {
branch  0 taken 100% (fallthrough)
branch  1 taken 0%
 43992179:   82:  if (block.getNumArguments() != 3)
branch  0 taken 100% (fallthrough)
branch  1 taken 0%
        -:   83:    return false;
 43992179:   84:  Operation *yieldOp = block.getTerminator();
call    0 returned 100%
branch  1 taken 100% (fallthrough)
branch  2 taken 0%
 43992179:   85:  if (yieldOp->getNumOperands() != 1)
branch  0 taken 100% (fallthrough)
branch  1 taken 0%
        -:   86:    return false;
        -:   87:
 43992179:   88:  AddOpType addOp = getSingleOpOfType<AddOpType>(block);
call    0 returned 100%
 43992179:   89:  MulOpType mulOp = getSingleOpOfType<MulOpType>(block);
call    0 returned 100%
branch  1 taken 75% (fallthrough)
branch  2 taken 25%
 43992179:   90:  if (!addOp || !mulOp)
branch  0 taken 75% (fallthrough)
branch  1 taken 25%
branch  2 taken 100% (fallthrough)
branch  3 taken 0%
        -:   91:    return false;
        -:   92:
 32810526:   93:  Value argA = block.getArgument(0), argB = block.getArgument(1);
 65621052:   94:  Value a = mulOp->getOperand(0), b = mulOp->getOperand(1);
call    0 returned 100%
call    1 returned 100%
call    2 returned 100%
call    3 returned 100%
 32810526:   95:  Value mul = mulOp->getResult(0);
call    0 returned 100%
 32810526:   96:  Value argC = block.getArgument(2);
 32810526:   97:  Value c1 = addOp->getOperand(0), c2 = addOp->getOperand(1);
call    0 returned 100%
call    1 returned 100%
 32810526:   98:  Value add = addOp->getResult(0);
call    0 returned 100%
 32810526:   99:  Value res = yieldOp->getOperand(0);
        -:  100:  // Result traces back to add.
 32810526:  101:  auto un = isChainOfUnaryOpsFrom;
 32810526:  102:  bool success = un(res, add);
call    0 returned 100%
        -:  103:  // One of the operands of add traces back to argC, the other to the mul.
32810526*:  104:  success |= (un(c1, argC) && un(c2, mul)) || ((un(c1, mul)) && un(c2, argC));
call    0 returned 100%
branch  1 taken 100% (fallthrough)
branch  2 taken 0%
call    3 returned 100%
branch  4 taken 0% (fallthrough)
branch  5 taken 100%
call    6 never executed
branch  7 never executed
branch  8 never executed
call    9 never executed
branch 10 never executed
branch 11 never executed
        -:  105:  // One of the operands of mul traces back to argA, the other to argB.
32810526*:  106:  success |= (un(a, argA) && un(b, argB)) || ((un(a, argB)) && un(b, argA));
call    0 returned 100%
branch  1 taken 100% (fallthrough)
branch  2 taken 0%
call    3 returned 100%
branch  4 taken 0% (fallthrough)
branch  5 taken 100%
call    6 never executed
branch  7 never executed
branch  8 never executed
call    9 never executed
branch 10 never executed
branch 11 never executed
 32810526:  107:  return success;
        -:  108:}
------------------
_Z8isAddMulIN4mlir5arith6AddFOpENS1_6MulFOpEEbRNS0_5BlockE:
function _Z8isAddMulIN4mlir5arith6AddFOpENS1_6MulFOpEEbRNS0_5BlockE called 59330470 returned 100% blocks executed 69%
 59330470:   81:static bool isAddMul(Block &block) {
branch  0 taken 100% (fallthrough)
branch  1 taken 0%
 59330470:   82:  if (block.getNumArguments() != 3)
branch  0 taken 100% (fallthrough)
branch  1 taken 0%
        -:   83:    return false;
 59330470:   84:  Operation *yieldOp = block.getTerminator();
call    0 returned 100%
branch  1 taken 100% (fallthrough)
branch  2 taken 0%
 59330470:   85:  if (yieldOp->getNumOperands() != 1)
branch  0 taken 100% (fallthrough)
branch  1 taken 0%
        -:   86:    return false;
        -:   87:
 59330470:   88:  AddOpType addOp = getSingleOpOfType<AddOpType>(block);
call    0 returned 100%
 59330470:   89:  MulOpType mulOp = getSingleOpOfType<MulOpType>(block);
call    0 returned 100%
branch  1 taken 26% (fallthrough)
branch  2 taken 74%
 59330470:   90:  if (!addOp || !mulOp)
branch  0 taken 26% (fallthrough)
branch  1 taken 74%
branch  2 taken 100% (fallthrough)
branch  3 taken 0%
        -:   91:    return false;
        -:   92:
 15338291:   93:  Value argA = block.getArgument(0), argB = block.getArgument(1);
 30676582:   94:  Value a = mulOp->getOperand(0), b = mulOp->getOperand(1);
call    0 returned 100%
call    1 returned 100%
call    2 returned 100%
call    3 returned 100%
 15338291:   95:  Value mul = mulOp->getResult(0);
call    0 returned 100%
 15338291:   96:  Value argC = block.getArgument(2);
 15338291:   97:  Value c1 = addOp->getOperand(0), c2 = addOp->getOperand(1);
call    0 returned 100%
call    1 returned 100%
 15338291:   98:  Value add = addOp->getResult(0);
call    0 returned 100%
 15338291:   99:  Value res = yieldOp->getOperand(0);
        -:  100:  // Result traces back to add.
 15338291:  101:  auto un = isChainOfUnaryOpsFrom;
 15338291:  102:  bool success = un(res, add);
call    0 returned 100%
        -:  103:  // One of the operands of add traces back to argC, the other to the mul.
15338291*:  104:  success |= (un(c1, argC) && un(c2, mul)) || ((un(c1, mul)) && un(c2, argC));
call    0 returned 100%
branch  1 taken 100% (fallthrough)
branch  2 taken 0%
call    3 returned 100%
branch  4 taken 0% (fallthrough)
branch  5 taken 100%
call    6 never executed
branch  7 never executed
branch  8 never executed
call    9 never executed
branch 10 never executed
branch 11 never executed
        -:  105:  // One of the operands of mul traces back to argA, the other to argB.
15338291*:  106:  success |= (un(a, argA) && un(b, argB)) || ((un(a, argB)) && un(b, argA));
call    0 returned 100%
branch  1 taken 100% (fallthrough)
branch  2 taken 0%
call    3 returned 100%
branch  4 taken 0% (fallthrough)
branch  5 taken 100%
call    6 never executed
branch  7 never executed
branch  8 never executed
call    9 never executed
branch 10 never executed
branch 11 never executed
 15338291:  107:  return success;
        -:  108:}
------------------
        -:  109:
        -:  110:enum class MatchContractionResult {
        -:  111:  Success = 0,
        -:  112:  NotLinalgOp,
        -:  113:  WrongNumOperands,
        -:  114:  NoReduction,
        -:  115:  NotProjectedPermutations,
        -:  116:  NotAddMul
        -:  117:};
function _ZL26isContractionInterfaceImplPN4mlir9OperationE called 59330470 returned 100% blocks executed 94%
 59330470:  118:static MatchContractionResult isContractionInterfaceImpl(Operation *op) {
 59330470:  119:  auto linalgOp = dyn_cast<linalg::LinalgOp>(op);
call    0 returned 100%
 59330470:  120:  if (!linalgOp)
branch  0 taken 100% (fallthrough)
branch  1 taken 0%
        -:  121:    return MatchContractionResult::NotLinalgOp;
177991409:  122:  if (linalgOp.getNumDpsInputs() != 2 || linalgOp.getNumDpsInits() != 1)
call    0 returned 100%
branch  1 taken 100% (fallthrough)
branch  2 taken 0%
branch  3 taken 0% (fallthrough)
branch  4 taken 100%
    #####:  123:    return MatchContractionResult::WrongNumOperands;
 59330469:  124:  auto mapRange = linalgOp.getIndexingMapsArray();
call    0 returned 100%
 59330470:  125:  if (linalgOp.getNumReductionLoops() == 0)
call    0 returned 100%
branch  1 taken 100% (fallthrough)
branch  2 taken 0%
        -:  126:    return MatchContractionResult::NoReduction;
 59330469:  127:  if (llvm::any_of(mapRange,
call    0 returned 100%
branch  1 taken 100% (fallthrough)
branch  2 taken 0%
        -:  128:                   [](AffineMap m) { return !m.isProjectedPermutation(); }))
        -:  129:    return MatchContractionResult::NotProjectedPermutations;
        -:  130:  // TODO: more fields than add/mul.
103322649:  131:  if (!isAddMul<arith::AddFOp, arith::MulFOp>(linalgOp->getRegion(0).front()) &&
call    0 returned 100%
call    1 returned 100%
call    2 returned 100%
branch  3 taken 25% (fallthrough)
branch  4 taken 75%
 55173832:  132:      !isAddMul<arith::AddIOp, arith::MulIOp>(linalgOp->getRegion(0).front()) &&
call    0 returned 100%
call    1 returned 100%
call    2 returned 100%
branch  3 taken 100% (fallthrough)
branch  4 taken 0%
 11181653:  133:      !isAddMul<complex::AddOp, complex::MulOp>(
call    0 returned 100%
 81693776:  134:          linalgOp->getRegion(0).front()) &&
branch  0 taken 74% (fallthrough)
branch  1 taken 26%
call    2 returned 100%
call    3 returned 100%
branch  4 taken 1% (fallthrough)
branch  5 taken 100%
 11181653:  135:      !isAddMul<arith::OrIOp, arith::AndIOp>(linalgOp->getRegion(0).front()))
call    0 returned 100%
call    1 returned 100%
call    2 returned 100%
     1248:  136:    return MatchContractionResult::NotAddMul;
        -:  137:  return MatchContractionResult::Success;
        -:  138:}
        -:  139:
function _ZN4mlir6linalg25isaContractionOpInterfaceENS0_8LinalgOpE called 0 returned 0% blocks executed 0%
    #####:  140:bool mlir::linalg::isaContractionOpInterface(LinalgOp linalgOp) {
    #####:  141:  if (!linalgOp)
branch  0 never executed
branch  1 never executed
        -:  142:    return false;
    #####:  143:  Operation *op = linalgOp.getOperation();
call    0 never executed
    #####:  144:  return isa<ContractionOpInterface>(op) ||
call    0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
    #####:  145:         (isContractionInterfaceImpl(op) == MatchContractionResult::Success);
call    0 never executed
        -:  146:}
        -:  147:
        -:  148:/// Verify that a LinalgOp `op` is a contraction.
        -:  149:/// A Linalg contraction is defined in general terms:
        -:  150:///   1. Has 2 input and 1 output shapes.
        -:  151:///   2. Has at least one reduction dimension.
        -:  152:///   3. Has only projected permutation indexing maps.
        -:  153:///   4. its body computes `u5(u1(c) + u2(u3(a) * u4(b)))` on some field
        -:  154:///   (AddOpType, MulOpType), where u1, u2, u3, u4 and u5 represent scalar unary
        -:  155:///   operations that may change the type (e.g. for mixed-precision).
        -:  156:/// As a consequence, when vectorization of such an op occurs, the only special
        -:  157:/// behavior is that the (unique) MulOpType is vectorized into a
        -:  158:/// `vector.contract`. All other ops are handled in a generic fashion.
        -:  159:/// In the future, we may wish to allow more input arguments and elementwise and
        -:  160:/// constant operations that do not involve the reduction dimension(s).
function _ZN4mlir6linalg6detail26verifyContractionInterfaceEPNS_9OperationE called 59330470 returned 100% blocks executed 39%
 59330470:  161:LogicalResult mlir::linalg::detail::verifyContractionInterface(Operation *op) {
 59330470:  162:  auto res = isContractionInterfaceImpl(op);
call    0 returned 100%
 59330470:  163:  if (res == MatchContractionResult::NotLinalgOp)
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
    #####:  164:    return op->emitError("expected a LinalgOp");
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
 59330470:  165:  if (res == MatchContractionResult::WrongNumOperands)
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
    #####:  166:    return op->emitError("expected op with 2 inputs and 1 outputs");
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
 59330470:  167:  if (res == MatchContractionResult::NoReduction)
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
    #####:  168:    return op->emitError("expected at least a reduction loop");
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
 59330470:  169:  if (res == MatchContractionResult::NotProjectedPermutations)
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
    #####:  170:    return op->emitError("expected all indexings to be projected permutations");
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
 59330470:  171:  if (res == MatchContractionResult::NotAddMul)
branch  0 taken 1% (fallthrough)
branch  1 taken 100%
     1248:  172:    return op->emitError("(add, mul) operations not found");
call    0 returned 100%
call    1 returned 100%
call    2 returned 100%
call    3 returned 100%
 59329222:  173:  return success();
        -:  174:}
        -:  175:
        -:  176://===----------------------------------------------------------------------===//
        -:  177:// ConvolutionOpInterface implementation
        -:  178://===----------------------------------------------------------------------===//
        -:  179:
        -:  180:/// Of the given two expressions returns one that is of type T (`lhs` gets
        -:  181:/// preference over `rhs`)
        -:  182:template <typename T>
    #####:  183:static T getAffineExprOfType(AffineExpr lhs, AffineExpr rhs) {
    #####:  184:  return lhs.isa<T>() ? lhs.cast<T>()
    #####:  185:                      : (rhs.isa<T>() ? rhs.cast<T>() : nullptr);
        -:  186:}
------------------
_Z19getAffineExprOfTypeIN4mlir13AffineDimExprEET_NS0_10AffineExprES3_:
function _Z19getAffineExprOfTypeIN4mlir13AffineDimExprEET_NS0_10AffineExprES3_ called 0 returned 0% blocks executed 0%
    #####:  183:static T getAffineExprOfType(AffineExpr lhs, AffineExpr rhs) {
call    0 never executed
    #####:  184:  return lhs.isa<T>() ? lhs.cast<T>()
call    0 never executed
    #####:  185:                      : (rhs.isa<T>() ? rhs.cast<T>() : nullptr);
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
call    4 never executed
call    5 never executed
        -:  186:}
------------------
_Z19getAffineExprOfTypeIN4mlir18AffineConstantExprEET_NS0_10AffineExprES3_:
function _Z19getAffineExprOfTypeIN4mlir18AffineConstantExprEET_NS0_10AffineExprES3_ called 0 returned 0% blocks executed 0%
    #####:  183:static T getAffineExprOfType(AffineExpr lhs, AffineExpr rhs) {
call    0 never executed
    #####:  184:  return lhs.isa<T>() ? lhs.cast<T>()
call    0 never executed
    #####:  185:                      : (rhs.isa<T>() ? rhs.cast<T>() : nullptr);
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
call    4 never executed
call    5 never executed
        -:  186:}
------------------
_Z19getAffineExprOfTypeIN4mlir16AffineSymbolExprEET_NS0_10AffineExprES3_:
function _Z19getAffineExprOfTypeIN4mlir16AffineSymbolExprEET_NS0_10AffineExprES3_ called 0 returned 0% blocks executed 0%
    #####:  183:static T getAffineExprOfType(AffineExpr lhs, AffineExpr rhs) {
call    0 never executed
    #####:  184:  return lhs.isa<T>() ? lhs.cast<T>()
call    0 never executed
    #####:  185:                      : (rhs.isa<T>() ? rhs.cast<T>() : nullptr);
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
call    4 never executed
call    5 never executed
        -:  186:}
------------------
        -:  187:
        -:  188:namespace {
        -:  189:/// Walk the indexing expressions for input of a convolution operation to verify
        -:  190:/// its of the right form, either
        -:  191:/// - AffineDimExpr
        -:  192:/// - AffineDimExpr (`*` (AffineSymbolExpr | AffineConstantExpr))?
        -:  193:///      (`+` AffineDimExpr (`*` (AffineSymbolExpr | AffineConstantExpr))?)*
        -:  194:///
        -:  195:/// classifies the AffineDimExpr as convolved dimensions or unconvolved
        -:  196:/// dimensions and verifies each dimension occurs only once.
    #####:  197:struct ConvAccessExprWalker
call    0 never executed
call    1 never executed
        -:  198:    : public AffineExprVisitor<ConvAccessExprWalker, LogicalResult> {
        -:  199:  llvm::SmallDenseSet<unsigned> convolvedDims;
        -:  200:  llvm::SmallDenseSet<unsigned> unConvolvedDims;
        -:  201:
function _ZN12_GLOBAL__N_120ConvAccessExprWalker12visitDimExprEN4mlir13AffineDimExprE called 0 returned 0% blocks executed 0%
    #####:  202:  LogicalResult visitDimExpr(AffineDimExpr dimExpr) {
    #####:  203:    unsigned position = dimExpr.getPosition();
call    0 never executed
    #####:  204:    if (unConvolvedDims.count(position) || convolvedDims.count(position)) {
call    0 never executed
call    1 never executed
    #####:  205:      return failure();
        -:  206:    }
    #####:  207:    unConvolvedDims.insert(position);
call    0 never executed
    #####:  208:    return success();
        -:  209:  }
        -:  210:
    #####:  211:  LogicalResult visitSymbolExpr(AffineSymbolExpr expr) { return failure(); }
        -:  212:
    #####:  213:  LogicalResult visitConstantExpr(AffineConstantExpr expr) { return failure(); }
        -:  214:
function _ZN12_GLOBAL__N_120ConvAccessExprWalker23visitAffineBinaryOpExprEN4mlir18AffineBinaryOpExprE called 0 returned 0% blocks executed 0%
    #####:  215:  LogicalResult visitAffineBinaryOpExpr(AffineBinaryOpExpr binaryExpr) {
        -:  216:    // In pre-order visit, top level op has to be an add op.
    #####:  217:    if (binaryExpr.getKind() != AffineExprKind::Add)
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  218:      return failure();
    #####:  219:    return success(succeeded(isDimExprOrMulExpr(binaryExpr.getLHS())) &&
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  220:                   succeeded(isDimExprOrMulExpr(binaryExpr.getRHS())));
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
        -:  221:  }
        -:  222:
function _ZN12_GLOBAL__N_120ConvAccessExprWalker18isDimExprOrMulExprEN4mlir10AffineExprE called 0 returned 0% blocks executed 0%
    #####:  223:  LogicalResult isDimExprOrMulExpr(AffineExpr expr) {
    #####:  224:    if (auto dimExpr = expr.dyn_cast<AffineDimExpr>()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  225:      unsigned dim = dimExpr.getPosition();
call    0 never executed
    #####:  226:      if (convolvedDims.count(dim) || unConvolvedDims.count(dim))
call    0 never executed
call    1 never executed
    #####:  227:        return failure();
    #####:  228:      convolvedDims.insert(dim);
call    0 never executed
    #####:  229:      return success();
        -:  230:    }
    #####:  231:    if (auto symbolMulExpr = expr.dyn_cast<AffineBinaryOpExpr>()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  232:      if (symbolMulExpr.getKind() != AffineExprKind::Mul)
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  233:        return failure();
    #####:  234:      auto lhsExpr = symbolMulExpr.getLHS();
call    0 never executed
    #####:  235:      auto rhsExpr = symbolMulExpr.getRHS();
call    0 never executed
        -:  236:      // Check for symbol expression.
    #####:  237:      AffineExpr mulExpr =
    #####:  238:          getAffineExprOfType<AffineSymbolExpr>(lhsExpr, rhsExpr);
call    0 never executed
        -:  239:      // If there was no symbol expr, check for constant expression.
    #####:  240:      if (!mulExpr) {
branch  0 never executed
branch  1 never executed
    #####:  241:        mulExpr = getAffineExprOfType<AffineConstantExpr>(lhsExpr, rhsExpr);
call    0 never executed
        -:  242:      }
    #####:  243:      auto dimExpr = getAffineExprOfType<AffineDimExpr>(lhsExpr, rhsExpr);
call    0 never executed
    #####:  244:      if (!mulExpr || !dimExpr)
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####:  245:        return failure();
    #####:  246:      unsigned dim = dimExpr.getPosition();
call    0 never executed
    #####:  247:      if (convolvedDims.count(dim) || unConvolvedDims.count(dim))
call    0 never executed
call    1 never executed
    #####:  248:        return failure();
    #####:  249:      convolvedDims.insert(dim);
call    0 never executed
    #####:  250:      return success();
        -:  251:    }
    #####:  252:    return failure();
        -:  253:  }
        -:  254:};
        -:  255:} // namespace
        -:  256:
function _ZL16getPreservedDimsN4mlir9AffineMapE called 0 returned 0% blocks executed 0%
    #####:  257:static llvm::SmallDenseSet<unsigned> getPreservedDims(AffineMap map) {
    #####:  258:  assert(map.isProjectedPermutation() &&
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
        -:  259:         "expected map to have projected permutations");
    #####:  260:  llvm::SmallDenseSet<unsigned> preservedDims;
call    0 never executed
    #####:  261:  for (auto expr : map.getResults())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  262:    preservedDims.insert(expr.cast<AffineDimExpr>().getPosition());
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  263:  return preservedDims;
        -:  264:}
        -:  265:
        -:  266:enum class MatchConvolutionResult {
        -:  267:  Success = 0,
        -:  268:  NotLinalgOp,
        -:  269:  WrongNumOperands,
        -:  270:  WrongInputIndexingMap,
        -:  271:  NotProjectedPermutations,
        -:  272:  NonConvolutionLoop,
        -:  273:  OutputDimsNotParallel,
        -:  274:  NonOutputDimNotReduction
        -:  275:};
        -:  276:
function _ZL26isConvolutionInterfaceImplPN4mlir9OperationE called 0 returned 0% blocks executed 0%
    #####:  277:static MatchConvolutionResult isConvolutionInterfaceImpl(Operation *op) {
    #####:  278:  auto linalgOp = dyn_cast<linalg::LinalgOp>(op);
call    0 never executed
    #####:  279:  if (!linalgOp)
branch  0 never executed
branch  1 never executed
        -:  280:    return MatchConvolutionResult::NotLinalgOp;
    #####:  281:  if (linalgOp.getNumDpsInputs() < 2 || linalgOp.getNumDpsInits() != 1)
call    0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
    #####:  282:    return MatchConvolutionResult::WrongNumOperands;
        -:  283:
    #####:  284:  auto indexingMaps = linalgOp.getIndexingMapsArray();
call    0 never executed
        -:  285:
        -:  286:  // Check the input indexing map has the right form.
    #####:  287:  ConvAccessExprWalker inputExprWalker;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  288:  if (llvm::any_of(indexingMaps[0].getResults(),
branch  0 never executed
branch  1 never executed
call    2 never executed
call    3 never executed
branch  4 never executed
branch  5 never executed
        -:  289:                   [&inputExprWalker](AffineExpr expr) {
        -:  290:                     return failed(inputExprWalker.visit(expr));
        -:  291:                   })) {
        -:  292:    return MatchConvolutionResult::WrongInputIndexingMap;
        -:  293:  }
        -:  294:
        -:  295:  // Filter and output maps must be projected permutation.
    #####:  296:  if (!indexingMaps[1].isProjectedPermutation() ||
branch  0 never executed
branch  1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
branch  6 never executed
    #####:  297:      !indexingMaps.back().isProjectedPermutation())
call    0 never executed
call    1 never executed
    #####:  298:    return MatchConvolutionResult::NotProjectedPermutations;
        -:  299:
    #####:  300:  auto iteratorTypes = linalgOp.getIteratorTypesArray();
call    0 never executed
call    1 never executed
        -:  301:
    #####:  302:  llvm::SmallDenseSet<unsigned> outputDims =
    #####:  303:      getPreservedDims(indexingMaps.back());
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  304:  llvm::SmallDenseSet<unsigned> filterDims = getPreservedDims(indexingMaps[1]);
branch  0 never executed
branch  1 never executed
call    2 never executed
call    3 never executed
        -:  305:  // Make sure all loops are charecterized as one of:
        -:  306:  // - Batch loop : present in output, as non-convolved in input, not present in
        -:  307:  //   filter.
        -:  308:  // - Output image dimension : present in output, convolved dims in input, not
        -:  309:  //   present in filter.
        -:  310:  // - Output channel dimension : present in output, not present in input,
        -:  311:  //   present in filter.
        -:  312:  // - Filter loop dimension : present in filter, convolved in input, not
        -:  313:  //   present in output.
        -:  314:  // - Input channel dimension : unconvolved in input, not present in output,
        -:  315:  //   present in filter.
        -:  316:  // - Depth multiplier : unconvolved in input, present in output, present in
        -:  317:  //   filter.
    #####:  318:  llvm::SmallDenseSet<unsigned> allLoopDims;
call    0 never executed
call    1 never executed
    #####:  319:  for (auto outputExpr : indexingMaps.back().getResults()) {
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  320:    unsigned outputDim = outputExpr.cast<AffineDimExpr>().getPosition();
call    0 never executed
call    1 never executed
    #####:  321:    if (inputExprWalker.unConvolvedDims.count(outputDim) &&
call    0 never executed
call    1 never executed
    #####:  322:        !filterDims.count(outputDim)) {
        -:  323:      // Batch dimension.
    #####:  324:      if (iteratorTypes[outputDim] != getParallelIteratorTypeName())
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####:  325:        return MatchConvolutionResult::OutputDimsNotParallel;
    #####:  326:      allLoopDims.insert(outputDim);
call    0 never executed
    #####:  327:      continue;
        -:  328:    }
    #####:  329:    if (inputExprWalker.convolvedDims.count(outputDim) &&
call    0 never executed
call    1 never executed
    #####:  330:        !filterDims.count(outputDim)) {
        -:  331:      // Output image Loop dimension.
    #####:  332:      if (iteratorTypes[outputDim] != getParallelIteratorTypeName())
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
        -:  333:        return MatchConvolutionResult::OutputDimsNotParallel;
    #####:  334:      allLoopDims.insert(outputDim);
call    0 never executed
    #####:  335:      continue;
        -:  336:    }
    #####:  337:    if (!inputExprWalker.convolvedDims.count(outputDim) &&
call    0 never executed
call    1 never executed
    #####:  338:        !inputExprWalker.unConvolvedDims.count(outputDim) &&
call    0 never executed
    #####:  339:        filterDims.count(outputDim)) {
        -:  340:      // Output channel dimension.
    #####:  341:      if (iteratorTypes[outputDim] != getParallelIteratorTypeName())
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
        -:  342:        return MatchConvolutionResult::OutputDimsNotParallel;
    #####:  343:      allLoopDims.insert(outputDim);
call    0 never executed
    #####:  344:      continue;
        -:  345:    }
    #####:  346:    if (inputExprWalker.unConvolvedDims.count(outputDim) &&
call    0 never executed
call    1 never executed
    #####:  347:        filterDims.count(outputDim)) {
        -:  348:      // Depth multiplier.
    #####:  349:      if (iteratorTypes[outputDim] != getParallelIteratorTypeName())
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
        -:  350:        return MatchConvolutionResult::OutputDimsNotParallel;
    #####:  351:      allLoopDims.insert(outputDim);
call    0 never executed
    #####:  352:      continue;
        -:  353:    }
        -:  354:    return MatchConvolutionResult::NonConvolutionLoop;
        -:  355:  }
    #####:  356:  for (auto filterExpr : indexingMaps[1].getResults()) {
branch  0 never executed
branch  1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
    #####:  357:    unsigned filterDim = filterExpr.cast<AffineDimExpr>().getPosition();
call    0 never executed
call    1 never executed
    #####:  358:    if (outputDims.count(filterDim) &&
call    0 never executed
call    1 never executed
    #####:  359:        !inputExprWalker.unConvolvedDims.count(filterDim) &&
call    0 never executed
    #####:  360:        !inputExprWalker.convolvedDims.count(filterDim)) {
        -:  361:      // Output channel dimension. THis is already seen, continue;
    #####:  362:      continue;
        -:  363:    }
    #####:  364:    if (inputExprWalker.convolvedDims.count(filterDim) &&
call    0 never executed
call    1 never executed
    #####:  365:        !outputDims.count(filterDim)) {
        -:  366:      // Filter loop dimension.
    #####:  367:      if (iteratorTypes[filterDim] != getReductionIteratorTypeName())
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####:  368:        return MatchConvolutionResult::NonOutputDimNotReduction;
    #####:  369:      if (allLoopDims.count(filterDim))
call    0 never executed
    #####:  370:        return MatchConvolutionResult::NonConvolutionLoop;
    #####:  371:      allLoopDims.insert(filterDim);
call    0 never executed
    #####:  372:      continue;
        -:  373:    }
    #####:  374:    if (inputExprWalker.unConvolvedDims.count(filterDim) &&
call    0 never executed
call    1 never executed
    #####:  375:        !outputDims.count(filterDim)) {
        -:  376:      // Input channel dimension.
    #####:  377:      if (iteratorTypes[filterDim] != getReductionIteratorTypeName())
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
        -:  378:        return MatchConvolutionResult::NonOutputDimNotReduction;
    #####:  379:      if (allLoopDims.count(filterDim))
call    0 never executed
    #####:  380:        return MatchConvolutionResult::NonConvolutionLoop;
    #####:  381:      allLoopDims.insert(filterDim);
call    0 never executed
    #####:  382:      continue;
        -:  383:    }
    #####:  384:    if (inputExprWalker.unConvolvedDims.count(filterDim) &&
call    0 never executed
call    1 never executed
    #####:  385:        outputDims.count(filterDim)) {
        -:  386:      // Depthwise loop. Already seen.
    #####:  387:      continue;
        -:  388:    }
        -:  389:    return MatchConvolutionResult::NonConvolutionLoop;
        -:  390:  }
        -:  391:  // All loops must be covered now.
    #####:  392:  if (allLoopDims.size() != linalgOp.getNumLoops())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  393:    return MatchConvolutionResult::NonConvolutionLoop;
        -:  394:
        -:  395:  return MatchConvolutionResult::Success;
        -:  396:}
        -:  397:
function _ZN4mlir6linalg6detail26verifyConvolutionInterfaceEPNS_9OperationE called 0 returned 0% blocks executed 0%
    #####:  398:LogicalResult mlir::linalg::detail::verifyConvolutionInterface(Operation *op) {
    #####:  399:  auto res = isConvolutionInterfaceImpl(op);
call    0 never executed
    #####:  400:  if (res == MatchConvolutionResult::NotLinalgOp)
branch  0 never executed
branch  1 never executed
    #####:  401:    return op->emitError("expected a LinalgOp");
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:  402:  if (res == MatchConvolutionResult::WrongNumOperands)
branch  0 never executed
branch  1 never executed
    #####:  403:    return op->emitError("expected op with 2 inputs and 1 output");
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:  404:  if (res == MatchConvolutionResult::WrongInputIndexingMap)
branch  0 never executed
branch  1 never executed
    #####:  405:    return op->emitError("unexpected input index map for convolutions");
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:  406:  if (res == MatchConvolutionResult::NotProjectedPermutations) {
branch  0 never executed
branch  1 never executed
    #####:  407:    return op->emitError(
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  408:        "expected output/filter indexing maps to be projected permutations");
call    0 never executed
        -:  409:  }
    #####:  410:  if (res == MatchConvolutionResult::NonConvolutionLoop) {
branch  0 never executed
branch  1 never executed
    #####:  411:    return op->emitError("unexpected loop dimension for convolution op");
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
        -:  412:  }
    #####:  413:  if (res == MatchConvolutionResult::OutputDimsNotParallel) {
branch  0 never executed
branch  1 never executed
    #####:  414:    return op->emitError(
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  415:        "expected all iterators used to access outputs to be parallel");
call    0 never executed
        -:  416:  }
    #####:  417:  if (res == MatchConvolutionResult::NonOutputDimNotReduction) {
branch  0 never executed
branch  1 never executed
    #####:  418:    return op->emitError(
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  419:        "expected all iterators not used to access outputs to be reduction");
call    0 never executed
        -:  420:  }
    #####:  421:  return success();
        -:  422:}
        -:  423:
        -:  424://===----------------------------------------------------------------------===//
        -:  425:// FillOpInterface implementation
        -:  426://===----------------------------------------------------------------------===//
        -:  427:
        -:  428:enum class MatchFillResult {
        -:  429:  Success = 0,
        -:  430:  NotLinalgOp,
        -:  431:  WrongNumOperands,
        -:  432:  NotScalarInput
        -:  433:};
        -:  434:
function _ZL19isFillInterfaceImplPN4mlir9OperationE called 0 returned 0% blocks executed 0%
    #####:  435:static MatchFillResult isFillInterfaceImpl(Operation *op) {
    #####:  436:  auto linalgOp = dyn_cast<linalg::LinalgOp>(op);
call    0 never executed
    #####:  437:  if (!linalgOp)
branch  0 never executed
branch  1 never executed
        -:  438:    return MatchFillResult::NotLinalgOp;
    #####:  439:  if (linalgOp.getNumDpsInputs() != 1 || linalgOp.getNumDpsInits() != 1)
call    0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
    #####:  440:    return MatchFillResult::WrongNumOperands;
        -:  441:
    #####:  442:  OpOperand *value = linalgOp.getDpsInputOperand(0);
call    0 never executed
    #####:  443:  if (!linalgOp.isScalar(value))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  444:    return MatchFillResult::NotScalarInput;
        -:  445:
        -:  446:  return MatchFillResult::Success;
        -:  447:}
        -:  448:
function _ZN4mlir6linalg6detail19verifyFillInterfaceEPNS_9OperationE called 0 returned 0% blocks executed 0%
    #####:  449:LogicalResult mlir::linalg::detail::verifyFillInterface(Operation *op) {
    #####:  450:  auto res = isFillInterfaceImpl(op);
call    0 never executed
    #####:  451:  if (res == MatchFillResult::NotLinalgOp)
branch  0 never executed
branch  1 never executed
    #####:  452:    return op->emitError("expected a LinalgOp");
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:  453:  if (res == MatchFillResult::WrongNumOperands)
branch  0 never executed
branch  1 never executed
    #####:  454:    return op->emitError("expected op with 1 input and 1 output");
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:  455:  if (res == MatchFillResult::NotScalarInput)
branch  0 never executed
branch  1 never executed
    #####:  456:    return op->emitError("expected op with scalar input");
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
        -:  457:
    #####:  458:  return success();
        -:  459:}
        -:  460:
        -:  461://===----------------------------------------------------------------------===//
        -:  462:// StructuredOpInterface implementation
        -:  463://===----------------------------------------------------------------------===//
        -:  464:
        -:  465:/// Helper function that creates a memref::DimOp or tensor::DimOp depending on
        -:  466:/// the type of `source`.
function _ZL17createOrFoldDimOpRN4mlir9OpBuilderENS_8LocationENS_5ValueEl called 0 returned 0% blocks executed 0%
    #####:  467:static Value createOrFoldDimOp(OpBuilder &b, Location loc, Value source,
        -:  468:                               int64_t dim) {
    #####:  469:  if (source.getType().isa<UnrankedMemRefType, MemRefType>())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  470:    return b.createOrFold<memref::DimOp>(loc, source, dim);
call    0 never executed
    #####:  471:  if (source.getType().isa<UnrankedTensorType, RankedTensorType>())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  472:    return b.createOrFold<tensor::DimOp>(loc, source, dim);
call    0 never executed
    #####:  473:  llvm_unreachable("Expected MemRefType or TensorType");
call    0 never executed
        -:  474:}
function _ZL17createFoldedDimOpRN4mlir9OpBuilderENS_8LocationENS_5ValueEl called 176 returned 100% blocks executed 77%
      176:  475:static OpFoldResult createFoldedDimOp(OpBuilder &b, Location loc, Value source,
        -:  476:                                      int64_t dim) {
      176:  477:  auto shapedType = source.getType().cast<ShapedType>();
call    0 returned 100%
      176:  478:  if (!shapedType.hasRank() || shapedType.isDynamicDim(dim))
call    0 returned 100%
branch  1 taken 100% (fallthrough)
branch  2 taken 0%
call    3 returned 100%
branch  4 taken 0% (fallthrough)
branch  5 taken 100%
    #####:  479:    return createOrFoldDimOp(b, loc, source, dim);
call    0 never executed
call    1 never executed
      176:  480:  return b.getIndexAttr(shapedType.getDimSize(dim));
call    0 returned 100%
call    1 returned 100%
call    2 returned 100%
        -:  481:}
        -:  482:
function _ZN4mlir6linalg8LinalgOp27createFlatListOfOperandDimsERNS_9OpBuilderENS_8LocationE called 33 returned 100% blocks executed 100%
       33:  483:SmallVector<OpFoldResult> LinalgOp::createFlatListOfOperandDims(OpBuilder &b,
        -:  484:                                                                Location loc) {
       33:  485:  SmallVector<OpFoldResult> res;
call    0 returned 100%
       99:  486:  for (OpOperand &opOperand : getOperation()->getOpOperands()) {
call    0 returned 100%
branch  1 taken 67% (fallthrough)
branch  2 taken 33%
      242:  487:    for (int64_t i = 0, e = getRank(&opOperand); i < e; ++i)
call    0 returned 100%
branch  1 taken 73% (fallthrough)
branch  2 taken 27%
      176:  488:      res.push_back(createFoldedDimOp(b, loc, opOperand.get(), i));
call    0 returned 100%
call    1 returned 100%
        -:  489:  }
       33:  490:  return res;
        -:  491:}
        -:  492:
function _ZN4mlir6linalg8LinalgOp33createFlatListOfOperandStaticDimsEv called 0 returned 0% blocks executed 0%
    #####:  493:SmallVector<int64_t, 4> LinalgOp::createFlatListOfOperandStaticDims() {
    #####:  494:  SmallVector<int64_t, 4> res;
call    0 never executed
    #####:  495:  assert(!hasDynamicShape() && "expected operands to have static shapes");
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
    #####:  496:  for (OpOperand &opOperand : getOperation()->getOpOperands())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  497:    llvm::append_range(res, getShape(&opOperand));
call    0 never executed
call    1 never executed
    #####:  498:  return res;
        -:  499:}
        -:  500:
function _ZN4mlir6linalg8LinalgOp16createLoopRangesERNS_9OpBuilderENS_8LocationE called 17 returned 100% blocks executed 87%
       17:  501:SmallVector<Range, 4> LinalgOp::createLoopRanges(OpBuilder &b, Location loc) {
       17:  502:  AffineMap map = getLoopsToShapesMap();
call    0 returned 100%
       17:  503:  unsigned numDims = map.getNumDims(), numRes = map.getNumResults();
call    0 returned 100%
call    1 returned 100%
       17:  504:  auto viewSizes = createFlatListOfOperandDims(b, loc);
call    0 returned 100%
       17:  505:  SmallVector<Range, 4> res(numDims);
call    0 returned 100%
       97:  506:  for (unsigned idx = 0; idx < numRes; ++idx) {
branch  0 taken 82% (fallthrough)
branch  1 taken 18%
       80:  507:    auto result = map.getResult(idx);
call    0 returned 100%
       80:  508:    if (auto d = result.dyn_cast<AffineDimExpr>()) {
call    0 returned 100%
branch  1 taken 100% (fallthrough)
branch  2 taken 0%
       80:  509:      if (res[d.getPosition()].offset)
call    0 returned 100%
branch  1 taken 0% (fallthrough)
branch  2 taken 100%
branch  3 taken 50% (fallthrough)
branch  4 taken 50%
       40:  510:        continue;
       40:  511:      res[d.getPosition()] =
call    0 returned 100%
branch  1 taken 0% (fallthrough)
branch  2 taken 100%
       40:  512:          Range{b.getIndexAttr(0), viewSizes[idx], b.getIndexAttr(1)};
call    0 returned 100%
call    1 returned 100%
branch  2 taken 0% (fallthrough)
branch  3 taken 100%
call    4 returned 100%
call    5 returned 100%
        -:  513:    }
        -:  514:  }
       17:  515:  return res;
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
        -:  516:}
        -:  517:
function _ZN4mlir6linalg8LinalgOp22computeStaticLoopSizesEv called 0 returned 0% blocks executed 0%
    #####:  518:SmallVector<int64_t, 4> LinalgOp::computeStaticLoopSizes() {
    #####:  519:  AffineMap map = getLoopsToShapesMap();
call    0 never executed
    #####:  520:  unsigned numDims = map.getNumDims(), numRes = map.getNumResults();
call    0 never executed
call    1 never executed
    #####:  521:  SmallVector<int64_t, 4> allShapeSizes = createFlatListOfOperandStaticDims();
call    0 never executed
    #####:  522:  SmallVector<int64_t, 4> res(numDims, 0);
call    0 never executed
    #####:  523:  for (unsigned idx = 0; idx < numRes; ++idx) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  524:    auto result = map.getResult(idx);
call    0 never executed
    #####:  525:    if (auto d = result.dyn_cast<AffineDimExpr>())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  526:      res[d.getPosition()] = allShapeSizes[idx];
branch  0 never executed
branch  1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
        -:  527:  }
    #####:  528:  return res;
branch  0 never executed
branch  1 never executed
        -:  529:}
        -:  530:
        -:  531:/// Visitor to check if any of the given set of positions from AffineDimExprs
        -:  532:/// are used within an AffineExpr.
       32:  533:struct HasAffineDimExprVisitor
        -:  534:    : public AffineExprVisitor<HasAffineDimExprVisitor, bool> {
       16:  535:  HasAffineDimExprVisitor(llvm::SmallBitVector positions)
       16:  536:      : positions(std::move(positions)) {}
call    0 returned 100%
        -:  537:
function _ZN23HasAffineDimExprVisitor23visitAffineBinaryOpExprEN4mlir18AffineBinaryOpExprE called 0 returned 0% blocks executed 0%
    #####:  538:  bool visitAffineBinaryOpExpr(AffineBinaryOpExpr binaryOpExpr) {
    #####:  539:    return visit(binaryOpExpr.getLHS()) || visit(binaryOpExpr.getRHS());
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
call    4 never executed
call    5 never executed
branch  6 never executed
branch  7 never executed
        -:  540:  }
        -:  541:
       48:  542:  bool visitDimExpr(AffineDimExpr dimExpr) {
       48:  543:    return positions.test(dimExpr.getPosition());
call    0 returned 100%
call    1 returned 100%
        -:  544:  }
        -:  545:
    #####:  546:  bool visitConstantExpr(AffineConstantExpr constExpr) { return false; }
call    0 never executed
        -:  547:
    #####:  548:  bool visitSymbolExpr(AffineSymbolExpr symbolExpr) { return false; }
call    0 never executed
        -:  549:
        -:  550:private:
        -:  551:  llvm::SmallBitVector positions;
        -:  552:};
        -:  553:
        -:  554:static std::pair<int64_t, int64_t>
function _ZL35getResultsPositionInLoopsToShapeMapRN4mlir6linalg8LinalgOpE called 16 returned 100% blocks executed 88%
       16:  555:getResultsPositionInLoopsToShapeMap(LinalgOp &op) {
       16:  556:  int64_t inputRankSum = 0;
       16:  557:  int64_t outputRankSum = 0;
       48:  558:  for (OpOperand *input : op.getDpsInputOperands())
call    0 returned 100%
branch  1 taken 50% (fallthrough)
branch  2 taken 50%
       16:  559:    inputRankSum += op.getRank(input);
call    0 returned 100%
       48:  560:  for (OpOperand *output : op.getDpsInitOperands())
call    0 returned 100%
branch  1 taken 50% (fallthrough)
branch  2 taken 50%
       16:  561:    outputRankSum += op.getRank(output);
call    0 returned 100%
       16:  562:  return {inputRankSum, inputRankSum + outputRankSum};
        -:  563:}
        -:  564:
        -:  565:LogicalResult
function _ZN4mlir6linalg8LinalgOp17reifyResultShapesERNS_9OpBuilderERN4llvm11SmallVectorINS5_INS_5ValueELj6EEELj1EEE called 16 returned 100% blocks executed 83%
       16:  566:LinalgOp::reifyResultShapes(OpBuilder &b,
        -:  567:                            ReifiedRankedShapedTypeDims &reifiedReturnShapes) {
        -:  568:  // An example that helps understand the logic below.
        -:  569:  // Consider the following expression O(i+j, j) += A(i,k) * B(k, j)
        -:  570:  // We want to express the shape of dim 0 of O in terms of shape of the inputs.
        -:  571:  // This is achieved as follows.
        -:  572:  //   loopsToShapesMap = (d0, d1, d2) -> (d0, d2, d2, d1, d0 + d1, d1)
        -:  573:  //   subMapOfResultShapes = (d0, d1, d2) -> (d0 + d1, d1)
        -:  574:  //   shapesToLoopsMap = (d0, d2, d2, d3, d4, d5) -> (d0, d3, d2)
        -:  575:  //   resultShapesFromInputShapes = subMapOfResultDim.compose(shapesToLoopMap)
        -:  576:  //     = (d0, d1, d2, d3, d4, d5) -> (d0 + d1, d1)
       16:  577:  AffineMap loopsToShapesMap = getLoopsToShapesMap();
call    0 returned 100%
        -:  578:
        -:  579:  // Find the position in the above map that represents the shape of the
        -:  580:  // result:dim being inferred.
       16:  581:  auto resultShapesSubMapPos = getResultsPositionInLoopsToShapeMap(*this);
call    0 returned 100%
        -:  582:
        -:  583:  /// From loopsToShapesMap extract the submap that represents the shape of the
        -:  584:  /// (resultIdx, dim) needed.
       16:  585:  AffineMap loopToResultsShapeMap = loopsToShapesMap.getSliceMap(
        -:  586:      resultShapesSubMapPos.first,
       16:  587:      resultShapesSubMapPos.second - resultShapesSubMapPos.first);
call    0 returned 100%
       16:  588:  AffineMap resultShapesFromInputShapesMap =
call    0 returned 100%
       16:  589:      loopToResultsShapeMap.compose(getShapesToLoopsMap());
call    0 returned 100%
        -:  590:
        -:  591:  // Check that the result dim map does not contain the positions corresponding
        -:  592:  // to the outputs.
       16:  593:  llvm::SmallBitVector outputDims(resultShapesFromInputShapesMap.getNumDims());
call    0 returned 100%
call    1 returned 100%
       16:  594:  outputDims.set(resultShapesSubMapPos.first, resultShapesSubMapPos.second);
call    0 returned 100%
       32:  595:  HasAffineDimExprVisitor checkDimExpr(std::move(outputDims));
call    0 returned 100%
call    1 returned 100%
       16:  596:  Location loc = getOperation()->getLoc();
call    0 returned 100%
       32:  597:  IRRewriter rewriter(b);
call    0 returned 100%
call    1 returned 100%
       16:  598:  SmallVector<OpFoldResult> allResultDimValues =
        -:  599:      makeComposedFoldedMultiResultAffineApply(
        -:  600:          rewriter, loc, resultShapesFromInputShapesMap,
       32:  601:          createFlatListOfOperandDims(b, loc));
call    0 returned 100%
call    1 returned 100%
branch  2 taken 0% (fallthrough)
branch  3 taken 100%
call    4 returned 100%
       16:  602:  int64_t pos = 0;
       16:  603:  ArrayRef<AffineExpr> shapeExprs = resultShapesFromInputShapesMap.getResults();
call    0 returned 100%
       48:  604:  for (OpOperand *opOperand : getDpsInitOperands()) {
call    0 returned 100%
branch  1 taken 50% (fallthrough)
branch  2 taken 50%
       32:  605:    SmallVector<Value> shapes;
call    0 returned 100%
       64:  606:    for (int64_t dim : llvm::seq<int64_t>(0, getRank(opOperand))) {
call    0 returned 100%
call    1 returned 100%
branch  2 taken 75% (fallthrough)
branch  3 taken 25%
       48:  607:      if (checkDimExpr.visit(shapeExprs[pos]))
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
call    2 returned 100%
branch  3 taken 0% (fallthrough)
branch  4 taken 100%
    #####:  608:        shapes.push_back(createOrFoldDimOp(b, loc, opOperand->get(), dim));
call    0 never executed
call    1 never executed
        -:  609:      else
       48:  610:        shapes.push_back(
call    0 returned 100%
       48:  611:            getValueOrCreateConstantIndexOp(b, loc, allResultDimValues[pos]));
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
call    2 returned 100%
       48:  612:      pos++;
call    0 returned 100%
        -:  613:    }
       16:  614:    reifiedReturnShapes.emplace_back(std::move(shapes));
call    0 returned 100%
branch  1 taken 0% (fallthrough)
branch  2 taken 100%
        -:  615:  }
       16:  616:  return success();
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
        -:  617:}
        -:  618:
function _ZN4mlir6linalg6detail27verifyStructuredOpInterfaceEPNS_9OperationE called 132638483 returned 100% blocks executed 42%
132638483:  619:LogicalResult mlir::linalg::detail::verifyStructuredOpInterface(Operation *op) {
132638483:  620:  LinalgOp linalgOp = cast<LinalgOp>(op);
call    0 returned 100%
        -:  621:
        -:  622:  // Check all iterator types are known.
132638485:  623:  auto iteratorTypesRange = linalgOp.getIteratorTypesArray();
call    0 returned 100%
474302911:  624:  for (StringRef iteratorType : iteratorTypesRange) {
branch  0 taken 72% (fallthrough)
branch  1 taken 28%
683328847:  625:    if (!llvm::is_contained(getAllIteratorTypeNames(), iteratorType) ||
branch  0 taken 100% (fallthrough)
branch  1 taken 0%
branch  2 taken 0% (fallthrough)
branch  3 taken 100%
341664423*:  626:        !utils::symbolizeIteratorType(iteratorType).has_value())
call    0 returned 100%
branch  1 taken 0% (fallthrough)
branch  2 taken 100%
    #####:  627:      return op->emitOpError("unexpected iterator_type (")
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:  628:             << iteratorType << ")";
call    0 never executed
call    1 never executed
        -:  629:  }
        -:  630:
        -:  631:  // Before checking indexing maps, we need to make sure the attributes
        -:  632:  // referenced by it are valid.
132638488:  633:  if (linalgOp.hasDynamicIndexingMaps())
call    0 returned 100%
branch  1 taken 0% (fallthrough)
branch  2 taken 100%
    #####:  634:    if (failed(linalgOp.verifyIndexingMapRequiredAttributes()))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  635:      return failure();
        -:  636:
        -:  637:  // All input/output operands must be indexed.
265276975:  638:  if (static_cast<int64_t>(linalgOp.getIndexingMapsArray().size()) !=
call    0 returned 100%
branch  1 taken 100% (fallthrough)
branch  2 taken 0%
branch  3 taken 0% (fallthrough)
branch  4 taken 100%
265276972:  639:      linalgOp->getNumOperands())
branch  0 taken 100% (fallthrough)
branch  1 taken 0%
branch  2 taken 0% (fallthrough)
branch  3 taken 100%
    #####:  640:    return op->emitOpError("expected the number of indexing_map (")
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  641:           << linalgOp.getIndexingMapsArray().size()
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  642:           << ") to be equal to the number of input/output operands ("
    #####:  643:           << linalgOp->getNumOperands() << ")";
branch  0 never executed
branch  1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
branch  5 never executed
branch  6 never executed
        -:  644:
502630743:  645:  for (OpOperand &opOperand : linalgOp->getOpOperands()) {
call    0 returned 100%
branch  1 taken 74% (fallthrough)
branch  2 taken 26%
369992255:  646:    AffineMap indexingMap = linalgOp.getMatchingIndexingMap(&opOperand);
call    0 returned 100%
        -:  647:
        -:  648:    // Symbols disallowed.
369992246:  649:    if (indexingMap.getNumSymbols() != 0)
call    0 returned 100%
branch  1 taken 0% (fallthrough)
branch  2 taken 100%
    #####:  650:      return op->emitOpError("unexpected symbols in indexing_map #")
call    0 never executed
call    1 never executed
    #####:  651:             << opOperand.getOperandNumber();
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
        -:  652:
        -:  653:    // Domain must be consistent.
369992246:  654:    unsigned numLoops = linalgOp.getNumLoops();
call    0 returned 100%
369992251:  655:    if (indexingMap.getNumDims() != numLoops)
call    0 returned 100%
branch  1 taken 0% (fallthrough)
branch  2 taken 100%
    #####:  656:      return op->emitOpError("expected indexing_map #")
call    0 never executed
call    1 never executed
    #####:  657:             << opOperand.getOperandNumber() << " to have " << numLoops
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
call    5 never executed
    #####:  658:             << " dim(s) to match the number of loops";
call    0 never executed
        -:  659:
369992251:  660:    int64_t rank = linalgOp.getRank(&opOperand);
call    0 returned 100%
369992260:  661:    if (indexingMap.getNumResults() != rank)
call    0 returned 100%
branch  1 taken 0% (fallthrough)
branch  2 taken 100%
    #####:  662:      return op->emitOpError("expected operand rank (")
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  663:             << rank << ") to match the result rank of indexing_map #"
call    0 never executed
    #####:  664:             << opOperand.getOperandNumber() << " ("
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  665:             << indexingMap.getNumResults() << ")";
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
        -:  666:  }
        -:  667:
265276974:  668:  SmallVector<unsigned> redDims;
call    0 returned 100%
branch  1 taken 1% (fallthrough)
branch  2 taken 100%
132638488:  669:  linalgOp.getReductionDims(redDims);
call    0 returned 100%
        -:  670:
132638481:  671:  if (!linalgOp.getShapesToLoopsMap())
call    0 returned 100%
branch  1 taken 0% (fallthrough)
branch  2 taken 100%
    #####:  672:    return op->emitOpError("expected the shape-to-loops map to be non-null");
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
        -:  673:
        -:  674:  // Check if given shapes match to inferred shapes.
265276975:  675:  SmallVector<int64_t, 4> endLoopRangeValues = linalgOp.getStaticLoopRanges();
call    0 returned 100%
branch  1 taken 0% (fallthrough)
branch  2 taken 100%
265276968:  676:  SmallVector<int64_t, 4> startLoopRangeValues(endLoopRangeValues.size(), 0);
call    0 returned 100%
branch  1 taken 1% (fallthrough)
branch  2 taken 100%
        -:  677:
        -:  678:  // Verify only static cases since we can't get exact dimension sizes and loop
        -:  679:  // ranges for dynamic cases in this stage.
132638482:  680:  if (llvm::none_of(endLoopRangeValues, ShapedType::isDynamic)) {
call    0 returned 100%
branch  1 taken 100% (fallthrough)
branch  2 taken 1%
473392618:  681:    for (int64_t &range : endLoopRangeValues)
branch  0 taken 72% (fallthrough)
branch  1 taken 28%
341090941:  682:      range -= 1;
501718924:  683:    for (OpOperand &opOperand : linalgOp->getOpOperands()) {
call    0 returned 100%
branch  1 taken 74% (fallthrough)
branch  2 taken 26%
369417244:  684:      AffineMap indexingMap = linalgOp.getMatchingIndexingMap(&opOperand);
call    0 returned 100%
369417244:  685:      SmallVector<int64_t, 4> startIndices =
call    0 returned 100%
738834491:  686:          indexingMap.compose(startLoopRangeValues);
call    0 returned 100%
369417227:  687:      SmallVector<int64_t, 4> endIndices =
call    0 returned 100%
738834474:  688:          indexingMap.compose(endLoopRangeValues);
call    0 returned 100%
branch  1 taken 1% (fallthrough)
branch  2 taken 100%
369417236:  689:      ArrayRef<int64_t> shape = linalgOp.getShape(&opOperand);
call    0 returned 100%
1821909990:  690:      for (auto dim : llvm::seq<int64_t>(0, shape.size())) {
call    0 returned 100%
branch  1 taken 66% (fallthrough)
branch  2 taken 34%
call    3 returned 100%
        -:  691:        // Ignore dynamic dimension or the case that the dimension size is 0
726246373*:  692:        if (ShapedType::isDynamic(shape[dim]) || shape[dim] == 0)
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
branch  2 taken 100% (fallthrough)
branch  3 taken 0%
branch  4 taken 100% (fallthrough)
branch  5 taken 0%
    #####:  693:          continue;
        -:  694:
        -:  695:        // The first index or last index should be the maximum or the minimum in
        -:  696:        // the inferred index ranges since the range is increasing or
        -:  697:        // decreasing. The size of dimensions of input/output operands and the
        -:  698:        // maximum value + 1 in the inferred range should be the same. But, for
        -:  699:        // now we check if the inferred ranges are in boundary of input/output
        -:  700:        // operands' size or not in case that Affine Expressions are complicated
        -:  701:        // such as d0 * 3
        -:  702:        // + d1 since it is not easy to handle the issues.
        -:  703:        // Found the case that this solution can't check, for example, (d0, d1)
        -:  704:        // -> (d1 - d0)
726246373:  705:        int64_t inferredDimSize =
726246373:  706:            std::max(startIndices[dim], endIndices[dim]) + 1;
branch  0 taken 0%
branch  1 taken 100%
branch  2 taken 0% (fallthrough)
branch  3 taken 100%
branch  4 taken 94% (fallthrough)
branch  5 taken 6%
726246373:  707:        if (std::min(startIndices[dim], endIndices[dim]) < 0) {
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
branch  2 taken 0% (fallthrough)
branch  3 taken 100%
    #####:  708:          std::string mapStr;
call    0 never executed
    #####:  709:          {
    #####:  710:            llvm::raw_string_ostream os(mapStr);
call    0 never executed
    #####:  711:            os << indexingMap;
call    0 never executed
call    1 never executed
        -:  712:          }
    #####:  713:          return op->emitOpError(
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
branch  4 never executed
branch  5 never executed
        -:  714:                     "unexpected result less than 0 at expression #")
    #####:  715:                 << dim << " in " << mapStr;
call    0 never executed
call    1 never executed
call    2 never executed
        -:  716:        }
726246373:  717:        if (indexingMap.getResult(dim).dyn_cast<AffineDimExpr>()) {
call    0 returned 100%
call    1 returned 100%
branch  2 taken 100% (fallthrough)
branch  3 taken 0%
726246369:  718:          if (inferredDimSize != shape[dim]) {
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
branch  2 taken 0% (fallthrough)
branch  3 taken 100%
    #####:  719:            return op->emitOpError("inferred input/output operand #")
call    0 never executed
call    1 never executed
    #####:  720:                   << opOperand.getOperandNumber() << " has shape's dimension #"
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
    #####:  721:                   << dim << " to be " << inferredDimSize << ", but found "
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  722:                   << shape[dim];
branch  0 never executed
branch  1 never executed
call    2 never executed
call    3 never executed
        -:  723:          }
        -:  724:        } else {
    #####:  725:          if (inferredDimSize > shape[dim]) {
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####:  726:            return op->emitOpError("inferred input/output operand #")
call    0 never executed
call    1 never executed
    #####:  727:                   << opOperand.getOperandNumber() << " has shape's dimension #"
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
    #####:  728:                   << dim << " to be greater than or equal to "
call    0 never executed
call    1 never executed
    #####:  729:                   << inferredDimSize << ", but found " << shape[dim];
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
call    4 never executed
        -:  730:          }
        -:  731:        }
        -:  732:      }
        -:  733:    }
        -:  734:  }
        -:  735:
        -:  736:  // Check the region has exactly one block.
132638487:  737:  if (linalgOp->getNumRegions() != 1 ||
branch  0 taken 100% (fallthrough)
branch  1 taken 0%
132638487:  738:      !llvm::hasSingleElement(linalgOp->getRegion(0)))
call    0 returned 100%
branch  1 taken 100% (fallthrough)
branch  2 taken 1%
     6862:  739:    return op->emitOpError("expects to have 1 region with 1 block");
call    0 returned 100%
call    1 returned 100%
call    2 returned 100%
call    3 returned 100%
        -:  740:
        -:  741:  // Simplifying assumption: bbargs match 1-1 with shape operands elemental
        -:  742:  // types.
        -:  743:  // TODO: once ranked shape types are plugged in, we may want to drop the
        -:  744:  // corresponding bbargs, that can never be read from. This will be subject to
        -:  745:  // consistency discussions (i.e. what to do with output tensors whose bbarg is
        -:  746:  // not used).
132631625:  747:  Block &block = linalgOp->getRegion(0).front();
call    0 returned 100%
        -:  748:
132631625:  749:  if (linalgOp.getOpOperandsMatchingBBargs().size() != block.getNumArguments())
call    0 returned 100%
branch  1 taken 0%
branch  2 taken 100%
branch  3 taken 0% (fallthrough)
branch  4 taken 100%
    #####:  750:    return op->emitOpError("expected as many non-induction variable region "
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  751:                           "arguments as the number of input/output operands");
call    0 never executed
        -:  752:
480020665:  753:  for (OpOperand *opOperand : linalgOp.getOpOperandsMatchingBBargs()) {
call    0 returned 100%
branch  1 taken 72% (fallthrough)
branch  2 taken 28%
347389041:  754:    Type elementType = getElementTypeOrSelf(opOperand->get());
call    0 returned 100%
347389041:  755:    Type argType = block.getArgument(opOperand->getOperandNumber()).getType();
call    0 returned 100%
branch  1 taken 0% (fallthrough)
branch  2 taken 100%
347389041:  756:    if (elementType != argType)
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
    #####:  757:      return op->emitOpError("expected type of bb argument #")
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  758:             << opOperand->getOperandNumber() << " (" << argType << ")"
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
call    5 never executed
call    6 never executed
    #####:  759:             << " to match element or self type of the corresponding operand ("
call    0 never executed
    #####:  760:             << elementType << ")";
call    0 never executed
call    1 never executed
        -:  761:  }
        -:  762:
132638486:  763:  return success();
branch  0 taken 1% (fallthrough)
branch  1 taken 100%
        -:  764:}
