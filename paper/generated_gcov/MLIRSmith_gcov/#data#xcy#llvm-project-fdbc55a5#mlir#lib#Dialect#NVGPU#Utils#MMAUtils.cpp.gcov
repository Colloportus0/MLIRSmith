        -:    0:Source:/data/xcy/llvm-project-fdbc55a5/mlir/lib/Dialect/NVGPU/Utils/MMAUtils.cpp
        -:    0:Graph:../tools/mlir/lib/Dialect/NVGPU/Utils/CMakeFiles/obj.MLIRNVGPUUtils.dir/MMAUtils.cpp.gcno
        -:    0:Data:../tools/mlir/lib/Dialect/NVGPU/Utils/CMakeFiles/obj.MLIRNVGPUUtils.dir/MMAUtils.cpp.gcda
        -:    0:Runs:116164
        -:    1://===- MMAUtils.cpp - MLIR NVGPU dialect utils for MMA operations----------===//
        -:    2://
        -:    3:// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
        -:    4:// See https://llvm.org/LICENSE.txt for license information.
        -:    5:// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
        -:    6://
        -:    7://===----------------------------------------------------------------------===//
        -:    8:#include "mlir/Dialect/NVGPU/Utils/MMAUtils.h"
        -:    9:
        -:   10:#include "mlir/Dialect/Affine/IR/AffineOps.h"
        -:   11:#include "mlir/Dialect/Arith/IR/Arith.h"
        -:   12:#include "mlir/Dialect/LLVMIR/NVVMDialect.h"
        -:   13:#include "mlir/Dialect/NVGPU/IR/NVGPUDialect.h"
        -:   14:#include "mlir/Dialect/Vector/IR/VectorOps.h"
        -:   15:
        -:   16:using namespace mlir;
        -:   17:using namespace mlir::nvgpu;
        -:   18:
        -:   19:/// There are always 4 threads per [128|256|512] bit row.
        -:   20:static constexpr int64_t kThreadsPerRow = 4;
        -:   21:static constexpr int64_t kNumRowsPerTile = 8;
        -:   22:
    #####:   23:static bool isAccumulatorOrResult(MatMulOperandRole operandType) {
    #####:   24:  return operandType == MatMulOperandRole::C;
        -:   25:}
        -:   26:
        -:   27:/// Returns the number of registers which compose a matrix fragment held by a
        -:   28:/// single thread.
function _ZL34inferNumRegistersPerMatrixFragmentRKN4mlir5nvgpu14WarpMatrixInfoE called 0 returned 0% blocks executed 0%
    #####:   29:static int64_t inferNumRegistersPerMatrixFragment(const WarpMatrixInfo &type) {
    #####:   30:  int64_t lineSize = inferTileWidthInBits(type);
call    0 never executed
    #####:   31:  auto shape = type.vectorType.getShape();
call    0 never executed
    #####:   32:  return (shape[0] / kNumRowsPerTile) *
branch  0 never executed
branch  1 never executed
    #####:   33:         (shape[1] * type.vectorType.getElementType().getIntOrFloatBitWidth()) /
branch  0 never executed
branch  1 never executed
call    2 never executed
call    3 never executed
    #####:   34:         lineSize;
        -:   35:}
        -:   36:
        -:   37:/// Returns the number of 8 x [128|256|512] bit tiles that compose the given
        -:   38:/// operand shape.
function _ZL12getTileShapeN4llvm8ArrayRefIlEEN4mlir4TypeEl called 0 returned 0% blocks executed 0%
    #####:   39:static std::array<int64_t, 2> getTileShape(ArrayRef<int64_t> operandShape,
        -:   40:                                           Type elementType,
        -:   41:                                           int64_t lineSizeBits) {
        -:   42:  // For each 8x128bit square, a thread is responsible for one 32bit register.
    #####:   43:  return {operandShape[0] / kNumRowsPerTile,
branch  0 never executed
branch  1 never executed
    #####:   44:          (operandShape[1] * elementType.getIntOrFloatBitWidth()) /
call    0 never executed
    #####:   45:              lineSizeBits};
branch  0 never executed
branch  1 never executed
        -:   46:}
        -:   47:
        -:   48:/// Returns the first user of the `op` that is vector.contract. If no
        -:   49:/// vector.contract user exists, return failure.
function _ZN4mlir5nvgpu15getUserContractEPNS_9OperationE called 0 returned 0% blocks executed 0%
    #####:   50:FailureOr<vector::ContractionOp> nvgpu::getUserContract(Operation *op) {
    #####:   51:  for (Operation *user : op->getUsers()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
    #####:   52:    if (auto contractOp = dyn_cast<vector::ContractionOp>(user))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:   53:      return contractOp;
        -:   54:  }
    #####:   55:  return failure();
        -:   56:}
        -:   57:
function _ZN4mlir5nvgpu17getWarpMatrixInfoEPNS_9OperationE called 0 returned 0% blocks executed 0%
    #####:   58:FailureOr<WarpMatrixInfo> nvgpu::getWarpMatrixInfo(Operation *op) {
    #####:   59:  WarpMatrixInfo info;
call    0 never executed
        -:   60:
        -:   61:  // Determine the vector type at warp-level.
    #####:   62:  if (vector::TransferWriteOp writeOp = dyn_cast<vector::TransferWriteOp>(op)) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:   63:    info.vectorType = writeOp.getVectorType();
call    0 never executed
    #####:   64:  } else if (isa<vector::TransferReadOp, vector::ContractionOp,
branch  0 never executed
branch  1 never executed
    #####:   65:                 vector::ExtractStridedSliceOp, arith::ConstantOp>(op)) {
call    0 never executed
    #####:   66:    info.vectorType = op->getResult(0).getType().cast<VectorType>();
call    0 never executed
        -:   67:  } else {
    #####:   68:    return op->emitError()
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:   69:           << "unhandled operation type in nvgpu.mma.sync conversion path";
call    0 never executed
        -:   70:  }
        -:   71:
        -:   72:  // Determine the operand role. We assume it is an accumulator/result unless it
        -:   73:  // is directly consumed by a `vector.contract` op.
    #####:   74:  info.operandRole = MatMulOperandRole::C;
    #####:   75:  FailureOr<vector::ContractionOp> contractOp = getUserContract(op);
call    0 never executed
    #####:   76:  if (failed(contractOp))
branch  0 never executed
branch  1 never executed
    #####:   77:    return info;
        -:   78:
    #####:   79:  if ((*contractOp).getLhs() == op->getResult(0))
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:   80:    info.operandRole = MatMulOperandRole::A;
    #####:   81:  else if ((*contractOp).getRhs() == op->getResult(0))
branch  0 never executed
branch  1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
    #####:   82:    info.operandRole = MatMulOperandRole::B;
        -:   83:
    #####:   84:  return info;
        -:   85:}
        -:   86:
function _ZN4mlir5nvgpu20inferTileWidthInBitsERKNS0_14WarpMatrixInfoE called 0 returned 0% blocks executed 0%
    #####:   87:int64_t nvgpu::inferTileWidthInBits(const WarpMatrixInfo &type) {
    #####:   88:  bool isAcc = isAccumulatorOrResult(type.operandRole);
    #####:   89:  Type elType = type.vectorType.getElementType();
call    0 never executed
    #####:   90:  if (isAcc && elType.getIntOrFloatBitWidth() == 32) {
branch  0 never executed
branch  1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
        -:   91:    return 256;
        -:   92:  }
    #####:   93:  if (elType.getIntOrFloatBitWidth() == 64) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:   94:    return isAcc ? 512 : 256;
branch  0 never executed
branch  1 never executed
        -:   95:  }
        -:   96:  return 128;
        -:   97:}
        -:   98:
        -:   99:FailureOr<FragmentElementInfo>
function _ZN4mlir5nvgpu22getMmaSyncRegisterTypeERKNS0_14WarpMatrixInfoE called 0 returned 0% blocks executed 0%
    #####:  100:nvgpu::getMmaSyncRegisterType(const WarpMatrixInfo &type) {
    #####:  101:  MLIRContext *ctx = type.vectorType.getContext();
call    0 never executed
    #####:  102:  const bool isAccum = isAccumulatorOrResult(type.operandRole);
        -:  103:
    #####:  104:  Type elType = type.vectorType.getElementType();
call    0 never executed
    #####:  105:  if (elType.isF16()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  106:    return FragmentElementInfo{
    #####:  107:        LLVM::getFixedVectorType(Float16Type::get(ctx), 2), 2, 32,
call    0 never executed
call    1 never executed
    #####:  108:        inferNumRegistersPerMatrixFragment(type)};
call    0 never executed
        -:  109:  }
        -:  110:
        -:  111:  // f64 operand
    #####:  112:  Type f64Ty = Float64Type::get(ctx);
call    0 never executed
    #####:  113:  if (elType.isF64()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  114:    return isAccum
    #####:  115:               ? FragmentElementInfo{LLVM::getFixedVectorType(f64Ty, 2), 2, 128,
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  116:                                     inferNumRegistersPerMatrixFragment(type)}
call    0 never executed
        -:  117:               : FragmentElementInfo{f64Ty, 1, 64,
    #####:  118:                                     inferNumRegistersPerMatrixFragment(type)};
call    0 never executed
        -:  119:  }
        -:  120:
        -:  121:  // int8 operand
    #####:  122:  if (elType.isInteger(8)) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  123:    return FragmentElementInfo{
    #####:  124:        LLVM::getFixedVectorType(IntegerType::get(ctx, 8), 4), 4, 32,
call    0 never executed
call    1 never executed
    #####:  125:        inferNumRegistersPerMatrixFragment(type)};
call    0 never executed
        -:  126:  }
        -:  127:
        -:  128:  // int4 operand
    #####:  129:  if (elType.isInteger(4)) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  130:    return FragmentElementInfo{
    #####:  131:        LLVM::getFixedVectorType(IntegerType::get(ctx, 4), 8), 8, 32,
call    0 never executed
call    1 never executed
    #####:  132:        inferNumRegistersPerMatrixFragment(type)};
call    0 never executed
        -:  133:  }
        -:  134:
        -:  135:  // Integer 32bit acc operands
    #####:  136:  if (elType.isInteger(32)) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  137:    return FragmentElementInfo{
    #####:  138:        LLVM::getFixedVectorType(IntegerType::get(ctx, 32), 2), 2, 64,
call    0 never executed
call    1 never executed
    #####:  139:        inferNumRegistersPerMatrixFragment(type)};
call    0 never executed
        -:  140:  }
        -:  141:
        -:  142:  // Floating point 32bit operands
    #####:  143:  if (elType.isF32()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  144:    Type f32Ty = Float32Type::get(ctx);
call    0 never executed
    #####:  145:    return isAccum
    #####:  146:               ? FragmentElementInfo{LLVM::getFixedVectorType(f32Ty, 2), 2, 64,
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  147:                                     inferNumRegistersPerMatrixFragment(type)}
call    0 never executed
        -:  148:               : FragmentElementInfo{f32Ty, 1, 32,
    #####:  149:                                     inferNumRegistersPerMatrixFragment(type)};
call    0 never executed
        -:  150:  }
    #####:  151:  return failure();
        -:  152:}
        -:  153:
function _ZL31getRegisterIndexToTileOffsetMaplN4mlir4TypeEN4llvm8ArrayRefIlEEblNS_10AffineExprE called 0 returned 0% blocks executed 0%
    #####:  154:static AffineMap getRegisterIndexToTileOffsetMap(int64_t lineSize,
        -:  155:                                                 Type elementType,
        -:  156:                                                 ArrayRef<int64_t> operandShape,
        -:  157:                                                 bool isAccumulator,
        -:  158:                                                 int64_t elementsPerRegister,
        -:  159:                                                 AffineExpr logicalValueId) {
    #####:  160:  const int64_t elementsPerLine =
    #####:  161:      lineSize / elementType.getIntOrFloatBitWidth();
call    0 never executed
    #####:  162:  const std::array<int64_t, 2> num8x128bTiles =
    #####:  163:      getTileShape(operandShape, elementType, lineSize);
call    0 never executed
    #####:  164:  AffineExpr registerIdx = logicalValueId.floorDiv(elementsPerRegister);
call    0 never executed
    #####:  165:  return AffineMap::get(
        -:  166:      2, 0,
    #####:  167:      {(registerIdx % num8x128bTiles[0]) * 8,
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  168:       (registerIdx.floorDiv(num8x128bTiles[0])) * elementsPerLine},
call    0 never executed
call    1 never executed
    #####:  169:      elementType.getContext());
call    0 never executed
call    1 never executed
call    2 never executed
        -:  170:}
        -:  171:
        -:  172:FailureOr<AffineMap>
function _ZN4mlir5nvgpu33getLaneIdAndValueIdToOperandCoordENS_8LocationERNS_9OpBuilderERKNS0_14WarpMatrixInfoE called 0 returned 0% blocks executed 0%
    #####:  173:nvgpu::getLaneIdAndValueIdToOperandCoord(Location loc, OpBuilder &builder,
        -:  174:                                         const WarpMatrixInfo &fragmentType) {
    #####:  175:  Type elementType = fragmentType.vectorType.getElementType();
call    0 never executed
    #####:  176:  ArrayRef<int64_t> operandShape = fragmentType.vectorType.getShape();
call    0 never executed
    #####:  177:  FailureOr<nvgpu::FragmentElementInfo> regInfo =
    #####:  178:      getMmaSyncRegisterType(fragmentType);
call    0 never executed
    #####:  179:  if (failed(regInfo))
branch  0 never executed
branch  1 never executed
    #####:  180:    return failure();
        -:  181:
    #####:  182:  const int64_t elementBitWidth = elementType.getIntOrFloatBitWidth();
call    0 never executed
    #####:  183:  const int64_t elementsPerRegister =
call    0 never executed
    #####:  184:      regInfo->registerWidthBits / elementBitWidth;
    #####:  185:  const int64_t lineSize = inferTileWidthInBits(fragmentType);
call    0 never executed
        -:  186:
    #####:  187:  AffineExpr laneId, logicalValueIdDim;
    #####:  188:  bindDims(builder.getContext(), laneId, logicalValueIdDim);
call    0 never executed
        -:  189:
        -:  190:  // Determine what register logicalValueId corresponds to. Use that as a
        -:  191:  // linear index into the coordinate mapping `index -> (tile row, tile col)`.
    #####:  192:  AffineMap registerIndexToTileCoord = getRegisterIndexToTileOffsetMap(
        -:  193:      lineSize, elementType, operandShape,
    #####:  194:      isAccumulatorOrResult(fragmentType.operandRole), elementsPerRegister,
    #####:  195:      logicalValueIdDim);
call    0 never executed
        -:  196:
    #####:  197:  auto makeMap = [&](ArrayRef<AffineExpr> dimExprs) -> AffineMap {
    #####:  198:    return AffineMap::get(2, 0, dimExprs, builder.getContext());
call    0 never executed
    #####:  199:  };
        -:  200:
    #####:  201:  auto tileRow = registerIndexToTileCoord.getResult(0);
call    0 never executed
    #####:  202:  auto tileCol = registerIndexToTileCoord.getResult(1);
call    0 never executed
    #####:  203:  return makeMap({tileRow + laneId.floorDiv(kThreadsPerRow),
call    0 never executed
call    1 never executed
    #####:  204:                  tileCol + (laneId % kThreadsPerRow) * elementsPerRegister +
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  205:                      (logicalValueIdDim % elementsPerRegister)});
call    0 never executed
call    1 never executed
call    2 never executed
        -:  206:}
        -:  207:
        -:  208:FailureOr<nvgpu::LdMatrixParams>
function _ZN4mlir5nvgpu17getLdMatrixParamsERKNS0_14WarpMatrixInfoEb called 0 returned 0% blocks executed 0%
    #####:  209:nvgpu::getLdMatrixParams(const WarpMatrixInfo &type, bool transpose) {
    #####:  210:  LdMatrixParams params;
call    0 never executed
    #####:  211:  Type elType = type.vectorType.getElementType();
call    0 never executed
    #####:  212:  params.fragmentType = type.vectorType;
    #####:  213:  if (type.operandRole == MatMulOperandRole::A ||
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
        -:  214:      type.operandRole == MatMulOperandRole::C) {
        -:  215:    params.targetLayout = NVVM::MMALayout::row;
        -:  216:  } else {
    #####:  217:    params.targetLayout = NVVM::MMALayout::col;
        -:  218:  }
    #####:  219:  ArrayRef<int64_t> shape = type.vectorType.getShape();
call    0 never executed
    #####:  220:  params.contiguousDimType = transpose ? vector::IteratorType::parallel
branch  0 never executed
branch  1 never executed
        -:  221:                                       : vector::IteratorType::reduction;
        -:  222:
    #####:  223:  if (params.contiguousDimType == vector::IteratorType::reduction) {
branch  0 never executed
branch  1 never executed
    #####:  224:    params.numTiles = (shape[0] / kNumRowsPerTile) *
branch  0 never executed
branch  1 never executed
    #####:  225:                      ((shape[1] * elType.getIntOrFloatBitWidth()) / 128);
branch  0 never executed
branch  1 never executed
call    2 never executed
        -:  226:  } else {
    #####:  227:    params.numTiles = (shape[1] / kNumRowsPerTile) *
branch  0 never executed
branch  1 never executed
    #####:  228:                      ((shape[0] * elType.getIntOrFloatBitWidth()) / 128);
call    0 never executed
        -:  229:  }
        -:  230:
    #####:  231:  if (params.numTiles == 0)
branch  0 never executed
branch  1 never executed
    #####:  232:    return failure();
        -:  233:
    #####:  234:  return params;
        -:  235:}
        -:  236:
        -:  237:FailureOr<AffineMap>
function _ZN4mlir5nvgpu30getLaneIdToLdMatrixMatrixCoordENS_8LocationERNS_9OpBuilderERKNS0_14LdMatrixParamsE called 0 returned 0% blocks executed 0%
    #####:  238:nvgpu::getLaneIdToLdMatrixMatrixCoord(Location loc, OpBuilder &builder,
        -:  239:                                      const LdMatrixParams &params) {
        -:  240:  // One thread per 128b row.
    #####:  241:  const int64_t kNumThreadsPerTile = kNumRowsPerTile;
    #####:  242:  const int bitsPerElement = static_cast<int>(
    #####:  243:      params.fragmentType.getElementType().getIntOrFloatBitWidth());
call    0 never executed
call    1 never executed
    #####:  244:  const int kElementsPer128b = (128 / bitsPerElement);
    #####:  245:  ArrayRef<int64_t> operandShape = params.fragmentType.getShape();
call    0 never executed
    #####:  246:  AffineExpr d0 = getAffineDimExpr(0, builder.getContext());
call    0 never executed
        -:  247:
    #####:  248:  auto makeMap = [&](ArrayRef<AffineExpr> dimExprs) -> AffineMap {
    #####:  249:    return AffineMap::get(1, 0, dimExprs, builder.getContext());
call    0 never executed
call    1 never executed
    #####:  250:  };
        -:  251:
        -:  252:  // This case corresponds to row-major A|C or col-major B operands.
    #####:  253:  if (params.contiguousDimType == vector::IteratorType::reduction) {
branch  0 never executed
branch  1 never executed
    #####:  254:    AffineExpr row = d0 % (operandShape[0]);
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  255:    AffineExpr col = d0.floorDiv(operandShape[0]) * (kElementsPer128b);
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  256:    return makeMap({row, col});
call    0 never executed
        -:  257:  }
        -:  258:
        -:  259:  // This case Corresponds to col-major A|C or row-major B operands. The
        -:  260:  // operandShape given is already pre-transposed (e.g. 8x16 = KxN).
    #####:  261:  if (params.contiguousDimType == vector::IteratorType::parallel) {
branch  0 never executed
branch  1 never executed
    #####:  262:    const int64_t num8x128bCols = (operandShape[0] * bitsPerElement) / 128;
branch  0 never executed
branch  1 never executed
        -:  263:    // Threads are assigned in groups of 8 first across columns, then to
        -:  264:    // rows. This is transpose of what `ldmatrix` expects, but when
        -:  265:    // `ldmatrix` gets the `.trans` qualifier, final the effect will be to
        -:  266:    // transpose just the blocks.
    #####:  267:    auto groupIdx = d0.floorDiv(kNumThreadsPerTile);
call    0 never executed
    #####:  268:    auto tileCol = (groupIdx % num8x128bCols);
call    0 never executed
    #####:  269:    auto tileRow = groupIdx.floorDiv(num8x128bCols);
call    0 never executed
    #####:  270:    return makeMap({tileCol * kElementsPer128b,
call    0 never executed
    #####:  271:                    tileRow * kNumRowsPerTile + (d0 % kNumRowsPerTile)});
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
        -:  272:  }
    #####:  273:  return failure();
        -:  274:}
        -:  275:
function _ZNK4mlir5nvgpu27PrepareContractToGPUMMASync15matchAndRewriteENS_6vector13ContractionOpERNS_15PatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  276:LogicalResult nvgpu::PrepareContractToGPUMMASync::matchAndRewrite(
        -:  277:    vector::ContractionOp op, PatternRewriter &rewriter) const {
    #####:  278:  Location loc = op.getLoc();
call    0 never executed
    #####:  279:  Value lhs = op.getLhs();
call    0 never executed
    #####:  280:  Value rhs = op.getRhs();
call    0 never executed
    #####:  281:  Value res = op.getAcc();
call    0 never executed
        -:  282:
        -:  283:  // Set up the parallel/reduction structure in right form.
    #####:  284:  using MapList = ArrayRef<ArrayRef<AffineExpr>>;
    #####:  285:  auto infer = [](MapList m) { return AffineMap::inferFromExprList(m); };
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
call    5 never executed
call    6 never executed
call    7 never executed
    #####:  286:  AffineExpr m;
    #####:  287:  AffineExpr n;
    #####:  288:  AffineExpr k;
    #####:  289:  bindDims(rewriter.getContext(), m, n, k);
call    0 never executed
    #####:  290:  static constexpr std::array<int64_t, 2> perm = {1, 0};
    #####:  291:  auto iteratorTypes = op.getIteratorTypes().getValue();
call    0 never executed
call    1 never executed
    #####:  292:  SmallVector<AffineMap, 4> maps = op.getIndexingMapsArray();
call    0 never executed
    #####:  293:  if (iteratorTypes.size() != 3)
branch  0 never executed
branch  1 never executed
    #####:  294:    return failure();
    #####:  295:  if (!(vector::isParallelIterator(iteratorTypes[0]) &&
call    0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
branch  6 never executed
    #####:  296:        vector::isParallelIterator(iteratorTypes[1]) &&
call    0 never executed
    #####:  297:        vector::isReductionIterator(iteratorTypes[2])))
call    0 never executed
    #####:  298:    return failure();
        -:  299:
        -:  300:  // The canonical form is "TNT" = A row-major, B col-major, C row-major.
    #####:  301:  const auto canonicalForm = infer({{m, k}, {n, k}, {m, n}});
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  302:  if (maps == canonicalForm) {
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####:  303:    return failure();
        -:  304:  }
    #####:  305:  if (maps == infer({{m, k}, {k, n}, {m, n}})) {
call    0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
branch  6 never executed
    #####:  306:    rhs = rewriter.create<vector::TransposeOp>(loc, rhs, perm);
call    0 never executed
    #####:  307:  } else if (maps == infer({{k, m}, {k, n}, {m, n}})) {
call    0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
branch  6 never executed
    #####:  308:    lhs = rewriter.create<vector::TransposeOp>(loc, lhs, perm);
call    0 never executed
    #####:  309:  } else if (maps == infer({{k, m}, {k, n}, {m, n}})) {
call    0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
branch  6 never executed
    #####:  310:    rhs = rewriter.create<vector::TransposeOp>(loc, rhs, perm);
call    0 never executed
call    1 never executed
    #####:  311:    lhs = rewriter.create<vector::TransposeOp>(loc, lhs, perm);
call    0 never executed
    #####:  312:  } else if (maps == infer({{k, m}, {k, n}, {n, m}})) {
call    0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
branch  6 never executed
    #####:  313:    std::swap(rhs, lhs);
call    0 never executed
    #####:  314:    rhs = rewriter.create<vector::TransposeOp>(loc, rhs, perm);
call    0 never executed
call    1 never executed
    #####:  315:    lhs = rewriter.create<vector::TransposeOp>(loc, lhs, perm);
call    0 never executed
    #####:  316:  } else if (maps == infer({{k, m}, {n, k}, {n, m}})) {
call    0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
branch  6 never executed
    #####:  317:    std::swap(rhs, lhs);
call    0 never executed
    #####:  318:    rhs = rewriter.create<vector::TransposeOp>(loc, rhs, perm);
call    0 never executed
    #####:  319:  } else if (maps == infer({{m, k}, {k, n}, {n, m}})) {
call    0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
branch  6 never executed
    #####:  320:    std::swap(lhs, rhs);
call    0 never executed
    #####:  321:    lhs = rewriter.create<vector::TransposeOp>(loc, lhs, perm);
call    0 never executed
    #####:  322:  } else if (maps == infer({{m, k}, {n, k}, {n, m}})) {
call    0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
branch  6 never executed
    #####:  323:    std::swap(lhs, rhs);
        -:  324:  } else {
    #####:  325:    return failure();
        -:  326:  }
    #####:  327:  rewriter.replaceOpWithNewOp<vector::ContractionOp>(
    #####:  328:      op, lhs, rhs, res, rewriter.getAffineMapArrayAttr(canonicalForm),
call    0 never executed
    #####:  329:      op.getIteratorTypes());
call    0 never executed
call    1 never executed
    #####:  330:  return success();
branch  0 never executed
branch  1 never executed
        -:  331:}
