        -:    0:Source:/data/xcy/llvm-project-fdbc55a5/mlir/lib/Dialect/Vector/Utils/VectorUtils.cpp
        -:    0:Graph:../tools/mlir/lib/Dialect/Vector/Utils/CMakeFiles/obj.MLIRVectorUtils.dir/VectorUtils.cpp.gcno
        -:    0:Data:../tools/mlir/lib/Dialect/Vector/Utils/CMakeFiles/obj.MLIRVectorUtils.dir/VectorUtils.cpp.gcda
        -:    0:Runs:116161
        -:    1://===- VectorUtils.cpp - MLIR Utilities for VectorOps   ------------------===//
        -:    2://
        -:    3:// Part of the MLIR Project, under the Apache License v2.0 with LLVM Exceptions.
        -:    4:// See https://llvm.org/LICENSE.txt for license information.
        -:    5:// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
        -:    6://
        -:    7://===----------------------------------------------------------------------===//
        -:    8://
        -:    9:// This file implements utility methods for working with the Vector dialect.
        -:   10://
        -:   11://===----------------------------------------------------------------------===//
        -:   12:
        -:   13:#include "mlir/Dialect/Vector/Utils/VectorUtils.h"
        -:   14:
        -:   15:#include "mlir/Dialect/Affine/Analysis/LoopAnalysis.h"
        -:   16:#include "mlir/Dialect/Affine/IR/AffineOps.h"
        -:   17:#include "mlir/Dialect/Arith/IR/Arith.h"
        -:   18:#include "mlir/Dialect/Func/IR/FuncOps.h"
        -:   19:#include "mlir/Dialect/MemRef/IR/MemRef.h"
        -:   20:#include "mlir/Dialect/Tensor/IR/Tensor.h"
        -:   21:#include "mlir/Dialect/Vector/IR/VectorOps.h"
        -:   22:#include "mlir/IR/Builders.h"
        -:   23:#include "mlir/IR/IntegerSet.h"
        -:   24:#include "mlir/IR/Operation.h"
        -:   25:#include "mlir/IR/TypeUtilities.h"
        -:   26:#include "mlir/Support/LLVM.h"
        -:   27:#include "mlir/Support/MathExtras.h"
        -:   28:#include <numeric>
        -:   29:
        -:   30:#include "llvm/ADT/DenseSet.h"
        -:   31:#include "llvm/ADT/SetVector.h"
        -:   32:
        -:   33:using namespace mlir;
        -:   34:
        -:   35:/// Helper function that creates a memref::DimOp or tensor::DimOp depending on
        -:   36:/// the type of `source`.
function _ZN4mlir6vector17createOrFoldDimOpERNS_9OpBuilderENS_8LocationENS_5ValueEl called 835 returned 100% blocks executed 50%
      835:   37:Value mlir::vector::createOrFoldDimOp(OpBuilder &b, Location loc, Value source,
        -:   38:                                      int64_t dim) {
      835:   39:  if (source.getType().isa<UnrankedMemRefType, MemRefType>())
call    0 returned 100%
branch  1 taken 100% (fallthrough)
branch  2 taken 0%
      835:   40:    return b.createOrFold<memref::DimOp>(loc, source, dim);
call    0 returned 100%
    #####:   41:  if (source.getType().isa<UnrankedTensorType, RankedTensorType>())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:   42:    return b.createOrFold<tensor::DimOp>(loc, source, dim);
call    0 never executed
    #####:   43:  llvm_unreachable("Expected MemRefType or TensorType");
call    0 never executed
        -:   44:}
        -:   45:
        -:   46:/// Return the number of elements of basis, `0` if empty.
function _ZN4mlir21computeMaxLinearIndexEN4llvm8ArrayRefIlEE called 62 returned 100% blocks executed 100%
       62:   47:int64_t mlir::computeMaxLinearIndex(ArrayRef<int64_t> basis) {
       62:   48:  if (basis.empty())
branch  0 taken 100% (fallthrough)
branch  1 taken 0%
        -:   49:    return 0;
       62:   50:  return std::accumulate(basis.begin(), basis.end(), 1,
       62:   51:                         std::multiplies<int64_t>());
        -:   52:}
        -:   53:
function _ZN4mlir14computeStridesEN4llvm8ArrayRefIlEES2_ called 1457 returned 100% blocks executed 68%
     1457:   54:SmallVector<int64_t, 4> mlir::computeStrides(ArrayRef<int64_t> shape,
        -:   55:                                             ArrayRef<int64_t> sizes) {
     1457:   56:  int64_t rank = shape.size();
call    0 returned 100%
        -:   57:  // Compute the count for each dimension.
     1457:   58:  SmallVector<int64_t, 4> sliceDimCounts(rank);
call    0 returned 100%
     4371:   59:  for (int64_t r = 0; r < rank; ++r)
call    0 returned 100%
branch  1 taken 67% (fallthrough)
branch  2 taken 33%
     2914:   60:    sliceDimCounts[r] = ceilDiv(shape[r], sizes[r]);
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
branch  2 taken 0% (fallthrough)
branch  3 taken 100%
call    4 returned 100%
branch  5 taken 0% (fallthrough)
branch  6 taken 100%
        -:   61:  // Use that to compute the slice stride for each dimension.
     1457:   62:  SmallVector<int64_t, 4> sliceStrides(rank);
call    0 returned 100%
     1457:   63:  sliceStrides[rank - 1] = 1;
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
     2914:   64:  for (int64_t r = rank - 2; r >= 0; --r)
branch  0 taken 50% (fallthrough)
branch  1 taken 50%
     1457:   65:    sliceStrides[r] = sliceStrides[r + 1] * sliceDimCounts[r + 1];
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
branch  2 taken 0% (fallthrough)
branch  3 taken 100%
branch  4 taken 0% (fallthrough)
branch  5 taken 100%
     1457:   66:  return sliceStrides;
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
        -:   67:}
        -:   68:
function _ZN4mlir43computeElementOffsetsFromVectorSliceOffsetsEN4llvm8ArrayRefIlEES2_ called 4096 returned 100% blocks executed 100%
     4096:   69:SmallVector<int64_t, 4> mlir::computeElementOffsetsFromVectorSliceOffsets(
        -:   70:    ArrayRef<int64_t> sizes, ArrayRef<int64_t> vectorOffsets) {
     4096:   71:  SmallVector<int64_t, 4> result;
    12288:   72:  for (auto it : llvm::zip(vectorOffsets, sizes))
branch  0 taken 67% (fallthrough)
branch  1 taken 33%
     8192:   73:    result.push_back(std::get<0>(it) * std::get<1>(it));
call    0 returned 100%
     4096:   74:  return result;
        -:   75:}
        -:   76:
function _ZN4mlir10shapeRatioEN4llvm8ArrayRefIlEES2_ called 19024 returned 100% blocks executed 85%
    19024:   77:Optional<SmallVector<int64_t, 4>> mlir::shapeRatio(ArrayRef<int64_t> superShape,
        -:   78:                                                   ArrayRef<int64_t> subShape) {
    19024:   79:  if (superShape.size() < subShape.size()) {
branch  0 taken 11% (fallthrough)
branch  1 taken 89%
     2116:   80:    return Optional<SmallVector<int64_t, 4>>();
        -:   81:  }
        -:   82:
        -:   83:  // Starting from the end, compute the integer divisors.
    16908:   84:  std::vector<int64_t> result;
call    0 returned 100%
    16908:   85:  result.reserve(superShape.size());
call    0 returned 100%
    50134:   86:  for (auto [superSize, subSize] :
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
    49015:   87:       llvm::zip(llvm::reverse(superShape), llvm::reverse(subShape))) {
branch  0 taken 68% (fallthrough)
branch  1 taken 32%
branch  2 taken 0% (fallthrough)
branch  3 taken 100%
   33226*:   88:    assert(superSize > 0 && "superSize must be > 0");
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
call    2 never executed
   33226*:   89:    assert(subSize > 0 && "subSize must be > 0");
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
call    2 never executed
        -:   90:
        -:   91:    // If integral division does not occur, return and let the caller decide.
    33226:   92:    if (superSize % subSize != 0)
branch  0 taken 3% (fallthrough)
branch  1 taken 97%
     1119:   93:      return None;
    32107:   94:    result.push_back(superSize / subSize);
call    0 returned 100%
        -:   95:  }
        -:   96:
        -:   97:  // At this point we computed the ratio (in reverse) for the common
        -:   98:  // size. Fill with the remaining entries from the super-vector shape (still in
        -:   99:  // reverse).
    15789:  100:  int commonSize = subShape.size();
call    0 returned 100%
    15789:  101:  std::copy(superShape.rbegin() + commonSize, superShape.rend(),
call    0 returned 100%
    15789:  102:            std::back_inserter(result));
call    0 returned 100%
        -:  103:
   15789*:  104:  assert(result.size() == superShape.size() &&
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
call    2 never executed
        -:  105:         "super to sub shape ratio is not of the same size as the super rank");
        -:  106:
        -:  107:  // Reverse again to get it back in the proper order and return.
    31578:  108:  return SmallVector<int64_t, 4>{result.rbegin(), result.rend()};
call    0 returned 100%
branch  1 taken 100% (fallthrough)
branch  2 taken 0%
branch  3 taken 0% (fallthrough)
branch  4 taken 100%
        -:  109:}
        -:  110:
function _ZN4mlir10shapeRatioENS_10VectorTypeES0_ called 0 returned 0% blocks executed 0%
    #####:  111:Optional<SmallVector<int64_t, 4>> mlir::shapeRatio(VectorType superVectorType,
        -:  112:                                                   VectorType subVectorType) {
    #####:  113:  assert(superVectorType.getElementType() == subVectorType.getElementType() &&
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
call    4 never executed
        -:  114:         "vector types must be of the same elemental type");
    #####:  115:  return shapeRatio(superVectorType.getShape(), subVectorType.getShape());
call    0 never executed
call    1 never executed
call    2 never executed
        -:  116:}
        -:  117:
        -:  118:/// Constructs a permutation map from memref indices to vector dimension.
        -:  119:///
        -:  120:/// The implementation uses the knowledge of the mapping of enclosing loop to
        -:  121:/// vector dimension. `enclosingLoopToVectorDim` carries this information as a
        -:  122:/// map with:
        -:  123:///   - keys representing "vectorized enclosing loops";
        -:  124:///   - values representing the corresponding vector dimension.
        -:  125:/// The algorithm traverses "vectorized enclosing loops" and extracts the
        -:  126:/// at-most-one MemRef index that is invariant along said loop. This index is
        -:  127:/// guaranteed to be at most one by construction: otherwise the MemRef is not
        -:  128:/// vectorizable.
        -:  129:/// If this invariant index is found, it is added to the permutation_map at the
        -:  130:/// proper vector dimension.
        -:  131:/// If no index is found to be invariant, 0 is added to the permutation_map and
        -:  132:/// corresponds to a vector broadcast along that dimension.
        -:  133:///
        -:  134:/// Returns an empty AffineMap if `enclosingLoopToVectorDim` is empty,
        -:  135:/// signalling that no permutation map can be constructed given
        -:  136:/// `enclosingLoopToVectorDim`.
        -:  137:///
        -:  138:/// Examples can be found in the documentation of `makePermutationMap`, in the
        -:  139:/// header file.
function _ZL18makePermutationMapN4llvm8ArrayRefIN4mlir5ValueEEERKNS_8DenseMapIPNS1_9OperationEjNS_12DenseMapInfoIS6_vEENS_6detail12DenseMapPairIS6_jEEEE called 0 returned 0% blocks executed 0%
    #####:  140:static AffineMap makePermutationMap(
        -:  141:    ArrayRef<Value> indices,
        -:  142:    const DenseMap<Operation *, unsigned> &enclosingLoopToVectorDim) {
    #####:  143:  if (enclosingLoopToVectorDim.empty())
branch  0 never executed
branch  1 never executed
    #####:  144:    return AffineMap();
    #####:  145:  MLIRContext *context =
    #####:  146:      enclosingLoopToVectorDim.begin()->getFirst()->getContext();
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  147:  SmallVector<AffineExpr, 4> perm(enclosingLoopToVectorDim.size(),
call    0 never executed
    #####:  148:                                  getAffineConstantExpr(0, context));
call    0 never executed
call    1 never executed
        -:  149:
    #####:  150:  for (auto kvp : enclosingLoopToVectorDim) {
call    0 never executed
call    1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
call    5 never executed
    #####:  151:    assert(kvp.second < perm.size());
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  152:    auto invariants = getInvariantAccesses(
    #####:  153:        cast<AffineForOp>(kvp.first).getInductionVar(), indices);
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:  154:    unsigned numIndices = indices.size();
    #####:  155:    unsigned countInvariantIndices = 0;
    #####:  156:    for (unsigned dim = 0; dim < numIndices; ++dim) {
branch  0 never executed
branch  1 never executed
    #####:  157:      if (!invariants.count(indices[dim])) {
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  158:        assert(perm[kvp.second] == getAffineConstantExpr(0, context) &&
call    0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
call    5 never executed
        -:  159:               "permutationMap already has an entry along dim");
    #####:  160:        perm[kvp.second] = getAffineDimExpr(dim, context);
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  161:      } else {
    #####:  162:        ++countInvariantIndices;
        -:  163:      }
        -:  164:    }
    #####:  165:    assert((countInvariantIndices == numIndices ||
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
call    4 never executed
        -:  166:            countInvariantIndices == numIndices - 1) &&
        -:  167:           "Vectorization prerequisite violated: at most 1 index may be "
        -:  168:           "invariant wrt a vectorized loop");
    #####:  169:    (void)countInvariantIndices;
call    0 never executed
        -:  170:  }
    #####:  171:  return AffineMap::get(indices.size(), 0, perm, context);
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  172:}
        -:  173:
        -:  174:/// Implementation detail that walks up the parents and records the ones with
        -:  175:/// the specified type.
        -:  176:/// TODO: could also be implemented as a collect parents followed by a
        -:  177:/// filter and made available outside this file.
        -:  178:template <typename T>
function _Z16getParentsOfTypeIN4mlir11AffineForOpEEN4llvm9SetVectorIPNS0_9OperationESt6vectorIS5_SaIS5_EENS2_8DenseSetIS5_NS2_12DenseMapInfoIS5_vEEEEEEPNS0_5BlockE called 0 returned 0% blocks executed 0%
    #####:  179:static SetVector<Operation *> getParentsOfType(Block *block) {
call    0 never executed
    #####:  180:  SetVector<Operation *> res;
    #####:  181:  auto *current = block->getParentOp();
call    0 never executed
    #####:  182:  while (current) {
branch  0 never executed
branch  1 never executed
    #####:  183:    if (auto typedParent = dyn_cast<T>(current)) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  184:      assert(res.count(current) == 0 && "Already inserted");
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
    #####:  185:      res.insert(current);
call    0 never executed
        -:  186:    }
    #####:  187:    current = current->getParentOp();
branch  0 never executed
branch  1 never executed
        -:  188:  }
    #####:  189:  return res;
        -:  190:}
        -:  191:
        -:  192:/// Returns the enclosing AffineForOp, from closest to farthest.
    #####:  193:static SetVector<Operation *> getEnclosingforOps(Block *block) {
    #####:  194:  return getParentsOfType<AffineForOp>(block);
        -:  195:}
        -:  196:
function _ZN4mlir18makePermutationMapEPNS_5BlockEN4llvm8ArrayRefINS_5ValueEEERKNS2_8DenseMapIPNS_9OperationEjNS2_12DenseMapInfoIS8_vEENS2_6detail12DenseMapPairIS8_jEEEE called 0 returned 0% blocks executed 0%
    #####:  197:AffineMap mlir::makePermutationMap(
        -:  198:    Block *insertPoint, ArrayRef<Value> indices,
        -:  199:    const DenseMap<Operation *, unsigned> &loopToVectorDim) {
    #####:  200:  DenseMap<Operation *, unsigned> enclosingLoopToVectorDim;
call    0 never executed
    #####:  201:  auto enclosingLoops = getEnclosingforOps(insertPoint);
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  202:  for (auto *forInst : enclosingLoops) {
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  203:    auto it = loopToVectorDim.find(forInst);
call    0 never executed
    #####:  204:    if (it != loopToVectorDim.end()) {
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  205:      enclosingLoopToVectorDim.insert(*it);
call    0 never executed
call    1 never executed
        -:  206:    }
        -:  207:  }
    #####:  208:  return ::makePermutationMap(indices, enclosingLoopToVectorDim);
call    0 never executed
        -:  209:}
        -:  210:
function _ZN4mlir18makePermutationMapEPNS_9OperationEN4llvm8ArrayRefINS_5ValueEEERKNS2_8DenseMapIS1_jNS2_12DenseMapInfoIS1_vEENS2_6detail12DenseMapPairIS1_jEEEE called 0 returned 0% blocks executed 0%
    #####:  211:AffineMap mlir::makePermutationMap(
        -:  212:    Operation *op, ArrayRef<Value> indices,
        -:  213:    const DenseMap<Operation *, unsigned> &loopToVectorDim) {
    #####:  214:  return makePermutationMap(op->getBlock(), indices, loopToVectorDim);
call    0 never executed
        -:  215:}
        -:  216:
function _ZN4mlir7matcher24operatesOnSuperVectorsOfERNS_9OperationENS_10VectorTypeE called 0 returned 0% blocks executed 0%
    #####:  217:bool matcher::operatesOnSuperVectorsOf(Operation &op,
        -:  218:                                       VectorType subVectorType) {
        -:  219:  // First, extract the vector type and distinguish between:
        -:  220:  //   a. ops that *must* lower a super-vector (i.e. vector.transfer_read,
        -:  221:  //      vector.transfer_write); and
        -:  222:  //   b. ops that *may* lower a super-vector (all other ops).
        -:  223:  // The ops that *may* lower a super-vector only do so if the super-vector to
        -:  224:  // sub-vector ratio exists. The ops that *must* lower a super-vector are
        -:  225:  // explicitly checked for this property.
        -:  226:  /// TODO: there should be a single function for all ops to do this so we
        -:  227:  /// do not have to special case. Maybe a trait, or just a method, unclear atm.
    #####:  228:  bool mustDivide = false;
    #####:  229:  (void)mustDivide;
    #####:  230:  VectorType superVectorType;
    #####:  231:  if (auto transfer = dyn_cast<VectorTransferOpInterface>(op)) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  232:    superVectorType = transfer.getVectorType();
    #####:  233:    mustDivide = true;
call    0 never executed
    #####:  234:  } else if (op.getNumResults() == 0) {
branch  0 never executed
branch  1 never executed
    #####:  235:    if (!isa<func::ReturnOp>(op)) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  236:      op.emitError("NYI: assuming only return operations can have 0 "
call    0 never executed
call    1 never executed
call    2 never executed
        -:  237:                   " results at this point");
        -:  238:    }
    #####:  239:    return false;
    #####:  240:  } else if (op.getNumResults() == 1) {
branch  0 never executed
branch  1 never executed
    #####:  241:    if (auto v = op.getResult(0).getType().dyn_cast<VectorType>()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  242:      superVectorType = v;
        -:  243:    } else {
        -:  244:      // Not a vector type.
    #####:  245:      return false;
        -:  246:    }
        -:  247:  } else {
        -:  248:    // Not a vector.transfer and has more than 1 result, fail hard for now to
        -:  249:    // wake us up when something changes.
    #####:  250:    op.emitError("NYI: operation has more than 1 result");
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  251:    return false;
        -:  252:  }
        -:  253:
        -:  254:  // Get the ratio.
    #####:  255:  auto ratio = shapeRatio(superVectorType, subVectorType);
call    0 never executed
        -:  256:
        -:  257:  // Sanity check.
    #####:  258:  assert((ratio || !mustDivide) &&
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
call    4 never executed
        -:  259:         "vector.transfer operation in which super-vector size is not an"
        -:  260:         " integer multiple of sub-vector size");
        -:  261:
        -:  262:  // This catches cases that are not strictly necessary to have multiplicity but
        -:  263:  // still aren't divisible by the sub-vector shape.
        -:  264:  // This could be useful information if we wanted to reshape at the level of
        -:  265:  // the vector type (but we would have to look at the compute and distinguish
        -:  266:  // between parallel, reduction and possibly other cases.
    #####:  267:  return ratio.has_value();
branch  0 never executed
branch  1 never executed
        -:  268:}
