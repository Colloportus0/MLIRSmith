        -:    0:Source:/data/xcy/llvm-project-fdbc55a5/mlir/lib/Dialect/Shape/IR/Shape.cpp
        -:    0:Graph:../tools/mlir/lib/Dialect/Shape/IR/CMakeFiles/obj.MLIRShapeDialect.dir/Shape.cpp.gcno
        -:    0:Data:../tools/mlir/lib/Dialect/Shape/IR/CMakeFiles/obj.MLIRShapeDialect.dir/Shape.cpp.gcda
        -:    0:Runs:116161
        -:    1://===- Shape.cpp - MLIR Shape Operations ----------------------------------===//
        -:    2://
        -:    3:// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
        -:    4:// See https://llvm.org/LICENSE.txt for license information.
        -:    5:// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
        -:    6://
        -:    7://===----------------------------------------------------------------------===//
        -:    8:
        -:    9:#include <utility>
        -:   10:
        -:   11:#include "mlir/Dialect/Shape/IR/Shape.h"
        -:   12:
        -:   13:#include "mlir/Dialect/Arith/IR/Arith.h"
        -:   14:#include "mlir/Dialect/CommonFolders.h"
        -:   15:#include "mlir/Dialect/Tensor/IR/Tensor.h"
        -:   16:#include "mlir/Dialect/Traits.h"
        -:   17:#include "mlir/IR/Builders.h"
        -:   18:#include "mlir/IR/BuiltinTypes.h"
        -:   19:#include "mlir/IR/DialectImplementation.h"
        -:   20:#include "mlir/IR/FunctionImplementation.h"
        -:   21:#include "mlir/IR/Matchers.h"
        -:   22:#include "mlir/IR/PatternMatch.h"
        -:   23:#include "mlir/IR/TypeUtilities.h"
        -:   24:#include "mlir/Transforms/InliningUtils.h"
        -:   25:#include "llvm/ADT/SetOperations.h"
        -:   26:#include "llvm/ADT/SmallString.h"
        -:   27:#include "llvm/ADT/TypeSwitch.h"
        -:   28:#include "llvm/Support/raw_ostream.h"
        -:   29:
        -:   30:using namespace mlir;
        -:   31:using namespace mlir::shape;
        -:   32:
        -:   33:#include "mlir/Dialect/Shape/IR/ShapeOpsDialect.cpp.inc"
        -:   34:
        -:   35:namespace {
        -:   36:#include "ShapeCanonicalization.inc"
        -:   37:} // namespace
        -:   38:
function _ZN4mlir5shape19getExtentTensorTypeEPNS_11MLIRContextEl called 0 returned 0% blocks executed 0%
    #####:   39:RankedTensorType shape::getExtentTensorType(MLIRContext *ctx, int64_t rank) {
    #####:   40:  return RankedTensorType::get({rank}, IndexType::get(ctx));
call    0 never executed
call    1 never executed
        -:   41:}
        -:   42:
function _ZN4mlir5shape18isExtentTensorTypeENS_4TypeE called 0 returned 0% blocks executed 0%
    #####:   43:bool shape::isExtentTensorType(Type type) {
    #####:   44:  auto ranked = type.dyn_cast<RankedTensorType>();
call    0 never executed
    #####:   45:  return ranked && ranked.getRank() == 1 && ranked.getElementType().isIndex();
branch  0 never executed
branch  1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
call    5 never executed
call    6 never executed
branch  7 never executed
branch  8 never executed
        -:   46:}
        -:   47:
function _ZN4mlir5shape11getShapeVecENS_5ValueERN4llvm15SmallVectorImplIlEE called 0 returned 0% blocks executed 0%
    #####:   48:LogicalResult shape::getShapeVec(Value input,
        -:   49:                                 SmallVectorImpl<int64_t> &shapeValues) {
    #####:   50:  if (auto inputOp = input.getDefiningOp<ShapeOfOp>()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:   51:    auto type = inputOp.getArg().getType().cast<ShapedType>();
call    0 never executed
call    1 never executed
    #####:   52:    if (!type.hasRank())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:   53:      return failure();
    #####:   54:    llvm::append_range(shapeValues, type.getShape());
call    0 never executed
call    1 never executed
    #####:   55:    return success();
        -:   56:  }
    #####:   57:  DenseIntElementsAttr attr;
    #####:   58:  if (matchPattern(input, m_Constant(&attr))) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:   59:    llvm::append_range(shapeValues, attr.getValues<int64_t>());
call    0 never executed
call    1 never executed
    #####:   60:    return success();
        -:   61:  }
    #####:   62:  return failure();
        -:   63:}
        -:   64:
    #####:   65:static bool isErrorPropagationPossible(TypeRange operandTypes) {
    #####:   66:  return llvm::any_of(operandTypes, [](Type ty) {
call    0 never executed
call    1 never executed
        -:   67:    return ty.isa<SizeType, ShapeType, ValueShapeType>();
        -:   68:  });
        -:   69:}
        -:   70:
function _ZL19verifySizeOrIndexOpPN4mlir9OperationE called 0 returned 0% blocks executed 0%
    #####:   71:static LogicalResult verifySizeOrIndexOp(Operation *op) {
    #####:   72:  assert(op != nullptr && op->getNumResults() == 1);
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
call    4 never executed
    #####:   73:  Type resultTy = op->getResultTypes().front();
call    0 never executed
call    1 never executed
    #####:   74:  if (isErrorPropagationPossible(op->getOperandTypes())) {
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:   75:    if (!resultTy.isa<SizeType>())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:   76:      return op->emitOpError()
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
        -:   77:             << "if at least one of the operands can hold error values then "
    #####:   78:                "the result must be of type `size` to propagate them";
call    0 never executed
        -:   79:  }
    #####:   80:  return success();
        -:   81:}
        -:   82:
function _ZL27verifyShapeOrExtentTensorOpPN4mlir9OperationE called 0 returned 0% blocks executed 0%
    #####:   83:static LogicalResult verifyShapeOrExtentTensorOp(Operation *op) {
    #####:   84:  assert(op != nullptr && op->getNumResults() == 1);
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
call    4 never executed
    #####:   85:  Type resultTy = op->getResultTypes().front();
call    0 never executed
call    1 never executed
    #####:   86:  if (isErrorPropagationPossible(op->getOperandTypes())) {
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:   87:    if (!resultTy.isa<ShapeType>())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:   88:      return op->emitOpError()
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
        -:   89:             << "if at least one of the operands can hold error values then "
    #####:   90:                "the result must be of type `shape` to propagate them";
call    0 never executed
        -:   91:  }
    #####:   92:  return success();
        -:   93:}
        -:   94:
        -:   95:template <typename... Ty>
function _Z21eachHasOnlyOneOfTypesIJN4mlir5shape8SizeTypeENS0_9IndexTypeEEEbNS0_9TypeRangeE called 0 returned 0% blocks executed 0%
    #####:   96:static bool eachHasOnlyOneOfTypes(TypeRange typeRange) {
    #####:   97:  return typeRange.size() == 1 && typeRange.front().isa<Ty...>();
branch  0 never executed
branch  1 never executed
call    2 never executed
call    3 never executed
branch  4 never executed
branch  5 never executed
        -:   98:}
        -:   99:
        -:  100:template <typename... Ty, typename... ranges>
function _Z21eachHasOnlyOneOfTypesIJN4mlir5shape8SizeTypeENS0_9IndexTypeEEJNS0_9TypeRangeEEEbS4_DpT0_ called 0 returned 0% blocks executed 0%
    #####:  101:static bool eachHasOnlyOneOfTypes(TypeRange l, ranges... rs) {
    #####:  102:  return eachHasOnlyOneOfTypes<Ty...>(l) && eachHasOnlyOneOfTypes<Ty...>(rs...);
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
branch  4 never executed
branch  5 never executed
        -:  103:}
        -:  104:
        -:  105://===----------------------------------------------------------------------===//
        -:  106:// InlinerInterface
        -:  107://===----------------------------------------------------------------------===//
        -:  108:
        -:  109:namespace {
        -:  110:/// This class defines the interface for inlining shape dialect ops.
        -:  111:struct ShapeInlinerInterface : public DialectInlinerInterface {
        -:  112:  using DialectInlinerInterface::DialectInlinerInterface;
        -:  113:
        -:  114:  // Returns true if the given region 'src' can be inlined into the region
        -:  115:  // 'dest' that is attached to an operation registered to the current dialect.
function _ZNK12_GLOBAL__N_121ShapeInlinerInterface15isLegalToInlineEPN4mlir6RegionES3_bRNS1_20BlockAndValueMappingE called 0 returned 0% blocks executed 0%
    #####:  116:  bool isLegalToInline(Region *dest, Region *src, bool wouldBeCloned,
        -:  117:                       BlockAndValueMapping &) const final {
    #####:  118:    return true;
        -:  119:  }
        -:  120:
        -:  121:  // Returns true if the given operation 'op', that is registered to this
        -:  122:  // dialect, can be inlined into the region 'dest' that is attached to an
        -:  123:  // operation registered to the current dialect.
function _ZNK12_GLOBAL__N_121ShapeInlinerInterface15isLegalToInlineEPN4mlir9OperationEPNS1_6RegionEbRNS1_20BlockAndValueMappingE called 0 returned 0% blocks executed 0%
    #####:  124:  bool isLegalToInline(Operation *op, Region *dest, bool wouldBeCloned,
        -:  125:                       BlockAndValueMapping &) const final {
    #####:  126:    return true;
        -:  127:  }
        -:  128:};
        -:  129:} // namespace
        -:  130:
function _ZN4mlir5shape12ShapeDialect10initializeEv called 1061 returned 100% blocks executed 100%
     1061:  131:void ShapeDialect::initialize() {
     1061:  132:  addOperations<
        -:  133:#define GET_OP_LIST
        -:  134:#include "mlir/Dialect/Shape/IR/ShapeOps.cpp.inc"
     1061:  135:      >();
call    0 returned 100%
     1061:  136:  addTypes<
        -:  137:#define GET_TYPEDEF_LIST
        -:  138:#include "mlir/Dialect/Shape/IR/ShapeOpsTypes.cpp.inc"
     1061:  139:      >();
call    0 returned 100%
     1061:  140:  addInterfaces<ShapeInlinerInterface>();
call    0 returned 100%
        -:  141:  // Allow unknown operations during prototyping and testing. As the dialect is
        -:  142:  // still evolving it makes it simple to start with an unregistered ops and
        -:  143:  // try different variants before actually defining the op.
     1061:  144:  allowUnknownOperations();
     1061:  145:}
        -:  146:
function _ZN4mlir5shape12ShapeDialect19materializeConstantERNS_9OpBuilderENS_9AttributeENS_4TypeENS_8LocationE called 0 returned 0% blocks executed 0%
    #####:  147:Operation *ShapeDialect::materializeConstant(OpBuilder &builder,
        -:  148:                                             Attribute value, Type type,
        -:  149:                                             Location loc) {
    #####:  150:  if (type.isa<ShapeType>() || isExtentTensorType(type))
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
branch  4 never executed
branch  5 never executed
    #####:  151:    return builder.create<ConstShapeOp>(loc, type,
call    0 never executed
    #####:  152:                                        value.cast<DenseIntElementsAttr>());
call    0 never executed
    #####:  153:  if (type.isa<SizeType>())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  154:    return builder.create<ConstSizeOp>(loc, type, value.cast<IntegerAttr>());
call    0 never executed
call    1 never executed
    #####:  155:  if (type.isa<WitnessType>())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  156:    return builder.create<ConstWitnessOp>(loc, type, value.cast<BoolAttr>());
call    0 never executed
call    1 never executed
    #####:  157:  if (arith::ConstantOp::isBuildableWith(value, type))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  158:    return builder.create<arith::ConstantOp>(loc, type, value);
call    0 never executed
        -:  159:  return nullptr;
        -:  160:}
        -:  161:
function _ZN4mlir5shape12ShapeDialect24verifyOperationAttributeEPNS_9OperationENS_14NamedAttributeE called 0 returned 0% blocks executed 0%
    #####:  162:LogicalResult ShapeDialect::verifyOperationAttribute(Operation *op,
        -:  163:                                                     NamedAttribute attribute) {
        -:  164:  // Verify shape.lib attribute.
    #####:  165:  if (attribute.getName() == "shape.lib") {
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  166:    if (!op->hasTrait<OpTrait::SymbolTable>())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  167:      return op->emitError(
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  168:          "shape.lib attribute may only be on op implementing SymbolTable");
call    0 never executed
        -:  169:
    #####:  170:    if (auto symbolRef = attribute.getValue().dyn_cast<SymbolRefAttr>()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  171:      auto *symbol = SymbolTable::lookupSymbolIn(op, symbolRef);
call    0 never executed
    #####:  172:      if (!symbol)
branch  0 never executed
branch  1 never executed
    #####:  173:        return op->emitError("shape function library ")
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:  174:               << symbolRef << " not found";
call    0 never executed
call    1 never executed
    #####:  175:      return isa<shape::FunctionLibraryOp>(symbol)
call    0 never executed
    #####:  176:                 ? success()
    #####:  177:                 : op->emitError()
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  178:                       << symbolRef << " required to be shape function library";
branch  0 never executed
branch  1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
        -:  179:    }
        -:  180:
    #####:  181:    if (auto arr = attribute.getValue().dyn_cast<ArrayAttr>()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  182:      // Verify all entries are function libraries and mappings in libraries
        -:  183:      // refer to unique ops.
    #####:  184:      DenseSet<StringAttr> key;
call    0 never executed
    #####:  185:      for (auto it : arr) {
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  186:        if (!it.isa<SymbolRefAttr>())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  187:          return op->emitError(
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  188:              "only SymbolRefAttr allowed in shape.lib attribute array");
call    0 never executed
        -:  189:
    #####:  190:        auto shapeFnLib = dyn_cast<shape::FunctionLibraryOp>(
call    0 never executed
    #####:  191:            SymbolTable::lookupSymbolIn(op, it.cast<SymbolRefAttr>()));
call    0 never executed
call    1 never executed
    #####:  192:        if (!shapeFnLib)
branch  0 never executed
branch  1 never executed
    #####:  193:          return op->emitError()
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:  194:                 << it << " does not refer to FunctionLibraryOp";
call    0 never executed
call    1 never executed
    #####:  195:        for (auto mapping : shapeFnLib.getMapping()) {
call    0 never executed
call    1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
    #####:  196:          if (!key.insert(mapping.getName()).second) {
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  197:            return op->emitError("only one op to shape mapping allowed, found "
call    0 never executed
call    1 never executed
        -:  198:                                 "multiple for `")
    #####:  199:                   << mapping.getName() << "`";
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
        -:  200:          }
        -:  201:        }
        -:  202:      }
    #####:  203:      return success();
call    0 never executed
        -:  204:    }
        -:  205:
    #####:  206:    return op->emitError("only SymbolRefAttr or array of SymbolRefAttrs "
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  207:                         "allowed as shape.lib attribute");
call    0 never executed
        -:  208:  }
    #####:  209:  return success();
        -:  210:}
        -:  211:
        -:  212://===----------------------------------------------------------------------===//
        -:  213:// AnyOp
        -:  214://===----------------------------------------------------------------------===//
        -:  215:
        -:  216:// TODO: Canonicalization should be implemented for shapes that can be
        -:  217:// determined through mixtures of the known dimensions of the inputs.
function _ZN4mlir5shape5AnyOp4foldEN4llvm8ArrayRefINS_9AttributeEEE called 0 returned 0% blocks executed 0%
    #####:  218:OpFoldResult AnyOp::fold(ArrayRef<Attribute> operands) {
        -:  219:  // Only the last operand is checked because AnyOp is commutative.
    #####:  220:  if (operands.back())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  221:    return operands.back();
call    0 never executed
        -:  222:
    #####:  223:  return nullptr;
        -:  224:}
        -:  225:
        -:  226://===----------------------------------------------------------------------===//
        -:  227:// AssumingOp
        -:  228://===----------------------------------------------------------------------===//
        -:  229:
function _ZN4mlir5shape10AssumingOp5parseERNS_11OpAsmParserERNS_14OperationStateE called 0 returned 0% blocks executed 0%
    #####:  230:ParseResult AssumingOp::parse(OpAsmParser &parser, OperationState &result) {
    #####:  231:  result.regions.reserve(1);
branch  0 never executed
branch  1 never executed
    #####:  232:  Region *doRegion = result.addRegion();
call    0 never executed
        -:  233:
    #####:  234:  auto &builder = parser.getBuilder();
call    0 never executed
    #####:  235:  OpAsmParser::UnresolvedOperand cond;
call    0 never executed
    #####:  236:  if (parser.parseOperand(cond) ||
call    0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
    #####:  237:      parser.resolveOperand(cond, builder.getType<WitnessType>(),
    #####:  238:                            result.operands))
branch  0 never executed
branch  1 never executed
call    2 never executed
call    3 never executed
branch  4 never executed
branch  5 never executed
    #####:  239:    return failure();
        -:  240:
        -:  241:  // Parse optional results type list.
    #####:  242:  if (parser.parseOptionalArrowTypeList(result.types))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  243:    return failure();
        -:  244:
        -:  245:  // Parse the region and add a terminator if elided.
    #####:  246:  if (parser.parseRegion(*doRegion, /*arguments=*/{}, /*argTypes=*/{}))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  247:    return failure();
    #####:  248:  AssumingOp::ensureTerminator(*doRegion, parser.getBuilder(), result.location);
call    0 never executed
call    1 never executed
        -:  249:
        -:  250:  // Parse the optional attribute list.
    #####:  251:  if (parser.parseOptionalAttrDict(result.attributes))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  252:    return failure();
    #####:  253:  return success();
        -:  254:}
        -:  255:
function _ZN4mlir5shape10AssumingOp5printERNS_12OpAsmPrinterE called 0 returned 0% blocks executed 0%
    #####:  256:void AssumingOp::print(OpAsmPrinter &p) {
    #####:  257:  bool yieldsResults = !getResults().empty();
call    0 never executed
call    1 never executed
        -:  258:
    #####:  259:  p << " " << getWitness();
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  260:  if (yieldsResults)
branch  0 never executed
branch  1 never executed
    #####:  261:    p << " -> (" << getResultTypes() << ")";
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
call    4 never executed
    #####:  262:  p << ' ';
call    0 never executed
    #####:  263:  p.printRegion(getDoRegion(),
call    0 never executed
        -:  264:                /*printEntryBlockArgs=*/false,
    #####:  265:                /*printBlockTerminators=*/yieldsResults);
call    0 never executed
    #####:  266:  p.printOptionalAttrDict((*this)->getAttrs());
call    0 never executed
call    1 never executed
    #####:  267:}
        -:  268:
        -:  269:namespace {
        -:  270:// Removes AssumingOp with a passing witness and inlines the region.
        -:  271:struct AssumingWithTrue : public OpRewritePattern<AssumingOp> {
        -:  272:  using OpRewritePattern<AssumingOp>::OpRewritePattern;
        -:  273:
function _ZNK12_GLOBAL__N_116AssumingWithTrue15matchAndRewriteEN4mlir5shape10AssumingOpERNS1_15PatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  274:  LogicalResult matchAndRewrite(AssumingOp op,
        -:  275:                                PatternRewriter &rewriter) const override {
    #####:  276:    auto witness = op.getWitness().getDefiningOp<ConstWitnessOp>();
call    0 never executed
call    1 never executed
    #####:  277:    if (!witness || !witness.getPassingAttr())
branch  0 never executed
branch  1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
    #####:  278:      return failure();
        -:  279:
    #####:  280:    AssumingOp::inlineRegionIntoParent(op, rewriter);
call    0 never executed
    #####:  281:    return success();
        -:  282:  }
        -:  283:};
        -:  284:
        -:  285:struct AssumingOpRemoveUnusedResults : public OpRewritePattern<AssumingOp> {
        -:  286:  using OpRewritePattern<AssumingOp>::OpRewritePattern;
        -:  287:
function _ZNK12_GLOBAL__N_129AssumingOpRemoveUnusedResults15matchAndRewriteEN4mlir5shape10AssumingOpERNS1_15PatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  288:  LogicalResult matchAndRewrite(AssumingOp op,
        -:  289:                                PatternRewriter &rewriter) const override {
    #####:  290:    Block *body = op.getBody();
call    0 never executed
    #####:  291:    auto yieldOp = llvm::cast<AssumingYieldOp>(body->getTerminator());
call    0 never executed
call    1 never executed
        -:  292:
        -:  293:    // Find used values.
    #####:  294:    SmallVector<Value, 4> newYieldOperands;
call    0 never executed
    #####:  295:    for (auto [opResult, yieldOperand] :
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  296:         llvm::zip(op.getResults(), yieldOp.getOperands())) {
call    0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
    #####:  297:      if (!opResult.getUses().empty()) {
branch  0 never executed
branch  1 never executed
    #####:  298:        newYieldOperands.push_back(yieldOperand);
call    0 never executed
        -:  299:      }
        -:  300:    }
        -:  301:
        -:  302:    // Rewrite only if redundant results exist.
    #####:  303:    if (newYieldOperands.size() == yieldOp->getNumOperands())
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####:  304:      return failure();
        -:  305:
        -:  306:    // Replace yield op in the old assuming op's body and move the entire region
        -:  307:    // to the new assuming op.
    #####:  308:    rewriter.setInsertionPointToEnd(body);
call    0 never executed
    #####:  309:    auto newYieldOp =
    #####:  310:        rewriter.replaceOpWithNewOp<AssumingYieldOp>(yieldOp, newYieldOperands);
call    0 never executed
    #####:  311:    rewriter.setInsertionPoint(op);
call    0 never executed
    #####:  312:    auto newOp = rewriter.create<AssumingOp>(
    #####:  313:        op.getLoc(), newYieldOp->getOperandTypes(), op.getWitness());
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  314:    newOp.getDoRegion().takeBody(op.getDoRegion());
call    0 never executed
call    1 never executed
call    2 never executed
        -:  315:
        -:  316:    // Use the new results to replace the previously used ones.
    #####:  317:    SmallVector<Value, 4> replacementValues;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  318:    auto src = newOp.getResults().begin();
call    0 never executed
call    1 never executed
    #####:  319:    for (auto it : op.getResults()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
    #####:  320:      if (it.getUses().empty())
branch  0 never executed
branch  1 never executed
    #####:  321:        replacementValues.push_back(nullptr);
call    0 never executed
        -:  322:      else
    #####:  323:        replacementValues.push_back(*src++);
call    0 never executed
call    1 never executed
        -:  324:    }
    #####:  325:    rewriter.replaceOp(op, replacementValues);
call    0 never executed
call    1 never executed
    #####:  326:    return success();
branch  0 never executed
branch  1 never executed
        -:  327:  }
        -:  328:};
        -:  329:} // namespace
        -:  330:
function _ZN4mlir5shape10AssumingOp27getCanonicalizationPatternsERNS_17RewritePatternSetEPNS_11MLIRContextE called 31 returned 100% blocks executed 100%
       31:  331:void AssumingOp::getCanonicalizationPatterns(RewritePatternSet &patterns,
        -:  332:                                             MLIRContext *context) {
       31:  333:  patterns.add<AssumingOpRemoveUnusedResults, AssumingWithTrue>(context);
call    0 returned 100%
       31:  334:}
        -:  335:
        -:  336:// See RegionBranchOpInterface in Interfaces/ControlFlowInterfaces.td
function _ZN4mlir5shape10AssumingOp19getSuccessorRegionsEN4llvm8OptionalIjEENS2_8ArrayRefINS_9AttributeEEERNS2_15SmallVectorImplINS_15RegionSuccessorEEE called 0 returned 0% blocks executed 0%
    #####:  337:void AssumingOp::getSuccessorRegions(
        -:  338:    Optional<unsigned> index, ArrayRef<Attribute> operands,
        -:  339:    SmallVectorImpl<RegionSuccessor> &regions) {
        -:  340:  // AssumingOp has unconditional control flow into the region and back to the
        -:  341:  // parent, so return the correct RegionSuccessor purely based on the index
        -:  342:  // being None or 0.
    #####:  343:  if (index) {
branch  0 never executed
branch  1 never executed
    #####:  344:    regions.push_back(RegionSuccessor(getResults()));
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  345:    return;
        -:  346:  }
        -:  347:
    #####:  348:  regions.push_back(RegionSuccessor(&getDoRegion()));
call    0 never executed
call    1 never executed
call    2 never executed
        -:  349:}
        -:  350:
function _ZN4mlir5shape10AssumingOp22inlineRegionIntoParentERS1_RNS_15PatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  351:void AssumingOp::inlineRegionIntoParent(AssumingOp &op,
        -:  352:                                        PatternRewriter &rewriter) {
    #####:  353:  auto *blockBeforeAssuming = rewriter.getInsertionBlock();
call    0 never executed
    #####:  354:  auto *assumingBlock = op.getBody();
call    0 never executed
    #####:  355:  auto initPosition = rewriter.getInsertionPoint();
call    0 never executed
    #####:  356:  auto *blockAfterAssuming =
    #####:  357:      rewriter.splitBlock(blockBeforeAssuming, initPosition);
call    0 never executed
        -:  358:
        -:  359:  // Remove the AssumingOp and AssumingYieldOp.
    #####:  360:  auto &yieldOp = assumingBlock->back();
call    0 never executed
    #####:  361:  rewriter.inlineRegionBefore(op.getDoRegion(), blockAfterAssuming);
call    0 never executed
call    1 never executed
    #####:  362:  rewriter.replaceOp(op, yieldOp.getOperands());
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  363:  rewriter.eraseOp(&yieldOp);
call    0 never executed
        -:  364:
        -:  365:  // Merge blocks together as there was no branching behavior from the
        -:  366:  // AssumingOp.
    #####:  367:  rewriter.mergeBlocks(assumingBlock, blockBeforeAssuming);
call    0 never executed
call    1 never executed
    #####:  368:  rewriter.mergeBlocks(blockAfterAssuming, blockBeforeAssuming);
call    0 never executed
call    1 never executed
    #####:  369:}
        -:  370:
function _ZN4mlir5shape10AssumingOp5buildERNS_9OpBuilderERNS_14OperationStateENS_5ValueEN4llvm12function_refIFNS7_11SmallVectorIS6_Lj2EEES3_NS_8LocationEEEE called 0 returned 0% blocks executed 0%
    #####:  371:void AssumingOp::build(
        -:  372:    OpBuilder &builder, OperationState &result, Value witness,
        -:  373:    function_ref<SmallVector<Value, 2>(OpBuilder &, Location)> bodyBuilder) {
        -:  374:
    #####:  375:  result.addOperands(witness);
call    0 never executed
call    1 never executed
    #####:  376:  Region *bodyRegion = result.addRegion();
call    0 never executed
    #####:  377:  bodyRegion->push_back(new Block);
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  378:  Block &bodyBlock = bodyRegion->front();
call    0 never executed
        -:  379:
        -:  380:  // Build body.
    #####:  381:  OpBuilder::InsertionGuard guard(builder);
call    0 never executed
    #####:  382:  builder.setInsertionPointToStart(&bodyBlock);
call    0 never executed
    #####:  383:  SmallVector<Value, 2> yieldValues = bodyBuilder(builder, result.location);
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  384:  builder.create<AssumingYieldOp>(result.location, yieldValues);
call    0 never executed
        -:  385:
    #####:  386:  SmallVector<Type, 2> assumingTypes;
branch  0 never executed
branch  1 never executed
    #####:  387:  for (Value v : yieldValues)
branch  0 never executed
branch  1 never executed
    #####:  388:    assumingTypes.push_back(v.getType());
call    0 never executed
    #####:  389:  result.addTypes(assumingTypes);
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  390:}
        -:  391:
        -:  392://===----------------------------------------------------------------------===//
        -:  393:// AddOp
        -:  394://===----------------------------------------------------------------------===//
        -:  395:
function _ZN4mlir5shape5AddOp16inferReturnTypesEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_10ValueRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_4TypeEEE called 0 returned 0% blocks executed 0%
    #####:  396:LogicalResult mlir::shape::AddOp::inferReturnTypes(
        -:  397:    MLIRContext *context, Optional<Location> location, ValueRange operands,
        -:  398:    DictionaryAttr attributes, RegionRange regions,
        -:  399:    SmallVectorImpl<Type> &inferredReturnTypes) {
    #####:  400:  if (operands[0].getType().isa<SizeType>() ||
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  401:      operands[1].getType().isa<SizeType>())
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  402:    inferredReturnTypes.assign({SizeType::get(context)});
call    0 never executed
call    1 never executed
        -:  403:  else
    #####:  404:    inferredReturnTypes.assign({IndexType::get(context)});
call    0 never executed
call    1 never executed
    #####:  405:  return success();
        -:  406:}
        -:  407:
function _ZN4mlir5shape5AddOp23isCompatibleReturnTypesENS_9TypeRangeES2_ called 0 returned 0% blocks executed 0%
    #####:  408:bool mlir::shape::AddOp::isCompatibleReturnTypes(TypeRange l, TypeRange r) {
        -:  409:  // SizeType is compatible with IndexType.
    #####:  410:  return eachHasOnlyOneOfTypes<SizeType, IndexType>(l, r);
call    0 never executed
call    1 never executed
call    2 never executed
        -:  411:}
        -:  412:
function _ZN4mlir5shape5AddOp4foldEN4llvm8ArrayRefINS_9AttributeEEE called 0 returned 0% blocks executed 0%
    #####:  413:OpFoldResult mlir::shape::AddOp::fold(ArrayRef<Attribute> operands) {
        -:  414:  // add(x, 0) -> x
    #####:  415:  if (matchPattern(getRhs(), m_Zero()))
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  416:    return getLhs();
call    0 never executed
call    1 never executed
        -:  417:
    #####:  418:  return constFoldBinaryOp<IntegerAttr>(
function _ZZN4mlir5shape5AddOp4foldEN4llvm8ArrayRefINS_9AttributeEEEENKUlNS2_5APIntERKS6_E_clES6_S8_.isra.0 called 0 returned 0% blocks executed 0%
    #####:  419:      operands, [](APInt a, const APInt &b) { return std::move(a) + b; });
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
call    4 never executed
        -:  420:}
        -:  421:
function _ZN4mlir5shape5AddOp6verifyEv called 0 returned 0% blocks executed 0%
    #####:  422:LogicalResult shape::AddOp::verify() { return verifySizeOrIndexOp(*this); }
call    0 never executed
call    1 never executed
call    2 never executed
        -:  423:
        -:  424://===----------------------------------------------------------------------===//
        -:  425:// AssumingAllOp
        -:  426://===----------------------------------------------------------------------===//
        -:  427:
        -:  428:namespace {
        -:  429:
        -:  430:// Merge multiple `shape.assuming_all` operations together.
        -:  431://
        -:  432://   %0 = shape.assuming_all %w0, %w1
        -:  433://   %1 = shape.assuming_all %w2, %0
        -:  434://
        -:  435:// to:
        -:  436://
        -:  437://   %0 = shape.assuming_all %w0, %w2, %w2
        -:  438:struct MergeAssumingAllOps : public OpRewritePattern<AssumingAllOp> {
        -:  439:  using OpRewritePattern<AssumingAllOp>::OpRewritePattern;
        -:  440:
function _ZNK12_GLOBAL__N_119MergeAssumingAllOps15matchAndRewriteEN4mlir5shape13AssumingAllOpERNS1_15PatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  441:  LogicalResult matchAndRewrite(AssumingAllOp op,
        -:  442:                                PatternRewriter &rewriter) const override {
    #####:  443:    SmallVector<Value> operands;
call    0 never executed
        -:  444:
    #####:  445:    for (Value operand : op.getInputs()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
    #####:  446:      if (auto assumeAll = operand.getDefiningOp<AssumingAllOp>())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  447:        operands.append(assumeAll.operand_begin(), assumeAll->operand_end());
call    0 never executed
call    1 never executed
call    2 never executed
        -:  448:      else
    #####:  449:        operands.push_back(operand);
call    0 never executed
        -:  450:    }
        -:  451:
        -:  452:    // We didn't find any other `assuming_all` ops to merge with.
    #####:  453:    if (operands.size() == op.getNumOperands())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  454:      return failure();
        -:  455:
        -:  456:    // Replace with a new `assuming_all` operation with merged constraints.
    #####:  457:    rewriter.replaceOpWithNewOp<AssumingAllOp>(op, operands);
call    0 never executed
    #####:  458:    return success();
branch  0 never executed
branch  1 never executed
        -:  459:  }
        -:  460:};
        -:  461:
        -:  462:// Eliminate `cstr_broadcastable` operands from `assuming_all` operation that
        -:  463:// are subsumed by others.
        -:  464://
        -:  465://   %0 = shape.cstr_broadcastable %shape0, %shape1
        -:  466://   %1 = shape.cstr_broadcastable %shape0, %shape1, %shape2
        -:  467://
        -:  468://   %2 = shape.cstr_broadcastable %shape3, %shape4
        -:  469://   %3 = shape.cstr_broadcastable %shape3, %shape4, %shape5
        -:  470://
        -:  471://   %4 = shape.assuming_all %0, %1, %2, %3
        -:  472://
        -:  473:// to:
        -:  474://
        -:  475://   %0 = shape.cstr_broadcastable %shape0, %shape1, %shape2
        -:  476://   %1 = shape.cstr_broadcastable %shape3, %shape4, %shape5
        -:  477://   %2 = shape.assuming_all %0, %1
        -:  478://
        -:  479:// In this example if shapes [0, 1, 2] are broadcastable, then it means that
        -:  480:// shapes [0, 1] are broadcastable too, and can be removed from the list of
        -:  481:// constraints. If shapes [0, 1, 2] are not broadcastable, then it doesn't
        -:  482:// matter if shapes [0, 1] are broadcastable (same for shapes [3, 4, 5]).
        -:  483:struct AssumingAllOfCstrBroadcastable : public OpRewritePattern<AssumingAllOp> {
        -:  484:  using OpRewritePattern<AssumingAllOp>::OpRewritePattern;
        -:  485:
function _ZNK12_GLOBAL__N_130AssumingAllOfCstrBroadcastable15matchAndRewriteEN4mlir5shape13AssumingAllOpERNS1_15PatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  486:  LogicalResult matchAndRewrite(AssumingAllOp op,
        -:  487:                                PatternRewriter &rewriter) const override {
        -:  488:    // Collect all `CstrBroadcastableOp` operands first.
    #####:  489:    SetVector<CstrBroadcastableOp> operands;
call    0 never executed
    #####:  490:    for (Value operand : op.getInputs()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
        -:  491:      // TODO: Apply this optimization if some of the witnesses are not
        -:  492:      // produced by the `cstr_broadcastable`.
    #####:  493:      auto broadcastable = operand.getDefiningOp<CstrBroadcastableOp>();
call    0 never executed
    #####:  494:      if (!broadcastable)
branch  0 never executed
branch  1 never executed
    #####:  495:        return failure();
        -:  496:
    #####:  497:      operands.insert(broadcastable);
call    0 never executed
        -:  498:    }
        -:  499:
        -:  500:    // Skip trivial `assuming_all` operations.
    #####:  501:    if (operands.size() <= 1)
branch  0 never executed
branch  1 never executed
    #####:  502:      return failure();
call    0 never executed
        -:  503:
        -:  504:    // Collect shapes checked by `cstr_broadcastable` operands.
    #####:  505:    SmallVector<std::pair<CstrBroadcastableOp, DenseSet<Value>>> shapes;
    #####:  506:    for (auto cstr : operands) {
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  507:      DenseSet<Value> shapesSet(cstr->operand_begin(), cstr->operand_end());
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  508:      shapes.emplace_back(cstr, std::move(shapesSet));
call    0 never executed
call    1 never executed
        -:  509:    }
        -:  510:
        -:  511:    // Sort by the number of shape operands (larger to smaller).
    #####:  512:    llvm::sort(shapes, [](auto a, auto b) {
call    0 never executed
        -:  513:      return a.first.getNumOperands() > b.first.getNumOperands();
        -:  514:    });
        -:  515:
        -:  516:    // We start from the `cst_broadcastable` operations with largest number of
        -:  517:    // shape operands, and remove redundant `cst_broadcastable` operations. We
        -:  518:    // do this until we find a set of `cst_broadcastable` operations with
        -:  519:    // non-overlapping constraints.
    #####:  520:    SmallVector<CstrBroadcastableOp> markedForErase;
call    0 never executed
        -:  521:
    #####:  522:    for (unsigned i = 0; i < shapes.size(); ++i) {
branch  0 never executed
branch  1 never executed
function _ZZNK12_GLOBAL__N_130AssumingAllOfCstrBroadcastable15matchAndRewriteEN4mlir5shape13AssumingAllOpERNS1_15PatternRewriterEENKUlT_E0_clISt4pairINS2_19CstrBroadcastableOpEN4llvm8DenseSetINS1_5ValueENSB_12DenseMapInfoISD_vEEEEEEEDaS6_.isra.0 called 0 returned 0% blocks executed 0%
    #####:  523:      auto isSubset = [&](auto pair) {
    #####:  524:        return llvm::set_is_subset(pair.second, shapes[i].second);
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  525:      };
        -:  526:
        -:  527:      // Keep redundant `cstr_broadcastable` operations to be erased.
    #####:  528:      auto *it = std::remove_if(shapes.begin() + i + 1, shapes.end(), isSubset);
call    0 never executed
    #####:  529:      for (auto *it0 = it; it0 < shapes.end(); ++it0)
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  530:        markedForErase.push_back(it0->first);
call    0 never executed
    #####:  531:      shapes.erase(it, shapes.end());
call    0 never executed
        -:  532:    }
        -:  533:
        -:  534:    // We didn't find any operands that could be removed.
    #####:  535:    if (markedForErase.empty())
branch  0 never executed
branch  1 never executed
    #####:  536:      return failure();
        -:  537:
        -:  538:    // Collect non-overlapping `cst_broadcastable` constraints.
    #####:  539:    SmallVector<Value> uniqueConstraints;
branch  0 never executed
branch  1 never executed
    #####:  540:    for (auto &shape : shapes)
branch  0 never executed
branch  1 never executed
    #####:  541:      uniqueConstraints.push_back(shape.first.getResult());
call    0 never executed
call    1 never executed
        -:  542:
        -:  543:    // Replace with a new `assuming_all` operation ...
    #####:  544:    rewriter.replaceOpWithNewOp<AssumingAllOp>(op, uniqueConstraints);
call    0 never executed
        -:  545:
        -:  546:    // ... and maybe erase `cstr_broadcastable` ops without uses.
    #####:  547:    for (auto &op : markedForErase)
branch  0 never executed
branch  1 never executed
    #####:  548:      if (op->use_empty())
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####:  549:        rewriter.eraseOp(op);
call    0 never executed
        -:  550:
    #####:  551:    return success();
branch  0 never executed
branch  1 never executed
        -:  552:  }
        -:  553:};
        -:  554:
        -:  555:struct AssumingAllToCstrEqCanonicalization
        -:  556:    : public OpRewritePattern<AssumingAllOp> {
        -:  557:  using OpRewritePattern<AssumingAllOp>::OpRewritePattern;
        -:  558:
function _ZNK12_GLOBAL__N_135AssumingAllToCstrEqCanonicalization15matchAndRewriteEN4mlir5shape13AssumingAllOpERNS1_15PatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  559:  LogicalResult matchAndRewrite(AssumingAllOp op,
        -:  560:                                PatternRewriter &rewriter) const override {
    #####:  561:    SmallVector<Value, 8> shapes;
call    0 never executed
    #####:  562:    for (Value w : op.getInputs()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
    #####:  563:      auto cstrEqOp = w.getDefiningOp<CstrEqOp>();
call    0 never executed
    #####:  564:      if (!cstrEqOp)
branch  0 never executed
branch  1 never executed
    #####:  565:        return failure();
    #####:  566:      bool disjointShapes = llvm::none_of(cstrEqOp.getShapes(), [&](Value s) {
call    0 never executed
call    1 never executed
    #####:  567:        return llvm::is_contained(shapes, s);
        -:  568:      });
    #####:  569:      if (!shapes.empty() && !cstrEqOp.getShapes().empty() && disjointShapes)
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
    #####:  570:        return failure();
    #####:  571:      shapes.append(cstrEqOp.getShapes().begin(), cstrEqOp.getShapes().end());
call    0 never executed
call    1 never executed
call    2 never executed
        -:  572:    }
    #####:  573:    rewriter.replaceOpWithNewOp<CstrEqOp>(op, shapes);
call    0 never executed
    #####:  574:    return success();
branch  0 never executed
branch  1 never executed
        -:  575:  }
        -:  576:};
        -:  577:
        -:  578:template <typename OpTy>
        -:  579:struct RemoveDuplicateOperandsPattern : public OpRewritePattern<OpTy> {
        -:  580:  using OpRewritePattern<OpTy>::OpRewritePattern;
        -:  581:
    #####:  582:  LogicalResult matchAndRewrite(OpTy op,
        -:  583:                                PatternRewriter &rewriter) const override {
        -:  584:    // Find unique operands.
    #####:  585:    SetVector<Value> unique(op.operand_begin(), op.operand_end());
        -:  586:
        -:  587:    // Reduce op to equivalent with unique operands.
    #####:  588:    if (unique.size() < op.getNumOperands()) {
    #####:  589:      rewriter.replaceOpWithNewOp<OpTy>(op, op->getResultTypes(),
        -:  590:                                        unique.takeVector(), op->getAttrs());
    #####:  591:      return success();
        -:  592:    }
        -:  593:
    #####:  594:    return failure();
        -:  595:  }
------------------
_ZNK12_GLOBAL__N_130RemoveDuplicateOperandsPatternIN4mlir5shape13AssumingAllOpEE15matchAndRewriteES3_RNS1_15PatternRewriterE:
function _ZNK12_GLOBAL__N_130RemoveDuplicateOperandsPatternIN4mlir5shape13AssumingAllOpEE15matchAndRewriteES3_RNS1_15PatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  582:  LogicalResult matchAndRewrite(OpTy op,
call    0 never executed
        -:  583:                                PatternRewriter &rewriter) const override {
        -:  584:    // Find unique operands.
    #####:  585:    SetVector<Value> unique(op.operand_begin(), op.operand_end());
call    0 never executed
call    1 never executed
call    2 never executed
        -:  586:
        -:  587:    // Reduce op to equivalent with unique operands.
    #####:  588:    if (unique.size() < op.getNumOperands()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  589:      rewriter.replaceOpWithNewOp<OpTy>(op, op->getResultTypes(),
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
call    4 never executed
branch  5 never executed
branch  6 never executed
        -:  590:                                        unique.takeVector(), op->getAttrs());
    #####:  591:      return success();
        -:  592:    }
        -:  593:
    #####:  594:    return failure();
call    0 never executed
        -:  595:  }
------------------
_ZNK12_GLOBAL__N_130RemoveDuplicateOperandsPatternIN4mlir5shape11BroadcastOpEE15matchAndRewriteES3_RNS1_15PatternRewriterE:
function _ZNK12_GLOBAL__N_130RemoveDuplicateOperandsPatternIN4mlir5shape11BroadcastOpEE15matchAndRewriteES3_RNS1_15PatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  582:  LogicalResult matchAndRewrite(OpTy op,
call    0 never executed
        -:  583:                                PatternRewriter &rewriter) const override {
        -:  584:    // Find unique operands.
    #####:  585:    SetVector<Value> unique(op.operand_begin(), op.operand_end());
call    0 never executed
call    1 never executed
call    2 never executed
        -:  586:
        -:  587:    // Reduce op to equivalent with unique operands.
    #####:  588:    if (unique.size() < op.getNumOperands()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  589:      rewriter.replaceOpWithNewOp<OpTy>(op, op->getResultTypes(),
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
call    4 never executed
branch  5 never executed
branch  6 never executed
        -:  590:                                        unique.takeVector(), op->getAttrs());
    #####:  591:      return success();
        -:  592:    }
        -:  593:
    #####:  594:    return failure();
call    0 never executed
        -:  595:  }
------------------
_ZNK12_GLOBAL__N_130RemoveDuplicateOperandsPatternIN4mlir5shape19CstrBroadcastableOpEE15matchAndRewriteES3_RNS1_15PatternRewriterE:
function _ZNK12_GLOBAL__N_130RemoveDuplicateOperandsPatternIN4mlir5shape19CstrBroadcastableOpEE15matchAndRewriteES3_RNS1_15PatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  582:  LogicalResult matchAndRewrite(OpTy op,
call    0 never executed
        -:  583:                                PatternRewriter &rewriter) const override {
        -:  584:    // Find unique operands.
    #####:  585:    SetVector<Value> unique(op.operand_begin(), op.operand_end());
call    0 never executed
call    1 never executed
call    2 never executed
        -:  586:
        -:  587:    // Reduce op to equivalent with unique operands.
    #####:  588:    if (unique.size() < op.getNumOperands()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  589:      rewriter.replaceOpWithNewOp<OpTy>(op, op->getResultTypes(),
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
call    4 never executed
branch  5 never executed
branch  6 never executed
        -:  590:                                        unique.takeVector(), op->getAttrs());
    #####:  591:      return success();
        -:  592:    }
        -:  593:
    #####:  594:    return failure();
call    0 never executed
        -:  595:  }
------------------
_ZNK12_GLOBAL__N_130RemoveDuplicateOperandsPatternIN4mlir5shape17IsBroadcastableOpEE15matchAndRewriteES3_RNS1_15PatternRewriterE:
function _ZNK12_GLOBAL__N_130RemoveDuplicateOperandsPatternIN4mlir5shape17IsBroadcastableOpEE15matchAndRewriteES3_RNS1_15PatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  582:  LogicalResult matchAndRewrite(OpTy op,
call    0 never executed
        -:  583:                                PatternRewriter &rewriter) const override {
        -:  584:    // Find unique operands.
    #####:  585:    SetVector<Value> unique(op.operand_begin(), op.operand_end());
call    0 never executed
call    1 never executed
call    2 never executed
        -:  586:
        -:  587:    // Reduce op to equivalent with unique operands.
    #####:  588:    if (unique.size() < op.getNumOperands()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  589:      rewriter.replaceOpWithNewOp<OpTy>(op, op->getResultTypes(),
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
call    4 never executed
branch  5 never executed
branch  6 never executed
        -:  590:                                        unique.takeVector(), op->getAttrs());
    #####:  591:      return success();
        -:  592:    }
        -:  593:
    #####:  594:    return failure();
call    0 never executed
        -:  595:  }
------------------
        -:  596:};
        -:  597:} // namespace
        -:  598:
function _ZN4mlir5shape13AssumingAllOp27getCanonicalizationPatternsERNS_17RewritePatternSetEPNS_11MLIRContextE called 31 returned 100% blocks executed 100%
       31:  599:void AssumingAllOp::getCanonicalizationPatterns(RewritePatternSet &patterns,
        -:  600:                                                MLIRContext *context) {
       31:  601:  patterns
        -:  602:      .add<MergeAssumingAllOps, AssumingAllOneOp,
        -:  603:           AssumingAllOfCstrBroadcastable, AssumingAllToCstrEqCanonicalization,
       31:  604:           RemoveDuplicateOperandsPattern<AssumingAllOp>>(context);
call    0 returned 100%
       31:  605:}
        -:  606:
function _ZN4mlir5shape13AssumingAllOp4foldEN4llvm8ArrayRefINS_9AttributeEEE called 0 returned 0% blocks executed 0%
    #####:  607:OpFoldResult AssumingAllOp::fold(ArrayRef<Attribute> operands) {
        -:  608:  // Iterate in reverse to first handle all constant operands. They are
        -:  609:  // guaranteed to be the tail of the inputs because this is commutative.
    #####:  610:  for (int idx = operands.size() - 1; idx >= 0; idx--) {
branch  0 never executed
branch  1 never executed
    #####:  611:    Attribute a = operands[idx];
branch  0 never executed
branch  1 never executed
        -:  612:    // Cannot fold if any inputs are not constant;
    #####:  613:    if (!a)
branch  0 never executed
branch  1 never executed
    #####:  614:      return nullptr;
        -:  615:
        -:  616:    // We do not need to keep statically known values after handling them in
        -:  617:    // this method.
    #####:  618:    getOperation()->eraseOperand(idx);
call    0 never executed
        -:  619:
        -:  620:    // Always false if any input is statically known false
    #####:  621:    if (!a.cast<BoolAttr>().getValue())
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  622:      return a;
call    0 never executed
        -:  623:  }
        -:  624:  // If this is reached, all inputs were statically known passing.
    #####:  625:  return BoolAttr::get(getContext(), true);
call    0 never executed
call    1 never executed
call    2 never executed
        -:  626:}
        -:  627:
function _ZN4mlir5shape13AssumingAllOp6verifyEv called 0 returned 0% blocks executed 0%
    #####:  628:LogicalResult AssumingAllOp::verify() {
        -:  629:  // Ensure that AssumingAllOp contains at least one operand
    #####:  630:  if (getNumOperands() == 0)
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  631:    return emitOpError("no operands specified");
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
        -:  632:
    #####:  633:  return success();
        -:  634:}
        -:  635:
        -:  636://===----------------------------------------------------------------------===//
        -:  637:// BroadcastOp
        -:  638://===----------------------------------------------------------------------===//
        -:  639:
function _ZN4mlir5shape11BroadcastOp4foldEN4llvm8ArrayRefINS_9AttributeEEE called 0 returned 0% blocks executed 0%
    #####:  640:OpFoldResult BroadcastOp::fold(ArrayRef<Attribute> operands) {
    #####:  641:  if (getShapes().size() == 1) {
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  642:    // Otherwise, we need a cast which would be a canonicalization, not folding.
    #####:  643:    if (getShapes().front().getType() != getType())
call    0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
    #####:  644:      return nullptr;
    #####:  645:    return getShapes().front();
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
        -:  646:  }
        -:  647:
        -:  648:  // TODO: Support folding with more than 2 input shapes
    #####:  649:  if (getShapes().size() > 2)
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  650:    return nullptr;
        -:  651:
    #####:  652:  if (!operands[0] || !operands[1])
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
branch  6 never executed
branch  7 never executed
    #####:  653:    return nullptr;
    #####:  654:  auto lhsShape = llvm::to_vector<6>(
    #####:  655:      operands[0].cast<DenseIntElementsAttr>().getValues<int64_t>());
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  656:  auto rhsShape = llvm::to_vector<6>(
    #####:  657:      operands[1].cast<DenseIntElementsAttr>().getValues<int64_t>());
call    0 never executed
call    1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
    #####:  658:  SmallVector<int64_t, 6> resultShape;
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  659:
        -:  660:  // If the shapes are not compatible, we can't fold it.
        -:  661:  // TODO: Fold to an "error".
    #####:  662:  if (!OpTrait::util::getBroadcastedShape(lhsShape, rhsShape, resultShape))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  663:    return nullptr;
        -:  664:
    #####:  665:  Builder builder(getContext());
call    0 never executed
call    1 never executed
    #####:  666:  return builder.getIndexTensorAttr(resultShape);
call    0 never executed
call    1 never executed
        -:  667:}
        -:  668:
function _ZN4mlir5shape11BroadcastOp6verifyEv called 0 returned 0% blocks executed 0%
    #####:  669:LogicalResult BroadcastOp::verify() {
    #####:  670:  return verifyShapeOrExtentTensorOp(*this);
call    0 never executed
call    1 never executed
call    2 never executed
        -:  671:}
        -:  672:
        -:  673:namespace {
        -:  674:template <typename OpTy>
        -:  675:struct RemoveEmptyShapeOperandsPattern : public OpRewritePattern<OpTy> {
        -:  676:  using OpRewritePattern<OpTy>::OpRewritePattern;
        -:  677:
    #####:  678:  LogicalResult matchAndRewrite(OpTy op,
        -:  679:                                PatternRewriter &rewriter) const override {
    #####:  680:    auto isPotentiallyNonEmptyShape = [](Value shape) {
    #####:  681:      if (auto extentTensorTy = shape.getType().dyn_cast<RankedTensorType>()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
branch  4 never executed
branch  5 never executed
    #####:  682:        if (extentTensorTy.getDimSize(0) == 0)
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
branch  4 never executed
branch  5 never executed
    #####:  683:          return false;
        -:  684:      }
    #####:  685:      if (auto constShape = shape.getDefiningOp<ConstShapeOp>()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
branch  4 never executed
branch  5 never executed
    #####:  686:        if (constShape.getShape().empty())
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
branch  4 never executed
branch  5 never executed
    #####:  687:          return false;
        -:  688:      }
    #####:  689:      return true;
        -:  690:    };
    #####:  691:    auto newOperands = llvm::to_vector<8>(
    #####:  692:        llvm::make_filter_range(op->getOperands(), isPotentiallyNonEmptyShape));
        -:  693:
        -:  694:    // Reduce op to equivalent without empty shape operands.
    #####:  695:    if (newOperands.size() < op.getNumOperands()) {
    #####:  696:      rewriter.replaceOpWithNewOp<OpTy>(op, op->getResultTypes(), newOperands,
        -:  697:                                        op->getAttrs());
    #####:  698:      return success();
        -:  699:    }
        -:  700:
    #####:  701:    return failure();
        -:  702:  }
------------------
_ZNK12_GLOBAL__N_131RemoveEmptyShapeOperandsPatternIN4mlir5shape11BroadcastOpEE15matchAndRewriteES3_RNS1_15PatternRewriterE:
function _ZNK12_GLOBAL__N_131RemoveEmptyShapeOperandsPatternIN4mlir5shape11BroadcastOpEE15matchAndRewriteES3_RNS1_15PatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  678:  LogicalResult matchAndRewrite(OpTy op,
        -:  679:                                PatternRewriter &rewriter) const override {
        -:  680:    auto isPotentiallyNonEmptyShape = [](Value shape) {
        -:  681:      if (auto extentTensorTy = shape.getType().dyn_cast<RankedTensorType>()) {
        -:  682:        if (extentTensorTy.getDimSize(0) == 0)
        -:  683:          return false;
        -:  684:      }
        -:  685:      if (auto constShape = shape.getDefiningOp<ConstShapeOp>()) {
        -:  686:        if (constShape.getShape().empty())
        -:  687:          return false;
        -:  688:      }
        -:  689:      return true;
        -:  690:    };
    #####:  691:    auto newOperands = llvm::to_vector<8>(
call    0 never executed
    #####:  692:        llvm::make_filter_range(op->getOperands(), isPotentiallyNonEmptyShape));
call    0 never executed
call    1 never executed
        -:  693:
        -:  694:    // Reduce op to equivalent without empty shape operands.
    #####:  695:    if (newOperands.size() < op.getNumOperands()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  696:      rewriter.replaceOpWithNewOp<OpTy>(op, op->getResultTypes(), newOperands,
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
        -:  697:                                        op->getAttrs());
    #####:  698:      return success();
        -:  699:    }
        -:  700:
    #####:  701:    return failure();
branch  0 never executed
branch  1 never executed
        -:  702:  }
------------------
_ZNK12_GLOBAL__N_131RemoveEmptyShapeOperandsPatternIN4mlir5shape19CstrBroadcastableOpEE15matchAndRewriteES3_RNS1_15PatternRewriterE:
function _ZNK12_GLOBAL__N_131RemoveEmptyShapeOperandsPatternIN4mlir5shape19CstrBroadcastableOpEE15matchAndRewriteES3_RNS1_15PatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  678:  LogicalResult matchAndRewrite(OpTy op,
        -:  679:                                PatternRewriter &rewriter) const override {
        -:  680:    auto isPotentiallyNonEmptyShape = [](Value shape) {
        -:  681:      if (auto extentTensorTy = shape.getType().dyn_cast<RankedTensorType>()) {
        -:  682:        if (extentTensorTy.getDimSize(0) == 0)
        -:  683:          return false;
        -:  684:      }
        -:  685:      if (auto constShape = shape.getDefiningOp<ConstShapeOp>()) {
        -:  686:        if (constShape.getShape().empty())
        -:  687:          return false;
        -:  688:      }
        -:  689:      return true;
        -:  690:    };
    #####:  691:    auto newOperands = llvm::to_vector<8>(
call    0 never executed
    #####:  692:        llvm::make_filter_range(op->getOperands(), isPotentiallyNonEmptyShape));
call    0 never executed
call    1 never executed
        -:  693:
        -:  694:    // Reduce op to equivalent without empty shape operands.
    #####:  695:    if (newOperands.size() < op.getNumOperands()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  696:      rewriter.replaceOpWithNewOp<OpTy>(op, op->getResultTypes(), newOperands,
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
        -:  697:                                        op->getAttrs());
    #####:  698:      return success();
        -:  699:    }
        -:  700:
    #####:  701:    return failure();
branch  0 never executed
branch  1 never executed
        -:  702:  }
------------------
        -:  703:};
        -:  704:
        -:  705:struct BroadcastForwardSingleOperandPattern
        -:  706:    : public OpRewritePattern<BroadcastOp> {
        -:  707:  using OpRewritePattern<BroadcastOp>::OpRewritePattern;
        -:  708:
function _ZNK12_GLOBAL__N_136BroadcastForwardSingleOperandPattern15matchAndRewriteEN4mlir5shape11BroadcastOpERNS1_15PatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  709:  LogicalResult matchAndRewrite(BroadcastOp op,
        -:  710:                                PatternRewriter &rewriter) const override {
    #####:  711:    if (op.getNumOperands() != 1)
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  712:      return failure();
    #####:  713:    Value replacement = op.getShapes().front();
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  714:
        -:  715:    // Insert cast if needed.
    #####:  716:    if (replacement.getType() != op.getType()) {
branch  0 never executed
branch  1 never executed
    #####:  717:      auto loc = op.getLoc();
call    0 never executed
    #####:  718:      if (op.getType().isa<ShapeType>()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  719:        replacement = rewriter.create<FromExtentTensorOp>(loc, replacement);
call    0 never executed
        -:  720:      } else {
    #####:  721:        assert(!op.getType().isa<ShapeType>() &&
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
branch  4 never executed
branch  5 never executed
call    6 never executed
        -:  722:               !replacement.getType().isa<ShapeType>() &&
        -:  723:               "expect extent tensor cast");
    #####:  724:        replacement =
    #####:  725:            rewriter.create<tensor::CastOp>(loc, op.getType(), replacement);
call    0 never executed
        -:  726:      }
        -:  727:    }
        -:  728:
    #####:  729:    rewriter.replaceOp(op, replacement);
call    0 never executed
call    1 never executed
    #####:  730:    return success();
        -:  731:  }
        -:  732:};
        -:  733:
        -:  734:struct BroadcastFoldConstantOperandsPattern
        -:  735:    : public OpRewritePattern<BroadcastOp> {
        -:  736:  using OpRewritePattern<BroadcastOp>::OpRewritePattern;
        -:  737:
function _ZNK12_GLOBAL__N_136BroadcastFoldConstantOperandsPattern15matchAndRewriteEN4mlir5shape11BroadcastOpERNS1_15PatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  738:  LogicalResult matchAndRewrite(BroadcastOp op,
        -:  739:                                PatternRewriter &rewriter) const override {
    #####:  740:    SmallVector<int64_t, 8> foldedConstantShape;
call    0 never executed
    #####:  741:    SmallVector<Value, 8> newShapeOperands;
branch  0 never executed
branch  1 never executed
    #####:  742:    for (Value shape : op.getShapes()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
    #####:  743:      if (auto constShape = shape.getDefiningOp<ConstShapeOp>()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  744:        SmallVector<int64_t, 8> newFoldedConstantShape;
call    0 never executed
    #####:  745:        if (OpTrait::util::getBroadcastedShape(
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
        -:  746:                foldedConstantShape,
    #####:  747:                llvm::to_vector<8>(constShape.getShape().getValues<int64_t>()),
call    0 never executed
call    1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
        -:  748:                newFoldedConstantShape)) {
    #####:  749:          foldedConstantShape = newFoldedConstantShape;
call    0 never executed
    #####:  750:          continue;
branch  0 never executed
branch  1 never executed
        -:  751:        }
        -:  752:      }
    #####:  753:      newShapeOperands.push_back(shape);
call    0 never executed
        -:  754:    }
        -:  755:
        -:  756:    // Need at least two constant operands to fold anything.
    #####:  757:    if (op.getNumOperands() - newShapeOperands.size() < 2)
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  758:      return failure();
        -:  759:
    #####:  760:    auto foldedConstantOperandsTy = RankedTensorType::get(
    #####:  761:        {static_cast<int64_t>(foldedConstantShape.size())},
call    0 never executed
    #####:  762:        rewriter.getIndexType());
call    0 never executed
call    1 never executed
    #####:  763:    newShapeOperands.push_back(rewriter.create<ConstShapeOp>(
call    0 never executed
        -:  764:        op.getLoc(), foldedConstantOperandsTy,
    #####:  765:        rewriter.getIndexTensorAttr(foldedConstantShape)));
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  766:    rewriter.replaceOpWithNewOp<BroadcastOp>(op, op.getType(),
    #####:  767:                                             newShapeOperands);
call    0 never executed
    #####:  768:    return success();
branch  0 never executed
branch  1 never executed
        -:  769:  }
        -:  770:};
        -:  771:
        -:  772:template <typename OpTy>
        -:  773:struct CanonicalizeCastExtentTensorOperandsPattern
        -:  774:    : public OpRewritePattern<OpTy> {
        -:  775:  using OpRewritePattern<OpTy>::OpRewritePattern;
        -:  776:
    #####:  777:  LogicalResult matchAndRewrite(OpTy op,
        -:  778:                                PatternRewriter &rewriter) const override {
        -:  779:    // Canonicalize operands.
    #####:  780:    bool anyChange = false;
    #####:  781:    auto canonicalizeOperand = [&](Value operand) -> Value {
    #####:  782:      if (auto castOp = operand.getDefiningOp<tensor::CastOp>()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
branch  4 never executed
branch  5 never executed
        -:  783:        // Only eliminate the cast if it holds no shape information.
        -:  784:        bool isInformationLoosingCast =
    #####:  785:            castOp.getType().cast<RankedTensorType>().isDynamicDim(0);
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:  786:        if (isInformationLoosingCast) {
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####:  787:          anyChange = true;
    #####:  788:          return castOp.getSource();
call    0 never executed
call    1 never executed
        -:  789:        }
        -:  790:      }
    #####:  791:      return operand;
        -:  792:    };
    #####:  793:    auto newOperands = llvm::to_vector<8>(
    #####:  794:        llvm::map_range(op.getOperands(), canonicalizeOperand));
        -:  795:
        -:  796:    // Rewrite op if any change required.
    #####:  797:    if (!anyChange)
    #####:  798:      return failure();
    #####:  799:    rewriter.replaceOpWithNewOp<OpTy>(op, op->getResultTypes(), newOperands);
    #####:  800:    return success();
        -:  801:  }
------------------
_ZNK12_GLOBAL__N_143CanonicalizeCastExtentTensorOperandsPatternIN4mlir5shape11BroadcastOpEE15matchAndRewriteES3_RNS1_15PatternRewriterE:
function _ZNK12_GLOBAL__N_143CanonicalizeCastExtentTensorOperandsPatternIN4mlir5shape11BroadcastOpEE15matchAndRewriteES3_RNS1_15PatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  777:  LogicalResult matchAndRewrite(OpTy op,
        -:  778:                                PatternRewriter &rewriter) const override {
        -:  779:    // Canonicalize operands.
    #####:  780:    bool anyChange = false;
    #####:  781:    auto canonicalizeOperand = [&](Value operand) -> Value {
call    0 never executed
        -:  782:      if (auto castOp = operand.getDefiningOp<tensor::CastOp>()) {
        -:  783:        // Only eliminate the cast if it holds no shape information.
        -:  784:        bool isInformationLoosingCast =
        -:  785:            castOp.getType().cast<RankedTensorType>().isDynamicDim(0);
        -:  786:        if (isInformationLoosingCast) {
        -:  787:          anyChange = true;
        -:  788:          return castOp.getSource();
        -:  789:        }
        -:  790:      }
        -:  791:      return operand;
        -:  792:    };
    #####:  793:    auto newOperands = llvm::to_vector<8>(
call    0 never executed
    #####:  794:        llvm::map_range(op.getOperands(), canonicalizeOperand));
call    0 never executed
        -:  795:
        -:  796:    // Rewrite op if any change required.
    #####:  797:    if (!anyChange)
branch  0 never executed
branch  1 never executed
    #####:  798:      return failure();
    #####:  799:    rewriter.replaceOpWithNewOp<OpTy>(op, op->getResultTypes(), newOperands);
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  800:    return success();
branch  0 never executed
branch  1 never executed
        -:  801:  }
------------------
_ZNK12_GLOBAL__N_143CanonicalizeCastExtentTensorOperandsPatternIN4mlir5shape19CstrBroadcastableOpEE15matchAndRewriteES3_RNS1_15PatternRewriterE:
function _ZNK12_GLOBAL__N_143CanonicalizeCastExtentTensorOperandsPatternIN4mlir5shape19CstrBroadcastableOpEE15matchAndRewriteES3_RNS1_15PatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  777:  LogicalResult matchAndRewrite(OpTy op,
        -:  778:                                PatternRewriter &rewriter) const override {
        -:  779:    // Canonicalize operands.
    #####:  780:    bool anyChange = false;
    #####:  781:    auto canonicalizeOperand = [&](Value operand) -> Value {
call    0 never executed
        -:  782:      if (auto castOp = operand.getDefiningOp<tensor::CastOp>()) {
        -:  783:        // Only eliminate the cast if it holds no shape information.
        -:  784:        bool isInformationLoosingCast =
        -:  785:            castOp.getType().cast<RankedTensorType>().isDynamicDim(0);
        -:  786:        if (isInformationLoosingCast) {
        -:  787:          anyChange = true;
        -:  788:          return castOp.getSource();
        -:  789:        }
        -:  790:      }
        -:  791:      return operand;
        -:  792:    };
    #####:  793:    auto newOperands = llvm::to_vector<8>(
call    0 never executed
    #####:  794:        llvm::map_range(op.getOperands(), canonicalizeOperand));
call    0 never executed
        -:  795:
        -:  796:    // Rewrite op if any change required.
    #####:  797:    if (!anyChange)
branch  0 never executed
branch  1 never executed
    #####:  798:      return failure();
    #####:  799:    rewriter.replaceOpWithNewOp<OpTy>(op, op->getResultTypes(), newOperands);
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  800:    return success();
branch  0 never executed
branch  1 never executed
        -:  801:  }
------------------
        -:  802:};
        -:  803:
        -:  804:struct BroadcastConcretizeResultTypePattern
        -:  805:    : public OpRewritePattern<BroadcastOp> {
        -:  806:  using OpRewritePattern<BroadcastOp>::OpRewritePattern;
        -:  807:
function _ZNK12_GLOBAL__N_136BroadcastConcretizeResultTypePattern15matchAndRewriteEN4mlir5shape11BroadcastOpERNS1_15PatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  808:  LogicalResult matchAndRewrite(BroadcastOp op,
        -:  809:                                PatternRewriter &rewriter) const override {
        -:  810:    // Only concretize dynamic extent tensor result types.
    #####:  811:    auto resultTy = op.getType().dyn_cast<RankedTensorType>();
call    0 never executed
    #####:  812:    if (!resultTy || !resultTy.isDynamicDim(0))
branch  0 never executed
branch  1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
    #####:  813:      return failure();
        -:  814:
        -:  815:    // Infer resulting shape rank if possible.
    #####:  816:    int64_t maxRank = 0;
    #####:  817:    for (Value shape : op.getShapes()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
    #####:  818:      if (auto extentTensorTy = shape.getType().dyn_cast<RankedTensorType>()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  819:        // Cannot infer resulting shape rank if any operand is dynamically
        -:  820:        // ranked.
    #####:  821:        if (extentTensorTy.isDynamicDim(0))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  822:          return failure();
    #####:  823:        maxRank = std::max(maxRank, extentTensorTy.getDimSize(0));
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  824:      }
        -:  825:    }
        -:  826:
    #####:  827:    auto newOp = rewriter.create<BroadcastOp>(
    #####:  828:        op.getLoc(), getExtentTensorType(getContext(), maxRank),
    #####:  829:        op.getShapes());
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  830:    rewriter.replaceOpWithNewOp<tensor::CastOp>(op, op.getType(), newOp);
call    0 never executed
    #####:  831:    return success();
        -:  832:  }
        -:  833:};
        -:  834:} // namespace
        -:  835:
function _ZN4mlir5shape11BroadcastOp27getCanonicalizationPatternsERNS_17RewritePatternSetEPNS_11MLIRContextE called 31 returned 100% blocks executed 100%
       31:  836:void BroadcastOp::getCanonicalizationPatterns(RewritePatternSet &patterns,
        -:  837:                                              MLIRContext *context) {
       31:  838:  patterns.add<BroadcastConcretizeResultTypePattern,
        -:  839:               BroadcastFoldConstantOperandsPattern,
        -:  840:               BroadcastForwardSingleOperandPattern,
        -:  841:               CanonicalizeCastExtentTensorOperandsPattern<BroadcastOp>,
        -:  842:               RemoveDuplicateOperandsPattern<BroadcastOp>,
       31:  843:               RemoveEmptyShapeOperandsPattern<BroadcastOp>>(context);
call    0 returned 100%
       31:  844:}
        -:  845:
        -:  846://===----------------------------------------------------------------------===//
        -:  847:// ConcatOp
        -:  848://===----------------------------------------------------------------------===//
        -:  849:
function _ZN4mlir5shape8ConcatOp4foldEN4llvm8ArrayRefINS_9AttributeEEE called 0 returned 0% blocks executed 0%
    #####:  850:OpFoldResult ConcatOp::fold(ArrayRef<Attribute> operands) {
    #####:  851:  if (!operands[0] || !operands[1])
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
branch  6 never executed
branch  7 never executed
    #####:  852:    return nullptr;
    #####:  853:  auto lhsShape = llvm::to_vector<6>(
    #####:  854:      operands[0].cast<DenseIntElementsAttr>().getValues<int64_t>());
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  855:  auto rhsShape = llvm::to_vector<6>(
    #####:  856:      operands[1].cast<DenseIntElementsAttr>().getValues<int64_t>());
call    0 never executed
call    1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
    #####:  857:  SmallVector<int64_t, 6> resultShape;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  858:  resultShape.append(lhsShape.begin(), lhsShape.end());
call    0 never executed
    #####:  859:  resultShape.append(rhsShape.begin(), rhsShape.end());
call    0 never executed
    #####:  860:  Builder builder(getContext());
call    0 never executed
call    1 never executed
    #####:  861:  return builder.getIndexTensorAttr(resultShape);
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
        -:  862:}
        -:  863:
        -:  864://===----------------------------------------------------------------------===//
        -:  865:// ConstShapeOp
        -:  866://===----------------------------------------------------------------------===//
        -:  867:
function _ZN4mlir5shape12ConstShapeOp5printERNS_12OpAsmPrinterE called 0 returned 0% blocks executed 0%
    #####:  868:void ConstShapeOp::print(OpAsmPrinter &p) {
    #####:  869:  p << " ";
call    0 never executed
    #####:  870:  p.printOptionalAttrDict((*this)->getAttrs(), /*elidedAttrs=*/{"shape"});
call    0 never executed
call    1 never executed
    #####:  871:  p << "[";
call    0 never executed
    #####:  872:  interleaveComma(getShape().getValues<int64_t>(), p);
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  873:  p << "] : ";
call    0 never executed
    #####:  874:  p.printType(getType());
call    0 never executed
    #####:  875:}
        -:  876:
function _ZN4mlir5shape12ConstShapeOp5parseERNS_11OpAsmParserERNS_14OperationStateE called 0 returned 0% blocks executed 0%
    #####:  877:ParseResult ConstShapeOp::parse(OpAsmParser &parser, OperationState &result) {
    #####:  878:  if (parser.parseOptionalAttrDict(result.attributes))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  879:    return failure();
        -:  880:  // We piggy-back on ArrayAttr parsing, though we don't internally store the
        -:  881:  // shape as an ArrayAttr.
        -:  882:  // TODO: Implement custom parser and maybe make syntax a bit more concise.
    #####:  883:  Attribute extentsRaw;
    #####:  884:  NamedAttrList dummy;
call    0 never executed
    #####:  885:  if (parser.parseAttribute(extentsRaw, "dummy", dummy))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  886:    return failure();
    #####:  887:  auto extentsArray = extentsRaw.dyn_cast<ArrayAttr>();
call    0 never executed
    #####:  888:  if (!extentsArray)
branch  0 never executed
branch  1 never executed
    #####:  889:    return failure();
    #####:  890:  SmallVector<int64_t, 6> ints;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  891:  for (Attribute extent : extentsArray) {
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  892:    IntegerAttr attr = extent.dyn_cast<IntegerAttr>();
call    0 never executed
    #####:  893:    if (!attr)
branch  0 never executed
branch  1 never executed
    #####:  894:      return failure();
    #####:  895:    ints.push_back(attr.getInt());
call    0 never executed
call    1 never executed
        -:  896:  }
    #####:  897:  Builder &builder = parser.getBuilder();
call    0 never executed
    #####:  898:  result.addAttribute("shape", builder.getIndexTensorAttr(ints));
call    0 never executed
call    1 never executed
    #####:  899:  Type resultTy;
    #####:  900:  if (parser.parseColonType(resultTy))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  901:    return failure();
    #####:  902:  result.types.push_back(resultTy);
call    0 never executed
    #####:  903:  return success();
        -:  904:}
        -:  905:
function _ZN4mlir5shape12ConstShapeOp4foldEN4llvm8ArrayRefINS_9AttributeEEE called 0 returned 0% blocks executed 0%
    #####:  906:OpFoldResult ConstShapeOp::fold(ArrayRef<Attribute>) { return getShapeAttr(); }
call    0 never executed
call    1 never executed
        -:  907:
function _ZN4mlir5shape12ConstShapeOp27getCanonicalizationPatternsERNS_17RewritePatternSetEPNS_11MLIRContextE called 31 returned 100% blocks executed 100%
       31:  908:void ConstShapeOp::getCanonicalizationPatterns(RewritePatternSet &patterns,
        -:  909:                                               MLIRContext *context) {
       31:  910:  patterns.add<TensorCastConstShape>(context);
call    0 returned 100%
       31:  911:}
        -:  912:
function _ZN4mlir5shape12ConstShapeOp16inferReturnTypesEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_10ValueRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_4TypeEEE called 0 returned 0% blocks executed 0%
    #####:  913:LogicalResult mlir::shape::ConstShapeOp::inferReturnTypes(
        -:  914:    MLIRContext *context, Optional<Location> location, ValueRange operands,
        -:  915:    DictionaryAttr attributes, RegionRange regions,
        -:  916:    SmallVectorImpl<Type> &inferredReturnTypes) {
    #####:  917:  Builder b(context);
call    0 never executed
    #####:  918:  auto shape = attributes.getAs<DenseIntElementsAttr>("shape");
call    0 never executed
    #####:  919:  if (!shape)
branch  0 never executed
branch  1 never executed
    #####:  920:    return emitOptionalError(location, "missing shape attribute");
call    0 never executed
    #####:  921:  inferredReturnTypes.assign({RankedTensorType::get(
call    0 never executed
    #####:  922:      {static_cast<int64_t>(shape.size())}, b.getIndexType())});
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  923:  return success();
        -:  924:}
        -:  925:
function _ZN4mlir5shape12ConstShapeOp23isCompatibleReturnTypesENS_9TypeRangeES2_ called 0 returned 0% blocks executed 0%
    #####:  926:bool mlir::shape::ConstShapeOp::isCompatibleReturnTypes(TypeRange l,
        -:  927:                                                        TypeRange r) {
    #####:  928:  if (l.size() != 1 || r.size() != 1)
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
        -:  929:    return false;
        -:  930:
    #####:  931:  Type lhs = l.front();
call    0 never executed
    #####:  932:  Type rhs = r.front();
call    0 never executed
        -:  933:
    #####:  934:  if (lhs.isa<ShapeType>() || rhs.isa<ShapeType>())
call    0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
        -:  935:    // Shape type is compatible with all other valid return types.
        -:  936:    return true;
    #####:  937:  return lhs == rhs;
        -:  938:}
        -:  939:
        -:  940://===----------------------------------------------------------------------===//
        -:  941:// CstrBroadcastableOp
        -:  942://===----------------------------------------------------------------------===//
        -:  943:
function _ZN4mlir5shape19CstrBroadcastableOp27getCanonicalizationPatternsERNS_17RewritePatternSetEPNS_11MLIRContextE called 31 returned 100% blocks executed 100%
       31:  944:void CstrBroadcastableOp::getCanonicalizationPatterns(
        -:  945:    RewritePatternSet &patterns, MLIRContext *context) {
        -:  946:  // Canonicalization patterns have overlap with the considerations during
        -:  947:  // folding in case additional shape information is inferred at some point that
        -:  948:  // does not result in folding.
       31:  949:  patterns.add<CanonicalizeCastExtentTensorOperandsPattern<CstrBroadcastableOp>,
        -:  950:               CstrBroadcastableEqOps,
        -:  951:               RemoveDuplicateOperandsPattern<CstrBroadcastableOp>,
       31:  952:               RemoveEmptyShapeOperandsPattern<CstrBroadcastableOp>>(context);
call    0 returned 100%
       31:  953:}
        -:  954:
        -:  955:// Return true if there is exactly one attribute not representing a scalar
        -:  956:// broadcast.
function _ZL24hasAtMostSingleNonScalarN4llvm8ArrayRefIN4mlir9AttributeEEE called 0 returned 0% blocks executed 0%
    #####:  957:static bool hasAtMostSingleNonScalar(ArrayRef<Attribute> attributes) {
    #####:  958:  bool nonScalarSeen = false;
    #####:  959:  for (Attribute a : attributes) {
branch  0 never executed
branch  1 never executed
    #####:  960:    if (!a || a.cast<DenseIntElementsAttr>().getNumElements() != 0) {
branch  0 never executed
branch  1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
    #####:  961:      if (nonScalarSeen)
branch  0 never executed
branch  1 never executed
    #####:  962:        return false;
        -:  963:      nonScalarSeen = true;
        -:  964:    }
        -:  965:  }
    #####:  966:  return true;
        -:  967:}
        -:  968:
function _ZN4mlir5shape19CstrBroadcastableOp4foldEN4llvm8ArrayRefINS_9AttributeEEE called 0 returned 0% blocks executed 0%
    #####:  969:OpFoldResult CstrBroadcastableOp::fold(ArrayRef<Attribute> operands) {
        -:  970:  // No broadcasting is needed if all operands but one are scalar.
    #####:  971:  if (hasAtMostSingleNonScalar(operands))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  972:    return BoolAttr::get(getContext(), true);
call    0 never executed
call    1 never executed
call    2 never executed
        -:  973:
function _ZZN4mlir5shape19CstrBroadcastableOp4foldEN4llvm8ArrayRefINS_9AttributeEEEENKUlvE_clEv.isra.0 called 0 returned 0% blocks executed 0%
    #####:  974:  if ([&] {
branch  0 never executed
branch  1 never executed
    #####:  975:        SmallVector<SmallVector<int64_t, 6>, 6> extents;
call    0 never executed
    #####:  976:        for (const auto &operand : operands) {
branch  0 never executed
branch  1 never executed
    #####:  977:          if (!operand)
branch  0 never executed
branch  1 never executed
        -:  978:            return false;
    #####:  979:          extents.push_back(llvm::to_vector<6>(
call    0 never executed
call    1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
    #####:  980:              operand.cast<DenseIntElementsAttr>().getValues<int64_t>()));
call    0 never executed
        -:  981:        }
    #####:  982:        return OpTrait::util::staticallyKnownBroadcastable(extents);
call    0 never executed
    #####:  983:      }())
call    0 never executed
    #####:  984:    return BoolAttr::get(getContext(), true);
call    0 never executed
call    1 never executed
call    2 never executed
        -:  985:
        -:  986:  // Lastly, see if folding can be completed based on what constraints are known
        -:  987:  // on the input shapes.
function _ZZN4mlir5shape19CstrBroadcastableOp4foldEN4llvm8ArrayRefINS_9AttributeEEEENKUlvE0_clEv.isra.0 called 0 returned 0% blocks executed 0%
    #####:  988:  if ([&] {
branch  0 never executed
branch  1 never executed
    #####:  989:        SmallVector<SmallVector<int64_t, 6>, 6> extents;
call    0 never executed
call    1 never executed
    #####:  990:        for (auto shapeValue : getShapes()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
    #####:  991:          extents.emplace_back();
call    0 never executed
    #####:  992:          if (failed(getShapeVec(shapeValue, extents.back())))
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  993:            return false;
        -:  994:        }
    #####:  995:        return OpTrait::util::staticallyKnownBroadcastable(extents);
call    0 never executed
    #####:  996:      }())
call    0 never executed
    #####:  997:    return BoolAttr::get(getContext(), true);
call    0 never executed
call    1 never executed
call    2 never executed
        -:  998:
        -:  999:  // Because a failing witness result here represents an eventual assertion
        -: 1000:  // failure, we do not replace it with a constant witness.
    #####: 1001:  return nullptr;
        -: 1002:}
        -: 1003:
function _ZN4mlir5shape19CstrBroadcastableOp6verifyEv called 0 returned 0% blocks executed 0%
    #####: 1004:LogicalResult CstrBroadcastableOp::verify() {
        -: 1005:  // Ensure that CstrBroadcastableOp contains at least two operands
    #####: 1006:  if (getNumOperands() < 2)
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1007:    return emitOpError("required at least 2 input shapes");
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####: 1008:  return success();
        -: 1009:}
        -: 1010:
        -: 1011://===----------------------------------------------------------------------===//
        -: 1012:// CstrEqOp
        -: 1013://===----------------------------------------------------------------------===//
        -: 1014:
function _ZN4mlir5shape8CstrEqOp27getCanonicalizationPatternsERNS_17RewritePatternSetEPNS_11MLIRContextE called 31 returned 100% blocks executed 100%
       31: 1015:void CstrEqOp::getCanonicalizationPatterns(RewritePatternSet &patterns,
        -: 1016:                                           MLIRContext *context) {
        -: 1017:  // If inputs are equal, return passing witness
       31: 1018:  patterns.add<CstrEqEqOps>(context);
call    0 returned 100%
       31: 1019:}
        -: 1020:
function _ZN4mlir5shape8CstrEqOp4foldEN4llvm8ArrayRefINS_9AttributeEEE called 0 returned 0% blocks executed 0%
    #####: 1021:OpFoldResult CstrEqOp::fold(ArrayRef<Attribute> operands) {
    #####: 1022:  if (llvm::all_of(operands,
call    0 never executed
branch  1 never executed
branch  2 never executed
function _ZZN4mlir5shape8CstrEqOp4foldEN4llvm8ArrayRefINS_9AttributeEEEENKUlS4_E_clES4_.isra.0 called 0 returned 0% blocks executed 0%
    #####: 1023:                   [&](Attribute a) { return a && a == operands[0]; }))
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
    #####: 1024:    return BoolAttr::get(getContext(), true);
call    0 never executed
call    1 never executed
call    2 never executed
        -: 1025:
        -: 1026:  // Because a failing witness result here represents an eventual assertion
        -: 1027:  // failure, we do not try to replace it with a constant witness. Similarly, we
        -: 1028:  // cannot if there are any non-const inputs.
    #####: 1029:  return nullptr;
        -: 1030:}
        -: 1031:
        -: 1032://===----------------------------------------------------------------------===//
        -: 1033:// ConstSizeOp
        -: 1034://===----------------------------------------------------------------------===//
        -: 1035:
function _ZN4mlir5shape11ConstSizeOp5buildERNS_9OpBuilderERNS_14OperationStateEl called 0 returned 0% blocks executed 0%
    #####: 1036:void ConstSizeOp::build(OpBuilder &builder, OperationState &result,
        -: 1037:                        int64_t value) {
    #####: 1038:  build(builder, result, builder.getIndexAttr(value));
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####: 1039:}
        -: 1040:
function _ZN4mlir5shape11ConstSizeOp4foldEN4llvm8ArrayRefINS_9AttributeEEE called 0 returned 0% blocks executed 0%
    #####: 1041:OpFoldResult ConstSizeOp::fold(ArrayRef<Attribute>) { return getValueAttr(); }
call    0 never executed
call    1 never executed
        -: 1042:
function _ZN4mlir5shape11ConstSizeOp17getAsmResultNamesEN4llvm12function_refIFvNS_5ValueENS2_9StringRefEEEE called 0 returned 0% blocks executed 0%
    #####: 1043:void ConstSizeOp::getAsmResultNames(
        -: 1044:    llvm::function_ref<void(Value, StringRef)> setNameFn) {
    #####: 1045:  SmallString<4> buffer;
call    0 never executed
    #####: 1046:  llvm::raw_svector_ostream os(buffer);
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1047:  os << "c" << getValue();
call    0 never executed
call    1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
    #####: 1048:  setNameFn(getResult(), os.str());
call    0 never executed
call    1 never executed
call    2 never executed
    #####: 1049:}
        -: 1050:
        -: 1051://===----------------------------------------------------------------------===//
        -: 1052:// ConstWitnessOp
        -: 1053://===----------------------------------------------------------------------===//
        -: 1054:
function _ZN4mlir5shape14ConstWitnessOp4foldEN4llvm8ArrayRefINS_9AttributeEEE called 0 returned 0% blocks executed 0%
    #####: 1055:OpFoldResult ConstWitnessOp::fold(ArrayRef<Attribute>) {
    #####: 1056:  return getPassingAttr();
call    0 never executed
call    1 never executed
        -: 1057:}
        -: 1058:
        -: 1059://===----------------------------------------------------------------------===//
        -: 1060:// CstrRequireOp
        -: 1061://===----------------------------------------------------------------------===//
        -: 1062:
function _ZN4mlir5shape13CstrRequireOp4foldEN4llvm8ArrayRefINS_9AttributeEEE called 0 returned 0% blocks executed 0%
    #####: 1063:OpFoldResult CstrRequireOp::fold(ArrayRef<Attribute> operands) {
    #####: 1064:  return operands[0];
branch  0 never executed
branch  1 never executed
call    2 never executed
        -: 1065:}
        -: 1066:
        -: 1067://===----------------------------------------------------------------------===//
        -: 1068:// DimOp
        -: 1069://===----------------------------------------------------------------------===//
        -: 1070:
function _ZN4mlir5shape5DimOp16getConstantIndexEv called 0 returned 0% blocks executed 0%
    #####: 1071:Optional<int64_t> DimOp::getConstantIndex() {
    #####: 1072:  if (auto constSizeOp = getIndex().getDefiningOp<ConstSizeOp>())
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1073:    return constSizeOp.getValue().getLimitedValue();
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1074:  if (auto constantOp = getIndex().getDefiningOp<arith::ConstantOp>())
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1075:    return constantOp.getValue().cast<IntegerAttr>().getInt();
call    0 never executed
call    1 never executed
call    2 never executed
    #####: 1076:  return llvm::None;
        -: 1077:}
        -: 1078:
function _ZN4mlir5shape5DimOp4foldEN4llvm8ArrayRefINS_9AttributeEEE called 0 returned 0% blocks executed 0%
    #####: 1079:OpFoldResult DimOp::fold(ArrayRef<Attribute> operands) {
    #####: 1080:  Type valType = getValue().getType();
call    0 never executed
call    1 never executed
    #####: 1081:  auto valShapedType = valType.dyn_cast<ShapedType>();
call    0 never executed
    #####: 1082:  if (!valShapedType || !valShapedType.hasRank())
branch  0 never executed
branch  1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
    #####: 1083:    return nullptr;
    #####: 1084:  Optional<int64_t> index = getConstantIndex();
call    0 never executed
    #####: 1085:  if (!index.has_value())
branch  0 never executed
branch  1 never executed
    #####: 1086:    return nullptr;
    #####: 1087:  if (index.value() >= valShapedType.getRank())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1088:    return nullptr;
    #####: 1089:  auto extent = valShapedType.getDimSize(*index);
call    0 never executed
    #####: 1090:  if (ShapedType::isDynamic(extent))
branch  0 never executed
branch  1 never executed
    #####: 1091:    return nullptr;
    #####: 1092:  return IntegerAttr::get(IndexType::get(getContext()), extent);
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
        -: 1093:}
        -: 1094:
function _ZN4mlir5shape5DimOp16inferReturnTypesEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_10ValueRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_4TypeEEE called 0 returned 0% blocks executed 0%
    #####: 1095:LogicalResult mlir::shape::DimOp::inferReturnTypes(
        -: 1096:    MLIRContext *context, Optional<Location> location, ValueRange operands,
        -: 1097:    DictionaryAttr attributes, RegionRange regions,
        -: 1098:    SmallVectorImpl<Type> &inferredReturnTypes) {
    #####: 1099:  DimOpAdaptor dimOp(operands);
call    0 never executed
call    1 never executed
    #####: 1100:  inferredReturnTypes.assign({dimOp.getIndex().getType()});
call    0 never executed
call    1 never executed
    #####: 1101:  return success();
        -: 1102:}
        -: 1103:
function _ZN4mlir5shape5DimOp23isCompatibleReturnTypesENS_9TypeRangeES2_ called 0 returned 0% blocks executed 0%
    #####: 1104:bool mlir::shape::DimOp::isCompatibleReturnTypes(TypeRange l, TypeRange r) {
    #####: 1105:  return eachHasOnlyOneOfTypes<SizeType, IndexType>(l, r);
call    0 never executed
call    1 never executed
call    2 never executed
        -: 1106:}
        -: 1107:
function _ZN4mlir5shape5DimOp6verifyEv called 0 returned 0% blocks executed 0%
    #####: 1108:LogicalResult mlir::shape::DimOp::verify() {
    #####: 1109:  auto st = getValue().getType().cast<ShapedType>();
call    0 never executed
call    1 never executed
call    2 never executed
    #####: 1110:  if (!st.hasRank())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1111:    return success();
    #####: 1112:  if (auto index = getConstantIndex()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1113:    if (*index < 0 || *index >= st.getRank())
branch  0 never executed
branch  1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
    #####: 1114:      return emitOpError("index is out of range");
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
        -: 1115:  }
    #####: 1116:  return success();
        -: 1117:}
        -: 1118:
        -: 1119://===----------------------------------------------------------------------===//
        -: 1120:// DivOp
        -: 1121://===----------------------------------------------------------------------===//
        -: 1122:
function _ZN4mlir5shape5DivOp4foldEN4llvm8ArrayRefINS_9AttributeEEE called 0 returned 0% blocks executed 0%
    #####: 1123:OpFoldResult DivOp::fold(ArrayRef<Attribute> operands) {
    #####: 1124:  auto lhs = operands[0].dyn_cast_or_null<IntegerAttr>();
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1125:  if (!lhs)
branch  0 never executed
branch  1 never executed
    #####: 1126:    return nullptr;
    #####: 1127:  auto rhs = operands[1].dyn_cast_or_null<IntegerAttr>();
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1128:  if (!rhs)
branch  0 never executed
branch  1 never executed
    #####: 1129:    return nullptr;
        -: 1130:
        -: 1131:  // Division in APInt does not follow floor(lhs, rhs) when the result is
        -: 1132:  // negative. Rather, APInt rounds toward zero.
    #####: 1133:  APInt quotient, remainder;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1134:  APInt::sdivrem(lhs.getValue(), rhs.getValue(), quotient, remainder);
call    0 never executed
call    1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
branch  6 never executed
    #####: 1135:  if (quotient.isNegative() && !remainder.isNullValue()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
    #####: 1136:    quotient -= 1;
call    0 never executed
        -: 1137:  }
        -: 1138:
    #####: 1139:  Type indexTy = IndexType::get(getContext());
call    0 never executed
call    1 never executed
    #####: 1140:  return IntegerAttr::get(indexTy, quotient);
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
        -: 1141:}
        -: 1142:
function _ZN4mlir5shape5DivOp16inferReturnTypesEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_10ValueRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_4TypeEEE called 0 returned 0% blocks executed 0%
    #####: 1143:LogicalResult mlir::shape::DivOp::inferReturnTypes(
        -: 1144:    MLIRContext *context, Optional<Location> location, ValueRange operands,
        -: 1145:    DictionaryAttr attributes, RegionRange regions,
        -: 1146:    SmallVectorImpl<Type> &inferredReturnTypes) {
    #####: 1147:  if (operands[0].getType().isa<SizeType>() ||
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1148:      operands[1].getType().isa<SizeType>())
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1149:    inferredReturnTypes.assign({SizeType::get(context)});
call    0 never executed
call    1 never executed
        -: 1150:  else
    #####: 1151:    inferredReturnTypes.assign({IndexType::get(context)});
call    0 never executed
call    1 never executed
    #####: 1152:  return success();
        -: 1153:}
        -: 1154:
function _ZN4mlir5shape5DivOp23isCompatibleReturnTypesENS_9TypeRangeES2_ called 0 returned 0% blocks executed 0%
    #####: 1155:bool mlir::shape::DivOp::isCompatibleReturnTypes(TypeRange l, TypeRange r) {
        -: 1156:  // SizeType is compatible with IndexType.
    #####: 1157:  return eachHasOnlyOneOfTypes<SizeType, IndexType>(l, r);
call    0 never executed
call    1 never executed
call    2 never executed
        -: 1158:}
        -: 1159:
function _ZN4mlir5shape5DivOp6verifyEv called 0 returned 0% blocks executed 0%
    #####: 1160:LogicalResult DivOp::verify() { return verifySizeOrIndexOp(*this); }
call    0 never executed
call    1 never executed
call    2 never executed
        -: 1161:
        -: 1162://===----------------------------------------------------------------------===//
        -: 1163:// ShapeEqOp
        -: 1164://===----------------------------------------------------------------------===//
        -: 1165:
function _ZN4mlir5shape9ShapeEqOp4foldEN4llvm8ArrayRefINS_9AttributeEEE called 0 returned 0% blocks executed 0%
    #####: 1166:OpFoldResult ShapeEqOp::fold(ArrayRef<Attribute> operands) {
    #####: 1167:  bool allSame = true;
    #####: 1168:  if (!operands.empty() && !operands[0])
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1169:    return {};
    #####: 1170:  for (Attribute operand : operands.drop_front(1)) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1171:    if (!operand)
branch  0 never executed
branch  1 never executed
    #####: 1172:      return {};
    #####: 1173:    allSame = allSame && operand == operands[0];
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
        -: 1174:  }
    #####: 1175:  return BoolAttr::get(getContext(), allSame);
call    0 never executed
call    1 never executed
call    2 never executed
        -: 1176:}
        -: 1177:
        -: 1178://===----------------------------------------------------------------------===//
        -: 1179:// IndexToSizeOp
        -: 1180://===----------------------------------------------------------------------===//
        -: 1181:
function _ZN4mlir5shape13IndexToSizeOp4foldEN4llvm8ArrayRefINS_9AttributeEEE called 0 returned 0% blocks executed 0%
    #####: 1182:OpFoldResult IndexToSizeOp::fold(ArrayRef<Attribute> operands) {
        -: 1183:  // Constant values of both types, `shape.size` and `index`, are represented as
        -: 1184:  // `IntegerAttr`s which makes constant folding simple.
    #####: 1185:  if (Attribute arg = operands[0])
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1186:    return arg;
call    0 never executed
    #####: 1187:  return {};
        -: 1188:}
        -: 1189:
function _ZN4mlir5shape13IndexToSizeOp27getCanonicalizationPatternsERNS_17RewritePatternSetEPNS_11MLIRContextE called 31 returned 100% blocks executed 100%
       31: 1190:void IndexToSizeOp::getCanonicalizationPatterns(RewritePatternSet &patterns,
        -: 1191:                                                MLIRContext *context) {
       31: 1192:  patterns.add<SizeToIndexToSizeCanonicalization>(context);
call    0 returned 100%
       31: 1193:}
        -: 1194:
        -: 1195://===----------------------------------------------------------------------===//
        -: 1196:// FromExtentsOp
        -: 1197://===----------------------------------------------------------------------===//
        -: 1198:
function _ZN4mlir5shape13FromExtentsOp4foldEN4llvm8ArrayRefINS_9AttributeEEE called 0 returned 0% blocks executed 0%
    #####: 1199:OpFoldResult FromExtentsOp::fold(ArrayRef<Attribute> operands) {
    #####: 1200:  if (llvm::any_of(operands, [](Attribute a) { return !a; }))
branch  0 never executed
branch  1 never executed
    #####: 1201:    return nullptr;
    #####: 1202:  SmallVector<int64_t, 6> extents;
    #####: 1203:  for (auto attr : operands)
branch  0 never executed
branch  1 never executed
    #####: 1204:    extents.push_back(attr.cast<IntegerAttr>().getInt());
call    0 never executed
call    1 never executed
call    2 never executed
    #####: 1205:  Builder builder(getContext());
call    0 never executed
call    1 never executed
    #####: 1206:  return builder.getIndexTensorAttr(extents);
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
        -: 1207:}
        -: 1208:
        -: 1209://===----------------------------------------------------------------------===//
        -: 1210:// FunctionLibraryOp
        -: 1211://===----------------------------------------------------------------------===//
        -: 1212:
function _ZN4mlir5shape17FunctionLibraryOp5buildERNS_9OpBuilderERNS_14OperationStateEN4llvm9StringRefE called 0 returned 0% blocks executed 0%
    #####: 1213:void FunctionLibraryOp::build(OpBuilder &builder, OperationState &result,
        -: 1214:                              StringRef name) {
    #####: 1215:  result.attributes.push_back(builder.getNamedAttr(
call    0 never executed
call    1 never executed
    #####: 1216:      ::mlir::SymbolTable::getSymbolAttrName(), builder.getStringAttr(name)));
call    0 never executed
call    1 never executed
    #####: 1217:}
        -: 1218:
function _ZN4mlir5shape17FunctionLibraryOp16getShapeFunctionEPNS_9OperationE called 0 returned 0% blocks executed 0%
    #####: 1219:FuncOp FunctionLibraryOp::getShapeFunction(Operation *op) {
    #####: 1220:  auto attr = getMapping()
call    0 never executed
    #####: 1221:                  .get(op->getName().getIdentifier())
call    0 never executed
call    1 never executed
    #####: 1222:                  .dyn_cast_or_null<FlatSymbolRefAttr>();
    #####: 1223:  if (!attr)
branch  0 never executed
branch  1 never executed
    #####: 1224:    return nullptr;
    #####: 1225:  return lookupSymbol<FuncOp>(attr);
call    0 never executed
        -: 1226:}
        -: 1227:
function _ZN4mlir5shape17FunctionLibraryOp5parseERNS_11OpAsmParserERNS_14OperationStateE called 0 returned 0% blocks executed 0%
    #####: 1228:ParseResult FunctionLibraryOp::parse(OpAsmParser &parser,
        -: 1229:                                     OperationState &result) {
        -: 1230:  // Parse the op name.
    #####: 1231:  StringAttr nameAttr;
    #####: 1232:  if (parser.parseSymbolName(nameAttr, ::mlir::SymbolTable::getSymbolAttrName(),
branch  0 never executed
branch  1 never executed
    #####: 1233:                             result.attributes))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1234:    return failure();
        -: 1235:
    #####: 1236:  if (parser.parseOptionalAttrDictWithKeyword(result.attributes))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1237:    return failure();
        -: 1238:
    #####: 1239:  auto *bodyRegion = result.addRegion();
call    0 never executed
    #####: 1240:  if (parser.parseRegion(*bodyRegion))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1241:    return failure();
        -: 1242:
    #####: 1243:  if (parser.parseKeyword("mapping"))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1244:    return failure();
        -: 1245:
    #####: 1246:  DictionaryAttr mappingAttr;
    #####: 1247:  if (parser.parseAttribute(mappingAttr,
    #####: 1248:                            parser.getBuilder().getType<NoneType>(), "mapping",
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1249:                            result.attributes))
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1250:    return failure();
    #####: 1251:  return success();
        -: 1252:}
        -: 1253:
function _ZN4mlir5shape17FunctionLibraryOp5printERNS_12OpAsmPrinterE called 0 returned 0% blocks executed 0%
    #####: 1254:void FunctionLibraryOp::print(OpAsmPrinter &p) {
    #####: 1255:  p << ' ';
call    0 never executed
    #####: 1256:  p.printSymbolName(getName());
call    0 never executed
call    1 never executed
    #####: 1257:  p.printOptionalAttrDictWithKeyword(
call    0 never executed
    #####: 1258:      (*this)->getAttrs(), {mlir::SymbolTable::getSymbolAttrName(), "mapping"});
call    0 never executed
    #####: 1259:  p << ' ';
call    0 never executed
    #####: 1260:  p.printRegion(getRegion(), /*printEntryBlockArgs=*/false,
call    0 never executed
    #####: 1261:                /*printBlockTerminators=*/false);
call    0 never executed
    #####: 1262:  p << " mapping ";
call    0 never executed
    #####: 1263:  p.printAttributeWithoutType(getMappingAttr());
call    0 never executed
call    1 never executed
    #####: 1264:}
        -: 1265:
        -: 1266://===----------------------------------------------------------------------===//
        -: 1267:// FuncOp
        -: 1268://===----------------------------------------------------------------------===//
        -: 1269:
function _ZN4mlir5shape6FuncOp6createENS_8LocationEN4llvm9StringRefENS_12FunctionTypeENS3_8ArrayRefINS_14NamedAttributeEEE called 0 returned 0% blocks executed 0%
    #####: 1270:FuncOp FuncOp::create(Location location, StringRef name, FunctionType type,
        -: 1271:                      ArrayRef<NamedAttribute> attrs) {
    #####: 1272:  OpBuilder builder(location->getContext());
call    0 never executed
call    1 never executed
    #####: 1273:  OperationState state(location, getOperationName());
call    0 never executed
call    1 never executed
    #####: 1274:  FuncOp::build(builder, state, name, type, attrs);
call    0 never executed
    #####: 1275:  return cast<FuncOp>(Operation::create(state));
call    0 never executed
call    1 never executed
        -: 1276:}
function _ZN4mlir5shape6FuncOp6createENS_8LocationEN4llvm9StringRefENS_12FunctionTypeENS3_14iterator_rangeINS_9Operation21dialect_attr_iteratorEEE called 0 returned 0% blocks executed 0%
    #####: 1277:FuncOp FuncOp::create(Location location, StringRef name, FunctionType type,
        -: 1278:                      Operation::dialect_attr_range attrs) {
    #####: 1279:  SmallVector<NamedAttribute, 8> attrRef(attrs);
call    0 never executed
    #####: 1280:  return create(location, name, type, llvm::makeArrayRef(attrRef));
call    0 never executed
branch  1 never executed
branch  2 never executed
        -: 1281:}
function _ZN4mlir5shape6FuncOp6createENS_8LocationEN4llvm9StringRefENS_12FunctionTypeENS3_8ArrayRefINS_14NamedAttributeEEENS6_INS_14DictionaryAttrEEE called 0 returned 0% blocks executed 0%
    #####: 1282:FuncOp FuncOp::create(Location location, StringRef name, FunctionType type,
        -: 1283:                      ArrayRef<NamedAttribute> attrs,
        -: 1284:                      ArrayRef<DictionaryAttr> argAttrs) {
    #####: 1285:  FuncOp func = create(location, name, type, attrs);
call    0 never executed
    #####: 1286:  func.setAllArgAttrs(argAttrs);
call    0 never executed
    #####: 1287:  return func;
        -: 1288:}
        -: 1289:
function _ZN4mlir5shape6FuncOp5buildERNS_9OpBuilderERNS_14OperationStateEN4llvm9StringRefENS_12FunctionTypeENS6_8ArrayRefINS_14NamedAttributeEEENS9_INS_14DictionaryAttrEEE called 0 returned 0% blocks executed 0%
    #####: 1290:void FuncOp::build(OpBuilder &builder, OperationState &state, StringRef name,
        -: 1291:                   FunctionType type, ArrayRef<NamedAttribute> attrs,
        -: 1292:                   ArrayRef<DictionaryAttr> argAttrs) {
    #####: 1293:  state.addAttribute(FuncOp::getSymNameAttrName(state.name),
call    0 never executed
    #####: 1294:                     builder.getStringAttr(name));
call    0 never executed
call    1 never executed
    #####: 1295:  state.addAttribute(FuncOp::getFunctionTypeAttrName(state.name),
call    0 never executed
    #####: 1296:                     TypeAttr::get(type));
call    0 never executed
    #####: 1297:  state.attributes.append(attrs.begin(), attrs.end());
call    0 never executed
    #####: 1298:  state.addRegion();
call    0 never executed
        -: 1299:
    #####: 1300:  if (argAttrs.empty())
branch  0 never executed
branch  1 never executed
        -: 1301:    return;
    #####: 1302:  assert(type.getNumInputs() == argAttrs.size());
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
    #####: 1303:  function_interface_impl::addArgAndResultAttrs(builder, state, argAttrs,
call    0 never executed
        -: 1304:                                                /*resultAttrs=*/llvm::None);
        -: 1305:}
        -: 1306:
function _ZN4mlir5shape6FuncOp5parseERNS_11OpAsmParserERNS_14OperationStateE called 0 returned 0% blocks executed 0%
    #####: 1307:ParseResult FuncOp::parse(OpAsmParser &parser, OperationState &result) {
    #####: 1308:  auto buildFuncType =
function _ZZN4mlir5shape6FuncOp5parseERNS_11OpAsmParserERNS_14OperationStateEENKUlRNS_7BuilderEN4llvm8ArrayRefINS_4TypeEEESB_NS_23function_interface_impl12VariadicFlagERNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEE_clES7_SB_SB_SD_SK_.isra.0 called 0 returned 0% blocks executed 0%
    #####: 1309:      [](Builder &builder, ArrayRef<Type> argTypes, ArrayRef<Type> results,
        -: 1310:         function_interface_impl::VariadicFlag,
    #####: 1311:         std::string &) { return builder.getFunctionType(argTypes, results); };
call    0 never executed
call    1 never executed
call    2 never executed
        -: 1312:
    #####: 1313:  return function_interface_impl::parseFunctionOp(
    #####: 1314:      parser, result, /*allowVariadic=*/false, buildFuncType);
call    0 never executed
        -: 1315:}
        -: 1316:
function _ZN4mlir5shape6FuncOp5printERNS_12OpAsmPrinterE called 0 returned 0% blocks executed 0%
    #####: 1317:void FuncOp::print(OpAsmPrinter &p) {
    #####: 1318:  function_interface_impl::printFunctionOp(p, *this, /*isVariadic=*/false);
call    0 never executed
call    1 never executed
    #####: 1319:}
        -: 1320:
        -: 1321://===----------------------------------------------------------------------===//
        -: 1322:// GetExtentOp
        -: 1323://===----------------------------------------------------------------------===//
        -: 1324:
function _ZN4mlir5shape11GetExtentOp14getConstantDimEv called 0 returned 0% blocks executed 0%
    #####: 1325:Optional<int64_t> GetExtentOp::getConstantDim() {
    #####: 1326:  if (auto constSizeOp = getDim().getDefiningOp<ConstSizeOp>())
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1327:    return constSizeOp.getValue().getLimitedValue();
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1328:  if (auto constantOp = getDim().getDefiningOp<arith::ConstantOp>())
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1329:    return constantOp.getValue().cast<IntegerAttr>().getInt();
call    0 never executed
call    1 never executed
call    2 never executed
    #####: 1330:  return llvm::None;
        -: 1331:}
        -: 1332:
function _ZN4mlir5shape11GetExtentOp4foldEN4llvm8ArrayRefINS_9AttributeEEE called 0 returned 0% blocks executed 0%
    #####: 1333:OpFoldResult GetExtentOp::fold(ArrayRef<Attribute> operands) {
    #####: 1334:  auto elements = operands[0].dyn_cast_or_null<DenseIntElementsAttr>();
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####: 1335:  if (!elements)
branch  0 never executed
branch  1 never executed
    #####: 1336:    return nullptr;
    #####: 1337:  Optional<int64_t> dim = getConstantDim();
call    0 never executed
    #####: 1338:  if (!dim.has_value())
branch  0 never executed
branch  1 never executed
    #####: 1339:    return nullptr;
    #####: 1340:  if (dim.value() >= elements.getNumElements())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1341:    return nullptr;
    #####: 1342:  return elements.getValues<Attribute>()[(uint64_t)dim.value()];
call    0 never executed
call    1 never executed
call    2 never executed
        -: 1343:}
        -: 1344:
function _ZN4mlir5shape11GetExtentOp5buildERNS_9OpBuilderERNS_14OperationStateENS_5ValueEl called 0 returned 0% blocks executed 0%
    #####: 1345:void GetExtentOp::build(OpBuilder &builder, OperationState &result, Value shape,
        -: 1346:                        int64_t dim) {
    #####: 1347:  auto loc = result.location;
    #####: 1348:  auto dimAttr = builder.getIndexAttr(dim);
call    0 never executed
    #####: 1349:  if (shape.getType().isa<ShapeType>()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1350:    Value dim = builder.create<ConstSizeOp>(loc, dimAttr);
call    0 never executed
call    1 never executed
    #####: 1351:    build(builder, result, builder.getType<SizeType>(), shape, dim);
call    0 never executed
call    1 never executed
        -: 1352:  } else {
    #####: 1353:    Value dim =
    #####: 1354:        builder.create<arith::ConstantOp>(loc, builder.getIndexType(), dimAttr);
call    0 never executed
call    1 never executed
call    2 never executed
    #####: 1355:    build(builder, result, builder.getIndexType(), shape, dim);
call    0 never executed
call    1 never executed
        -: 1356:  }
    #####: 1357:}
        -: 1358:
function _ZN4mlir5shape11GetExtentOp16inferReturnTypesEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_10ValueRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_4TypeEEE called 0 returned 0% blocks executed 0%
    #####: 1359:LogicalResult mlir::shape::GetExtentOp::inferReturnTypes(
        -: 1360:    MLIRContext *context, Optional<Location> location, ValueRange operands,
        -: 1361:    DictionaryAttr attributes, RegionRange regions,
        -: 1362:    SmallVectorImpl<Type> &inferredReturnTypes) {
    #####: 1363:  inferredReturnTypes.assign({IndexType::get(context)});
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
call    5 never executed
call    6 never executed
call    7 never executed
call    8 never executed
call    9 never executed
    #####: 1364:  return success();
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
        -: 1365:}
        -: 1366:
function _ZN4mlir5shape11GetExtentOp23isCompatibleReturnTypesENS_9TypeRangeES2_ called 0 returned 0% blocks executed 0%
    #####: 1367:bool mlir::shape::GetExtentOp::isCompatibleReturnTypes(TypeRange l,
        -: 1368:                                                       TypeRange r) {
        -: 1369:  // SizeType is compatible with IndexType.
    #####: 1370:  return eachHasOnlyOneOfTypes<SizeType, IndexType>(l, r);
call    0 never executed
call    1 never executed
call    2 never executed
        -: 1371:}
        -: 1372:
function _ZN4mlir5shape11GetExtentOp6verifyEv called 0 returned 0% blocks executed 0%
    #####: 1373:LogicalResult GetExtentOp::verify() { return verifySizeOrIndexOp(*this); }
call    0 never executed
call    1 never executed
call    2 never executed
        -: 1374:
        -: 1375://===----------------------------------------------------------------------===//
        -: 1376:// IsBroadcastableOp
        -: 1377://===----------------------------------------------------------------------===//
        -: 1378:
function _ZN4mlir5shape17IsBroadcastableOp27getCanonicalizationPatternsERNS_17RewritePatternSetEPNS_11MLIRContextE called 31 returned 100% blocks executed 100%
       31: 1379:void IsBroadcastableOp::getCanonicalizationPatterns(RewritePatternSet &patterns,
        -: 1380:                                                    MLIRContext *context) {
       31: 1381:  patterns.add<RemoveDuplicateOperandsPattern<IsBroadcastableOp>>(context);
call    0 returned 100%
       31: 1382:}
        -: 1383:
function _ZN4mlir5shape17IsBroadcastableOp4foldEN4llvm8ArrayRefINS_9AttributeEEE called 0 returned 0% blocks executed 0%
    #####: 1384:OpFoldResult IsBroadcastableOp::fold(ArrayRef<Attribute> operands) {
        -: 1385:  // Can always broadcast fewer than two shapes.
    #####: 1386:  if (operands.size() < 2) {
branch  0 never executed
branch  1 never executed
    #####: 1387:    return BoolAttr::get(getContext(), true);
call    0 never executed
call    1 never executed
call    2 never executed
        -: 1388:  }
        -: 1389:
    #####: 1390:  return nullptr;
        -: 1391:}
        -: 1392:
        -: 1393://===----------------------------------------------------------------------===//
        -: 1394:// MeetOp
        -: 1395://===----------------------------------------------------------------------===//
        -: 1396:
function _ZN4mlir5shape6MeetOp16inferReturnTypesEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_10ValueRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_4TypeEEE called 0 returned 0% blocks executed 0%
    #####: 1397:LogicalResult mlir::shape::MeetOp::inferReturnTypes(
        -: 1398:    MLIRContext *context, Optional<Location> location, ValueRange operands,
        -: 1399:    DictionaryAttr attributes, RegionRange regions,
        -: 1400:    SmallVectorImpl<Type> &inferredReturnTypes) {
    #####: 1401:  if (operands.empty())
branch  0 never executed
branch  1 never executed
    #####: 1402:    return failure();
        -: 1403:
function _ZZN4mlir5shape6MeetOp16inferReturnTypesEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_10ValueRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_4TypeEEEENKUlSC_E_clESC_.isra.0 called 0 returned 0% blocks executed 0%
    #####: 1404:  auto isShapeType = [](Type arg) {
    #####: 1405:    if (arg.isa<ShapeType>())
call    0 never executed
branch  1 never executed
branch  2 never executed
        -: 1406:      return true;
    #####: 1407:    return isExtentTensorType(arg);
call    0 never executed
        -: 1408:  };
        -: 1409:
    #####: 1410:  ValueRange::type_range types = operands.getTypes();
call    0 never executed
    #####: 1411:  Type acc = types.front();
call    0 never executed
    #####: 1412:  for (auto t : drop_begin(types)) {
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####: 1413:    Type l = acc, r = t;
    #####: 1414:    if (!l.isa<ShapeType, SizeType>())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1415:      std::swap(l, r);
        -: 1416:
        -: 1417:    // Handle sizes, propagate error type if present.
    #####: 1418:    if (l.isa<SizeType>()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1419:      if (r.isa<SizeType, IndexType>())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1420:        acc = l;
        -: 1421:      else
    #####: 1422:        return emitOptionalError(location, "requires all sizes or shapes");
call    0 never executed
    #####: 1423:    } else if (l.isa<IndexType>()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1424:      if (r.isa<IndexType>())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1425:        acc = r;
        -: 1426:      else
    #####: 1427:        return emitOptionalError(location, "requires all sizes or shapes");
call    0 never executed
    #####: 1428:    } else if (l.isa<ShapeType>()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
        -: 1429:      // Handle shapes, propagate error type if present.
    #####: 1430:      if (isShapeType(r))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1431:        acc = l;
        -: 1432:      else
    #####: 1433:        return emitOptionalError(location, "requires all sizes or shapes");
call    0 never executed
    #####: 1434:    } else if (isExtentTensorType(l)) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1435:      auto rank1 = l.cast<RankedTensorType>().getShape()[0];
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1436:      auto rank2 = r.cast<RankedTensorType>().getShape()[0];
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1437:      if (ShapedType::isDynamic(rank1))
branch  0 never executed
branch  1 never executed
    #####: 1438:        acc = l;
    #####: 1439:      else if (ShapedType::isDynamic(rank2))
branch  0 never executed
branch  1 never executed
    #####: 1440:        acc = r;
    #####: 1441:      else if (rank1 != rank2)
branch  0 never executed
branch  1 never executed
    #####: 1442:        return emitOptionalError(location, "unequal shape cardinality");
call    0 never executed
        -: 1443:      else
    #####: 1444:        acc = l;
        -: 1445:    }
        -: 1446:  }
    #####: 1447:  inferredReturnTypes.assign({acc});
call    0 never executed
    #####: 1448:  return success();
        -: 1449:}
        -: 1450:
function _ZN4mlir5shape6MeetOp23isCompatibleReturnTypesENS_9TypeRangeES2_ called 0 returned 0% blocks executed 0%
    #####: 1451:bool mlir::shape::MeetOp::isCompatibleReturnTypes(TypeRange l, TypeRange r) {
    #####: 1452:  if (l.size() != 1 || r.size() != 1)
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
        -: 1453:    return false;
    #####: 1454:  if (l == r)
call    0 never executed
branch  1 never executed
branch  2 never executed
        -: 1455:    return true;
        -: 1456:
    #####: 1457:  Type lhs = l.front();
call    0 never executed
    #####: 1458:  Type rhs = r.front();
call    0 never executed
        -: 1459:
    #####: 1460:  if (!lhs.isa<ShapeType, SizeType>())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1461:    std::swap(lhs, rhs);
        -: 1462:
    #####: 1463:  if (lhs.isa<SizeType>())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1464:    return rhs.isa<SizeType, IndexType>();
call    0 never executed
    #####: 1465:  if (lhs.isa<ShapeType>())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1466:    return rhs.isa<ShapeType, TensorType>();
call    0 never executed
        -: 1467:
    #####: 1468:  if (succeeded(verifyCompatibleShapes({lhs, rhs})))
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1469:    return true;
        -: 1470:  return false;
        -: 1471:}
        -: 1472:
        -: 1473://===----------------------------------------------------------------------===//
        -: 1474:// RankOp
        -: 1475://===----------------------------------------------------------------------===//
        -: 1476:
function _ZN4mlir5shape6RankOp4foldEN4llvm8ArrayRefINS_9AttributeEEE called 0 returned 0% blocks executed 0%
    #####: 1477:OpFoldResult shape::RankOp::fold(ArrayRef<Attribute> operands) {
    #####: 1478:  auto shape = operands[0].dyn_cast_or_null<DenseIntElementsAttr>();
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####: 1479:  if (!shape)
branch  0 never executed
branch  1 never executed
    #####: 1480:    return {};
    #####: 1481:  int64_t rank = shape.getNumElements();
call    0 never executed
    #####: 1482:  Builder builder(getContext());
call    0 never executed
call    1 never executed
    #####: 1483:  return builder.getIndexAttr(rank);
call    0 never executed
call    1 never executed
        -: 1484:}
        -: 1485:
        -: 1486:/// Evaluate the `rank` operation for shapes of ranked tensors at compile time.
        -: 1487:/// Constant folding fails in cases where only the rank is constant, not the
        -: 1488:/// shape itself.
        -: 1489:/// This canonicalization matches `shape.rank(shape.shape_of(%ranked_tensor))`.
        -: 1490:///
        -: 1491:/// Example:
        -: 1492:///
        -: 1493:/// %shape = shape.shape_of %ranked_tensor : tensor<1x2x?xf32>
        -: 1494:/// %rank = shape.rank %shape
        -: 1495:///
        -: 1496:/// becomes
        -: 1497:///
        -: 1498:/// %rank = shape.const_size 3
        -: 1499:
        -: 1500:namespace {
        -: 1501:struct RankShapeOfCanonicalizationPattern
        -: 1502:    : public OpRewritePattern<shape::RankOp> {
        -: 1503:  using OpRewritePattern<shape::RankOp>::OpRewritePattern;
        -: 1504:
function _ZNK12_GLOBAL__N_134RankShapeOfCanonicalizationPattern15matchAndRewriteEN4mlir5shape6RankOpERNS1_15PatternRewriterE called 0 returned 0% blocks executed 0%
    #####: 1505:  LogicalResult matchAndRewrite(shape::RankOp op,
        -: 1506:                                PatternRewriter &rewriter) const override {
    #####: 1507:    auto shapeOfOp = op.getShape().getDefiningOp<ShapeOfOp>();
call    0 never executed
call    1 never executed
    #####: 1508:    if (!shapeOfOp)
branch  0 never executed
branch  1 never executed
    #####: 1509:      return failure();
    #####: 1510:    auto rankedTensorType =
call    0 never executed
    #####: 1511:        shapeOfOp.getArg().getType().dyn_cast<RankedTensorType>();
call    0 never executed
    #####: 1512:    if (!rankedTensorType)
branch  0 never executed
branch  1 never executed
    #####: 1513:      return failure();
    #####: 1514:    int64_t rank = rankedTensorType.getRank();
call    0 never executed
    #####: 1515:    if (op.getType().isa<IndexType>()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1516:      rewriter.replaceOpWithNewOp<arith::ConstantIndexOp>(op.getOperation(),
    #####: 1517:                                                          rank);
call    0 never executed
    #####: 1518:    } else if (op.getType().isa<shape::SizeType>()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1519:      rewriter.replaceOpWithNewOp<shape::ConstSizeOp>(op.getOperation(), rank);
call    0 never executed
        -: 1520:    } else {
    #####: 1521:      return failure();
        -: 1522:    }
    #####: 1523:    return success();
        -: 1524:  }
        -: 1525:};
        -: 1526:} // namespace
        -: 1527:
function _ZN4mlir5shape6RankOp27getCanonicalizationPatternsERNS_17RewritePatternSetEPNS_11MLIRContextE called 31 returned 100% blocks executed 100%
       31: 1528:void shape::RankOp::getCanonicalizationPatterns(RewritePatternSet &patterns,
        -: 1529:                                                MLIRContext *context) {
       31: 1530:  patterns.add<RankShapeOfCanonicalizationPattern>(context);
call    0 returned 100%
       31: 1531:}
        -: 1532:
function _ZN4mlir5shape6RankOp16inferReturnTypesEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_10ValueRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_4TypeEEE called 0 returned 0% blocks executed 0%
    #####: 1533:LogicalResult mlir::shape::RankOp::inferReturnTypes(
        -: 1534:    MLIRContext *context, Optional<Location> location, ValueRange operands,
        -: 1535:    DictionaryAttr attributes, RegionRange regions,
        -: 1536:    SmallVectorImpl<Type> &inferredReturnTypes) {
    #####: 1537:  if (operands[0].getType().isa<ShapeType>())
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1538:    inferredReturnTypes.assign({SizeType::get(context)});
call    0 never executed
call    1 never executed
        -: 1539:  else
    #####: 1540:    inferredReturnTypes.assign({IndexType::get(context)});
call    0 never executed
call    1 never executed
    #####: 1541:  return success();
        -: 1542:}
        -: 1543:
function _ZN4mlir5shape6RankOp23isCompatibleReturnTypesENS_9TypeRangeES2_ called 0 returned 0% blocks executed 0%
    #####: 1544:bool mlir::shape::RankOp::isCompatibleReturnTypes(TypeRange l, TypeRange r) {
        -: 1545:  // SizeType is compatible with IndexType.
    #####: 1546:  return eachHasOnlyOneOfTypes<SizeType, IndexType>(l, r);
call    0 never executed
call    1 never executed
call    2 never executed
        -: 1547:}
        -: 1548:
function _ZN4mlir5shape6RankOp6verifyEv called 0 returned 0% blocks executed 0%
    #####: 1549:LogicalResult shape::RankOp::verify() { return verifySizeOrIndexOp(*this); }
call    0 never executed
call    1 never executed
call    2 never executed
        -: 1550:
        -: 1551://===----------------------------------------------------------------------===//
        -: 1552:// NumElementsOp
        -: 1553://===----------------------------------------------------------------------===//
        -: 1554:
function _ZN4mlir5shape13NumElementsOp4foldEN4llvm8ArrayRefINS_9AttributeEEE called 0 returned 0% blocks executed 0%
    #####: 1555:OpFoldResult NumElementsOp::fold(ArrayRef<Attribute> operands) {
        -: 1556:
        -: 1557:  // Fold only when argument constant.
    #####: 1558:  Attribute shape = operands[0];
branch  0 never executed
branch  1 never executed
    #####: 1559:  if (!shape)
branch  0 never executed
branch  1 never executed
    #####: 1560:    return {};
        -: 1561:
    #####: 1562:  APInt product(64, 1);
call    0 never executed
    #####: 1563:  for (auto value : shape.cast<DenseIntElementsAttr>())
call    0 never executed
call    1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
call    5 never executed
    #####: 1564:    product *= value;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1565:  Builder builder(getContext());
call    0 never executed
call    1 never executed
    #####: 1566:  return builder.getIndexAttr(product.getLimitedValue());
call    0 never executed
call    1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
        -: 1567:}
        -: 1568:
function _ZN4mlir5shape13NumElementsOp16inferReturnTypesEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_10ValueRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_4TypeEEE called 0 returned 0% blocks executed 0%
    #####: 1569:LogicalResult mlir::shape::NumElementsOp::inferReturnTypes(
        -: 1570:    MLIRContext *context, Optional<Location> location, ValueRange operands,
        -: 1571:    DictionaryAttr attributes, RegionRange regions,
        -: 1572:    SmallVectorImpl<Type> &inferredReturnTypes) {
    #####: 1573:  if (operands[0].getType().isa<ShapeType>())
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1574:    inferredReturnTypes.assign({SizeType::get(context)});
call    0 never executed
call    1 never executed
        -: 1575:  else
    #####: 1576:    inferredReturnTypes.assign({IndexType::get(context)});
call    0 never executed
call    1 never executed
    #####: 1577:  return success();
        -: 1578:}
        -: 1579:
function _ZN4mlir5shape13NumElementsOp23isCompatibleReturnTypesENS_9TypeRangeES2_ called 0 returned 0% blocks executed 0%
    #####: 1580:bool mlir::shape::NumElementsOp::isCompatibleReturnTypes(TypeRange l,
        -: 1581:                                                         TypeRange r) {
        -: 1582:  // SizeType is compatible with IndexType.
    #####: 1583:  return eachHasOnlyOneOfTypes<SizeType, IndexType>(l, r);
call    0 never executed
call    1 never executed
call    2 never executed
        -: 1584:}
        -: 1585:
function _ZN4mlir5shape13NumElementsOp6verifyEv called 0 returned 0% blocks executed 0%
    #####: 1586:LogicalResult shape::NumElementsOp::verify() {
    #####: 1587:  return verifySizeOrIndexOp(*this);
call    0 never executed
call    1 never executed
call    2 never executed
        -: 1588:}
        -: 1589:
        -: 1590://===----------------------------------------------------------------------===//
        -: 1591:// MaxOp
        -: 1592://===----------------------------------------------------------------------===//
        -: 1593:
function _ZN4mlir5shape5MaxOp4foldEN4llvm8ArrayRefINS_9AttributeEEE called 0 returned 0% blocks executed 0%
    #####: 1594:OpFoldResult MaxOp::fold(llvm::ArrayRef<mlir::Attribute> operands) {
        -: 1595:  // If operands are equal, just propagate one.
    #####: 1596:  if (getLhs() == getRhs())
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1597:    return getLhs();
call    0 never executed
call    1 never executed
    #####: 1598:  return nullptr;
        -: 1599:}
        -: 1600:
function _ZN4mlir5shape5MaxOp16inferReturnTypesEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_10ValueRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_4TypeEEE called 0 returned 0% blocks executed 0%
    #####: 1601:LogicalResult mlir::shape::MaxOp::inferReturnTypes(
        -: 1602:    MLIRContext *context, Optional<Location> location, ValueRange operands,
        -: 1603:    DictionaryAttr attributes, RegionRange regions,
        -: 1604:    SmallVectorImpl<Type> &inferredReturnTypes) {
    #####: 1605:  if (operands[0].getType() == operands[1].getType())
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1606:    inferredReturnTypes.assign({operands[0].getType()});
call    0 never executed
call    1 never executed
        -: 1607:  else
    #####: 1608:    inferredReturnTypes.assign({SizeType::get(context)});
call    0 never executed
call    1 never executed
    #####: 1609:  return success();
        -: 1610:}
        -: 1611:
function _ZN4mlir5shape5MaxOp23isCompatibleReturnTypesENS_9TypeRangeES2_ called 0 returned 0% blocks executed 0%
    #####: 1612:bool mlir::shape::MaxOp::isCompatibleReturnTypes(TypeRange l, TypeRange r) {
    #####: 1613:  if (l.size() != 1 || r.size() != 1)
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
        -: 1614:    return false;
    #####: 1615:  if (l.front().isa<ShapeType>() && r.front().isa<ShapeType>())
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
call    4 never executed
call    5 never executed
branch  6 never executed
branch  7 never executed
    #####: 1616:    return true;
    #####: 1617:  if (l.front().isa<SizeType>() && r.front().isa<SizeType>())
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
call    4 never executed
call    5 never executed
branch  6 never executed
branch  7 never executed
    #####: 1618:    return true;
        -: 1619:  return false;
        -: 1620:}
        -: 1621:
        -: 1622://===----------------------------------------------------------------------===//
        -: 1623:// MinOp
        -: 1624://===----------------------------------------------------------------------===//
        -: 1625:
function _ZN4mlir5shape5MinOp4foldEN4llvm8ArrayRefINS_9AttributeEEE called 0 returned 0% blocks executed 0%
    #####: 1626:OpFoldResult MinOp::fold(llvm::ArrayRef<mlir::Attribute> operands) {
        -: 1627:  // If operands are equal, just propagate one.
    #####: 1628:  if (getLhs() == getRhs())
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1629:    return getLhs();
call    0 never executed
call    1 never executed
    #####: 1630:  return nullptr;
        -: 1631:}
        -: 1632:
function _ZN4mlir5shape5MinOp16inferReturnTypesEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_10ValueRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_4TypeEEE called 0 returned 0% blocks executed 0%
    #####: 1633:LogicalResult mlir::shape::MinOp::inferReturnTypes(
        -: 1634:    MLIRContext *context, Optional<Location> location, ValueRange operands,
        -: 1635:    DictionaryAttr attributes, RegionRange regions,
        -: 1636:    SmallVectorImpl<Type> &inferredReturnTypes) {
    #####: 1637:  if (operands[0].getType() == operands[1].getType())
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1638:    inferredReturnTypes.assign({operands[0].getType()});
call    0 never executed
call    1 never executed
        -: 1639:  else
    #####: 1640:    inferredReturnTypes.assign({SizeType::get(context)});
call    0 never executed
call    1 never executed
    #####: 1641:  return success();
        -: 1642:}
        -: 1643:
function _ZN4mlir5shape5MinOp23isCompatibleReturnTypesENS_9TypeRangeES2_ called 0 returned 0% blocks executed 0%
    #####: 1644:bool mlir::shape::MinOp::isCompatibleReturnTypes(TypeRange l, TypeRange r) {
    #####: 1645:  if (l.size() != 1 || r.size() != 1)
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
        -: 1646:    return false;
    #####: 1647:  if (l.front().isa<ShapeType>() && r.front().isa<ShapeType>())
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
call    4 never executed
call    5 never executed
branch  6 never executed
branch  7 never executed
    #####: 1648:    return true;
    #####: 1649:  if (l.front().isa<SizeType>() && r.front().isa<SizeType>())
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
call    4 never executed
call    5 never executed
branch  6 never executed
branch  7 never executed
    #####: 1650:    return true;
        -: 1651:  return false;
        -: 1652:}
        -: 1653:
        -: 1654://===----------------------------------------------------------------------===//
        -: 1655:// MulOp
        -: 1656://===----------------------------------------------------------------------===//
        -: 1657:
function _ZN4mlir5shape5MulOp4foldEN4llvm8ArrayRefINS_9AttributeEEE called 0 returned 0% blocks executed 0%
    #####: 1658:OpFoldResult MulOp::fold(ArrayRef<Attribute> operands) {
    #####: 1659:  auto lhs = operands[0].dyn_cast_or_null<IntegerAttr>();
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1660:  if (!lhs)
branch  0 never executed
branch  1 never executed
    #####: 1661:    return nullptr;
    #####: 1662:  auto rhs = operands[1].dyn_cast_or_null<IntegerAttr>();
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1663:  if (!rhs)
branch  0 never executed
branch  1 never executed
    #####: 1664:    return nullptr;
    #####: 1665:  APInt folded = lhs.getValue() * rhs.getValue();
call    0 never executed
call    1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
branch  6 never executed
    #####: 1666:  Type indexTy = IndexType::get(getContext());
call    0 never executed
call    1 never executed
    #####: 1667:  return IntegerAttr::get(indexTy, folded);
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
        -: 1668:}
        -: 1669:
function _ZN4mlir5shape5MulOp16inferReturnTypesEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_10ValueRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_4TypeEEE called 0 returned 0% blocks executed 0%
    #####: 1670:LogicalResult mlir::shape::MulOp::inferReturnTypes(
        -: 1671:    MLIRContext *context, Optional<Location> location, ValueRange operands,
        -: 1672:    DictionaryAttr attributes, RegionRange regions,
        -: 1673:    SmallVectorImpl<Type> &inferredReturnTypes) {
    #####: 1674:  if (operands[0].getType().isa<SizeType>() ||
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1675:      operands[1].getType().isa<SizeType>())
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1676:    inferredReturnTypes.assign({SizeType::get(context)});
call    0 never executed
call    1 never executed
        -: 1677:  else
    #####: 1678:    inferredReturnTypes.assign({IndexType::get(context)});
call    0 never executed
call    1 never executed
    #####: 1679:  return success();
        -: 1680:}
        -: 1681:
function _ZN4mlir5shape5MulOp23isCompatibleReturnTypesENS_9TypeRangeES2_ called 0 returned 0% blocks executed 0%
    #####: 1682:bool mlir::shape::MulOp::isCompatibleReturnTypes(TypeRange l, TypeRange r) {
        -: 1683:  // SizeType is compatible with IndexType.
    #####: 1684:  return eachHasOnlyOneOfTypes<SizeType, IndexType>(l, r);
call    0 never executed
call    1 never executed
call    2 never executed
        -: 1685:}
        -: 1686:
function _ZN4mlir5shape5MulOp6verifyEv called 0 returned 0% blocks executed 0%
    #####: 1687:LogicalResult shape::MulOp::verify() { return verifySizeOrIndexOp(*this); }
call    0 never executed
call    1 never executed
call    2 never executed
        -: 1688:
        -: 1689://===----------------------------------------------------------------------===//
        -: 1690:// ShapeOfOp
        -: 1691://===----------------------------------------------------------------------===//
        -: 1692:
function _ZN4mlir5shape9ShapeOfOp4foldEN4llvm8ArrayRefINS_9AttributeEEE called 0 returned 0% blocks executed 0%
    #####: 1693:OpFoldResult ShapeOfOp::fold(ArrayRef<Attribute>) {
    #####: 1694:  auto type = getOperand().getType().dyn_cast<ShapedType>();
call    0 never executed
call    1 never executed
    #####: 1695:  if (!type || !type.hasStaticShape())
branch  0 never executed
branch  1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
    #####: 1696:    return nullptr;
    #####: 1697:  Builder builder(getContext());
call    0 never executed
call    1 never executed
    #####: 1698:  return builder.getIndexTensorAttr(type.getShape());
call    0 never executed
call    1 never executed
call    2 never executed
        -: 1699:}
        -: 1700:
        -: 1701:namespace {
        -: 1702:struct ShapeOfWithTensor : public OpRewritePattern<shape::ShapeOfOp> {
        -: 1703:  using OpRewritePattern<shape::ShapeOfOp>::OpRewritePattern;
        -: 1704:
function _ZNK12_GLOBAL__N_117ShapeOfWithTensor15matchAndRewriteEN4mlir5shape9ShapeOfOpERNS1_15PatternRewriterE called 0 returned 0% blocks executed 0%
    #####: 1705:  LogicalResult matchAndRewrite(shape::ShapeOfOp op,
        -: 1706:                                PatternRewriter &rewriter) const override {
    #####: 1707:    if (!op.getArg().getType().isa<ShapedType>())
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1708:      return failure();
    #####: 1709:    if (op.getType().isa<ShapedType>())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1710:      return failure();
        -: 1711:
    #####: 1712:    rewriter.replaceOpWithNewOp<shape::ShapeOfOp>(op.getOperation(),
    #####: 1713:                                                  op.getArg());
call    0 never executed
call    1 never executed
    #####: 1714:    return success();
        -: 1715:  }
        -: 1716:};
        -: 1717:
        -: 1718:// Canonicalize
        -: 1719:// ```
        -: 1720:// %0 = shape.shape_of %arg : tensor<?x?x?xf32> -> tensor<3xindex>
        -: 1721:// %1 = tensor.cast %0 : tensor<3xindex> to tensor<?xindex>
        -: 1722:// ```
        -: 1723:// to
        -: 1724:// ```
        -: 1725:// %1 = shape.shape_of %arg : tensor<?x?x?xf32> -> tensor<?xindex>
        -: 1726:// ```
        -: 1727:struct ShapeOfCastExtentTensor : public OpRewritePattern<tensor::CastOp> {
        -: 1728:  using OpRewritePattern<tensor::CastOp>::OpRewritePattern;
        -: 1729:
function _ZNK12_GLOBAL__N_123ShapeOfCastExtentTensor15matchAndRewriteEN4mlir6tensor6CastOpERNS1_15PatternRewriterE called 15 returned 100% blocks executed 48%
       15: 1730:  LogicalResult matchAndRewrite(tensor::CastOp op,
        -: 1731:                                PatternRewriter &rewriter) const override {
       15: 1732:    auto ty = op.getType().dyn_cast<RankedTensorType>();
call    0 returned 100%
call    1 returned 100%
       15: 1733:    if (!ty || ty.getRank() != 1)
branch  0 taken 100% (fallthrough)
branch  1 taken 0%
call    2 returned 100%
branch  3 taken 20% (fallthrough)
branch  4 taken 80%
        3: 1734:      return failure();
        -: 1735:
       12: 1736:    auto shapeOfOp = op.getSource().getDefiningOp<ShapeOfOp>();
call    0 returned 100%
call    1 returned 100%
       12: 1737:    if (!shapeOfOp)
branch  0 taken 100% (fallthrough)
branch  1 taken 0%
       12: 1738:      return failure();
        -: 1739:
        -: 1740:    // Argument type must be ranked and must not conflict.
    #####: 1741:    auto argTy = shapeOfOp.getArg().getType().dyn_cast<RankedTensorType>();
call    0 never executed
call    1 never executed
    #####: 1742:    if (!argTy || (!ty.isDynamicDim(0) && ty.getDimSize(0) != argTy.getRank()))
branch  0 never executed
branch  1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
call    5 never executed
call    6 never executed
branch  7 never executed
branch  8 never executed
    #####: 1743:      return failure();
        -: 1744:
    #####: 1745:    rewriter.replaceOpWithNewOp<ShapeOfOp>(op, ty, shapeOfOp.getArg());
call    0 never executed
call    1 never executed
    #####: 1746:    return success();
        -: 1747:  }
        -: 1748:};
        -: 1749:} // namespace
        -: 1750:
function _ZN4mlir5shape9ShapeOfOp27getCanonicalizationPatternsERNS_17RewritePatternSetEPNS_11MLIRContextE called 31 returned 100% blocks executed 100%
       31: 1751:void ShapeOfOp::getCanonicalizationPatterns(RewritePatternSet &patterns,
        -: 1752:                                            MLIRContext *context) {
       31: 1753:  patterns.add<ShapeOfCastExtentTensor, ShapeOfWithTensor,
       31: 1754:               ExtractFromShapeOfExtentTensor>(context);
call    0 returned 100%
       31: 1755:}
        -: 1756:
function _ZN4mlir5shape9ShapeOfOp16inferReturnTypesEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_10ValueRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_4TypeEEE called 0 returned 0% blocks executed 0%
    #####: 1757:LogicalResult mlir::shape::ShapeOfOp::inferReturnTypes(
        -: 1758:    MLIRContext *context, Optional<Location> location, ValueRange operands,
        -: 1759:    DictionaryAttr attributes, RegionRange regions,
        -: 1760:    SmallVectorImpl<Type> &inferredReturnTypes) {
    #####: 1761:  if (operands[0].getType().isa<ValueShapeType>())
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1762:    inferredReturnTypes.assign({ShapeType::get(context)});
call    0 never executed
call    1 never executed
        -: 1763:  else {
    #####: 1764:    auto shapedTy = operands[0].getType().cast<ShapedType>();
call    0 never executed
call    1 never executed
    #####: 1765:    int64_t rank =
    #####: 1766:        shapedTy.hasRank() ? shapedTy.getRank() : ShapedType::kDynamicSize;
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
    #####: 1767:    Type indexTy = IndexType::get(context);
call    0 never executed
    #####: 1768:    Type extentTensorTy = RankedTensorType::get({rank}, indexTy);
call    0 never executed
    #####: 1769:    inferredReturnTypes.assign({extentTensorTy});
call    0 never executed
        -: 1770:  }
    #####: 1771:  return success();
        -: 1772:}
        -: 1773:
function _ZN4mlir5shape9ShapeOfOp23isCompatibleReturnTypesENS_9TypeRangeES2_ called 0 returned 0% blocks executed 0%
    #####: 1774:bool mlir::shape::ShapeOfOp::isCompatibleReturnTypes(TypeRange l, TypeRange r) {
    #####: 1775:  if (l.size() != 1 || r.size() != 1)
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
        -: 1776:    return false;
    #####: 1777:  if (l == r)
call    0 never executed
branch  1 never executed
branch  2 never executed
        -: 1778:    return true;
        -: 1779:
    #####: 1780:  Type lhs = l.front();
call    0 never executed
    #####: 1781:  Type rhs = r.front();
call    0 never executed
        -: 1782:
    #####: 1783:  if (!lhs.isa<ShapeType, ShapedType>() || !rhs.isa<ShapeType, ShapedType>())
call    0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
    #####: 1784:    return false;
        -: 1785:
    #####: 1786:  if (lhs.isa<ShapeType>() || rhs.isa<ShapeType>())
call    0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
        -: 1787:    // Shape type is compatible with all other valid return types.
        -: 1788:    return true;
        -: 1789:
    #####: 1790:  if (succeeded(verifyCompatibleShapes({lhs, rhs})))
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1791:    return true;
        -: 1792:  return false;
        -: 1793:}
        -: 1794:
function _ZN4mlir5shape9ShapeOfOp6verifyEv called 0 returned 0% blocks executed 0%
    #####: 1795:LogicalResult shape::ShapeOfOp::verify() {
    #####: 1796:  return verifyShapeOrExtentTensorOp(*this);
call    0 never executed
call    1 never executed
call    2 never executed
        -: 1797:}
        -: 1798:
        -: 1799://===----------------------------------------------------------------------===//
        -: 1800:// SizeToIndexOp
        -: 1801://===----------------------------------------------------------------------===//
        -: 1802:
function _ZN4mlir5shape13SizeToIndexOp4foldEN4llvm8ArrayRefINS_9AttributeEEE called 0 returned 0% blocks executed 0%
    #####: 1803:OpFoldResult SizeToIndexOp::fold(ArrayRef<Attribute> operands) {
        -: 1804:  // Constant values of both types, `shape.size` and `index`, are represented as
        -: 1805:  // `IntegerAttr`s which makes constant folding simple.
    #####: 1806:  if (Attribute arg = operands[0])
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1807:    return arg;
call    0 never executed
    #####: 1808:  return OpFoldResult();
        -: 1809:}
        -: 1810:
function _ZN4mlir5shape13SizeToIndexOp27getCanonicalizationPatternsERNS_17RewritePatternSetEPNS_11MLIRContextE called 31 returned 100% blocks executed 100%
       31: 1811:void SizeToIndexOp::getCanonicalizationPatterns(RewritePatternSet &patterns,
        -: 1812:                                                MLIRContext *context) {
       31: 1813:  patterns.add<IndexToSizeToIndexCanonicalization>(context);
call    0 returned 100%
       31: 1814:}
        -: 1815:
function _ZN4mlir5shape13SizeToIndexOp17areCastCompatibleENS_9TypeRangeES2_ called 0 returned 0% blocks executed 0%
    #####: 1816:bool SizeToIndexOp::areCastCompatible(TypeRange inputs, TypeRange outputs) {
    #####: 1817:  if (inputs.size() != 1 || outputs.size() != 1)
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
        -: 1818:    return false;
    #####: 1819:  return inputs[0].isa<IndexType, SizeType>() && outputs[0].isa<IndexType>();
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
call    4 never executed
call    5 never executed
branch  6 never executed
branch  7 never executed
        -: 1820:}
        -: 1821:
        -: 1822://===----------------------------------------------------------------------===//
        -: 1823:// YieldOp
        -: 1824://===----------------------------------------------------------------------===//
        -: 1825:
function _ZN4mlir5shape7YieldOp6verifyEv called 0 returned 0% blocks executed 0%
    #####: 1826:LogicalResult shape::YieldOp::verify() {
    #####: 1827:  auto *parentOp = (*this)->getParentOp();
branch  0 never executed
branch  1 never executed
    #####: 1828:  auto results = parentOp->getResults();
branch  0 never executed
branch  1 never executed
    #####: 1829:  auto operands = getOperands();
call    0 never executed
        -: 1830:
    #####: 1831:  if (parentOp->getNumResults() != getNumOperands())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1832:    return emitOpError() << "number of operands does not match number of "
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####: 1833:                            "results of its parent";
call    0 never executed
    #####: 1834:  for (auto e : llvm::zip(results, operands))
branch  0 never executed
branch  1 never executed
    #####: 1835:    if (std::get<0>(e).getType() != std::get<1>(e).getType())
branch  0 never executed
branch  1 never executed
    #####: 1836:      return emitOpError() << "types mismatch between yield op and its parent";
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
        -: 1837:
    #####: 1838:  return success();
        -: 1839:}
        -: 1840:
        -: 1841://===----------------------------------------------------------------------===//
        -: 1842:// SplitAtOp
        -: 1843://===----------------------------------------------------------------------===//
        -: 1844:
function _ZN4mlir5shape9SplitAtOp4foldEN4llvm8ArrayRefINS_9AttributeEEERNS2_15SmallVectorImplINS_12OpFoldResultEEE called 0 returned 0% blocks executed 0%
    #####: 1845:LogicalResult SplitAtOp::fold(ArrayRef<Attribute> operands,
        -: 1846:                              SmallVectorImpl<OpFoldResult> &results) {
    #####: 1847:  if (!operands[0] || !operands[1])
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
branch  6 never executed
branch  7 never executed
    #####: 1848:    return failure();
    #####: 1849:  auto shapeVec = llvm::to_vector<6>(
    #####: 1850:      operands[0].cast<DenseIntElementsAttr>().getValues<int64_t>());
call    0 never executed
call    1 never executed
call    2 never executed
    #####: 1851:  auto shape = llvm::makeArrayRef(shapeVec);
call    0 never executed
    #####: 1852:  auto splitPoint = operands[1].cast<IntegerAttr>().getInt();
call    0 never executed
call    1 never executed
        -: 1853:  // Verify that the split point is in the correct range.
        -: 1854:  // TODO: Constant fold to an "error".
    #####: 1855:  int64_t rank = shape.size();
branch  0 never executed
branch  1 never executed
    #####: 1856:  if (-rank > splitPoint || splitPoint > rank)
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1857:    return failure();
    #####: 1858:  if (splitPoint < 0)
branch  0 never executed
branch  1 never executed
    #####: 1859:    splitPoint += shape.size();
    #####: 1860:  Builder builder(operands[0].getContext());
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1861:  results.push_back(builder.getIndexTensorAttr(shape.take_front(splitPoint)));
branch  0 never executed
branch  1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
    #####: 1862:  results.push_back(builder.getIndexTensorAttr(shape.drop_front(splitPoint)));
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####: 1863:  return success();
branch  0 never executed
branch  1 never executed
        -: 1864:}
        -: 1865:
        -: 1866://===----------------------------------------------------------------------===//
        -: 1867:// ToExtentTensorOp
        -: 1868://===----------------------------------------------------------------------===//
        -: 1869:
function _ZN4mlir5shape16ToExtentTensorOp4foldEN4llvm8ArrayRefINS_9AttributeEEE called 0 returned 0% blocks executed 0%
    #####: 1870:OpFoldResult ToExtentTensorOp::fold(ArrayRef<Attribute> operands) {
    #####: 1871:  if (!operands[0])
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1872:    return OpFoldResult();
    #####: 1873:  Builder builder(getContext());
call    0 never executed
call    1 never executed
    #####: 1874:  auto shape = llvm::to_vector<6>(
    #####: 1875:      operands[0].cast<DenseIntElementsAttr>().getValues<int64_t>());
call    0 never executed
call    1 never executed
call    2 never executed
    #####: 1876:  auto type = RankedTensorType::get({static_cast<int64_t>(shape.size())},
call    0 never executed
    #####: 1877:                                    builder.getIndexType());
call    0 never executed
call    1 never executed
    #####: 1878:  return DenseIntElementsAttr::get(type, shape);
call    0 never executed
call    1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
        -: 1879:}
        -: 1880:
function _ZN4mlir5shape16ToExtentTensorOp17areCastCompatibleENS_9TypeRangeES2_ called 0 returned 0% blocks executed 0%
    #####: 1881:bool ToExtentTensorOp::areCastCompatible(TypeRange inputs, TypeRange outputs) {
    #####: 1882:  if (inputs.size() != 1 || outputs.size() != 1)
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
        -: 1883:    return false;
    #####: 1884:  if (auto inputTensor = inputs[0].dyn_cast<RankedTensorType>()) {
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1885:    if (!inputTensor.getElementType().isa<IndexType>() ||
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
    #####: 1886:        inputTensor.getRank() != 1)
call    0 never executed
    #####: 1887:      return false;
    #####: 1888:  } else if (!inputs[0].isa<ShapeType>()) {
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
        -: 1889:    return false;
        -: 1890:  }
        -: 1891:
    #####: 1892:  TensorType outputTensor = outputs[0].dyn_cast<TensorType>();
call    0 never executed
call    1 never executed
    #####: 1893:  return outputTensor && outputTensor.getElementType().isa<IndexType>();
branch  0 never executed
branch  1 never executed
call    2 never executed
call    3 never executed
branch  4 never executed
branch  5 never executed
        -: 1894:}
        -: 1895:
        -: 1896://===----------------------------------------------------------------------===//
        -: 1897:// ReduceOp
        -: 1898://===----------------------------------------------------------------------===//
        -: 1899:
function _ZN4mlir5shape8ReduceOp5buildERNS_9OpBuilderERNS_14OperationStateENS_5ValueENS_10ValueRangeE called 0 returned 0% blocks executed 0%
    #####: 1900:void ReduceOp::build(OpBuilder &builder, OperationState &result, Value shape,
        -: 1901:                     ValueRange initVals) {
    #####: 1902:  result.addOperands(shape);
call    0 never executed
call    1 never executed
    #####: 1903:  result.addOperands(initVals);
call    0 never executed
        -: 1904:
    #####: 1905:  Region *bodyRegion = result.addRegion();
call    0 never executed
    #####: 1906:  bodyRegion->push_back(new Block);
call    0 never executed
call    1 never executed
call    2 never executed
    #####: 1907:  Block &bodyBlock = bodyRegion->front();
call    0 never executed
    #####: 1908:  bodyBlock.addArgument(builder.getIndexType(), result.location);
call    0 never executed
call    1 never executed
        -: 1909:
    #####: 1910:  Type elementType;
    #####: 1911:  if (auto tensorType = shape.getType().dyn_cast<TensorType>())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1912:    elementType = tensorType.getElementType();
call    0 never executed
        -: 1913:  else
    #####: 1914:    elementType = SizeType::get(builder.getContext());
call    0 never executed
    #####: 1915:  bodyBlock.addArgument(elementType, shape.getLoc());
call    0 never executed
call    1 never executed
        -: 1916:
    #####: 1917:  for (Value initVal : initVals) {
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####: 1918:    bodyBlock.addArgument(initVal.getType(), initVal.getLoc());
call    0 never executed
call    1 never executed
    #####: 1919:    result.addTypes(initVal.getType());
call    0 never executed
        -: 1920:  }
    #####: 1921:}
        -: 1922:
function _ZN4mlir5shape8ReduceOp6verifyEv called 0 returned 0% blocks executed 0%
    #####: 1923:LogicalResult ReduceOp::verify() {
        -: 1924:  // Verify block arg types.
    #####: 1925:  Block &block = getRegion().front();
call    0 never executed
call    1 never executed
        -: 1926:
        -: 1927:  // The block takes index, extent, and aggregated values as arguments.
    #####: 1928:  auto blockArgsCount = getInitVals().size() + 2;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1929:  if (block.getNumArguments() != blockArgsCount)
branch  0 never executed
branch  1 never executed
    #####: 1930:    return emitOpError() << "ReduceOp body is expected to have "
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
    #####: 1931:                         << blockArgsCount << " arguments";
call    0 never executed
call    1 never executed
        -: 1932:
        -: 1933:  // The first block argument is the index and must always be of type `index`.
    #####: 1934:  if (!block.getArgument(0).getType().isa<IndexType>())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1935:    return emitOpError(
call    0 never executed
call    1 never executed
call    2 never executed
    #####: 1936:        "argument 0 of ReduceOp body is expected to be of IndexType");
call    0 never executed
        -: 1937:
        -: 1938:  // The second block argument is the extent and must be of type `size` or
        -: 1939:  // `index`, depending on whether the reduce operation is applied to a shape or
        -: 1940:  // to an extent tensor.
    #####: 1941:  Type extentTy = block.getArgument(1).getType();
call    0 never executed
    #####: 1942:  if (getShape().getType().isa<ShapeType>()) {
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1943:    if (!extentTy.isa<SizeType>())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1944:      return emitOpError("argument 1 of ReduceOp body is expected to be of "
call    0 never executed
call    1 never executed
call    2 never executed
    #####: 1945:                         "SizeType if the ReduceOp operates on a ShapeType");
call    0 never executed
        -: 1946:  } else {
    #####: 1947:    if (!extentTy.isa<IndexType>())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1948:      return emitOpError(
call    0 never executed
call    1 never executed
call    2 never executed
        -: 1949:          "argument 1 of ReduceOp body is expected to be of IndexType if the "
    #####: 1950:          "ReduceOp operates on an extent tensor");
call    0 never executed
        -: 1951:  }
        -: 1952:
    #####: 1953:  for (const auto &type : llvm::enumerate(getInitVals()))
call    0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
call    5 never executed
    #####: 1954:    if (block.getArgument(type.index() + 2).getType() != type.value().getType())
branch  0 never executed
branch  1 never executed
    #####: 1955:      return emitOpError() << "type mismatch between argument "
call    0 never executed
call    1 never executed
call    2 never executed
    #####: 1956:                           << type.index() + 2
call    0 never executed
call    1 never executed
    #####: 1957:                           << " of ReduceOp body and initial value "
    #####: 1958:                           << type.index();
call    0 never executed
call    1 never executed
call    2 never executed
    #####: 1959:  return success();
        -: 1960:}
        -: 1961:
function _ZN4mlir5shape8ReduceOp5parseERNS_11OpAsmParserERNS_14OperationStateE called 0 returned 0% blocks executed 0%
    #####: 1962:ParseResult ReduceOp::parse(OpAsmParser &parser, OperationState &result) {
        -: 1963:  // Parse operands.
    #####: 1964:  SmallVector<OpAsmParser::UnresolvedOperand, 3> operands;
call    0 never executed
    #####: 1965:  Type shapeOrExtentTensorType;
    #####: 1966:  if (parser.parseOperandList(operands, /*requiredOperandCount=*/-1,
call    0 never executed
    #####: 1967:                              OpAsmParser::Delimiter::Paren) ||
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1968:      parser.parseColonType(shapeOrExtentTensorType) ||
branch  0 never executed
branch  1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
branch  6 never executed
    #####: 1969:      parser.parseOptionalArrowTypeList(result.types))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1970:    return failure();
        -: 1971:
        -: 1972:  // Resolve operands.
    #####: 1973:  auto initVals = llvm::makeArrayRef(operands).drop_front();
call    0 never executed
    #####: 1974:  if (parser.resolveOperand(operands.front(), shapeOrExtentTensorType,
    #####: 1975:                            result.operands) ||
branch  0 never executed
branch  1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
branch  6 never executed
    #####: 1976:      parser.resolveOperands(initVals, result.types, parser.getNameLoc(),
    #####: 1977:                             result.operands))
branch  0 never executed
branch  1 never executed
call    2 never executed
call    3 never executed
branch  4 never executed
branch  5 never executed
    #####: 1978:    return failure();
        -: 1979:
        -: 1980:  // Parse the body.
    #####: 1981:  Region *body = result.addRegion();
call    0 never executed
    #####: 1982:  if (parser.parseRegion(*body, /*args=*/{}, /*argTypes=*/{}))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1983:    return failure();
        -: 1984:
        -: 1985:  // Parse attributes.
    #####: 1986:  if (parser.parseOptionalAttrDict(result.attributes))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1987:    return failure();
        -: 1988:
    #####: 1989:  return success();
        -: 1990:}
        -: 1991:
function _ZN4mlir5shape8ReduceOp5printERNS_12OpAsmPrinterE called 0 returned 0% blocks executed 0%
    #####: 1992:void ReduceOp::print(OpAsmPrinter &p) {
    #####: 1993:  p << '(' << getShape() << ", " << getInitVals()
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
call    5 never executed
    #####: 1994:    << ") : " << getShape().getType();
call    0 never executed
call    1 never executed
call    2 never executed
    #####: 1995:  p.printOptionalArrowTypeList(getResultTypes());
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1996:  p << ' ';
call    0 never executed
    #####: 1997:  p.printRegion(getRegion());
call    0 never executed
call    1 never executed
    #####: 1998:  p.printOptionalAttrDict((*this)->getAttrs());
call    0 never executed
call    1 never executed
    #####: 1999:}
        -: 2000:
        -: 2001:#define GET_OP_CLASSES
        -: 2002:#include "mlir/Dialect/Shape/IR/ShapeOps.cpp.inc"
        -: 2003:
        -: 2004:#define GET_TYPEDEF_CLASSES
        -: 2005:#include "mlir/Dialect/Shape/IR/ShapeOpsTypes.cpp.inc"
