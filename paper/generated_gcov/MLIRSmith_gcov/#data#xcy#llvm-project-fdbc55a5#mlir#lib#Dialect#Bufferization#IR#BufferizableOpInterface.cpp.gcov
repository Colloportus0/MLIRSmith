        -:    0:Source:/data/xcy/llvm-project-fdbc55a5/mlir/lib/Dialect/Bufferization/IR/BufferizableOpInterface.cpp
        -:    0:Graph:../tools/mlir/lib/Dialect/Bufferization/IR/CMakeFiles/obj.MLIRBufferizationDialect.dir/BufferizableOpInterface.cpp.gcno
        -:    0:Data:../tools/mlir/lib/Dialect/Bufferization/IR/CMakeFiles/obj.MLIRBufferizationDialect.dir/BufferizableOpInterface.cpp.gcda
        -:    0:Runs:116157
        -:    1://===- BufferizableOpInterface.cpp - Bufferizable Ops  ---=----------------===//
        -:    2://
        -:    3:// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
        -:    4:// See https://llvm.org/LICENSE.txt for license information.
        -:    5:// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
        -:    6://
        -:    7://===----------------------------------------------------------------------===//
        -:    8:
        -:    9:#include "mlir/Dialect/Bufferization/IR/BufferizableOpInterface.h"
        -:   10:#include "mlir/Dialect/Bufferization/IR/Bufferization.h"
        -:   11:#include "mlir/Dialect/Func/IR/FuncOps.h"
        -:   12:#include "mlir/Dialect/MemRef/IR/MemRef.h"
        -:   13:#include "mlir/Dialect/Tensor/IR/Tensor.h"
        -:   14:#include "mlir/IR/AsmState.h"
        -:   15:#include "mlir/IR/BlockAndValueMapping.h"
        -:   16:#include "mlir/IR/BuiltinOps.h"
        -:   17:#include "mlir/IR/Operation.h"
        -:   18:#include "mlir/IR/TypeUtilities.h"
        -:   19:#include "mlir/IR/Value.h"
        -:   20:#include "mlir/Interfaces/ControlFlowInterfaces.h"
        -:   21:#include "llvm/Support/Debug.h"
        -:   22:
        -:   23://===----------------------------------------------------------------------===//
        -:   24:// BufferizableOpInterface
        -:   25://===----------------------------------------------------------------------===//
        -:   26:
        -:   27:namespace mlir {
        -:   28:namespace bufferization {
        -:   29:
        -:   30:#include "mlir/Dialect/Bufferization/IR/BufferizableOpInterface.cpp.inc"
        -:   31:
        -:   32:} // namespace bufferization
        -:   33:} // namespace mlir
        -:   34:
        -:   35:#define DEBUG_TYPE "bufferizable-op-interface"
        -:   36:#define DBGS() (llvm::dbgs() << '[' << DEBUG_TYPE << "] ")
        -:   37:#define LDBG(X) LLVM_DEBUG(DBGS() << (X))
        -:   38:
        -:   39:using namespace mlir;
        -:   40:using namespace bufferization;
        -:   41:
function _ZN4mlir13bufferization15getOwnerOfValueENS_5ValueE called 110237 returned 100% blocks executed 100%
   110237:   42:Operation *bufferization::getOwnerOfValue(Value value) {
   110237:   43:  if (auto opResult = value.dyn_cast<OpResult>())
call    0 returned 100%
branch  1 taken 100% (fallthrough)
branch  2 taken 1%
   110217:   44:    return opResult.getDefiningOp();
call    0 returned 100%
       20:   45:  return value.cast<BlockArgument>().getOwner()->getParentOp();
call    0 returned 100%
call    1 returned 100%
        -:   46:}
        -:   47:
function _ZN4mlir13bufferization23allocationDoesNotEscapeENS_8OpResultE called 0 returned 0% blocks executed 0%
    #####:   48:bool bufferization::allocationDoesNotEscape(OpResult opResult) {
        -:   49:#ifndef NDEBUG
    #####:   50:  auto bufferizableOp = opResult.getDefiningOp<BufferizableOpInterface>();
call    0 never executed
    #####:   51:  assert(bufferizableOp && bufferizableOp.bufferizesToAllocation(opResult) &&
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
call    4 never executed
        -:   52:         "expected op that bufferizes to an allocation");
        -:   53:#endif // NDEBUG
        -:   54:
    #####:   55:  Operation *op = opResult.getDefiningOp();
call    0 never executed
        -:   56:  // If there is no 'escape' attribute, we cannot say for sure.
    #####:   57:  if (!op->hasAttr(BufferizationDialect::kEscapeAttrName))
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:   58:    return false;
    #####:   59:  auto attr =
    #####:   60:      op->getAttrOfType<ArrayAttr>(BufferizationDialect::kEscapeAttrName);
call    0 never executed
    #####:   61:  return !attr[opResult.getResultNumber()].cast<BoolAttr>().getValue();
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
        -:   62:}
        -:   63:
        -:   64:/// Create an AllocTensorOp for the given shaped value. If `copy` is set, the
        -:   65:/// shaped value is copied. Otherwise, a tensor with undefined contents is
        -:   66:/// allocated.
function _ZN4mlir13bufferization28allocateTensorForShapedValueERNS_9OpBuilderENS_8LocationENS_5ValueEbRKNS0_20BufferizationOptionsEb called 26779 returned 100% blocks executed 83%
    26779:   67:FailureOr<Value> bufferization::allocateTensorForShapedValue(
        -:   68:    OpBuilder &b, Location loc, Value shapedValue, bool escape,
        -:   69:    const BufferizationOptions &options, bool copy) {
    26779:   70:  Value tensor;
    26779:   71:  if (shapedValue.getType().isa<RankedTensorType>()) {
call    0 returned 100%
branch  1 taken 0% (fallthrough)
branch  2 taken 100%
        -:   72:    tensor = shapedValue;
    #####:   73:  } else if (shapedValue.getType().isa<MemRefType>()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:   74:    tensor = b.create<ToTensorOp>(loc, shapedValue);
call    0 never executed
        -:   75:  } else {
    #####:   76:    llvm_unreachable("expected RankedTensorType or MemRefType");
call    0 never executed
        -:   77:  }
    26779:   78:  RankedTensorType tensorType = tensor.getType().cast<RankedTensorType>();
call    0 returned 100%
    26779:   79:  SmallVector<Value> dynamicSizes;
branch  0 taken 45% (fallthrough)
branch  1 taken 55%
    26779:   80:  if (!copy) {
branch  0 taken 45% (fallthrough)
branch  1 taken 55%
        -:   81:    // Compute the dynamic part of the shape.
        -:   82:    // First try to query the shape via ReifyRankedShapedTypeOpInterface.
    12011:   83:    bool reifiedShapes = false;
   12011*:   84:    if (shapedValue.getType().isa<RankedTensorType>() &&
call    0 returned 100%
branch  1 taken 100% (fallthrough)
branch  2 taken 0%
    12011:   85:        shapedValue.isa<OpResult>()) {
branch  0 taken 100% (fallthrough)
branch  1 taken 0%
    12011:   86:      if (auto rankedOp = dyn_cast_or_null<ReifyRankedShapedTypeOpInterface>(
branch  0 taken 45% (fallthrough)
branch  1 taken 55%
    24022:   87:              shapedValue.getDefiningOp())) {
call    0 returned 100%
branch  1 taken 100%
branch  2 taken 0%
branch  3 taken 45% (fallthrough)
branch  4 taken 55%
    13218:   88:        ReifiedRankedShapedTypeDims resultDims;
call    0 returned 100%
call    1 returned 100%
     6609:   89:        if (succeeded(rankedOp.reifyResultShapes(b, resultDims))) {
call    0 returned 100%
branch  1 taken 100% (fallthrough)
branch  2 taken 0%
     6609:   90:          reifiedShapes = true;
     6609:   91:          auto &shape =
call    0 returned 100%
     6609:   92:              resultDims[shapedValue.cast<OpResult>().getResultNumber()];
call    0 returned 100%
branch  1 taken 0% (fallthrough)
branch  2 taken 100%
    19539:   93:          for (const auto &dim : enumerate(tensorType.getShape()))
call    0 returned 100%
branch  1 taken 66% (fallthrough)
branch  2 taken 34%
call    3 returned 100%
    12930:   94:            if (ShapedType::isDynamic(dim.value()))
branch  0 taken 25% (fallthrough)
branch  1 taken 75%
     3287:   95:              dynamicSizes.push_back(shape[dim.index()]);
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
call    2 returned 100%
        -:   96:        }
        -:   97:      }
        -:   98:    }
        -:   99:
        -:  100:    // If the shape could not be reified, create DimOps.
   12011*:  101:    if (!reifiedShapes)
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
     5402:  102:      populateDynamicDimSizes(b, loc, tensor, dynamicSizes);
call    0 returned 100%
        -:  103:  }
        -:  104:
        -:  105:  // Create AllocTensorOp.
    26779:  106:  auto allocTensorOp = b.create<AllocTensorOp>(loc, tensorType, dynamicSizes,
    38790:  107:                                               copy ? tensor : Value());
branch  0 taken 55% (fallthrough)
branch  1 taken 45%
call    2 returned 100%
    26779:  108:  allocTensorOp->setAttr(BufferizationDialect::kEscapeAttrName,
call    0 returned 100%
call    1 returned 100%
    26779:  109:                         b.getBoolArrayAttr({escape}));
call    0 returned 100%
        -:  110:
        -:  111:  // Add 'memory_space' attribute. Not needed if 'copy' operand is specified.
    26779:  112:  if (copy)
branch  0 taken 55% (fallthrough)
branch  1 taken 45%
    14768:  113:    return allocTensorOp.getResult();
call    0 returned 100%
    12011:  114:  FailureOr<BaseMemRefType> copyBufferType = getBufferType(tensor, options);
call    0 returned 100%
    12011:  115:  if (failed(copyBufferType))
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
    #####:  116:    return failure();
    24022:  117:  allocTensorOp.setMemorySpaceAttr(
call    0 returned 100%
call    1 returned 100%
call    2 returned 100%
    12011:  118:      b.getIntegerAttr(b.getIntegerType(64, /*isSigned=*/false),
call    0 returned 100%
    12011:  119:                       copyBufferType->getMemorySpaceAsInt()));
call    0 returned 100%
    12011:  120:  return allocTensorOp.getResult();
call    0 returned 100%
        -:  121:}
        -:  122:
function _ZN4mlir13bufferization23BufferizableOpInterface31resolveTensorOpOperandConflictsERNS_12RewriterBaseERKNS0_13AnalysisStateE called 204797 returned 100% blocks executed 81%
   204797:  123:LogicalResult BufferizableOpInterface::resolveTensorOpOperandConflicts(
        -:  124:    RewriterBase &rewriter, const AnalysisState &state) {
   204797:  125:  OpBuilder::InsertionGuard g(rewriter);
call    0 returned 100%
   204797:  126:  Operation *op = getOperation();
call    0 returned 100%
   409593:  127:  SmallVector<OpOperand *> outOfPlaceOpOperands;
call    0 returned 100%
branch  1 taken 100% (fallthrough)
branch  2 taken 0%
   409593:  128:  DenseSet<OpOperand *> copiedOpOperands;
call    0 returned 100%
branch  1 taken 0% (fallthrough)
branch  2 taken 100%
   409593:  129:  DenseSet<OpOperand *> escapingOpOperandCopies;
call    0 returned 100%
call    1 returned 100%
   409593:  130:  SmallVector<OpResult> outOfPlaceOpResults;
call    0 returned 100%
call    1 returned 100%
   409593:  131:  DenseSet<OpResult> copiedOpResults;
call    0 returned 100%
branch  1 taken 0% (fallthrough)
branch  2 taken 100%
   409593:  132:  DenseSet<OpResult> escapingOpResultCopies;
call    0 returned 100%
call    1 returned 100%
        -:  133:
        -:  134:  // Find all out-of-place OpOperands.
  1336433:  135:  for (OpOperand &opOperand : op->getOpOperands()) {
call    0 returned 100%
branch  1 taken 85% (fallthrough)
branch  2 taken 15%
  1131637:  136:    Type operandType = opOperand.get().getType();
call    0 returned 100%
  1131637:  137:    if (!operandType.isa<TensorType>())
call    0 returned 100%
branch  1 taken 89% (fallthrough)
branch  2 taken 11%
  1112454:  138:      continue;
   123514:  139:    if (state.isInPlace(opOperand))
call    0 returned 100%
branch  1 taken 84% (fallthrough)
branch  2 taken 16%
   104331:  140:      continue;
    19182:  141:    if (operandType.isa<UnrankedTensorType>())
call    0 returned 100%
branch  1 taken 0% (fallthrough)
branch  2 taken 100%
    #####:  142:      return op->emitError("copies of unranked tensors are not supported");
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
        -:  143:
    19182:  144:    SmallVector<OpResult> aliasingOpResults =
    38364:  145:        state.getAliasingOpResult(opOperand);
call    0 returned 100%
        -:  146:    // Is the result yielded from a block? Or are deallocations turned off
        -:  147:    // entirely? In either case, mark the allocation as "escaping", so that it
        -:  148:    // will not be deallocated.
    19182:  149:    bool escape = !state.getOptions().createDeallocs ||
branch  0 taken 3% (fallthrough)
branch  1 taken 97%
      481:  150:                  llvm::any_of(aliasingOpResults, [&](Value v) {
call    0 returned 100%
branch  1 taken 0% (fallthrough)
branch  2 taken 100%
        -:  151:                    return state.isTensorYielded(v);
    19182:  152:                  });
        -:  153:
    38364:  154:    if (aliasingOpResults.size() == 1 &&
branch  0 taken 100% (fallthrough)
branch  1 taken 0%
branch  2 taken 1% (fallthrough)
branch  3 taken 100%
    19197:  155:        !state.bufferizesToMemoryWrite(opOperand) &&
branch  0 taken 100% (fallthrough)
branch  1 taken 0%
call    2 returned 100%
branch  3 taken 0% (fallthrough)
branch  4 taken 100%
    19197:  156:        state.getAliasingOpOperand(aliasingOpResults.front()).size() == 1) {
call    0 returned 100%
branch  1 taken 0% (fallthrough)
branch  2 taken 100%
branch  3 taken 0% (fallthrough)
branch  4 taken 100%
branch  5 taken 1% (fallthrough)
branch  6 taken 100%
        -:  157:      // The op itself does not write but may create exactly one alias. Instead
        -:  158:      // of copying the OpOperand, copy the OpResult. The OpResult can sometimes
        -:  159:      // be smaller than the OpOperand (e.g., in the case of an extract_slice,
        -:  160:      // where the result is usually a smaller part of the source).
       15:  161:      outOfPlaceOpResults.push_back(aliasingOpResults.front());
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
call    2 returned 100%
       15:  162:      if (!state.canOmitTensorCopy(opOperand))
call    0 returned 100%
branch  1 taken 87% (fallthrough)
branch  2 taken 13%
       13:  163:        copiedOpResults.insert(aliasingOpResults.front());
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
call    2 returned 100%
       15:  164:      if (escape)
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
    #####:  165:        escapingOpResultCopies.insert(aliasingOpResults.front());
branch  0 never executed
branch  1 never executed
call    2 never executed
        -:  166:    } else {
        -:  167:      // In all other cases, make a copy of the OpOperand.
    19167:  168:      outOfPlaceOpOperands.push_back(&opOperand);
call    0 returned 100%
    19167:  169:      if (!state.canOmitTensorCopy(opOperand))
call    0 returned 100%
branch  1 taken 77% (fallthrough)
branch  2 taken 23%
    14751:  170:        copiedOpOperands.insert(&opOperand);
call    0 returned 100%
    19167:  171:      if (escape)
branch  0 taken 98% (fallthrough)
branch  1 taken 2%
    18701:  172:        escapingOpOperandCopies.insert(&opOperand);
call    0 returned 100%
        -:  173:    }
        -:  174:  }
        -:  175:
        -:  176:  // Insert copies of OpOperands.
   204796:  177:  rewriter.setInsertionPoint(op);
call    0 returned 100%
   223963:  178:  for (OpOperand *opOperand : outOfPlaceOpOperands) {
branch  0 taken 9% (fallthrough)
branch  1 taken 91%
    19167:  179:    FailureOr<Value> copy = allocateTensorForShapedValue(
        -:  180:        rewriter, op->getLoc(), opOperand->get(),
    19167:  181:        escapingOpOperandCopies.contains(opOperand), state.getOptions(),
call    0 returned 100%
    19167:  182:        copiedOpOperands.contains(opOperand));
call    0 returned 100%
call    1 returned 100%
call    2 returned 100%
    19167:  183:    if (failed(copy))
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
    #####:  184:      return failure();
function _ZZN4mlir13bufferization23BufferizableOpInterface31resolveTensorOpOperandConflictsERNS_12RewriterBaseERKNS0_13AnalysisStateEENKUlvE0_clEv.isra.0 called 19167 returned 100% blocks executed 78%
    38334:  185:    rewriter.updateRootInPlace(op, [&]() { opOperand->set(*copy); });
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
branch  2 taken 100% (fallthrough)
branch  3 taken 0%
call    4 returned 100%
        -:  186:  }
        -:  187:
        -:  188:  // Insert copies of OpResults.
   204796:  189:  rewriter.setInsertionPointAfter(op);
call    0 returned 100%
   204811:  190:  for (OpResult opResult : outOfPlaceOpResults) {
branch  0 taken 1% (fallthrough)
branch  1 taken 100%
       15:  191:    FailureOr<Value> copy = allocateTensorForShapedValue(
call    0 returned 100%
        -:  192:        rewriter, op->getLoc(), opResult,
       15:  193:        escapingOpResultCopies.contains(opResult), state.getOptions(),
call    0 returned 100%
       15:  194:        copiedOpResults.count(opResult));
call    0 returned 100%
call    1 returned 100%
       15:  195:    if (failed(copy))
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
    #####:  196:      return failure();
       15:  197:    SmallVector<OpOperand *> uses = llvm::to_vector(llvm::map_range(
call    0 returned 100%
       83:  198:        opResult.getUses(), [](OpOperand &use) { return &use; }));
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
call    2 returned 100%
       68:  199:    for (OpOperand *use : uses) {
branch  0 taken 78% (fallthrough)
branch  1 taken 22%
        -:  200:      // Do not update the alloc_tensor op that we just created.
       53:  201:      if (use->getOwner() != copy->getDefiningOp())
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
call    2 returned 100%
branch  3 taken 75% (fallthrough)
branch  4 taken 25%
function _ZZN4mlir13bufferization23BufferizableOpInterface31resolveTensorOpOperandConflictsERNS_12RewriterBaseERKNS0_13AnalysisStateEENKUlvE2_clEv.isra.0 called 40 returned 100% blocks executed 89%
       80:  202:        rewriter.updateRootInPlace(use->getOwner(), [&]() { use->set(*copy); });
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
branch  2 taken 100% (fallthrough)
branch  3 taken 0%
call    4 returned 100%
        -:  203:    }
        -:  204:  }
        -:  205:
   204796:  206:  return success();
call    0 returned 100%
        -:  207:}
        -:  208:
function _ZN4mlir13bufferization24shouldDeallocateOpResultENS_8OpResultERKNS0_20BufferizationOptionsE called 23173 returned 100% blocks executed 79%
    23173:  209:bool bufferization::shouldDeallocateOpResult(
        -:  210:    OpResult opResult, const BufferizationOptions &options) {
    23173:  211:  Operation *op = opResult.getOwner();
call    0 returned 100%
   23173*:  212:  assert(options.dynCastBufferizableOp(op).bufferizesToAllocation(opResult) &&
call    0 returned 100%
call    1 returned 100%
branch  2 taken 0% (fallthrough)
branch  3 taken 100%
call    4 never executed
        -:  213:         "expected that op allocates");
        -:  214:
    23173:  215:  AnalysisState analysisState(options);
call    0 returned 100%
    23173:  216:  if (op->hasAttr(BufferizationDialect::kEscapeAttrName)) {
call    0 returned 100%
branch  1 taken 100% (fallthrough)
branch  2 taken 0%
        -:  217:    // AllocTensorOp has one result.
    23173:  218:    ArrayAttr escapeAttr =
call    0 returned 100%
    23173:  219:        op->getAttr(BufferizationDialect::kEscapeAttrName).cast<ArrayAttr>();
call    0 returned 100%
    23173:  220:    return !escapeAttr[0].cast<BoolAttr>().getValue();
call    0 returned 100%
call    1 returned 100%
call    2 returned 100%
        -:  221:  }
        -:  222:
        -:  223:  // No "escape" annotation found.
    #####:  224:  if (options.createDeallocs) {
branch  0 never executed
branch  1 never executed
        -:  225:    // Perform an ad-hoc analysis.
    #####:  226:    return !analysisState.isTensorYielded(opResult);
call    0 never executed
        -:  227:  }
        -:  228:
        -:  229:  return false;
        -:  230:}
        -:  231:
        -:  232://===----------------------------------------------------------------------===//
        -:  233:// OpFilter
        -:  234://===----------------------------------------------------------------------===//
        -:  235:
function _ZNK4mlir13bufferization8OpFilter11isOpAllowedEPNS_9OperationE called 2343755 returned 100% blocks executed 79%
  2343755:  236:bool OpFilter::isOpAllowed(Operation *op) const {
        -:  237:  // All other ops: Allow/disallow according to filter.
  2343755:  238:  bool isAllowed = !hasAllowRule();
  5897453:  239:  for (const Entry &entry : entries) {
branch  0 taken 60% (fallthrough)
branch  1 taken 40%
  3553707:  240:    bool filterResult = entry.fn(op);
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
  3553698:  241:    switch (entry.type) {
branch  0 taken 100%
branch  1 taken 0%
branch  2 taken 0%
  3553698:  242:    case Entry::ALLOW:
  3553698:  243:      isAllowed |= filterResult;
  3553698:  244:      break;
    #####:  245:    case Entry::DENY:
    #####:  246:      if (filterResult)
branch  0 never executed
branch  1 never executed
        -:  247:        // DENY filter matches. This op is no allowed. (Even if other ALLOW
        -:  248:        // filters may match.)
        -:  249:        return false;
  3553698:  250:    };
        -:  251:  }
        -:  252:  return isAllowed;
        -:  253:}
        -:  254:
        -:  255://===----------------------------------------------------------------------===//
        -:  256:// BufferizationOptions
        -:  257://===----------------------------------------------------------------------===//
        -:  258:
        -:  259:/// Default unknown type converter: Use a fully dynamic layout map.
        -:  260:static BaseMemRefType
function _ZL27defaultUnknownTypeConverterN4mlir5ValueEjRKNS_13bufferization20BufferizationOptionsE called 0 returned 0% blocks executed 0%
    #####:  261:defaultUnknownTypeConverter(Value value, unsigned memorySpace,
        -:  262:                            const BufferizationOptions &options) {
    #####:  263:  return getMemRefTypeWithFullyDynamicLayout(value.getType().cast<TensorType>(),
call    0 never executed
    #####:  264:                                             memorySpace);
call    0 never executed
        -:  265:}
        -:  266:
        -:  267:// Default constructor for BufferizationOptions.
function _ZN4mlir13bufferization20BufferizationOptionsC2Ev called 4018 returned 100% blocks executed 100%
     4018:  268:BufferizationOptions::BufferizationOptions()
     4018:  269:    : unknownTypeConverterFn(defaultUnknownTypeConverter) {}
        -:  270:
function _ZNK4mlir13bufferization20BufferizationOptions11isOpAllowedEPNS_9OperationE called 2436243 returned 100% blocks executed 88%
  2436243:  271:bool BufferizationOptions::isOpAllowed(Operation *op) const {
        -:  272:  // Special case: If function boundary bufferization is deactivated, do not
        -:  273:  // allow ops that belong to the `func` dialect.
  2436243:  274:  bool isFuncBoundaryOp = isa_and_nonnull<func::FuncDialect>(op->getDialect());
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
branch  2 taken 100% (fallthrough)
branch  3 taken 0%
  2436243:  275:  if (!bufferizeFunctionBoundaries && isFuncBoundaryOp)
branch  0 taken 89% (fallthrough)
branch  1 taken 11%
branch  2 taken 96% (fallthrough)
branch  3 taken 4%
        -:  276:    return false;
        -:  277:
  2342394:  278:  return opFilter.isOpAllowed(op);
call    0 returned 100%
        -:  279:}
        -:  280:
        -:  281:BufferizableOpInterface
function _ZNK4mlir13bufferization20BufferizationOptions21dynCastBufferizableOpEPNS_9OperationE called 7430044 returned 100% blocks executed 100%
  7430044:  282:BufferizationOptions::dynCastBufferizableOp(Operation *op) const {
  7430044:  283:  auto bufferizableOp = dyn_cast<BufferizableOpInterface>(op);
call    0 returned 100%
  7430375:  284:  if (!bufferizableOp)
branch  0 taken 75% (fallthrough)
branch  1 taken 25%
  5593283:  285:    return nullptr;
  1837092:  286:  if (!isOpAllowed(op))
call    0 returned 100%
branch  1 taken 54% (fallthrough)
branch  2 taken 46%
   996495:  287:    return nullptr;
   840622:  288:  return bufferizableOp;
        -:  289:}
        -:  290:
        -:  291:BufferizableOpInterface
function _ZNK4mlir13bufferization20BufferizationOptions21dynCastBufferizableOpENS_5ValueE called 94088 returned 100% blocks executed 100%
    94088:  292:BufferizationOptions::dynCastBufferizableOp(Value value) const {
    94088:  293:  if (auto bufferizableOp = value.getDefiningOp<BufferizableOpInterface>())
call    0 returned 100%
branch  1 taken 12% (fallthrough)
branch  2 taken 88%
    11100:  294:    if (isOpAllowed(bufferizableOp.getOperation()))
call    0 returned 100%
branch  1 taken 100% (fallthrough)
branch  2 taken 0%
    11100:  295:      return bufferizableOp;
    82988:  296:  return nullptr;
        -:  297:}
        -:  298:
function _ZN4mlir13bufferization20BufferizationOptions26addDialectStateInitializerEN4llvm9StringRefERKSt8functionIFSt10unique_ptrINS0_20DialectAnalysisStateESt14default_deleteIS6_EEvEE called 0 returned 0% blocks executed 0%
    #####:  299:void BufferizationOptions::addDialectStateInitializer(
        -:  300:    StringRef name, const DialectStateInitFn &fn) {
    #####:  301:  stateInitializers.push_back(
branch  0 never executed
branch  1 never executed
call    2 never executed
call    3 never executed
branch  4 never executed
branch  5 never executed
function _ZZN4mlir13bufferization20BufferizationOptions26addDialectStateInitializerEN4llvm9StringRefERKSt8functionIFSt10unique_ptrINS0_20DialectAnalysisStateESt14default_deleteIS6_EEvEEENKUlRNS0_13AnalysisStateEE_clESF_ called 0 returned 0% blocks executed 0%
    #####:  302:      [=](AnalysisState &state) { state.insertDialectState(name, fn()); });
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
call    4 never executed
branch  5 never executed
branch  6 never executed
    #####:  303:}
        -:  304:
        -:  305://===----------------------------------------------------------------------===//
        -:  306:// Helper functions for BufferizableOpInterface
        -:  307://===----------------------------------------------------------------------===//
        -:  308:
function _ZL22setInsertionPointAfterRN4mlir9OpBuilderENS_5ValueE called 60282 returned 100% blocks executed 100%
    60282:  309:static void setInsertionPointAfter(OpBuilder &b, Value value) {
    60282:  310:  if (auto bbArg = value.dyn_cast<BlockArgument>()) {
call    0 returned 100%
branch  1 taken 1% (fallthrough)
branch  2 taken 100%
       20:  311:    b.setInsertionPointToStart(bbArg.getOwner());
        -:  312:  } else {
    60262:  313:    b.setInsertionPointAfter(value.getDefiningOp());
call    0 returned 100%
call    1 returned 100%
        -:  314:  }
    60282:  315:}
        -:  316:
        -:  317:/// Determine which OpOperand* will alias with `result` if the op is bufferized
        -:  318:/// in place. Return an empty vector if the op is not bufferizable.
        -:  319:SmallVector<OpOperand *>
function _ZNK4mlir13bufferization13AnalysisState20getAliasingOpOperandENS_8OpResultE called 2763 returned 100% blocks executed 78%
     2763:  320:AnalysisState::getAliasingOpOperand(OpResult result) const {
     2763:  321:  if (Operation *op = result.getDefiningOp())
call    0 returned 100%
branch  1 taken 100% (fallthrough)
branch  2 taken 0%
     2763:  322:    if (auto bufferizableOp = getOptions().dynCastBufferizableOp(op))
call    0 returned 100%
branch  1 taken 100% (fallthrough)
branch  2 taken 0%
     2763:  323:      return bufferizableOp.getAliasingOpOperand(result, *this);
call    0 returned 100%
    #####:  324:  return {};
        -:  325:}
        -:  326:
        -:  327:/// Determine which OpResult will alias with `opOperand` if the op is bufferized
        -:  328:/// in place. Return an empty vector if the op is not bufferizable.
        -:  329:SmallVector<OpResult>
function _ZNK4mlir13bufferization13AnalysisState19getAliasingOpResultERNS_9OpOperandE called 74668 returned 100% blocks executed 83%
    74668:  330:AnalysisState::getAliasingOpResult(OpOperand &opOperand) const {
    74668:  331:  if (auto bufferizableOp =
branch  0 taken 100% (fallthrough)
branch  1 taken 0%
    74668:  332:          getOptions().dynCastBufferizableOp(opOperand.getOwner()))
call    0 returned 100%
branch  1 taken 100% (fallthrough)
branch  2 taken 0%
    74668:  333:    return bufferizableOp.getAliasingOpResult(opOperand, *this);
call    0 returned 100%
    #####:  334:  return {};
        -:  335:}
        -:  336:
        -:  337:/// Return true if `opOperand` bufferizes to a memory read. Return `true` if the
        -:  338:/// op is not bufferizable.
function _ZNK4mlir13bufferization13AnalysisState22bufferizesToMemoryReadERNS_9OpOperandE called 148217 returned 100% blocks executed 100%
   148217:  339:bool AnalysisState::bufferizesToMemoryRead(OpOperand &opOperand) const {
   148217:  340:  if (auto bufferizableOp =
branch  0 taken 53% (fallthrough)
branch  1 taken 47%
   148217:  341:          getOptions().dynCastBufferizableOp(opOperand.getOwner()))
call    0 returned 100%
branch  1 taken 53% (fallthrough)
branch  2 taken 47%
    79088:  342:    return bufferizableOp.bufferizesToMemoryRead(opOperand, *this);
call    0 returned 100%
        -:  343:
        -:  344:  // Unknown op that returns a tensor. The inplace analysis does not support it.
        -:  345:  // Conservatively return true.
    69129:  346:  return true;
        -:  347:}
        -:  348:
        -:  349:/// Return true if `opOperand` bufferizes to a memory write. Return
        -:  350:/// `true` if the op is not bufferizable.
function _ZNK4mlir13bufferization13AnalysisState23bufferizesToMemoryWriteERNS_9OpOperandE called 302770 returned 100% blocks executed 100%
   302770:  351:bool AnalysisState::bufferizesToMemoryWrite(OpOperand &opOperand) const {
   302769:  352:  if (auto bufferizableOp =
branch  0 taken 73% (fallthrough)
branch  1 taken 27%
   302770:  353:          getOptions().dynCastBufferizableOp(opOperand.getOwner()))
call    0 returned 100%
branch  1 taken 73% (fallthrough)
branch  2 taken 27%
   219942:  354:    return bufferizableOp.bufferizesToMemoryWrite(opOperand, *this);
call    0 returned 100%
        -:  355:
        -:  356:  // Unknown op that returns a tensor. The inplace analysis does not support it.
        -:  357:  // Conservatively return true.
    82827:  358:  return true;
        -:  359:}
        -:  360:
        -:  361:/// Return true if `opOperand` does neither read nor write but bufferizes to an
        -:  362:/// alias. Return false if the op is not bufferizable.
function _ZNK4mlir13bufferization13AnalysisState21bufferizesToAliasOnlyERNS_9OpOperandE called 2336 returned 100% blocks executed 100%
     2336:  363:bool AnalysisState::bufferizesToAliasOnly(OpOperand &opOperand) const {
     2336:  364:  if (auto bufferizableOp =
branch  0 taken 60% (fallthrough)
branch  1 taken 40%
     2336:  365:          getOptions().dynCastBufferizableOp(opOperand.getOwner()))
call    0 returned 100%
branch  1 taken 60% (fallthrough)
branch  2 taken 40%
     1406:  366:    return bufferizableOp.bufferizesToAliasOnly(opOperand, *this);
call    0 returned 100%
        -:  367:
        -:  368:  // Unknown op that returns a tensor. The inplace analysis does not support it.
        -:  369:  // Conservatively return false.
      930:  370:  return false;
        -:  371:}
        -:  372:
        -:  373:/// Return true if the given value is read by an op that bufferizes to a memory
        -:  374:/// read. Also takes into account ops that create an alias but do not read by
        -:  375:/// themselves (e.g., ExtractSliceOp).
function _ZNK4mlir13bufferization13AnalysisState11isValueReadENS_5ValueE called 8804 returned 100% blocks executed 93%
     8804:  376:bool AnalysisState::isValueRead(Value value) const {
    8804*:  377:  assert(value.getType().isa<TensorType>() && "expected TensorType");
call    0 returned 100%
branch  1 taken 0% (fallthrough)
branch  2 taken 100%
call    3 never executed
     8804:  378:  SmallVector<OpOperand *> workingSet;
    13173:  379:  for (OpOperand &use : value.getUses())
branch  0 taken 33% (fallthrough)
branch  1 taken 67%
     4369:  380:    workingSet.push_back(&use);
call    0 returned 100%
        -:  381:
     9590:  382:  while (!workingSet.empty()) {
branch  0 taken 24% (fallthrough)
branch  1 taken 76%
     2336:  383:    OpOperand *uMaybeReading = workingSet.pop_back_val();
call    0 returned 100%
        -:  384:    // Skip over all ops that neither read nor write (but create an alias).
     2336:  385:    if (bufferizesToAliasOnly(*uMaybeReading))
call    0 returned 100%
branch  1 taken 13% (fallthrough)
branch  2 taken 87%
      939:  386:      for (OpResult opResult : getAliasingOpResult(*uMaybeReading))
call    0 returned 100%
branch  1 taken 50% (fallthrough)
branch  2 taken 50%
      507:  387:        for (OpOperand &use : opResult.getUses())
branch  0 taken 38% (fallthrough)
branch  1 taken 62%
      194:  388:          workingSet.push_back(&use);
call    0 returned 100%
     2336:  389:    if (bufferizesToMemoryRead(*uMaybeReading))
call    0 returned 100%
branch  1 taken 34%
branch  2 taken 66% (fallthrough)
        -:  390:      return true;
        -:  391:  }
        -:  392:
        -:  393:  return false;
        -:  394:}
        -:  395:
        -:  396:// Starting from `value`, follow the use-def chain in reverse, always selecting
        -:  397:// the aliasing OpOperands. Find and return Values for which `condition`
        -:  398:// evaluates to true. OpOperands of such matching Values are not traversed any
        -:  399:// further.
function _ZNK4mlir13bufferization13AnalysisState29findValueInReverseUseDefChainENS_5ValueEN4llvm12function_refIFbS2_EEEb called 89753 returned 100% blocks executed 89%
    89753:  400:llvm::SetVector<Value> AnalysisState::findValueInReverseUseDefChain(
        -:  401:    Value value, llvm::function_ref<bool(Value)> condition,
        -:  402:    bool followEquivalentOnly) const {
    89753:  403:  llvm::SetVector<Value> result, workingSet;
call    0 returned 100%
call    1 returned 100%
    89753:  404:  workingSet.insert(value);
call    0 returned 100%
        -:  405:
   182035:  406:  while (!workingSet.empty()) {
branch  0 taken 51% (fallthrough)
branch  1 taken 49%
    92282:  407:    Value value = workingSet.pop_back_val();
call    0 returned 100%
    94951:  408:    if (condition(value) || value.isa<BlockArgument>()) {
call    0 returned 100%
branch  1 taken 3% (fallthrough)
branch  2 taken 97%
branch  3 taken 0% (fallthrough)
branch  4 taken 100%
    89613:  409:      result.insert(value);
call    0 returned 100%
    89613:  410:      continue;
        -:  411:    }
        -:  412:
     2669:  413:    OpResult opResult = value.cast<OpResult>();
call    0 returned 100%
     2669:  414:    BufferizableOpInterface bufferizableOp =
     2669:  415:        options.dynCastBufferizableOp(opResult.getDefiningOp());
call    0 returned 100%
call    1 returned 100%
     5198:  416:    SmallVector<OpOperand *> opOperands = getAliasingOpOperand(opResult);
call    0 returned 100%
        -:  417:
        -:  418:    // Stop iterating in either one of these cases:
        -:  419:    // * The current op is not bufferizable or excluded in the filter.
        -:  420:    // * There are no OpOperands to follow.
        -:  421:    // * There is an OpOperand, but it is not an equivalent tensor (only if
        -:  422:    //   `followEquivalentOnly` is set).
     2669:  423:    if (!bufferizableOp || opOperands.empty() ||
branch  0 taken 100% (fallthrough)
branch  1 taken 0%
branch  2 taken 95% (fallthrough)
branch  3 taken 5%
branch  4 taken 0% (fallthrough)
branch  5 taken 100%
    #####:  424:        (followEquivalentOnly &&
    #####:  425:         bufferizableOp.bufferRelation(opResult, *this) !=
branch  0 never executed
branch  1 never executed
        -:  426:             BufferRelation::Equivalent)) {
      140:  427:      result.insert(value);
call    0 returned 100%
    89893:  428:      continue;
branch  0 taken 0%
branch  1 taken 100%
        -:  429:    }
        -:  430:
     5058:  431:    for (OpOperand *o : opOperands)
branch  0 taken 50% (fallthrough)
branch  1 taken 50%
     2529:  432:      workingSet.insert(o->get());
call    0 returned 100%
        -:  433:  }
        -:  434:
    89753:  435:  return result;
call    0 returned 100%
        -:  436:}
        -:  437:
        -:  438:// Find the Values of the last preceding write of a given Value.
        -:  439:llvm::SetVector<Value>
function _ZNK4mlir13bufferization13AnalysisState22findLastPrecedingWriteENS_5ValueE called 89753 returned 100% blocks executed 100%
    89753:  440:AnalysisState::findLastPrecedingWrite(Value value) const {
function _ZZNK4mlir13bufferization13AnalysisState22findLastPrecedingWriteENS_5ValueEENKUlS2_E_clES2_.isra.0 called 92282 returned 100% blocks executed 100%
   182035:  441:  return findValueInReverseUseDefChain(value, [&](Value value) {
    92282:  442:    Operation *op = value.getDefiningOp();
call    0 returned 100%
    92282:  443:    if (!op)
branch  0 taken 100% (fallthrough)
branch  1 taken 0%
        -:  444:      return true;
    92282:  445:    auto bufferizableOp = options.dynCastBufferizableOp(op);
call    0 returned 100%
    92282:  446:    if (!bufferizableOp)
branch  0 taken 12% (fallthrough)
branch  1 taken 88%
        -:  447:      return true;
    11305:  448:    return bufferizableOp.isMemoryWrite(value.cast<OpResult>(), *this);
call    0 returned 100%
call    1 returned 100%
    89753:  449:  });
call    0 returned 100%
        -:  450:}
        -:  451:
function _ZN4mlir13bufferization13AnalysisStateC2ERKNS0_20BufferizationOptionsE called 38389 returned 100% blocks executed 62%
    38389:  452:AnalysisState::AnalysisState(const BufferizationOptions &options)
    38389:  453:    : options(options) {
call    0 returned 100%
   38407*:  454:  for (const BufferizationOptions::AnalysisStateInitFn &fn :
    38407:  455:       options.stateInitializers)
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
      19*:  456:    fn(*this);
branch  0 never executed
branch  1 never executed
    38407:  457:}
        -:  458:
function _ZNK4mlir13bufferization13AnalysisState17canOmitTensorCopyERNS_9OpOperandE called 19182 returned 100% blocks executed 94%
    19182:  459:bool AnalysisState::canOmitTensorCopy(OpOperand &opOperand) const {
        -:  460:  // Do not copy if the tensor has undefined contents.
    19182:  461:  if (hasUndefinedContents(&opOperand))
call    0 returned 100%
branch  1 taken 100% (fallthrough)
branch  2 taken 0%
        -:  462:    return true;
        -:  463:
        -:  464:  // Do not copy if the buffer of the tensor is entirely overwritten (with
        -:  465:  // values that do not depend on the old tensor).
    19182:  466:  if (bufferizesToMemoryWrite(opOperand) && !bufferizesToMemoryRead(opOperand))
call    0 returned 100%
branch  1 taken 100% (fallthrough)
branch  2 taken 1%
call    3 returned 100%
branch  4 taken 77% (fallthrough)
branch  5 taken 23%
        -:  467:    return true;
        -:  468:
        -:  469:  // Do not copy if the tensor is never read.
    14766:  470:  SmallVector<OpResult> aliasingOpResults = getAliasingOpResult(opOperand);
call    0 returned 100%
    14766:  471:  if (!bufferizesToMemoryRead(opOperand) &&
call    0 returned 100%
branch  1 taken 1% (fallthrough)
branch  2 taken 100%
       15:  472:      llvm::none_of(aliasingOpResults,
call    0 returned 100%
branch  1 taken 13% (fallthrough)
branch  2 taken 87%
        -:  473:                    [&](OpResult opResult) { return isValueRead(opResult); }))
        2:  474:    return true;
        -:  475:
        -:  476:  // Default: Cannot omit the copy.
        -:  477:  return false;
        -:  478:}
        -:  479:
function _ZNK4mlir13bufferization13AnalysisState9isInPlaceERNS_9OpOperandE called 119276 returned 100% blocks executed 100%
   119276:  480:bool AnalysisState::isInPlace(OpOperand &opOperand) const {
        -:  481:  // ToMemrefOps are always in-place.
   119276:  482:  if (isa<ToMemrefOp>(opOperand.getOwner()))
call    0 returned 100%
branch  1 taken 81% (fallthrough)
branch  2 taken 19%
        -:  483:    return true;
        -:  484:
        -:  485:  // In the absence of analysis information, OpOperands that bufferize to a
        -:  486:  // memory write are out-of-place, i.e., an alloc and copy is inserted.
    96222:  487:  return !bufferizesToMemoryWrite(opOperand);
call    0 returned 100%
        -:  488:}
        -:  489:
function _ZNK4mlir13bufferization13AnalysisState29areEquivalentBufferizedValuesENS_5ValueES2_ called 0 returned 0% blocks executed 0%
    #####:  490:bool AnalysisState::areEquivalentBufferizedValues(Value v1, Value v2) const {
        -:  491:  // In the absence of analysis information, we do not know if the values are
        -:  492:  // equivalent. The conservative answer is "false".
    #####:  493:  return false;
        -:  494:}
        -:  495:
function _ZNK4mlir13bufferization13AnalysisState27areAliasingBufferizedValuesENS_5ValueES2_ called 0 returned 0% blocks executed 0%
    #####:  496:bool AnalysisState::areAliasingBufferizedValues(Value v1, Value v2) const {
        -:  497:  // In the absence of analysis information, we do not know if the values may be
        -:  498:  // aliasing. The conservative answer is "true".
    #####:  499:  return true;
        -:  500:}
        -:  501:
function _ZNK4mlir13bufferization13AnalysisState20hasUndefinedContentsEPNS_9OpOperandE called 18701 returned 100% blocks executed 100%
    18701:  502:bool AnalysisState::hasUndefinedContents(OpOperand *opOperand) const {
        -:  503:  // In the absence of analysis information, the conservative answer is "false".
    18701:  504:  return false;
        -:  505:}
        -:  506:
function _ZNK4mlir13bufferization13AnalysisState15isTensorYieldedENS_5ValueE called 4 returned 100% blocks executed 9%
        4:  507:bool AnalysisState::isTensorYielded(Value tensor) const {
        -:  508:  // In the absence of analysis information, the conservative answer is "true".
        4:  509:  if (!tensor.getDefiningOp<AllocTensorOp>())
call    0 returned 100%
branch  1 taken 0% (fallthrough)
branch  2 taken 100%
        -:  510:    return true;
        -:  511:
        -:  512:  // For AllocTensorOp results, we can do better: They do not alias with any
        -:  513:  // preceding value, so we can follow SSA use-def chains and do a simple
        -:  514:  // analysis.
    #####:  515:  SmallVector<OpOperand *> worklist;
    #####:  516:  for (OpOperand &use : tensor.getUses())
branch  0 never executed
branch  1 never executed
    #####:  517:    worklist.push_back(&use);
call    0 never executed
        -:  518:
    #####:  519:  while (!worklist.empty()) {
branch  0 never executed
branch  1 never executed
    #####:  520:    OpOperand *operand = worklist.pop_back_val();
call    0 never executed
    #####:  521:    Operation *op = operand->getOwner();
call    0 never executed
        -:  522:
        -:  523:    // If the op is not bufferizable, we can safely assume that the value is not
        -:  524:    // yielded. (When bufferizing that op, it must handle such cases.)
    #####:  525:    if (!options.dynCastBufferizableOp(op))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  526:      continue;
        -:  527:
        -:  528:    // We cannot analyze through ToMemrefOps, so we have to conservatively
        -:  529:    // assume that the value is yielded.
    #####:  530:    if (isa<ToMemrefOp>(op))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  531:      return true;
branch  0 never executed
branch  1 never executed
        -:  532:
        -:  533:    // Check if the op is returning/yielding.
    #####:  534:    if (isRegionReturnLike(op))
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  535:      return true;
        -:  536:
        -:  537:    // Add all aliasing OpResults to the worklist.
        -:  538:    // Note: In the absence of detailed analysis information (e.g., there may be
        -:  539:    // no function call analysis information), this `getAliasingOpResult` is
        -:  540:    // conservative and may report additional OpResults as potentially aliasing.
    #####:  541:    for (OpResult opResult : getAliasingOpResult(*operand))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  542:      for (OpOperand &use : opResult.getUses())
branch  0 never executed
branch  1 never executed
    #####:  543:        worklist.push_back(&use);
call    0 never executed
        -:  544:  }
        -:  545:
        -:  546:  // No ReturnLike op found: The value is not yielded.
        -:  547:  return false;
        -:  548:}
        -:  549:
        -:  550:// bufferization.to_memref is not allowed to change the rank.
function _ZL23ensureToMemrefOpIsValidN4mlir5ValueENS_4TypeE called 60282 returned 100% blocks executed 88%
    60282:  551:static void ensureToMemrefOpIsValid(Value tensor, Type memrefType) {
        -:  552:#ifndef NDEBUG
    60282:  553:  auto rankedTensorType = tensor.getType().dyn_cast<RankedTensorType>();
call    0 returned 100%
  120564*:  554:  assert((!rankedTensorType || memrefType.cast<MemRefType>().getRank() ==
branch  0 taken 100% (fallthrough)
branch  1 taken 0%
call    2 returned 100%
call    3 returned 100%
branch  4 taken 0% (fallthrough)
branch  5 taken 100%
call    6 never executed
        -:  555:                                   rankedTensorType.getRank()) &&
        -:  556:         "to_memref would be invalid: mismatching ranks");
        -:  557:#endif
    60282:  558:}
        -:  559:
function _ZN4mlir13bufferization9getBufferERNS_12RewriterBaseENS_5ValueERKNS0_20BufferizationOptionsE called 71224 returned 100% blocks executed 82%
    71224:  560:FailureOr<Value> bufferization::getBuffer(RewriterBase &rewriter, Value value,
        -:  561:                                          const BufferizationOptions &options) {
        -:  562:#ifndef NDEBUG
    71224:  563:  auto tensorType = value.getType().dyn_cast<TensorType>();
call    0 returned 100%
   71224*:  564:  assert(tensorType && "unexpected non-tensor type");
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
call    2 never executed
        -:  565:#endif // NDEBUG
        -:  566:
        -:  567:  // Replace "%t = to_tensor %m" with %m.
    71224:  568:  if (auto toTensorOp = value.getDefiningOp<bufferization::ToTensorOp>())
call    0 returned 100%
branch  1 taken 15% (fallthrough)
branch  2 taken 85%
    10942:  569:    return toTensorOp.getMemref();
call    0 returned 100%
        -:  570:
        -:  571:  // Insert to_memref op.
    60282:  572:  OpBuilder::InsertionGuard g(rewriter);
call    0 returned 100%
    60282:  573:  setInsertionPointAfter(rewriter, value);
call    0 returned 100%
    60282:  574:  FailureOr<BaseMemRefType> memrefType = getBufferType(value, options);
call    0 returned 100%
    60282:  575:  if (failed(memrefType))
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
    #####:  576:    return failure();
    60282:  577:  ensureToMemrefOpIsValid(value, *memrefType);
call    0 returned 100%
    60282:  578:  return rewriter
    60282:  579:      .create<bufferization::ToMemrefOp>(value.getLoc(), *memrefType, value)
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
call    2 returned 100%
call    3 returned 100%
    60282:  580:      .getResult();
        -:  581:}
        -:  582:
function _ZN4mlir13bufferization6detail20defaultGetBufferTypeENS_5ValueERKNS0_20BufferizationOptionsERKN4llvm8DenseMapIS2_NS_14BaseMemRefTypeENS6_12DenseMapInfoIS2_vEENS6_6detail12DenseMapPairIS2_S8_EEEE called 7609 returned 100% blocks executed 69%
     7609:  583:FailureOr<BaseMemRefType> bufferization::detail::defaultGetBufferType(
        -:  584:    Value value, const BufferizationOptions &options,
        -:  585:    const DenseMap<Value, BaseMemRefType> &fixedTypes) {
    7609*:  586:  assert(value.getType().isa<TensorType>() && "expected tensor type");
call    0 returned 100%
branch  1 taken 0% (fallthrough)
branch  2 taken 100%
call    3 never executed
        -:  587:
        -:  588:  // No further analysis is possible for a block argument.
     7609:  589:  if (value.isa<BlockArgument>())
call    0 returned 100%
branch  1 taken 0% (fallthrough)
branch  2 taken 100%
    #####:  590:    return bufferization::getMemRefType(value, options);
call    0 never executed
call    1 never executed
        -:  591:
        -:  592:  // Value is an OpResult.
     7609:  593:  Operation *op = getOwnerOfValue(value);
call    0 returned 100%
     7609:  594:  auto opResult = value.cast<OpResult>();
call    0 returned 100%
     7609:  595:  auto bufferizableOp = cast<BufferizableOpInterface>(op);
call    0 returned 100%
     7609:  596:  AnalysisState state(options);
call    0 returned 100%
    15218:  597:  auto aliasingOperands = bufferizableOp.getAliasingOpOperand(opResult, state);
call    0 returned 100%
call    1 returned 100%
     7609:  598:  if (!aliasingOperands.empty() &&
branch  0 taken 1% (fallthrough)
branch  1 taken 100%
       16:  599:      bufferizableOp.bufferRelation(opResult, state) ==
branch  0 taken 100% (fallthrough)
branch  1 taken 0%
        -:  600:          BufferRelation::Equivalent) {
        -:  601:    // If the OpResult has an equivalent OpOperand, both OpResult and
        -:  602:    // OpOperand bufferize to the exact same buffer type.
       16:  603:    Value equivalentOperand = aliasingOperands.front()->get();
branch  0 taken 0%
branch  1 taken 100%
call    2 returned 100%
       16:  604:    return getBufferType(equivalentOperand, options, fixedTypes);
call    0 returned 100%
        -:  605:  }
        -:  606:
        -:  607:  // If we do not know the memory space and there is no default memory space,
        -:  608:  // report a failure.
     7593:  609:  if (!options.defaultMemorySpace.has_value())
branch  0 taken 0%
branch  1 taken 100%
    #####:  610:    return op->emitError("could not infer memory space");
call    0 never executed
call    1 never executed
call    2 never executed
        -:  611:
     7593:  612:  return getMemRefType(value, options, /*layout=*/{},
     7593:  613:                       *options.defaultMemorySpace);
call    0 returned 100%
call    1 returned 100%
        -:  614:}
        -:  615:
        -:  616:/// Return the buffer type for a given Value (tensor) after bufferization.
        -:  617:FailureOr<BaseMemRefType>
function _ZN4mlir13bufferization13getBufferTypeENS_5ValueERKNS0_20BufferizationOptionsE called 87873 returned 100% blocks executed 100%
    87873:  618:bufferization::getBufferType(Value value, const BufferizationOptions &options) {
    87873:  619:  DenseMap<Value, BaseMemRefType> fixedTypes;
call    0 returned 100%
    87873:  620:  return getBufferType(value, options, fixedTypes);
call    0 returned 100%
call    1 returned 100%
        -:  621:}
        -:  622:
        -:  623:/// Return the buffer type for a given Value (tensor) after bufferization.
function _ZN4mlir13bufferization13getBufferTypeENS_5ValueERKNS0_20BufferizationOptionsERKN4llvm8DenseMapIS1_NS_14BaseMemRefTypeENS5_12DenseMapInfoIS1_vEENS5_6detail12DenseMapPairIS1_S7_EEEE called 95019 returned 100% blocks executed 72%
    95019:  624:FailureOr<BaseMemRefType> bufferization::getBufferType(
        -:  625:    Value value, const BufferizationOptions &options,
        -:  626:    const DenseMap<Value, BaseMemRefType> &fixedTypes) {
   95019*:  627:  assert(value.getType().isa<TensorType>() && "unexpected non-tensor type");
call    0 returned 100%
branch  1 taken 0% (fallthrough)
branch  2 taken 100%
call    3 never executed
        -:  628:
        -:  629:  // If the `value` is in `fixedTypes`, return the mapped type.
    95019:  630:  const auto &it = fixedTypes.find(value);
call    0 returned 100%
    95019:  631:  if (it != fixedTypes.end())
call    0 returned 100%
call    1 returned 100%
branch  2 taken 0% (fallthrough)
branch  3 taken 100%
    #####:  632:    return it->second;
call    0 never executed
        -:  633:
        -:  634:  // Try querying BufferizableOpInterface.
    95019:  635:  Operation *op = getOwnerOfValue(value);
call    0 returned 100%
    95019:  636:  auto bufferizableOp = options.dynCastBufferizableOp(op);
call    0 returned 100%
    95019:  637:  if (bufferizableOp)
branch  0 taken 25% (fallthrough)
branch  1 taken 75%
    23581:  638:    return bufferizableOp.getBufferType(value, options, fixedTypes);
call    0 returned 100%
call    1 returned 100%
call    2 returned 100%
        -:  639:
        -:  640:  // Op is not bufferizable.
    71438:  641:  if (!options.defaultMemorySpace.has_value())
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
    #####:  642:    return op->emitError("could not infer memory space");
call    0 never executed
call    1 never executed
call    2 never executed
        -:  643:
    71438:  644:  return getMemRefType(value, options, /*layout=*/{},
    71438:  645:                       *options.defaultMemorySpace);
call    0 returned 100%
call    1 returned 100%
        -:  646:}
        -:  647:
function _ZN4mlir13bufferization29replaceOpWithBufferizedValuesERNS_12RewriterBaseEPNS_9OperationENS_10ValueRangeE called 55872 returned 100% blocks executed 80%
    55872:  648:void bufferization::replaceOpWithBufferizedValues(RewriterBase &rewriter,
        -:  649:                                                  Operation *op,
        -:  650:                                                  ValueRange values) {
   55872*:  651:  assert(values.size() == op->getNumResults() &&
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
call    2 never executed
        -:  652:         "expected one value per OpResult");
    55872:  653:  OpBuilder::InsertionGuard g(rewriter);
branch  0 taken 100% (fallthrough)
branch  1 taken 1%
        -:  654:
        -:  655:  // Replace all OpResults with the given values.
   111744:  656:  SmallVector<Value> replacements;
branch  0 taken 100% (fallthrough)
branch  1 taken 1%
branch  2 taken 100% (fallthrough)
branch  3 taken 0%
   167610:  657:  for (OpResult opResult : op->getOpResults()) {
branch  0 taken 100% (fallthrough)
branch  1 taken 1%
branch  2 taken 50% (fallthrough)
branch  3 taken 50%
call    4 returned 100%
    55869:  658:    Value replacement = values[opResult.getResultNumber()];
call    0 returned 100%
call    1 returned 100%
    55869:  659:    if (opResult.getType().isa<TensorType>()) {
call    0 returned 100%
branch  1 taken 75% (fallthrough)
branch  2 taken 25%
        -:  660:      // The OpResult is a tensor. Such values are replaced with memrefs during
        -:  661:      // bufferization.
   42075*:  662:      assert((replacement.getType().isa<MemRefType>() ||
call    0 returned 100%
branch  1 taken 0% (fallthrough)
branch  2 taken 100%
call    3 never executed
branch  4 never executed
branch  5 never executed
call    6 never executed
        -:  663:              replacement.getType().isa<UnrankedMemRefType>()) &&
        -:  664:             "tensor op result should be replaced with a memref value");
        -:  665:      // The existing uses of the OpResult still expect a tensor. Insert a
        -:  666:      // ToTensorOp. Throughout bufferization, this ToTensorOp will gradually
        -:  667:      // loose all of its users and eventually DCE away.
    42075:  668:      rewriter.setInsertionPointAfter(op);
call    0 returned 100%
    42075:  669:      replacement = rewriter.create<bufferization::ToTensorOp>(
    42075:  670:          replacement.getLoc(), replacement);
call    0 returned 100%
call    1 returned 100%
        -:  671:    }
    55869:  672:    replacements.push_back(replacement);
call    0 returned 100%
        -:  673:  }
        -:  674:
    55872:  675:  rewriter.replaceOp(op, replacements);
call    0 returned 100%
call    1 returned 100%
branch  2 taken 0%
branch  3 taken 100%
    55872:  676:}
        -:  677:
        -:  678://===----------------------------------------------------------------------===//
        -:  679:// Bufferization-specific scoped alloc/dealloc insertion support.
        -:  680://===----------------------------------------------------------------------===//
        -:  681:
        -:  682:/// Create a memref allocation with the given type and dynamic extents.
function _ZNK4mlir13bufferization20BufferizationOptions11createAllocERNS_9OpBuilderENS_8LocationENS_10MemRefTypeENS_10ValueRangeE called 15580 returned 100% blocks executed 67%
    15580:  683:FailureOr<Value> BufferizationOptions::createAlloc(OpBuilder &b, Location loc,
        -:  684:                                                   MemRefType type,
        -:  685:                                                   ValueRange dynShape) const {
    15580:  686:  if (allocationFn)
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
    #####:  687:    return (*allocationFn)(b, loc, type, dynShape, bufferAlignment);
branch  0 never executed
branch  1 never executed
        -:  688:
        -:  689:  // Default bufferallocation via AllocOp.
    15580:  690:  if (bufferAlignment != 0)
branch  0 taken 100% (fallthrough)
branch  1 taken 1%
    15525:  691:    return b
    15525:  692:        .create<memref::AllocOp>(loc, type, dynShape,
    15525:  693:                                 b.getI64IntegerAttr(bufferAlignment))
call    0 returned 100%
call    1 returned 100%
    15525:  694:        .getResult();
       55:  695:  return b.create<memref::AllocOp>(loc, type, dynShape).getResult();
call    0 returned 100%
        -:  696:}
        -:  697:
        -:  698:/// Creates a memref deallocation. The given memref buffer must have been
        -:  699:/// allocated using `createAlloc`.
function _ZNK4mlir13bufferization20BufferizationOptions13createDeallocERNS_9OpBuilderENS_8LocationENS_5ValueE called 28800 returned 100% blocks executed 50%
    28800:  700:LogicalResult BufferizationOptions::createDealloc(OpBuilder &b, Location loc,
        -:  701:                                                  Value allocatedBuffer) const {
    28800:  702:  if (deallocationFn)
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
    #####:  703:    return (*deallocationFn)(b, loc, allocatedBuffer);
branch  0 never executed
branch  1 never executed
        -:  704:
        -:  705:  // Default buffer deallocation via DeallocOp.
    28800:  706:  b.create<memref::DeallocOp>(loc, allocatedBuffer);
call    0 returned 100%
    28800:  707:  return success();
        -:  708:}
        -:  709:
        -:  710:/// Create a memory copy between two memref buffers.
function _ZNK4mlir13bufferization20BufferizationOptions12createMemCpyERNS_9OpBuilderENS_8LocationENS_5ValueES5_ called 7118 returned 100% blocks executed 50%
     7118:  711:LogicalResult BufferizationOptions::createMemCpy(OpBuilder &b, Location loc,
        -:  712:                                                 Value from, Value to) const {
     7118:  713:  if (memCpyFn)
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
    #####:  714:    return (*memCpyFn)(b, loc, from, to);
branch  0 never executed
branch  1 never executed
        -:  715:
     7118:  716:  b.create<memref::CopyOp>(loc, from, to);
call    0 returned 100%
     7118:  717:  return success();
        -:  718:}
        -:  719:
        -:  720://===----------------------------------------------------------------------===//
        -:  721:// Bufferization-specific BlockAndValueMapping support with debugging.
        -:  722://===----------------------------------------------------------------------===//
        -:  723:
function _ZN4mlir13bufferization18isFunctionArgumentENS_5ValueE called 0 returned 0% blocks executed 0%
    #####:  724:bool bufferization::isFunctionArgument(Value value) {
    #####:  725:  auto bbArg = value.dyn_cast<BlockArgument>();
call    0 never executed
    #####:  726:  if (!bbArg)
branch  0 never executed
branch  1 never executed
        -:  727:    return false;
    #####:  728:  return isa<func::FuncOp>(bbArg.getOwner()->getParentOp());
call    0 never executed
call    1 never executed
        -:  729:}
        -:  730:
function _ZN4mlir13bufferization13getMemRefTypeENS_5ValueERKNS0_20BufferizationOptionsENS_25MemRefLayoutAttrInterfaceEj called 82837 returned 100% blocks executed 73%
    82837:  731:BaseMemRefType bufferization::getMemRefType(Value value,
        -:  732:                                            const BufferizationOptions &options,
        -:  733:                                            MemRefLayoutAttrInterface layout,
        -:  734:                                            unsigned memorySpace) {
    82837:  735:  auto tensorType = value.getType().cast<TensorType>();
call    0 returned 100%
    82837:  736:  auto memorySpaceAttr = IntegerAttr::get(
    82837:  737:      IntegerType::get(tensorType.getContext(), 64), memorySpace);
call    0 returned 100%
call    1 returned 100%
call    2 returned 100%
        -:  738:
        -:  739:  // Case 1: Unranked memref type.
    82837:  740:  if (auto unrankedTensorType = tensorType.dyn_cast<UnrankedTensorType>()) {
call    0 returned 100%
branch  1 taken 0% (fallthrough)
branch  2 taken 100%
    #####:  741:    assert(!layout && "UnrankedTensorType cannot have a layout map");
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  742:    return UnrankedMemRefType::get(unrankedTensorType.getElementType(),
    #####:  743:                                   memorySpaceAttr);
call    0 never executed
call    1 never executed
        -:  744:  }
        -:  745:
        -:  746:  // Case 2: Ranked memref type with specified layout.
    82837:  747:  auto rankedTensorType = tensorType.cast<RankedTensorType>();
call    0 returned 100%
    82837:  748:  if (layout) {
branch  0 taken 5% (fallthrough)
branch  1 taken 95%
     7612:  749:    return MemRefType::get(rankedTensorType.getShape(),
        -:  750:                           rankedTensorType.getElementType(), layout,
     3806:  751:                           memorySpaceAttr);
call    0 returned 100%
call    1 returned 100%
call    2 returned 100%
        -:  752:  }
        -:  753:
   158062:  754:  return options.unknownTypeConverterFn(value, memorySpace, options);
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
        -:  755:}
        -:  756:
        -:  757:BaseMemRefType
function _ZN4mlir13bufferization35getMemRefTypeWithFullyDynamicLayoutENS_10TensorTypeEj called 258 returned 100% blocks executed 81%
      258:  758:bufferization::getMemRefTypeWithFullyDynamicLayout(TensorType tensorType,
        -:  759:                                                   unsigned memorySpace) {
        -:  760:  // Case 1: Unranked memref type.
      258:  761:  if (auto unrankedTensorType = tensorType.dyn_cast<UnrankedTensorType>()) {
call    0 returned 100%
branch  1 taken 0% (fallthrough)
branch  2 taken 100%
    #####:  762:    return UnrankedMemRefType::get(unrankedTensorType.getElementType(),
    #####:  763:                                   memorySpace);
call    0 never executed
call    1 never executed
        -:  764:  }
        -:  765:
        -:  766:  // Case 2: Ranked memref type.
      258:  767:  auto memorySpaceAttr = IntegerAttr::get(
      258:  768:      IntegerType::get(tensorType.getContext(), 64), memorySpace);
call    0 returned 100%
call    1 returned 100%
call    2 returned 100%
      258:  769:  auto rankedTensorType = tensorType.cast<RankedTensorType>();
call    0 returned 100%
      258:  770:  int64_t dynamicOffset = ShapedType::kDynamicStrideOrOffset;
      258:  771:  SmallVector<int64_t> dynamicStrides(rankedTensorType.getRank(),
call    0 returned 100%
      258:  772:                                      ShapedType::kDynamicStrideOrOffset);
call    0 returned 100%
      258:  773:  auto stridedLayout = StridedLayoutAttr::get(tensorType.getContext(),
call    0 returned 100%
      258:  774:                                              dynamicOffset, dynamicStrides);
call    0 returned 100%
call    1 returned 100%
      258:  775:  return MemRefType::get(rankedTensorType.getShape(),
call    0 returned 100%
        -:  776:                         rankedTensorType.getElementType(), stridedLayout,
      258:  777:                         memorySpaceAttr);
call    0 returned 100%
call    1 returned 100%
call    2 returned 100%
branch  3 taken 0% (fallthrough)
branch  4 taken 100%
        -:  778:}
        -:  779:
        -:  780:/// Return a MemRef type with a static identity layout (i.e., no layout map). If
        -:  781:/// the given tensor type is unranked, return an unranked MemRef type.
        -:  782:BaseMemRefType
function _ZN4mlir13bufferization37getMemRefTypeWithStaticIdentityLayoutENS_10TensorTypeEj called 94453 returned 100% blocks executed 80%
    94453:  783:bufferization::getMemRefTypeWithStaticIdentityLayout(TensorType tensorType,
        -:  784:                                                     unsigned memorySpace) {
        -:  785:  // Case 1: Unranked memref type.
    94453:  786:  if (auto unrankedTensorType = tensorType.dyn_cast<UnrankedTensorType>()) {
call    0 returned 100%
branch  1 taken 0% (fallthrough)
branch  2 taken 100%
    #####:  787:    return UnrankedMemRefType::get(unrankedTensorType.getElementType(),
    #####:  788:                                   memorySpace);
call    0 never executed
call    1 never executed
        -:  789:  }
        -:  790:
        -:  791:  // Case 2: Ranked memref type.
    94453:  792:  auto rankedTensorType = tensorType.cast<RankedTensorType>();
call    0 returned 100%
    94453:  793:  auto memorySpaceAttr = IntegerAttr::get(
    94453:  794:      IntegerType::get(tensorType.getContext(), 64), memorySpace);
call    0 returned 100%
call    1 returned 100%
call    2 returned 100%
    94453:  795:  MemRefLayoutAttrInterface layout = {};
call    0 returned 100%
   188906:  796:  return MemRefType::get(rankedTensorType.getShape(),
        -:  797:                         rankedTensorType.getElementType(), layout,
    94453:  798:                         memorySpaceAttr);
call    0 returned 100%
call    1 returned 100%
call    2 returned 100%
        -:  799:}
        -:  800:
function _ZN4mlir13bufferization6detail25defaultIsRepetitiveRegionENS0_23BufferizableOpInterfaceEj called 8519 returned 100% blocks executed 83%
     8519:  801:bool bufferization::detail::defaultIsRepetitiveRegion(
        -:  802:    BufferizableOpInterface bufferizableOp, unsigned index) {
    8519*:  803:  assert(index < bufferizableOp->getNumRegions() && "invalid region index");
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
call    2 never executed
     8519:  804:  auto regionInterface =
     8519:  805:      dyn_cast<RegionBranchOpInterface>(bufferizableOp.getOperation());
call    0 returned 100%
     8519:  806:  if (!regionInterface)
branch  0 taken 28% (fallthrough)
branch  1 taken 72%
        -:  807:    return false;
     2384:  808:  return regionInterface.isRepetitiveRegion(index);
call    0 returned 100%
        -:  809:}
