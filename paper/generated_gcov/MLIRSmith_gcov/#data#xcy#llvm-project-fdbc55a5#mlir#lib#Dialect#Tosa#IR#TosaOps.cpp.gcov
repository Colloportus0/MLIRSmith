        -:    0:Source:/data/xcy/llvm-project-fdbc55a5/mlir/lib/Dialect/Tosa/IR/TosaOps.cpp
        -:    0:Graph:../tools/mlir/lib/Dialect/Tosa/CMakeFiles/obj.MLIRTosaDialect.dir/IR/TosaOps.cpp.gcno
        -:    0:Data:../tools/mlir/lib/Dialect/Tosa/CMakeFiles/obj.MLIRTosaDialect.dir/IR/TosaOps.cpp.gcda
        -:    0:Runs:116161
        -:    1://===- TosaOps.cpp - MLIR Dialect for TOSA --------------------------------===//
        -:    2://
        -:    3:// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
        -:    4:// See https://llvm.org/LICENSE.txt for license information.
        -:    5:// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
        -:    6://
        -:    7://===----------------------------------------------------------------------===//
        -:    8://
        -:    9:// \file
        -:   10:// This file implements the TOSA Specification:
        -:   11:// https://developer.mlplatform.org/w/tosa/
        -:   12://
        -:   13://===----------------------------------------------------------------------===//
        -:   14:
        -:   15:#include "mlir/Dialect/Tosa/IR/TosaOps.h"
        -:   16:#include "mlir/Dialect/Quant/QuantOps.h"
        -:   17:#include "mlir/Dialect/Tensor/IR/Tensor.h"
        -:   18:#include "mlir/Dialect/Tosa/Utils/QuantUtils.h"
        -:   19:#include "mlir/Dialect/Tosa/Utils/ShapeUtils.h"
        -:   20:#include "mlir/IR/BuiltinTypes.h"
        -:   21:#include "mlir/IR/DialectImplementation.h"
        -:   22:#include "mlir/IR/Matchers.h"
        -:   23:#include "mlir/IR/PatternMatch.h"
        -:   24:#include "mlir/IR/TypeUtilities.h"
        -:   25:#include "mlir/Transforms/InliningUtils.h"
        -:   26:#include "llvm/ADT/DenseMap.h"
        -:   27:#include "llvm/ADT/TypeSwitch.h"
        -:   28:
        -:   29:using namespace mlir;
        -:   30:using namespace mlir::tosa;
        -:   31:
        -:   32:#include "mlir/Dialect/Tosa/IR/TosaOpsDialect.cpp.inc"
        -:   33:
        -:   34://===----------------------------------------------------------------------===//
        -:   35:// Tosa dialect interface includes.
        -:   36://===----------------------------------------------------------------------===//
        -:   37:
        -:   38:#include "mlir/Dialect/Tosa/IR/TosaInterfaces.cpp.inc"
        -:   39:
        -:   40:namespace {
        -:   41://===----------------------------------------------------------------------===//
        -:   42:// Dialect Function Inliner Interface.
        -:   43://===----------------------------------------------------------------------===//
        -:   44:struct TosaInlinerInterface : public DialectInlinerInterface {
        -:   45:  using DialectInlinerInterface::DialectInlinerInterface;
        -:   46:
        -:   47:  //===--------------------------------------------------------------------===//
        -:   48:  // Analysis Hooks.
        -:   49:  //===--------------------------------------------------------------------===//
        -:   50:
        -:   51:  /// All operations can be inlined by default.
function _ZNK12_GLOBAL__N_120TosaInlinerInterface15isLegalToInlineEPN4mlir9OperationEPNS1_6RegionEbRNS1_20BlockAndValueMappingE called 0 returned 0% blocks executed 0%
    #####:   52:  bool isLegalToInline(Operation *op, Region *region, bool wouldBeCloned,
        -:   53:                       BlockAndValueMapping &map) const final {
    #####:   54:    return true;
        -:   55:  }
        -:   56:
        -:   57:  /// All regions with If and While parent operators can be inlined.
function _ZNK12_GLOBAL__N_120TosaInlinerInterface15isLegalToInlineEPN4mlir6RegionES3_bRNS1_20BlockAndValueMappingE called 0 returned 0% blocks executed 0%
    #####:   58:  bool isLegalToInline(Region *dest, Region *src, bool wouldBeCloned,
        -:   59:                       BlockAndValueMapping &map) const final {
    #####:   60:    return (isa<tosa::IfOp>(dest->getParentOp()) ||
call    0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
    #####:   61:            isa<tosa::WhileOp>(dest->getParentOp()));
call    0 never executed
        -:   62:  }
        -:   63:};
        -:   64:} // namespace
        -:   65:
        -:   66://===----------------------------------------------------------------------===//
        -:   67:// TOSA control flow support.
        -:   68://===----------------------------------------------------------------------===//
        -:   69:
        -:   70:/// Returns the while loop body.
function _ZN4mlir4tosa7WhileOp11getLoopBodyEv called 0 returned 0% blocks executed 0%
    #####:   71:Region &tosa::WhileOp::getLoopBody() { return getBody(); }
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
        -:   72:
        -:   73://===----------------------------------------------------------------------===//
        -:   74:// Tosa dialect initialization.
        -:   75://===----------------------------------------------------------------------===//
        -:   76:
function _ZN4mlir4tosa11TosaDialect10initializeEv called 475 returned 100% blocks executed 100%
      475:   77:void TosaDialect::initialize() {
      475:   78:  addOperations<
        -:   79:#define GET_OP_LIST
        -:   80:#include "mlir/Dialect/Tosa/IR/TosaOps.cpp.inc"
      475:   81:      >();
call    0 returned 100%
      475:   82:  addAttributes<
        -:   83:#define GET_ATTRDEF_LIST
        -:   84:#include "mlir/Dialect/Tosa/IR/TosaAttributes.cpp.inc"
      475:   85:      >();
call    0 returned 100%
      475:   86:  addInterfaces<TosaInlinerInterface>();
call    0 returned 100%
      475:   87:}
        -:   88:
function _ZN4mlir4tosa11TosaDialect19materializeConstantERNS_9OpBuilderENS_9AttributeENS_4TypeENS_8LocationE called 0 returned 0% blocks executed 0%
    #####:   89:Operation *TosaDialect::materializeConstant(OpBuilder &builder, Attribute value,
        -:   90:                                            Type type, Location loc) {
        -:   91:  // Tosa dialect constants only support ElementsAttr unlike standard dialect
        -:   92:  // constant which supports all attributes.
    #####:   93:  if (value.isa<ElementsAttr>())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:   94:    return builder.create<tosa::ConstOp>(loc, type, value.cast<ElementsAttr>());
call    0 never executed
call    1 never executed
        -:   95:  return nullptr;
        -:   96:}
        -:   97:
        -:   98://===----------------------------------------------------------------------===//
        -:   99:// TOSA Operator Verifiers.
        -:  100://===----------------------------------------------------------------------===//
        -:  101:
        -:  102:template <typename T>
    #####:  103:static LogicalResult verifyConvOp(T op) {
        -:  104:  // All TOSA conv ops have an input() and weight().
    #####:  105:  auto inputType =
    #####:  106:      op.getInput().getType().template dyn_cast<RankedTensorType>();
    #####:  107:  auto weightType =
    #####:  108:      op.getWeight().getType().template dyn_cast<RankedTensorType>();
        -:  109:
        -:  110:  // Must be ranked tensor types
    #####:  111:  if (!inputType) {
    #####:  112:    op.emitOpError("expect a ranked tensor for input, got ") << op.getInput();
    #####:  113:    return failure();
        -:  114:  }
    #####:  115:  if (!weightType) {
    #####:  116:    op.emitOpError("expect a ranked tensor for weight, got ") << op.getWeight();
    #####:  117:    return failure();
        -:  118:  }
        -:  119:
    #####:  120:  auto inputEType = inputType.getElementType();
    #####:  121:  auto weightEType = weightType.getElementType();
        -:  122:
    #####:  123:  bool inputIsQuant = !inputEType.template isa<FloatType>();
    #####:  124:  bool weightIsQuant = !weightEType.template isa<FloatType>();
        -:  125:
        -:  126:  // Either both must be quantized or both unquantized.
    #####:  127:  if (inputIsQuant != weightIsQuant) {
        -:  128:    op.emitOpError(
        -:  129:        "expect both input and weight to be float or not together, got ")
    #####:  130:        << inputEType << " and " << weightEType;
    #####:  131:    return failure();
        -:  132:  }
        -:  133:
        -:  134:  // Quantized type must have constructed the quantizationattr, and unquantized
        -:  135:  // types should not have a quantizationattr.
    #####:  136:  if ((inputIsQuant && !op.getQuantizationInfo()) ||
    #####:  137:      (!inputIsQuant && op.getQuantizationInfo())) {
    #####:  138:    op.emitOpError("quantizationattr is required for quantized type, and not "
        -:  139:                   "allowed for float type");
    #####:  140:    return failure();
        -:  141:  }
        -:  142:
    #####:  143:  return success();
        -:  144:}
------------------
_Z12verifyConvOpIN4mlir4tosa17DepthwiseConv2DOpEENS0_13LogicalResultET_:
function _Z12verifyConvOpIN4mlir4tosa17DepthwiseConv2DOpEENS0_13LogicalResultET_ called 0 returned 0% blocks executed 0%
    #####:  103:static LogicalResult verifyConvOp(T op) {
call    0 never executed
        -:  104:  // All TOSA conv ops have an input() and weight().
    #####:  105:  auto inputType =
    #####:  106:      op.getInput().getType().template dyn_cast<RankedTensorType>();
call    0 never executed
call    1 never executed
    #####:  107:  auto weightType =
    #####:  108:      op.getWeight().getType().template dyn_cast<RankedTensorType>();
call    0 never executed
        -:  109:
        -:  110:  // Must be ranked tensor types
    #####:  111:  if (!inputType) {
branch  0 never executed
branch  1 never executed
    #####:  112:    op.emitOpError("expect a ranked tensor for input, got ") << op.getInput();
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
    #####:  113:    return failure();
        -:  114:  }
    #####:  115:  if (!weightType) {
branch  0 never executed
branch  1 never executed
    #####:  116:    op.emitOpError("expect a ranked tensor for weight, got ") << op.getWeight();
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
    #####:  117:    return failure();
        -:  118:  }
        -:  119:
    #####:  120:  auto inputEType = inputType.getElementType();
call    0 never executed
    #####:  121:  auto weightEType = weightType.getElementType();
call    0 never executed
call    1 never executed
        -:  122:
    #####:  123:  bool inputIsQuant = !inputEType.template isa<FloatType>();
call    0 never executed
    #####:  124:  bool weightIsQuant = !weightEType.template isa<FloatType>();
        -:  125:
        -:  126:  // Either both must be quantized or both unquantized.
    #####:  127:  if (inputIsQuant != weightIsQuant) {
branch  0 never executed
branch  1 never executed
        -:  128:    op.emitOpError(
        -:  129:        "expect both input and weight to be float or not together, got ")
    #####:  130:        << inputEType << " and " << weightEType;
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
call    5 never executed
    #####:  131:    return failure();
        -:  132:  }
        -:  133:
        -:  134:  // Quantized type must have constructed the quantizationattr, and unquantized
        -:  135:  // types should not have a quantizationattr.
    #####:  136:  if ((inputIsQuant && !op.getQuantizationInfo()) ||
branch  0 never executed
branch  1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
branch  6 never executed
    #####:  137:      (!inputIsQuant && op.getQuantizationInfo())) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  138:    op.emitOpError("quantizationattr is required for quantized type, and not "
call    0 never executed
call    1 never executed
call    2 never executed
        -:  139:                   "allowed for float type");
    #####:  140:    return failure();
        -:  141:  }
        -:  142:
    #####:  143:  return success();
        -:  144:}
------------------
_Z12verifyConvOpIN4mlir4tosa8Conv3DOpEENS0_13LogicalResultET_:
function _Z12verifyConvOpIN4mlir4tosa8Conv3DOpEENS0_13LogicalResultET_ called 0 returned 0% blocks executed 0%
    #####:  103:static LogicalResult verifyConvOp(T op) {
call    0 never executed
        -:  104:  // All TOSA conv ops have an input() and weight().
    #####:  105:  auto inputType =
    #####:  106:      op.getInput().getType().template dyn_cast<RankedTensorType>();
call    0 never executed
call    1 never executed
    #####:  107:  auto weightType =
    #####:  108:      op.getWeight().getType().template dyn_cast<RankedTensorType>();
call    0 never executed
        -:  109:
        -:  110:  // Must be ranked tensor types
    #####:  111:  if (!inputType) {
branch  0 never executed
branch  1 never executed
    #####:  112:    op.emitOpError("expect a ranked tensor for input, got ") << op.getInput();
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
    #####:  113:    return failure();
        -:  114:  }
    #####:  115:  if (!weightType) {
branch  0 never executed
branch  1 never executed
    #####:  116:    op.emitOpError("expect a ranked tensor for weight, got ") << op.getWeight();
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
    #####:  117:    return failure();
        -:  118:  }
        -:  119:
    #####:  120:  auto inputEType = inputType.getElementType();
call    0 never executed
    #####:  121:  auto weightEType = weightType.getElementType();
call    0 never executed
call    1 never executed
        -:  122:
    #####:  123:  bool inputIsQuant = !inputEType.template isa<FloatType>();
call    0 never executed
    #####:  124:  bool weightIsQuant = !weightEType.template isa<FloatType>();
        -:  125:
        -:  126:  // Either both must be quantized or both unquantized.
    #####:  127:  if (inputIsQuant != weightIsQuant) {
branch  0 never executed
branch  1 never executed
        -:  128:    op.emitOpError(
        -:  129:        "expect both input and weight to be float or not together, got ")
    #####:  130:        << inputEType << " and " << weightEType;
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
call    5 never executed
    #####:  131:    return failure();
        -:  132:  }
        -:  133:
        -:  134:  // Quantized type must have constructed the quantizationattr, and unquantized
        -:  135:  // types should not have a quantizationattr.
    #####:  136:  if ((inputIsQuant && !op.getQuantizationInfo()) ||
branch  0 never executed
branch  1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
branch  6 never executed
    #####:  137:      (!inputIsQuant && op.getQuantizationInfo())) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  138:    op.emitOpError("quantizationattr is required for quantized type, and not "
call    0 never executed
call    1 never executed
call    2 never executed
        -:  139:                   "allowed for float type");
    #####:  140:    return failure();
        -:  141:  }
        -:  142:
    #####:  143:  return success();
        -:  144:}
------------------
_Z12verifyConvOpIN4mlir4tosa8Conv2DOpEENS0_13LogicalResultET_:
function _Z12verifyConvOpIN4mlir4tosa8Conv2DOpEENS0_13LogicalResultET_ called 0 returned 0% blocks executed 0%
    #####:  103:static LogicalResult verifyConvOp(T op) {
call    0 never executed
        -:  104:  // All TOSA conv ops have an input() and weight().
    #####:  105:  auto inputType =
    #####:  106:      op.getInput().getType().template dyn_cast<RankedTensorType>();
call    0 never executed
call    1 never executed
    #####:  107:  auto weightType =
    #####:  108:      op.getWeight().getType().template dyn_cast<RankedTensorType>();
call    0 never executed
        -:  109:
        -:  110:  // Must be ranked tensor types
    #####:  111:  if (!inputType) {
branch  0 never executed
branch  1 never executed
    #####:  112:    op.emitOpError("expect a ranked tensor for input, got ") << op.getInput();
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
    #####:  113:    return failure();
        -:  114:  }
    #####:  115:  if (!weightType) {
branch  0 never executed
branch  1 never executed
    #####:  116:    op.emitOpError("expect a ranked tensor for weight, got ") << op.getWeight();
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
    #####:  117:    return failure();
        -:  118:  }
        -:  119:
    #####:  120:  auto inputEType = inputType.getElementType();
call    0 never executed
    #####:  121:  auto weightEType = weightType.getElementType();
call    0 never executed
call    1 never executed
        -:  122:
    #####:  123:  bool inputIsQuant = !inputEType.template isa<FloatType>();
call    0 never executed
    #####:  124:  bool weightIsQuant = !weightEType.template isa<FloatType>();
        -:  125:
        -:  126:  // Either both must be quantized or both unquantized.
    #####:  127:  if (inputIsQuant != weightIsQuant) {
branch  0 never executed
branch  1 never executed
        -:  128:    op.emitOpError(
        -:  129:        "expect both input and weight to be float or not together, got ")
    #####:  130:        << inputEType << " and " << weightEType;
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
call    5 never executed
    #####:  131:    return failure();
        -:  132:  }
        -:  133:
        -:  134:  // Quantized type must have constructed the quantizationattr, and unquantized
        -:  135:  // types should not have a quantizationattr.
    #####:  136:  if ((inputIsQuant && !op.getQuantizationInfo()) ||
branch  0 never executed
branch  1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
branch  6 never executed
    #####:  137:      (!inputIsQuant && op.getQuantizationInfo())) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  138:    op.emitOpError("quantizationattr is required for quantized type, and not "
call    0 never executed
call    1 never executed
call    2 never executed
        -:  139:                   "allowed for float type");
    #####:  140:    return failure();
        -:  141:  }
        -:  142:
    #####:  143:  return success();
        -:  144:}
------------------
_Z12verifyConvOpIN4mlir4tosa16FullyConnectedOpEENS0_13LogicalResultET_:
function _Z12verifyConvOpIN4mlir4tosa16FullyConnectedOpEENS0_13LogicalResultET_ called 0 returned 0% blocks executed 0%
    #####:  103:static LogicalResult verifyConvOp(T op) {
call    0 never executed
        -:  104:  // All TOSA conv ops have an input() and weight().
    #####:  105:  auto inputType =
    #####:  106:      op.getInput().getType().template dyn_cast<RankedTensorType>();
call    0 never executed
call    1 never executed
    #####:  107:  auto weightType =
    #####:  108:      op.getWeight().getType().template dyn_cast<RankedTensorType>();
call    0 never executed
        -:  109:
        -:  110:  // Must be ranked tensor types
    #####:  111:  if (!inputType) {
branch  0 never executed
branch  1 never executed
    #####:  112:    op.emitOpError("expect a ranked tensor for input, got ") << op.getInput();
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
    #####:  113:    return failure();
        -:  114:  }
    #####:  115:  if (!weightType) {
branch  0 never executed
branch  1 never executed
    #####:  116:    op.emitOpError("expect a ranked tensor for weight, got ") << op.getWeight();
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
    #####:  117:    return failure();
        -:  118:  }
        -:  119:
    #####:  120:  auto inputEType = inputType.getElementType();
call    0 never executed
    #####:  121:  auto weightEType = weightType.getElementType();
call    0 never executed
call    1 never executed
        -:  122:
    #####:  123:  bool inputIsQuant = !inputEType.template isa<FloatType>();
call    0 never executed
    #####:  124:  bool weightIsQuant = !weightEType.template isa<FloatType>();
        -:  125:
        -:  126:  // Either both must be quantized or both unquantized.
    #####:  127:  if (inputIsQuant != weightIsQuant) {
branch  0 never executed
branch  1 never executed
        -:  128:    op.emitOpError(
        -:  129:        "expect both input and weight to be float or not together, got ")
    #####:  130:        << inputEType << " and " << weightEType;
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
call    5 never executed
    #####:  131:    return failure();
        -:  132:  }
        -:  133:
        -:  134:  // Quantized type must have constructed the quantizationattr, and unquantized
        -:  135:  // types should not have a quantizationattr.
    #####:  136:  if ((inputIsQuant && !op.getQuantizationInfo()) ||
branch  0 never executed
branch  1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
branch  6 never executed
    #####:  137:      (!inputIsQuant && op.getQuantizationInfo())) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  138:    op.emitOpError("quantizationattr is required for quantized type, and not "
call    0 never executed
call    1 never executed
call    2 never executed
        -:  139:                   "allowed for float type");
    #####:  140:    return failure();
        -:  141:  }
        -:  142:
    #####:  143:  return success();
        -:  144:}
------------------
        -:  145:
function _ZN4mlir4tosa11AvgPool2dOp6verifyEv called 0 returned 0% blocks executed 0%
    #####:  146:LogicalResult tosa::AvgPool2dOp::verify() {
    #####:  147:  auto inputETy = getInput().getType().cast<ShapedType>().getElementType();
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  148:  auto resultETy = getType().cast<ShapedType>().getElementType();
call    0 never executed
call    1 never executed
        -:  149:
    #####:  150:  if (auto quantType = inputETy.dyn_cast<mlir::quant::UniformQuantizedType>())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  151:    inputETy = quantType.getStorageType();
call    0 never executed
        -:  152:
    #####:  153:  if (auto quantType = resultETy.dyn_cast<mlir::quant::UniformQuantizedType>())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  154:    resultETy = quantType.getStorageType();
call    0 never executed
        -:  155:
    #####:  156:  if (inputETy.isF32() && resultETy.isF32())
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
branch  4 never executed
branch  5 never executed
    #####:  157:    return success();
    #####:  158:  if (inputETy.isInteger(8) && resultETy.isInteger(8))
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
branch  4 never executed
branch  5 never executed
    #####:  159:    return success();
    #####:  160:  if (inputETy.isInteger(16) && resultETy.isInteger(16))
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
branch  4 never executed
branch  5 never executed
    #####:  161:    return success();
        -:  162:
    #####:  163:  return emitOpError("input/output element types are incompatible.");
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
        -:  164:}
        -:  165:
        -:  166://===----------------------------------------------------------------------===//
        -:  167:// TOSA Operator Quantization Builders.
        -:  168://===----------------------------------------------------------------------===//
        -:  169:
        -:  170:/// This builder is called on all convolution operators except TransposeConv,
        -:  171:/// which has specialized output shape semantics. The builder also defines the
        -:  172:/// bitwidth of the output given the bit width of the input & weight content.
function _ZL24buildConvOpWithQuantInfoRN4mlir9OpBuilderERNS_14OperationStateENS_4TypeENS_5ValueES5_S5_NS_9ArrayAttrES6_S6_ called 0 returned 0% blocks executed 0%
    #####:  173:static void buildConvOpWithQuantInfo(OpBuilder &builder, OperationState &result,
        -:  174:                                     Type outputType, Value input, Value weight,
        -:  175:                                     Value bias, ArrayAttr pad,
        -:  176:                                     ArrayAttr stride, ArrayAttr dilation) {
        -:  177:
    #####:  178:  result.addOperands({input, weight, bias});
call    0 never executed
call    1 never executed
    #####:  179:  result.addAttribute("pad", pad);
call    0 never executed
    #####:  180:  result.addAttribute("stride", stride);
call    0 never executed
    #####:  181:  result.addAttribute("dilation", dilation);
call    0 never executed
        -:  182:
    #####:  183:  auto quantAttr = buildConvOpQuantizationAttr(builder, input, weight);
call    0 never executed
    #####:  184:  if (quantAttr) {
branch  0 never executed
branch  1 never executed
    #####:  185:    result.addAttribute("quantization_info", quantAttr);
call    0 never executed
    #####:  186:    result.addTypes(
call    0 never executed
    #####:  187:        buildConvOpResultTypeInfo(builder, outputType, input, weight));
call    0 never executed
call    1 never executed
        -:  188:  } else {
    #####:  189:    result.addTypes(outputType);
call    0 never executed
        -:  190:  }
    #####:  191:}
        -:  192:
        -:  193:/// Handles tosa.transpose_conv2d which has outpad and output shape attributes.
function _ZL29buildTransConvOpWithQuantInfoRN4mlir9OpBuilderERNS_14OperationStateENS_4TypeENS_5ValueES5_S5_NS_9ArrayAttrES6_S6_ called 0 returned 0% blocks executed 0%
    #####:  194:static void buildTransConvOpWithQuantInfo(OpBuilder &builder,
        -:  195:                                          OperationState &result,
        -:  196:                                          Type outputType, Value input,
        -:  197:                                          Value weight, Value bias,
        -:  198:                                          ArrayAttr outpad, ArrayAttr stride,
        -:  199:                                          ArrayAttr outputShape) {
    #####:  200:  result.addOperands({input, weight, bias});
call    0 never executed
call    1 never executed
    #####:  201:  result.addAttribute("out_pad", outpad);
call    0 never executed
    #####:  202:  result.addAttribute("stride", stride);
call    0 never executed
    #####:  203:  result.addAttribute("out_shape", outputShape);
call    0 never executed
    #####:  204:  auto quantAttr = ::buildConvOpQuantizationAttr(builder, input, weight);
call    0 never executed
        -:  205:
    #####:  206:  if (quantAttr) {
branch  0 never executed
branch  1 never executed
    #####:  207:    result.addAttribute("quantization_info", quantAttr);
call    0 never executed
    #####:  208:    result.addTypes(
call    0 never executed
    #####:  209:        buildConvOpResultTypeInfo(builder, outputType, input, weight));
call    0 never executed
call    1 never executed
        -:  210:  } else {
    #####:  211:    result.addTypes(outputType);
call    0 never executed
        -:  212:  }
    #####:  213:}
        -:  214:
        -:  215:/// The tosa.fully_connected op has its own builder as it does not have
        -:  216:/// strides/dilation/padding.
function _ZL22buildFCOpWithQuantInfoRN4mlir9OpBuilderERNS_14OperationStateENS_4TypeENS_5ValueES5_S5_ called 0 returned 0% blocks executed 0%
    #####:  217:static void buildFCOpWithQuantInfo(OpBuilder &builder, OperationState &result,
        -:  218:                                   Type outputType, Value input, Value weight,
        -:  219:                                   Value bias) {
        -:  220:
    #####:  221:  result.addOperands({input, weight, bias});
call    0 never executed
call    1 never executed
    #####:  222:  auto quantAttr = ::buildConvOpQuantizationAttr(builder, input, weight);
call    0 never executed
    #####:  223:  if (quantAttr) {
branch  0 never executed
branch  1 never executed
    #####:  224:    result.addAttribute("quantization_info", quantAttr);
call    0 never executed
    #####:  225:    result.addTypes(
call    0 never executed
    #####:  226:        buildConvOpResultTypeInfo(builder, outputType, input, weight));
call    0 never executed
call    1 never executed
        -:  227:  } else {
    #####:  228:    result.addTypes(outputType);
call    0 never executed
        -:  229:  }
    #####:  230:}
        -:  231:
        -:  232:/// The tosa.matmul op is also intended to be generated where a fully_connected
        -:  233:/// op must be constructed where the weight is not a constant. In this case,
        -:  234:/// the fully_connected op must be expressed using matmul.
        -:  235:/// TODO: Add link to the leglization document explaining this.
function _ZL26buildMatMulOpWithQuantInfoRN4mlir9OpBuilderERNS_14OperationStateENS_4TypeENS_5ValueES5_ called 0 returned 0% blocks executed 0%
    #####:  236:static void buildMatMulOpWithQuantInfo(OpBuilder &builder,
        -:  237:                                       OperationState &result, Type outputType,
        -:  238:                                       Value a, Value b) {
    #####:  239:  result.addOperands({a, b});
call    0 never executed
call    1 never executed
    #####:  240:  auto quantAttr = ::buildMatMulOpQuantizationAttr(builder, a, b);
call    0 never executed
        -:  241:
    #####:  242:  if (quantAttr) {
branch  0 never executed
branch  1 never executed
    #####:  243:    result.addAttribute("quantization_info", quantAttr);
call    0 never executed
        -:  244:
    #####:  245:    auto inputType = a.getType().dyn_cast<ShapedType>();
call    0 never executed
    #####:  246:    assert(inputType && "Input must be a shaped tensor type!");
branch  0 never executed
branch  1 never executed
call    2 never executed
        -:  247:
    #####:  248:    auto inputQType = inputType.getElementType()
call    0 never executed
call    1 never executed
    #####:  249:                          .dyn_cast<mlir::quant::UniformQuantizedType>();
    #####:  250:    assert(inputQType && "Tensor must have quantized datatype!");
branch  0 never executed
branch  1 never executed
call    2 never executed
        -:  251:
    #####:  252:    unsigned inputBits = inputQType.getStorageTypeIntegralWidth();
call    0 never executed
        -:  253:
    #####:  254:    auto outputShapedType = outputType.dyn_cast<ShapedType>();
call    0 never executed
    #####:  255:    assert(outputShapedType && "Output must be a shaped type");
branch  0 never executed
branch  1 never executed
call    2 never executed
        -:  256:
    #####:  257:    IntegerType accElementType;
    #####:  258:    if (inputBits == 16)
branch  0 never executed
branch  1 never executed
    #####:  259:      accElementType = builder.getIntegerType(48);
call    0 never executed
        -:  260:    else
    #####:  261:      accElementType = builder.getI32Type();
call    0 never executed
    #####:  262:    auto accType = outputShapedType.clone(accElementType);
call    0 never executed
    #####:  263:    result.addTypes(accType);
call    0 never executed
        -:  264:  } else {
    #####:  265:    result.addTypes(outputType);
call    0 never executed
        -:  266:  }
    #####:  267:}
        -:  268:
        -:  269:/// Both the tosa.avg_pool2d and unary ops use the same UnaruOpQuantizationAttr
        -:  270:/// but avg_pool operator has its own builder as it has additional parameters
        -:  271:/// not part of the unary ops.
function _ZL29buildAvgPool2dOpWithQuantInfoRN4mlir9OpBuilderERNS_14OperationStateENS_4TypeENS_5ValueENS_9ArrayAttrES6_S6_ called 0 returned 0% blocks executed 0%
    #####:  272:static void buildAvgPool2dOpWithQuantInfo(OpBuilder &builder,
        -:  273:                                          OperationState &result,
        -:  274:                                          Type outputType, Value input,
        -:  275:                                          ArrayAttr kernel, ArrayAttr stride,
        -:  276:                                          ArrayAttr pad) {
    #####:  277:  result.addOperands(input);
call    0 never executed
call    1 never executed
    #####:  278:  result.addAttribute("kernel", kernel);
call    0 never executed
    #####:  279:  result.addAttribute("stride", stride);
call    0 never executed
    #####:  280:  result.addAttribute("pad", pad);
call    0 never executed
    #####:  281:  auto quantAttr = buildUnaryOpQuantizationAttr(builder, input, outputType);
call    0 never executed
    #####:  282:  if (quantAttr)
branch  0 never executed
branch  1 never executed
    #####:  283:    result.addAttribute("quantization_info", quantAttr);
call    0 never executed
    #####:  284:  result.types.push_back(outputType);
call    0 never executed
    #####:  285:}
        -:  286:
        -:  287:/// This builder is called on single-parameter unary operators that have scale
        -:  288:/// relationship between their input and output, expressed by the
        -:  289:/// UnaryOpQuantizationAttr.
function _ZL25buildUnaryOpWithQuantInfoRN4mlir9OpBuilderERNS_14OperationStateENS_4TypeENS_5ValueE called 0 returned 0% blocks executed 0%
    #####:  290:static void buildUnaryOpWithQuantInfo(OpBuilder &builder,
        -:  291:                                      OperationState &result, Type outputType,
        -:  292:                                      Value input) {
    #####:  293:  result.addOperands(input);
call    0 never executed
call    1 never executed
    #####:  294:  auto quantAttr = buildUnaryOpQuantizationAttr(builder, input, outputType);
call    0 never executed
    #####:  295:  if (quantAttr)
branch  0 never executed
branch  1 never executed
    #####:  296:    result.addAttribute("quantization_info", quantAttr);
call    0 never executed
    #####:  297:  result.types.push_back(outputType);
call    0 never executed
    #####:  298:}
        -:  299:
        -:  300:/// This builder is called on TOSA pad operator that needs to create its own
        -:  301:/// OptionalAttr quantization_attr parameter to scale the padding values
        -:  302:/// correctly. No pad_const is interpreted as zero-padding.
function _ZL23buildPadOpWithQuantInfoRN4mlir9OpBuilderERNS_14OperationStateENS_4TypeENS_5ValueES5_ called 0 returned 0% blocks executed 0%
    #####:  303:static void buildPadOpWithQuantInfo(OpBuilder &builder, OperationState &result,
        -:  304:                                    Type outputType, Value input,
        -:  305:                                    Value paddings) {
    #####:  306:  result.addOperands({input, paddings});
call    0 never executed
call    1 never executed
    #####:  307:  auto quantAttr = buildPadOpQuantizationAttr(builder, input);
call    0 never executed
    #####:  308:  if (quantAttr)
branch  0 never executed
branch  1 never executed
    #####:  309:    result.addAttribute("quantization_info", quantAttr);
call    0 never executed
    #####:  310:  result.types.push_back(outputType);
call    0 never executed
    #####:  311:}
        -:  312:
        -:  313:/// This builder is called on TOSA pad operator when an explicit pad_const
        -:  314:/// value is passed in. It also optionally constructs quantization_attr.
function _ZL36buildExplicitValuePadOpWithQuantInfoRN4mlir9OpBuilderERNS_14OperationStateENS_4TypeENS_5ValueES5_S5_ called 0 returned 0% blocks executed 0%
    #####:  315:static void buildExplicitValuePadOpWithQuantInfo(OpBuilder &builder,
        -:  316:                                                 OperationState &result,
        -:  317:                                                 Type outputType, Value input,
        -:  318:                                                 Value paddings,
        -:  319:                                                 Value padConst) {
    #####:  320:  result.addOperands({input, paddings, padConst});
call    0 never executed
call    1 never executed
    #####:  321:  auto quantAttr = buildPadOpQuantizationAttr(builder, input);
call    0 never executed
    #####:  322:  if (quantAttr)
branch  0 never executed
branch  1 never executed
    #####:  323:    result.addAttribute("quantization_info", quantAttr);
call    0 never executed
    #####:  324:  result.types.push_back(outputType);
call    0 never executed
    #####:  325:}
        -:  326:
        -:  327://===----------------------------------------------------------------------===//
        -:  328:// TOSA Operator Return Type Inference.
        -:  329://===----------------------------------------------------------------------===//
        -:  330:
function _ZL12getI64ValuesN4mlir9ArrayAttrERN4llvm11SmallVectorIlLj6EEE called 0 returned 0% blocks executed 0%
    #####:  331:static void getI64Values(ArrayAttr arrayAttr, SmallVector<int64_t> &values) {
    #####:  332:  for (auto it : arrayAttr) {
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  333:    values.push_back(it.cast<IntegerAttr>().getValue().getSExtValue());
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
branch  4 never executed
branch  5 never executed
        -:  334:  }
    #####:  335:}
        -:  336:
function _ZL21resolveBroadcastShapeRKN4mlir15ValueShapeRangeERN4llvm11SmallVectorIlLj6EEE called 0 returned 0% blocks executed 0%
    #####:  337:static LogicalResult resolveBroadcastShape(const ValueShapeRange &operands,
        -:  338:                                           SmallVector<int64_t> &outShape) {
    #####:  339:  int64_t outRank = 0;
    #####:  340:  for (int i = 0, e = operands.size(); i != e; ++i) {
branch  0 never executed
branch  1 never executed
    #####:  341:    auto shape = operands.getShape(i);
call    0 never executed
    #####:  342:    if (!shape.hasRank()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  343:      // TODO(jennik): Update function to have better case handling for invalid
        -:  344:      // operands and for ranked tensors.
    #####:  345:      return failure();
        -:  346:    }
    #####:  347:    outRank = std::max<int64_t>(outRank, shape.getRank());
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  348:  }
        -:  349:
    #####:  350:  outShape.resize(outRank, 1);
call    0 never executed
        -:  351:
    #####:  352:  for (int i = 0, e = operands.size(); i != e; ++i) {
branch  0 never executed
branch  1 never executed
    #####:  353:    auto shape = operands.getShape(i);
call    0 never executed
    #####:  354:    auto rankDiff = outShape.size() - shape.getRank();
call    0 never executed
        -:  355:
    #####:  356:    for (size_t i = 0, e = shape.getRank(); i < e; ++i) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  357:      auto dim1 = outShape[i + rankDiff];
branch  0 never executed
branch  1 never executed
    #####:  358:      auto dim2 = shape.getDimSize(i);
call    0 never executed
    #####:  359:      auto resolvedDim = dim1;
        -:  360:
    #####:  361:      if (dim1 == 1) {
branch  0 never executed
branch  1 never executed
        -:  362:        resolvedDim = dim2;
    #####:  363:      } else if (dim2 == 1) {
branch  0 never executed
branch  1 never executed
        -:  364:        resolvedDim = dim1;
    #####:  365:      } else if (dim1 != dim2) {
branch  0 never executed
branch  1 never executed
    #####:  366:        return failure();
        -:  367:      }
    #####:  368:      outShape[i + rankDiff] = resolvedDim;
branch  0 never executed
branch  1 never executed
        -:  369:    }
        -:  370:  }
        -:  371:
    #####:  372:  return success();
        -:  373:}
        -:  374:
function _ZN4mlir4tosa8ArgMaxOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  375:LogicalResult tosa::ArgMaxOp::inferReturnTypeComponents(
        -:  376:    MLIRContext *context, ::llvm::Optional<Location> location,
        -:  377:    ValueShapeRange operands, DictionaryAttr attributes, RegionRange regions,
        -:  378:    SmallVectorImpl<ShapedTypeComponents> &inferredReturnShapes) {
    #####:  379:  ShapeAdaptor inputShape = operands.getShape(0);
call    0 never executed
    #####:  380:  IntegerAttr axis = attributes.get("axis").cast<IntegerAttr>();
call    0 never executed
call    1 never executed
    #####:  381:  int32_t axisVal = axis.getValue().getSExtValue();
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
        -:  382:
    #####:  383:  if (!inputShape.hasRank()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  384:    inferredReturnShapes.push_back(ShapedTypeComponents());
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  385:    return success();
        -:  386:  }
        -:  387:
    #####:  388:  SmallVector<int64_t> outShape;
call    0 never executed
    #####:  389:  outShape.reserve(inputShape.getRank() - 1);
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  390:  for (int i = 0, s = inputShape.getRank(); i < s; i++) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  391:    if (i == axisVal)
branch  0 never executed
branch  1 never executed
    #####:  392:      continue;
    #####:  393:    outShape.push_back(inputShape.getDimSize(i));
call    0 never executed
call    1 never executed
        -:  394:  }
        -:  395:
    #####:  396:  inferredReturnShapes.push_back(ShapedTypeComponents(outShape));
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  397:  return success();
branch  0 never executed
branch  1 never executed
        -:  398:}
        -:  399:
function _ZN4mlir4tosa8ConcatOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  400:LogicalResult tosa::ConcatOp::inferReturnTypeComponents(
        -:  401:    MLIRContext *context, ::llvm::Optional<Location> location,
        -:  402:    ValueShapeRange operands, DictionaryAttr attributes, RegionRange regions,
        -:  403:    SmallVectorImpl<ShapedTypeComponents> &inferredReturnShapes) {
        -:  404:  // Infer all dimension sizes by reducing based on inputs.
    #####:  405:  int32_t axis =
call    0 never executed
    #####:  406:      attributes.get("axis").cast<IntegerAttr>().getValue().getSExtValue();
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
branch  4 never executed
branch  5 never executed
    #####:  407:  llvm::SmallVector<int64_t> outputShape;
    #####:  408:  bool hasRankedInput = false;
    #####:  409:  for (auto operand : operands) {
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  410:    ShapeAdaptor operandShape = operands.getShape(operand);
call    0 never executed
    #####:  411:    if (!operandShape.hasRank())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  412:      continue;
        -:  413:
        -:  414:    // Copy the Operand's rank.
    #####:  415:    if (!hasRankedInput)
branch  0 never executed
branch  1 never executed
    #####:  416:      outputShape.resize(operandShape.getRank(), ShapedType::kDynamicSize);
call    0 never executed
call    1 never executed
        -:  417:
        -:  418:    // Copy shapes until the dim is non-dynamic.
    #####:  419:    for (int i = 0, s = operandShape.getRank(); i < s; i++) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  420:      if (i == axis || operandShape.isDynamicDim(i))
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####:  421:        continue;
    #####:  422:      if (outputShape[i] == ShapedType::kDynamicSize)
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####:  423:        outputShape[i] = operandShape.getDimSize(i);
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  424:      if (outputShape[i] != operandShape.getDimSize(i))
branch  0 never executed
branch  1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
    #####:  425:        return failure();
        -:  426:    }
        -:  427:
    #####:  428:    hasRankedInput = true;
        -:  429:  }
        -:  430:
    #####:  431:  if (!hasRankedInput) {
branch  0 never executed
branch  1 never executed
    #####:  432:    inferredReturnShapes.push_back(ShapedTypeComponents());
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  433:    return success();
        -:  434:  }
        -:  435:
        -:  436:  // Determine the dimension size along the concatenation axis.
    #####:  437:  int64_t concatDimSize = 0;
    #####:  438:  for (auto operand : operands) {
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  439:    ShapeAdaptor operandShape = operands.getShape(operand);
call    0 never executed
        -:  440:
        -:  441:    // We need to know the length of the concatenation axis of all inputs to
        -:  442:    // determine the dimension size of the output shape.
    #####:  443:    if (!operandShape.hasRank() || operandShape.isDynamicDim(axis)) {
call    0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
    #####:  444:      concatDimSize = ShapedType::kDynamicSize;
    #####:  445:      break;
        -:  446:    }
        -:  447:
    #####:  448:    concatDimSize += operandShape.getDimSize(axis);
call    0 never executed
        -:  449:  }
        -:  450:
    #####:  451:  outputShape[axis] = concatDimSize;
branch  0 never executed
branch  1 never executed
        -:  452:
    #####:  453:  inferredReturnShapes.push_back(ShapedTypeComponents(outputShape));
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  454:  return success();
branch  0 never executed
branch  1 never executed
        -:  455:}
        -:  456:
function _ZN4mlir4tosa7EqualOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  457:LogicalResult tosa::EqualOp::inferReturnTypeComponents(
        -:  458:    MLIRContext *context, ::llvm::Optional<Location> location,
        -:  459:    ValueShapeRange operands, DictionaryAttr attributes, RegionRange regions,
        -:  460:    SmallVectorImpl<ShapedTypeComponents> &inferredReturnShapes) {
    #####:  461:  llvm::SmallVector<int64_t> outShape;
call    0 never executed
    #####:  462:  if (resolveBroadcastShape(operands, outShape).failed()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  463:    inferredReturnShapes.push_back(ShapedTypeComponents());
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  464:    return success();
        -:  465:  }
        -:  466:
    #####:  467:  inferredReturnShapes.push_back(
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  468:      ShapedTypeComponents(outShape, IntegerType::get(context, /*width=*/1)));
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  469:  return success();
branch  0 never executed
branch  1 never executed
        -:  470:}
        -:  471:
function _ZN4mlir4tosa7EqualOp23isCompatibleReturnTypesENS_9TypeRangeES2_ called 0 returned 0% blocks executed 0%
    #####:  472:bool tosa::EqualOp::isCompatibleReturnTypes(TypeRange l, TypeRange r) {
    #####:  473:  if (l.size() != r.size() || l.size() != 1)
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
        -:  474:    return false;
    #####:  475:  return succeeded(verifyCompatibleShape(l[0], r[0]));
call    0 never executed
call    1 never executed
call    2 never executed
        -:  476:}
        -:  477:
function _ZN4mlir4tosa16FullyConnectedOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  478:LogicalResult tosa::FullyConnectedOp::inferReturnTypeComponents(
        -:  479:    MLIRContext *context, ::llvm::Optional<Location> location,
        -:  480:    ValueShapeRange operands, DictionaryAttr attributes, RegionRange regions,
        -:  481:    SmallVectorImpl<ShapedTypeComponents> &inferredReturnShapes) {
    #####:  482:  ShapeAdaptor inputShape = operands.getShape(0);
call    0 never executed
    #####:  483:  ShapeAdaptor weightShape = operands.getShape(1);
call    0 never executed
    #####:  484:  ShapeAdaptor biasShape = operands.getShape(2);
call    0 never executed
        -:  485:
        -:  486:  // All shapes are dynamic.
    #####:  487:  SmallVector<int64_t> outShape;
call    0 never executed
    #####:  488:  outShape.resize(2, ShapedType::kDynamicSize);
call    0 never executed
        -:  489:
    #####:  490:  if (inputShape.hasRank()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  491:    outShape[0] = inputShape.getDimSize(0);
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  492:  }
        -:  493:
    #####:  494:  if (weightShape.hasRank()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  495:    outShape[1] = weightShape.getDimSize(0);
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  496:  }
        -:  497:
    #####:  498:  if (biasShape.hasRank()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  499:    outShape[1] = outShape[1] == ShapedType::kDynamicSize
branch  0 never executed
branch  1 never executed
    #####:  500:                      ? biasShape.getDimSize(0)
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  501:                      : outShape[1];
branch  0 never executed
branch  1 never executed
        -:  502:  }
        -:  503:
    #####:  504:  inferredReturnShapes.push_back(ShapedTypeComponents(outShape));
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  505:  return success();
branch  0 never executed
branch  1 never executed
        -:  506:}
        -:  507:
function _ZN4mlir4tosa16FullyConnectedOp6verifyEv called 0 returned 0% blocks executed 0%
    #####:  508:LogicalResult FullyConnectedOp::verify() { return verifyConvOp(*this); }
call    0 never executed
call    1 never executed
call    2 never executed
        -:  509:
function _ZN4mlir4tosa8MatMulOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  510:LogicalResult tosa::MatMulOp::inferReturnTypeComponents(
        -:  511:    MLIRContext *context, ::llvm::Optional<Location> location,
        -:  512:    ValueShapeRange operands, DictionaryAttr attributes, RegionRange regions,
        -:  513:    SmallVectorImpl<ShapedTypeComponents> &inferredReturnShapes) {
    #####:  514:  ShapeAdaptor lhsShape = operands.getShape(0);
call    0 never executed
    #####:  515:  ShapeAdaptor rhsShape = operands.getShape(1);
call    0 never executed
        -:  516:
        -:  517:  // All shapes are dynamic.
    #####:  518:  SmallVector<int64_t> outShape;
call    0 never executed
    #####:  519:  outShape.resize(3, ShapedType::kDynamicSize);
call    0 never executed
        -:  520:
    #####:  521:  if (lhsShape.hasRank()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  522:    outShape[0] = lhsShape.getDimSize(0);
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  523:    outShape[1] = lhsShape.getDimSize(1);
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  524:  }
        -:  525:
    #####:  526:  if (rhsShape.hasRank()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  527:    outShape[0] = outShape[0] == ShapedType::kDynamicSize
branch  0 never executed
branch  1 never executed
    #####:  528:                      ? rhsShape.getDimSize(0)
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  529:                      : outShape[0];
branch  0 never executed
branch  1 never executed
    #####:  530:    outShape[2] = rhsShape.getDimSize(2);
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  531:  }
        -:  532:
    #####:  533:  inferredReturnShapes.push_back(ShapedTypeComponents(outShape));
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  534:  return success();
branch  0 never executed
branch  1 never executed
        -:  535:}
        -:  536:
function _ZN4mlir4tosa5PadOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  537:LogicalResult tosa::PadOp::inferReturnTypeComponents(
        -:  538:    MLIRContext *context, ::llvm::Optional<Location> location,
        -:  539:    ValueShapeRange operands, DictionaryAttr attributes, RegionRange regions,
        -:  540:    SmallVectorImpl<ShapedTypeComponents> &inferredReturnShapes) {
    #####:  541:  ShapeAdaptor inputShape = operands.getShape(0);
call    0 never executed
    #####:  542:  ShapeAdaptor paddingShape = operands.getShape(1);
call    0 never executed
    #####:  543:  SmallVector<int64_t> outputShape;
call    0 never executed
        -:  544:
        -:  545:  // If both inputs have unknown shape, we cannot determine the shape of the
        -:  546:  // output.
    #####:  547:  if (!inputShape.hasRank() && !paddingShape.hasRank()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
branch  4 never executed
branch  5 never executed
    #####:  548:    inferredReturnShapes.push_back(ShapedTypeComponents());
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  549:    return success();
        -:  550:  }
        -:  551:
        -:  552:  // If the input rank is unknown we can info the output rank using the padding
        -:  553:  // shape's first dim.
    #####:  554:  if (!inputShape.hasRank()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  555:    if (paddingShape.isDynamicDim(0)) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  556:      inferredReturnShapes.push_back(ShapedTypeComponents());
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  557:      return success();
        -:  558:    }
        -:  559:
    #####:  560:    outputShape.resize(paddingShape.getDimSize(0), ShapedType::kDynamicSize);
call    0 never executed
call    1 never executed
    #####:  561:    inferredReturnShapes.push_back(ShapedTypeComponents(outputShape));
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  562:    return success();
        -:  563:  }
        -:  564:
    #####:  565:  DenseIntElementsAttr paddings;
        -:  566:  // If the paddings value is not a constant, all dimensions must be dynamic.
    #####:  567:  if (!matchPattern(operands[1], m_Constant(&paddings))) {
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  568:    outputShape.resize(inputShape.getRank(), ShapedType::kDynamicSize);
call    0 never executed
call    1 never executed
    #####:  569:    inferredReturnShapes.push_back(ShapedTypeComponents(outputShape));
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  570:    return success();
        -:  571:  }
        -:  572:
    #####:  573:  SmallVector<int64_t> paddingValues;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  574:  for (auto val : paddings) {
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
call    4 never executed
    #####:  575:    paddingValues.push_back(val.getSExtValue());
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
        -:  576:  }
        -:  577:
    #####:  578:  outputShape.reserve(inputShape.getRank());
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  579:  for (int i = 0, s = inputShape.getRank(); i < s; i++) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  580:    if (inputShape.isDynamicDim(i)) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  581:      outputShape.push_back(ShapedType::kDynamicSize);
call    0 never executed
    #####:  582:      continue;
        -:  583:    }
        -:  584:
    #####:  585:    outputShape.push_back(inputShape.getDimSize(i) + paddingValues[i * 2] +
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  586:                          paddingValues[i * 2 + 1]);
branch  0 never executed
branch  1 never executed
call    2 never executed
        -:  587:  }
        -:  588:
    #####:  589:  inferredReturnShapes.push_back(ShapedTypeComponents(outputShape));
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  590:  return success();
branch  0 never executed
branch  1 never executed
        -:  591:}
        -:  592:
function _ZN4mlir4tosa7SliceOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  593:LogicalResult tosa::SliceOp::inferReturnTypeComponents(
        -:  594:    MLIRContext *context, ::llvm::Optional<Location> location,
        -:  595:    ValueShapeRange operands, DictionaryAttr attributes, RegionRange regions,
        -:  596:    SmallVectorImpl<ShapedTypeComponents> &inferredReturnShapes) {
    #####:  597:  ArrayAttr sizes = SliceOpAdaptor(operands, attributes).getSize();
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:  598:  SmallVector<int64_t> outputShape;
call    0 never executed
    #####:  599:  outputShape.reserve(sizes.size());
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  600:  for (auto val : sizes) {
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  601:    outputShape.push_back(val.cast<IntegerAttr>().getValue().getSExtValue());
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
branch  4 never executed
branch  5 never executed
        -:  602:  }
        -:  603:
    #####:  604:  inferredReturnShapes.push_back(ShapedTypeComponents(outputShape));
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  605:  return success();
branch  0 never executed
branch  1 never executed
        -:  606:}
        -:  607:
function _ZN4mlir4tosa7TableOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  608:LogicalResult tosa::TableOp::inferReturnTypeComponents(
        -:  609:    MLIRContext *context, ::llvm::Optional<Location> location,
        -:  610:    ValueShapeRange operands, DictionaryAttr attributes, RegionRange regions,
        -:  611:    SmallVectorImpl<ShapedTypeComponents> &inferredReturnShapes) {
    #####:  612:  ShapeAdaptor inputShape = operands.getShape(0);
call    0 never executed
        -:  613:
    #####:  614:  if (!inputShape.hasRank()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  615:    inferredReturnShapes.push_back(ShapedTypeComponents());
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  616:    return success();
        -:  617:  }
        -:  618:
    #####:  619:  inferredReturnShapes.resize(1);
call    0 never executed
    #####:  620:  inputShape.getDims(inferredReturnShapes[0]);
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  621:  return success();
        -:  622:}
        -:  623:
function _ZN4mlir4tosa6TileOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  624:LogicalResult tosa::TileOp::inferReturnTypeComponents(
        -:  625:    MLIRContext *context, ::llvm::Optional<Location> location,
        -:  626:    ValueShapeRange operands, DictionaryAttr attributes, RegionRange regions,
        -:  627:    SmallVectorImpl<ShapedTypeComponents> &inferredReturnShapes) {
    #####:  628:  TileOpAdaptor adaptor(operands, attributes);
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  629:  ArrayAttr multiples = adaptor.getMultiples();
call    0 never executed
    #####:  630:  ShapeAdaptor inputShape = operands.getShape(0);
call    0 never executed
    #####:  631:  SmallVector<int64_t> outputShape;
call    0 never executed
    #####:  632:  if (!inputShape.hasRank()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  633:    outputShape.resize(multiples.size(), ShapedType::kDynamicSize);
call    0 never executed
call    1 never executed
    #####:  634:    inferredReturnShapes.push_back(ShapedTypeComponents(outputShape));
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  635:    return success();
        -:  636:  }
        -:  637:
        -:  638:  // We need the multiple values to determine the output shape.
    #####:  639:  SmallVector<int64_t> multipleValues;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  640:  multipleValues.reserve(multiples.size());
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  641:  for (auto val : multiples) {
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  642:    multipleValues.push_back(val.cast<IntegerAttr>().getValue().getSExtValue());
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
branch  4 never executed
branch  5 never executed
        -:  643:  }
        -:  644:
        -:  645:  // Any non dynamic dimension can be multiplied to a known size.
    #####:  646:  outputShape.reserve(multiples.size());
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  647:  for (int i = 0, s = inputShape.getRank(); i < s; i++) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  648:    int64_t dim = inputShape.getDimSize(i);
call    0 never executed
    #####:  649:    if (dim != ShapedType::kDynamicSize)
branch  0 never executed
branch  1 never executed
    #####:  650:      dim *= multipleValues[i];
branch  0 never executed
branch  1 never executed
    #####:  651:    outputShape.push_back(dim);
call    0 never executed
        -:  652:  }
        -:  653:
    #####:  654:  inferredReturnShapes.push_back(ShapedTypeComponents(outputShape));
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  655:  return success();
branch  0 never executed
branch  1 never executed
        -:  656:}
        -:  657:
    #####:  658:static SmallVector<int64_t> ConvertToMlirShape(ArrayRef<int64_t> shape) {
    #####:  659:  return to_vector(llvm::map_range(shape, [](int64_t dim) {
    #####:  660:    return dim == -1 ? ShapedType::kDynamicSize : dim;
branch  0 never executed
branch  1 never executed
    #####:  661:  }));
call    0 never executed
call    1 never executed
        -:  662:}
        -:  663:
function _ZN4mlir4tosa9ReshapeOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  664:LogicalResult tosa::ReshapeOp::inferReturnTypeComponents(
        -:  665:    MLIRContext *context, ::llvm::Optional<Location> location,
        -:  666:    ValueShapeRange operands, DictionaryAttr attributes, RegionRange regions,
        -:  667:    SmallVectorImpl<ShapedTypeComponents> &inferredReturnShapes) {
    #####:  668:  ReshapeOpAdaptor adaptor(operands, attributes);
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  669:  ShapeAdaptor inputShape = operands.getShape(0);
call    0 never executed
        -:  670:
    #####:  671:  ArrayAttr newShape = adaptor.getNewShape();
call    0 never executed
    #####:  672:  llvm::SmallVector<int64_t> newShapeValue;
call    0 never executed
    #####:  673:  getI64Values(newShape, newShapeValue);
call    0 never executed
    #####:  674:  newShapeValue = ConvertToMlirShape(newShapeValue);
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
        -:  675:
        -:  676:  // We cannot infer from the total number of elements so we must take the
        -:  677:  // shape attribute as exact.
    #####:  678:  if (!inputShape.hasRank() || !inputShape.hasStaticShape()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
branch  4 never executed
branch  5 never executed
    #####:  679:    inferredReturnShapes.push_back(ShapedTypeComponents(newShapeValue));
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  680:    return success();
        -:  681:  }
        -:  682:
        -:  683:  // Determine the number of elements covered by the slice of all static
        -:  684:  // dimensions. This allows us to infer the length of the remaining dynamic
        -:  685:  // dimension.
    #####:  686:  int64_t numElements = inputShape.getNumElements();
call    0 never executed
    #####:  687:  int64_t staticMul = 1;
    #####:  688:  for (auto val : newShapeValue) {
branch  0 never executed
branch  1 never executed
    #####:  689:    if (!ShapedType::isDynamic(val)) {
branch  0 never executed
branch  1 never executed
    #####:  690:      staticMul *= val;
        -:  691:    }
        -:  692:  }
        -:  693:
        -:  694:  // Determine the length of the dynamic dimension.
    #####:  695:  for (auto &val : newShapeValue) {
branch  0 never executed
branch  1 never executed
    #####:  696:    if (ShapedType::isDynamic(val))
branch  0 never executed
branch  1 never executed
    #####:  697:      val = numElements / staticMul;
        -:  698:  }
        -:  699:
    #####:  700:  inferredReturnShapes.push_back(ShapedTypeComponents(newShapeValue));
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  701:  return success();
branch  0 never executed
branch  1 never executed
        -:  702:}
        -:  703:
function _ZN4mlir4tosa11TransposeOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  704:LogicalResult tosa::TransposeOp::inferReturnTypeComponents(
        -:  705:    MLIRContext *context, ::llvm::Optional<Location> location,
        -:  706:    ValueShapeRange operands, DictionaryAttr attributes, RegionRange regions,
        -:  707:    SmallVectorImpl<ShapedTypeComponents> &inferredReturnShapes) {
    #####:  708:  ShapeAdaptor inputShape = operands.getShape(0);
call    0 never executed
    #####:  709:  ShapeAdaptor permsShape = operands.getShape(1);
call    0 never executed
        -:  710:
        -:  711:  // If input rank and permutation length is unknown, the output rank is
        -:  712:  // unknown.
    #####:  713:  if (!inputShape.hasRank() || !permsShape.hasRank() ||
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
branch  4 never executed
branch  5 never executed
    #####:  714:      permsShape.isDynamicDim(0)) {
branch  0 never executed
branch  1 never executed
    #####:  715:    inferredReturnShapes.push_back(ShapedTypeComponents());
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  716:    return success();
        -:  717:  }
        -:  718:
        -:  719:  // This would imply the number of permutations does not match the rank of the
        -:  720:  // input which is illegal.
    #####:  721:  if (permsShape.getDimSize(0) != inputShape.getRank()) {
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  722:    return failure();
        -:  723:  }
        -:  724:
        -:  725:  // Without the input dims we cannot determine the output dim sizes but we
        -:  726:  // can determine the output rank.
    #####:  727:  SmallVector<int64_t> outputShape;
call    0 never executed
    #####:  728:  if (!inputShape.hasRank()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  729:    outputShape.resize(permsShape.getDimSize(0), ShapedType::kDynamicSize);
call    0 never executed
call    1 never executed
    #####:  730:    inferredReturnShapes.push_back(ShapedTypeComponents(outputShape));
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  731:    return success();
        -:  732:  }
        -:  733:
        -:  734:  // Rank-0 means no permutations matter.
    #####:  735:  if (inputShape.getRank() == 0) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  736:    inferredReturnShapes.push_back(ShapedTypeComponents(outputShape));
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  737:    return success();
        -:  738:  }
        -:  739:
        -:  740:  // Check whether the input dimensions are all the same.
    #####:  741:  bool allTheSame = true;
    #####:  742:  for (int i = 1, s = inputShape.getRank(); i < s; i++) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  743:    if (inputShape.getDimSize(0) != inputShape.getDimSize(i)) {
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
        -:  744:      allTheSame = false;
        -:  745:      break;
        -:  746:    }
        -:  747:  }
        -:  748:
        -:  749:  // If all of the input dimensions are the same we don't care about the
        -:  750:  // permutation.
    #####:  751:  if (allTheSame) {
branch  0 never executed
branch  1 never executed
    #####:  752:    outputShape.resize(inputShape.getRank(), inputShape.getDimSize(0));
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  753:    inferredReturnShapes.push_back(ShapedTypeComponents(outputShape));
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  754:    return success();
        -:  755:  }
        -:  756:
    #####:  757:  outputShape.resize(inputShape.getRank(), ShapedType::kDynamicSize);
call    0 never executed
call    1 never executed
        -:  758:  // If the permuations are a constant we can directly determine the output
        -:  759:  // shape.
    #####:  760:  if (ShapeAdaptor permShape = operands.getValueAsShape(1)) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  761:    outputShape.reserve(inputShape.getRank());
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  762:    for (int i = 0, s = inputShape.getRank(); i < s; i++) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  763:      outputShape[i] = inputShape.getDimSize(permShape.getDimSize(i));
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
        -:  764:    }
        -:  765:  }
        -:  766:
    #####:  767:  inferredReturnShapes.push_back(ShapedTypeComponents(outputShape));
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  768:  return success();
branch  0 never executed
branch  1 never executed
        -:  769:}
        -:  770:
function _ZN4mlir4tosa8GatherOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  771:LogicalResult tosa::GatherOp::inferReturnTypeComponents(
        -:  772:    MLIRContext *context, ::llvm::Optional<Location> location,
        -:  773:    ValueShapeRange operands, DictionaryAttr attributes, RegionRange regions,
        -:  774:    SmallVectorImpl<ShapedTypeComponents> &inferredReturnShapes) {
    #####:  775:  llvm::SmallVector<int64_t> outputShape;
call    0 never executed
    #####:  776:  outputShape.resize(3, ShapedType::kDynamicSize);
call    0 never executed
        -:  777:
    #####:  778:  ShapeAdaptor valuesShape = operands.getShape(0);
call    0 never executed
    #####:  779:  if (valuesShape.hasRank()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  780:    outputShape[0] = valuesShape.getDimSize(0);
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  781:    outputShape[2] = valuesShape.getDimSize(2);
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  782:  }
        -:  783:
    #####:  784:  ShapeAdaptor indicesShape = operands.getShape(1);
call    0 never executed
    #####:  785:  if (indicesShape.hasRank()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  786:    if (outputShape[0] == ShapedType::kDynamicSize)
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####:  787:      outputShape[0] = indicesShape.getDimSize(0);
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  788:    if (outputShape[1] == ShapedType::kDynamicSize)
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####:  789:      outputShape[1] = indicesShape.getDimSize(1);
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  790:  }
        -:  791:
    #####:  792:  inferredReturnShapes.push_back(ShapedTypeComponents(outputShape));
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  793:  return success();
branch  0 never executed
branch  1 never executed
        -:  794:}
        -:  795:
function _ZN4mlir4tosa8ResizeOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  796:LogicalResult tosa::ResizeOp::inferReturnTypeComponents(
        -:  797:    MLIRContext *context, ::llvm::Optional<Location> location,
        -:  798:    ValueShapeRange operands, DictionaryAttr attributes, RegionRange regions,
        -:  799:    SmallVectorImpl<ShapedTypeComponents> &inferredReturnShapes) {
    #####:  800:  ResizeOpAdaptor adaptor(operands, attributes);
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  801:  llvm::SmallVector<int64_t, 4> outputShape;
call    0 never executed
    #####:  802:  outputShape.resize(4, ShapedType::kDynamicSize);
call    0 never executed
        -:  803:
    #####:  804:  ShapeAdaptor inputShape = operands.getShape(adaptor.getInput());
call    0 never executed
call    1 never executed
    #####:  805:  if (!inputShape.hasRank())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  806:    return failure();
        -:  807:
    #####:  808:  outputShape[0] = inputShape.getDimSize(0);
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  809:  outputShape[3] = inputShape.getDimSize(3);
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  810:  int64_t inputHeight = inputShape.getDimSize(1);
call    0 never executed
    #####:  811:  int64_t inputWidth = inputShape.getDimSize(2);
call    0 never executed
        -:  812:
    #####:  813:  if ((inputHeight == ShapedType::kDynamicSize) ||
    #####:  814:      (inputWidth == ShapedType::kDynamicSize))
branch  0 never executed
branch  1 never executed
    #####:  815:    return failure();
        -:  816:
    #####:  817:  llvm::SmallVector<int64_t> scaleInt;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  818:  llvm::SmallVector<int64_t> offsetInt;
branch  0 never executed
branch  1 never executed
    #####:  819:  llvm::SmallVector<int64_t> borderInt;
branch  0 never executed
branch  1 never executed
    #####:  820:  getI64Values(adaptor.getScale(), scaleInt);
call    0 never executed
call    1 never executed
    #####:  821:  getI64Values(adaptor.getOffset(), offsetInt);
call    0 never executed
call    1 never executed
    #####:  822:  getI64Values(adaptor.getBorder(), borderInt);
call    0 never executed
call    1 never executed
        -:  823:
        -:  824:  // Compute the output shape based on attributes: scale, offset, and border.
    #####:  825:  outputShape[1] =
    #####:  826:      (((inputHeight - 1) * scaleInt[0] - offsetInt[0] + borderInt[0]) /
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
branch  6 never executed
branch  7 never executed
    #####:  827:       scaleInt[1]) +
branch  0 never executed
branch  1 never executed
        -:  828:      1;
        -:  829:
    #####:  830:  outputShape[2] =
    #####:  831:      (((inputWidth - 1) * scaleInt[2] - offsetInt[1] + borderInt[1]) /
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
branch  6 never executed
branch  7 never executed
    #####:  832:       scaleInt[3]) +
branch  0 never executed
branch  1 never executed
        -:  833:      1;
        -:  834:
    #####:  835:  inferredReturnShapes.push_back(ShapedTypeComponents(outputShape));
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  836:  return success();
branch  0 never executed
branch  1 never executed
        -:  837:}
        -:  838:
function _ZN4mlir4tosa9ScatterOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  839:LogicalResult tosa::ScatterOp::inferReturnTypeComponents(
        -:  840:    MLIRContext *context, ::llvm::Optional<Location> location,
        -:  841:    ValueShapeRange operands, DictionaryAttr attributes, RegionRange regions,
        -:  842:    SmallVectorImpl<ShapedTypeComponents> &inferredReturnShapes) {
    #####:  843:  llvm::SmallVector<int64_t> outputShape;
call    0 never executed
    #####:  844:  outputShape.resize(3, ShapedType::kDynamicSize);
call    0 never executed
        -:  845:
    #####:  846:  ShapeAdaptor valuesInShape = operands.getShape(0);
call    0 never executed
    #####:  847:  if (valuesInShape.hasRank()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  848:    outputShape[0] = valuesInShape.getDimSize(0);
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  849:    outputShape[1] = valuesInShape.getDimSize(1);
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  850:    outputShape[2] = valuesInShape.getDimSize(2);
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  851:  }
        -:  852:
    #####:  853:  ShapeAdaptor indicesShape = operands.getShape(1);
call    0 never executed
    #####:  854:  if (indicesShape.hasRank()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  855:    if (outputShape[0] == ShapedType::kDynamicSize)
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####:  856:      outputShape[0] = indicesShape.getDimSize(0);
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  857:  }
        -:  858:
    #####:  859:  ShapeAdaptor inputShape = operands.getShape(2);
call    0 never executed
    #####:  860:  if (inputShape.hasRank()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  861:    if (outputShape[0] == ShapedType::kDynamicSize)
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####:  862:      outputShape[0] = inputShape.getDimSize(0);
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  863:    if (outputShape[2] == ShapedType::kDynamicSize)
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####:  864:      outputShape[2] = inputShape.getDimSize(2);
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  865:  }
        -:  866:
    #####:  867:  inferredReturnShapes.push_back(ShapedTypeComponents(outputShape));
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  868:  return success();
branch  0 never executed
branch  1 never executed
        -:  869:}
        -:  870:
function _ZL22ReduceInferReturnTypesN4mlir12ShapeAdaptorENS_11IntegerAttrERN4llvm15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  871:static LogicalResult ReduceInferReturnTypes(
        -:  872:    ShapeAdaptor operandShape, IntegerAttr axis,
        -:  873:    SmallVectorImpl<ShapedTypeComponents> &inferredReturnShapes) {
    #####:  874:  if (!operandShape.hasRank()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  875:    inferredReturnShapes.push_back(ShapedTypeComponents());
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  876:    return success();
        -:  877:  }
        -:  878:
    #####:  879:  SmallVector<int64_t> outputShape;
call    0 never executed
    #####:  880:  operandShape.getDims(outputShape);
call    0 never executed
    #####:  881:  int64_t axisVal = axis.getValue().getSExtValue();
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  882:  outputShape[axisVal] = 1;
branch  0 never executed
branch  1 never executed
    #####:  883:  inferredReturnShapes.push_back(ShapedTypeComponents(outputShape));
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  884:  return success();
branch  0 never executed
branch  1 never executed
        -:  885:}
        -:  886:
        -:  887:#define REDUCE_SHAPE_INFER(OP)                                                 \
        -:  888:  LogicalResult OP::inferReturnTypeComponents(                                 \
        -:  889:      MLIRContext *context, ::llvm::Optional<Location> location,               \
        -:  890:      ValueShapeRange operands, DictionaryAttr attributes,                     \
        -:  891:      RegionRange regions,                                                     \
        -:  892:      SmallVectorImpl<ShapedTypeComponents> &inferredReturnShapes) {           \
        -:  893:    return ReduceInferReturnTypes(operands.getShape(0),                        \
        -:  894:                                  attributes.get("axis").cast<IntegerAttr>(),  \
        -:  895:                                  inferredReturnShapes);                       \
        -:  896:  }
        -:  897:
function _ZN4mlir4tosa11ReduceAllOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  898:REDUCE_SHAPE_INFER(tosa::ReduceAllOp)
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
function _ZN4mlir4tosa11ReduceAnyOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  899:REDUCE_SHAPE_INFER(tosa::ReduceAnyOp)
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
function _ZN4mlir4tosa11ReduceMaxOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  900:REDUCE_SHAPE_INFER(tosa::ReduceMaxOp)
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
function _ZN4mlir4tosa11ReduceMinOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  901:REDUCE_SHAPE_INFER(tosa::ReduceMinOp)
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
function _ZN4mlir4tosa12ReduceProdOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  902:REDUCE_SHAPE_INFER(tosa::ReduceProdOp)
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
function _ZN4mlir4tosa11ReduceSumOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  903:REDUCE_SHAPE_INFER(tosa::ReduceSumOp)
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
        -:  904:#undef REDUCE_SHAPE_INFER
        -:  905:
function _ZL20NAryInferReturnTypesRKN4mlir15ValueShapeRangeERN4llvm15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  906:static LogicalResult NAryInferReturnTypes(
        -:  907:    const ValueShapeRange &operands,
        -:  908:    SmallVectorImpl<ShapedTypeComponents> &inferredReturnShapes) {
    #####:  909:  llvm::SmallVector<int64_t> outShape;
call    0 never executed
    #####:  910:  if (resolveBroadcastShape(operands, outShape).failed()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  911:    inferredReturnShapes.push_back(ShapedTypeComponents());
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  912:  } else {
    #####:  913:    inferredReturnShapes.push_back(ShapedTypeComponents(outShape));
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
        -:  914:  }
    #####:  915:  return success();
branch  0 never executed
branch  1 never executed
        -:  916:}
        -:  917:
        -:  918:#define NARY_SHAPE_INFER(OP)                                                   \
        -:  919:  LogicalResult OP::inferReturnTypeComponents(                                 \
        -:  920:      MLIRContext *context, ::llvm::Optional<Location> location,               \
        -:  921:      ValueShapeRange operands, DictionaryAttr attributes,                     \
        -:  922:      RegionRange regions,                                                     \
        -:  923:      SmallVectorImpl<ShapedTypeComponents> &inferredReturnShapes) {           \
        -:  924:    return NAryInferReturnTypes(operands, inferredReturnShapes);               \
        -:  925:  }
        -:  926:
function _ZN4mlir4tosa5AbsOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  927:NARY_SHAPE_INFER(tosa::AbsOp)
call    0 never executed
call    1 never executed
function _ZN4mlir4tosa5AddOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  928:NARY_SHAPE_INFER(tosa::AddOp)
call    0 never executed
call    1 never executed
function _ZN4mlir4tosa22ArithmeticRightShiftOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  929:NARY_SHAPE_INFER(tosa::ArithmeticRightShiftOp)
call    0 never executed
call    1 never executed
function _ZN4mlir4tosa12BitwiseAndOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  930:NARY_SHAPE_INFER(tosa::BitwiseAndOp)
call    0 never executed
call    1 never executed
function _ZN4mlir4tosa11BitwiseOrOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  931:NARY_SHAPE_INFER(tosa::BitwiseOrOp)
call    0 never executed
call    1 never executed
function _ZN4mlir4tosa12BitwiseXorOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  932:NARY_SHAPE_INFER(tosa::BitwiseXorOp)
call    0 never executed
call    1 never executed
function _ZN4mlir4tosa12BitwiseNotOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  933:NARY_SHAPE_INFER(tosa::BitwiseNotOp)
call    0 never executed
call    1 never executed
function _ZN4mlir4tosa6CastOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  934:NARY_SHAPE_INFER(tosa::CastOp)
call    0 never executed
call    1 never executed
function _ZN4mlir4tosa6CeilOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  935:NARY_SHAPE_INFER(tosa::CeilOp)
call    0 never executed
call    1 never executed
function _ZN4mlir4tosa7ClampOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  936:NARY_SHAPE_INFER(tosa::ClampOp)
call    0 never executed
call    1 never executed
function _ZN4mlir4tosa5ClzOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  937:NARY_SHAPE_INFER(tosa::ClzOp)
call    0 never executed
call    1 never executed
function _ZN4mlir4tosa5DivOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  938:NARY_SHAPE_INFER(tosa::DivOp)
call    0 never executed
call    1 never executed
function _ZN4mlir4tosa5ExpOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  939:NARY_SHAPE_INFER(tosa::ExpOp)
call    0 never executed
call    1 never executed
function _ZN4mlir4tosa7FloorOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  940:NARY_SHAPE_INFER(tosa::FloorOp)
call    0 never executed
call    1 never executed
function _ZN4mlir4tosa14GreaterEqualOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  941:NARY_SHAPE_INFER(tosa::GreaterEqualOp)
call    0 never executed
call    1 never executed
function _ZN4mlir4tosa9GreaterOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  942:NARY_SHAPE_INFER(tosa::GreaterOp)
call    0 never executed
call    1 never executed
function _ZN4mlir4tosa10IdentityOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  943:NARY_SHAPE_INFER(tosa::IdentityOp)
call    0 never executed
call    1 never executed
function _ZN4mlir4tosa5LogOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  944:NARY_SHAPE_INFER(tosa::LogOp)
call    0 never executed
call    1 never executed
function _ZN4mlir4tosa12LogicalAndOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  945:NARY_SHAPE_INFER(tosa::LogicalAndOp)
call    0 never executed
call    1 never executed
function _ZN4mlir4tosa18LogicalLeftShiftOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  946:NARY_SHAPE_INFER(tosa::LogicalLeftShiftOp)
call    0 never executed
call    1 never executed
function _ZN4mlir4tosa12LogicalNotOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  947:NARY_SHAPE_INFER(tosa::LogicalNotOp)
call    0 never executed
call    1 never executed
function _ZN4mlir4tosa11LogicalOrOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  948:NARY_SHAPE_INFER(tosa::LogicalOrOp)
call    0 never executed
call    1 never executed
function _ZN4mlir4tosa19LogicalRightShiftOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  949:NARY_SHAPE_INFER(tosa::LogicalRightShiftOp)
call    0 never executed
call    1 never executed
function _ZN4mlir4tosa12LogicalXorOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  950:NARY_SHAPE_INFER(tosa::LogicalXorOp)
call    0 never executed
call    1 never executed
function _ZN4mlir4tosa9MaximumOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  951:NARY_SHAPE_INFER(tosa::MaximumOp)
call    0 never executed
call    1 never executed
function _ZN4mlir4tosa9MinimumOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  952:NARY_SHAPE_INFER(tosa::MinimumOp)
call    0 never executed
call    1 never executed
function _ZN4mlir4tosa5MulOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  953:NARY_SHAPE_INFER(tosa::MulOp)
call    0 never executed
call    1 never executed
function _ZN4mlir4tosa8NegateOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  954:NARY_SHAPE_INFER(tosa::NegateOp)
call    0 never executed
call    1 never executed
function _ZN4mlir4tosa5PowOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  955:NARY_SHAPE_INFER(tosa::PowOp)
call    0 never executed
call    1 never executed
function _ZN4mlir4tosa12ReciprocalOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  956:NARY_SHAPE_INFER(tosa::ReciprocalOp)
call    0 never executed
call    1 never executed
function _ZN4mlir4tosa9RescaleOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  957:NARY_SHAPE_INFER(tosa::RescaleOp)
call    0 never executed
call    1 never executed
function _ZN4mlir4tosa9ReverseOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  958:NARY_SHAPE_INFER(tosa::ReverseOp)
call    0 never executed
call    1 never executed
function _ZN4mlir4tosa7RsqrtOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  959:NARY_SHAPE_INFER(tosa::RsqrtOp)
call    0 never executed
call    1 never executed
function _ZN4mlir4tosa8SelectOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  960:NARY_SHAPE_INFER(tosa::SelectOp)
call    0 never executed
call    1 never executed
function _ZN4mlir4tosa5SubOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  961:NARY_SHAPE_INFER(tosa::SubOp)
call    0 never executed
call    1 never executed
function _ZN4mlir4tosa6TanhOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  962:NARY_SHAPE_INFER(tosa::TanhOp)
call    0 never executed
call    1 never executed
function _ZN4mlir4tosa9SigmoidOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  963:NARY_SHAPE_INFER(tosa::SigmoidOp)
call    0 never executed
call    1 never executed
        -:  964:#undef PRED_SHAPE_INFER
        -:  965:
function _ZL23poolingInferReturnTypesRKN4mlir15ValueShapeRangeENS_14DictionaryAttrERN4llvm15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####:  966:static LogicalResult poolingInferReturnTypes(
        -:  967:    const ValueShapeRange &operands, DictionaryAttr attributes,
        -:  968:    SmallVectorImpl<ShapedTypeComponents> &inferredReturnShapes) {
    #####:  969:  ShapeAdaptor inputShape = operands.getShape(0);
call    0 never executed
    #####:  970:  llvm::SmallVector<int64_t> outputShape;
call    0 never executed
    #####:  971:  outputShape.resize(4, ShapedType::kDynamicSize);
call    0 never executed
        -:  972:
        -:  973:  // We only know the rank if the input type is unranked.
    #####:  974:  if (!inputShape) {
branch  0 never executed
branch  1 never executed
    #####:  975:    inferredReturnShapes.push_back(ShapedTypeComponents(outputShape));
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  976:    return success();
        -:  977:  }
        -:  978:
        -:  979:  // Batch and number of channels are identical for pooling layer.
    #####:  980:  outputShape[0] = inputShape.getDimSize(0);
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  981:  outputShape[3] = inputShape.getDimSize(3);
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  982:
    #####:  983:  int64_t height = inputShape.getDimSize(1);
call    0 never executed
    #####:  984:  int64_t width = inputShape.getDimSize(2);
call    0 never executed
        -:  985:
    #####:  986:  llvm::SmallVector<int64_t> kernel;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  987:  llvm::SmallVector<int64_t> stride;
branch  0 never executed
branch  1 never executed
    #####:  988:  llvm::SmallVector<int64_t> pad;
branch  0 never executed
branch  1 never executed
        -:  989:
    #####:  990:  getI64Values(attributes.get("kernel").cast<ArrayAttr>(), kernel);
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  991:  getI64Values(attributes.get("stride").cast<ArrayAttr>(), stride);
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  992:  getI64Values(attributes.get("pad").cast<ArrayAttr>(), pad);
call    0 never executed
call    1 never executed
call    2 never executed
        -:  993:
    #####:  994:  if (!ShapedType::isDynamic(height)) {
branch  0 never executed
branch  1 never executed
    #####:  995:    int64_t padded = height + pad[0] + pad[1] - kernel[0];
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
    #####:  996:    outputShape[1] = padded / stride[0] + 1;
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
        -:  997:  }
        -:  998:
    #####:  999:  if (!ShapedType::isDynamic(width)) {
branch  0 never executed
branch  1 never executed
    #####: 1000:    int64_t padded = width + pad[2] + pad[3] - kernel[1];
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
    #####: 1001:    outputShape[2] = padded / stride[1] + 1;
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
        -: 1002:  }
        -: 1003:
    #####: 1004:  inferredReturnShapes.push_back(ShapedTypeComponents(outputShape));
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1005:  return success();
branch  0 never executed
branch  1 never executed
        -: 1006:}
        -: 1007:
function _ZN4mlir4tosa8Conv2DOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####: 1008:LogicalResult Conv2DOp::inferReturnTypeComponents(
        -: 1009:    MLIRContext *context, ::llvm::Optional<Location> location,
        -: 1010:    ValueShapeRange operands, DictionaryAttr attributes, RegionRange regions,
        -: 1011:    SmallVectorImpl<ShapedTypeComponents> &inferredReturnShapes) {
    #####: 1012:  llvm::SmallVector<int64_t> outputShape(4, ShapedType::kDynamicSize);
call    0 never executed
    #####: 1013:  Conv2DOp::Adaptor adaptor(operands.getValues(), attributes);
call    0 never executed
call    1 never executed
call    2 never executed
        -: 1014:
    #####: 1015:  int64_t inputWidth = ShapedType::kDynamicSize;
    #####: 1016:  int64_t inputHeight = ShapedType::kDynamicSize;
    #####: 1017:  int64_t weightWidth = ShapedType::kDynamicSize;
    #####: 1018:  int64_t weightHeight = ShapedType::kDynamicSize;
        -: 1019:
        -: 1020:  // Input shape describes input width/height and batch.
        -: 1021:
    #####: 1022:  ShapeAdaptor inputShape = operands.getShape(adaptor.getInput());
call    0 never executed
call    1 never executed
    #####: 1023:  if (inputShape.hasRank()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1024:    outputShape[0] = inputShape.getDimSize(0);
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1025:    inputHeight = inputShape.getDimSize(1);
call    0 never executed
    #####: 1026:    inputWidth = inputShape.getDimSize(2);
call    0 never executed
        -: 1027:  }
        -: 1028:
        -: 1029:  // Weight shapes describes the filter width/height and the output channels.
    #####: 1030:  ShapeAdaptor weightShape = operands.getShape(adaptor.getWeight());
call    0 never executed
call    1 never executed
    #####: 1031:  if (weightShape.hasRank()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1032:    outputShape[3] = weightShape.getDimSize(0);
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1033:    weightHeight = weightShape.getDimSize(1);
call    0 never executed
    #####: 1034:    weightWidth = weightShape.getDimSize(2);
call    0 never executed
        -: 1035:  }
        -: 1036:
        -: 1037:  // Bias shape can describe the output channels.
    #####: 1038:  ShapeAdaptor biasShape = operands.getShape(adaptor.getBias());
call    0 never executed
call    1 never executed
    #####: 1039:  if (biasShape.hasRank()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1040:    outputShape[3] = ShapedType::isDynamic(outputShape[3])
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1041:                         ? biasShape.getDimSize(0)
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####: 1042:                         : outputShape[3];
branch  0 never executed
branch  1 never executed
        -: 1043:  }
        -: 1044:
    #####: 1045:  llvm::SmallVector<int64_t> dilation;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1046:  llvm::SmallVector<int64_t> padding;
branch  0 never executed
branch  1 never executed
    #####: 1047:  llvm::SmallVector<int64_t> stride;
branch  0 never executed
branch  1 never executed
        -: 1048:
    #####: 1049:  getI64Values(adaptor.getDilation(), dilation);
call    0 never executed
call    1 never executed
    #####: 1050:  getI64Values(adaptor.getPad(), padding);
call    0 never executed
call    1 never executed
    #####: 1051:  getI64Values(adaptor.getStride(), stride);
call    0 never executed
call    1 never executed
        -: 1052:
    #####: 1053:  if (!ShapedType::isDynamic(inputHeight) &&
branch  0 never executed
branch  1 never executed
    #####: 1054:      !ShapedType::isDynamic(weightHeight)) {
branch  0 never executed
branch  1 never executed
    #####: 1055:    int64_t inputSize = inputHeight + padding[0] + padding[1];
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1056:    int64_t filterSize = (weightHeight - 1) * dilation[0] + 1;
branch  0 never executed
branch  1 never executed
    #####: 1057:    int64_t unstridedResult = inputSize - filterSize + 1;
    #####: 1058:    outputShape[1] = (unstridedResult - 1) / stride[0] + 1;
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
        -: 1059:  }
        -: 1060:
    #####: 1061:  if (!ShapedType::isDynamic(inputWidth) &&
branch  0 never executed
branch  1 never executed
    #####: 1062:      !ShapedType::isDynamic(weightWidth)) {
branch  0 never executed
branch  1 never executed
    #####: 1063:    int64_t inputSize = inputWidth + padding[2] + padding[3];
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1064:    int64_t filterSize = (weightWidth - 1) * dilation[1] + 1;
branch  0 never executed
branch  1 never executed
    #####: 1065:    int64_t unstridedResult = inputSize - filterSize + 1;
    #####: 1066:    outputShape[2] = (unstridedResult - 1) / stride[1] + 1;
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
        -: 1067:  }
        -: 1068:
    #####: 1069:  inferredReturnShapes.push_back(ShapedTypeComponents(outputShape));
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1070:  return success();
branch  0 never executed
branch  1 never executed
        -: 1071:}
        -: 1072:
function _ZN4mlir4tosa8Conv2DOp6verifyEv called 0 returned 0% blocks executed 0%
    #####: 1073:LogicalResult Conv2DOp::verify() { return verifyConvOp(*this); }
call    0 never executed
call    1 never executed
call    2 never executed
        -: 1074:
function _ZN4mlir4tosa8Conv3DOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####: 1075:LogicalResult Conv3DOp::inferReturnTypeComponents(
        -: 1076:    MLIRContext *context, ::llvm::Optional<Location> location,
        -: 1077:    ValueShapeRange operands, DictionaryAttr attributes, RegionRange regions,
        -: 1078:    SmallVectorImpl<ShapedTypeComponents> &inferredReturnShapes) {
    #####: 1079:  llvm::SmallVector<int64_t> outputShape(5, ShapedType::kDynamicSize);
call    0 never executed
    #####: 1080:  Conv3DOp::Adaptor adaptor(operands.getValues(), attributes);
call    0 never executed
call    1 never executed
call    2 never executed
        -: 1081:
    #####: 1082:  int64_t inputWidth = ShapedType::kDynamicSize;
    #####: 1083:  int64_t inputHeight = ShapedType::kDynamicSize;
    #####: 1084:  int64_t inputDepth = ShapedType::kDynamicSize;
        -: 1085:
    #####: 1086:  int64_t weightWidth = ShapedType::kDynamicSize;
    #####: 1087:  int64_t weightHeight = ShapedType::kDynamicSize;
    #####: 1088:  int64_t weightDepth = ShapedType::kDynamicSize;
        -: 1089:
        -: 1090:  // Input shape describes input width/height and batch.
    #####: 1091:  ShapeAdaptor inputShape = operands.getShape(adaptor.getInput());
call    0 never executed
call    1 never executed
    #####: 1092:  if (inputShape.hasRank()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1093:    outputShape[0] = inputShape.getDimSize(0);
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1094:    inputDepth = inputShape.getDimSize(1);
call    0 never executed
    #####: 1095:    inputHeight = inputShape.getDimSize(2);
call    0 never executed
    #####: 1096:    inputWidth = inputShape.getDimSize(3);
call    0 never executed
        -: 1097:  }
        -: 1098:
        -: 1099:  // Weight shapes describes the filter width/height and the output channels.
    #####: 1100:  ShapeAdaptor weightShape = operands.getShape(adaptor.getWeight());
call    0 never executed
call    1 never executed
    #####: 1101:  if (weightShape.hasRank()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1102:    outputShape[4] = weightShape.getDimSize(0);
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1103:    weightDepth = weightShape.getDimSize(1);
call    0 never executed
    #####: 1104:    weightHeight = weightShape.getDimSize(2);
call    0 never executed
    #####: 1105:    weightWidth = weightShape.getDimSize(3);
call    0 never executed
        -: 1106:  }
        -: 1107:
        -: 1108:  // Bias shape can describe the output channels.
    #####: 1109:  ShapeAdaptor biasShape = operands.getShape(adaptor.getBias());
call    0 never executed
call    1 never executed
    #####: 1110:  if (biasShape.hasRank() && ShapedType::isDynamic(outputShape[4])) {
call    0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
    #####: 1111:    outputShape[4] = biasShape.getDimSize(0);
call    0 never executed
branch  1 never executed
branch  2 never executed
        -: 1112:  }
        -: 1113:
    #####: 1114:  llvm::SmallVector<int64_t> dilation;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1115:  llvm::SmallVector<int64_t> pad;
branch  0 never executed
branch  1 never executed
    #####: 1116:  llvm::SmallVector<int64_t> stride;
branch  0 never executed
branch  1 never executed
        -: 1117:
    #####: 1118:  getI64Values(adaptor.getDilation(), dilation);
call    0 never executed
call    1 never executed
    #####: 1119:  getI64Values(adaptor.getPad(), pad);
call    0 never executed
call    1 never executed
    #####: 1120:  getI64Values(adaptor.getStride(), stride);
call    0 never executed
call    1 never executed
        -: 1121:
    #####: 1122:  if (!ShapedType::isDynamic(inputDepth) &&
branch  0 never executed
branch  1 never executed
    #####: 1123:      !ShapedType::isDynamic(weightDepth)) {
branch  0 never executed
branch  1 never executed
    #####: 1124:    int32_t inputSize = inputDepth + pad[0] + pad[1];
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1125:    int32_t filterSize = (weightDepth - 1) * dilation[0] + 1;
branch  0 never executed
branch  1 never executed
    #####: 1126:    int32_t unstridedResult = inputSize - filterSize + 1;
    #####: 1127:    outputShape[1] = (unstridedResult - 1) / stride[0] + 1;
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
        -: 1128:  }
        -: 1129:
    #####: 1130:  if (!ShapedType::isDynamic(inputHeight) &&
branch  0 never executed
branch  1 never executed
    #####: 1131:      !ShapedType::isDynamic(weightHeight)) {
branch  0 never executed
branch  1 never executed
    #####: 1132:    int32_t inputSize = inputHeight + pad[2] + pad[3];
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1133:    int32_t filterSize = (weightHeight - 1) * dilation[1] + 1;
branch  0 never executed
branch  1 never executed
    #####: 1134:    int32_t unstridedResult = inputSize - filterSize + 1;
    #####: 1135:    outputShape[2] = (unstridedResult - 1) / stride[1] + 1;
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
        -: 1136:  }
        -: 1137:
    #####: 1138:  if (!ShapedType::isDynamic(inputWidth) &&
branch  0 never executed
branch  1 never executed
    #####: 1139:      !ShapedType::isDynamic(weightWidth)) {
branch  0 never executed
branch  1 never executed
    #####: 1140:    int32_t inputSize = inputWidth + pad[4] + pad[5];
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1141:    int32_t filterSize = (weightWidth - 1) * dilation[2] + 1;
branch  0 never executed
branch  1 never executed
    #####: 1142:    int32_t unstridedResult = inputSize - filterSize + 1;
    #####: 1143:    outputShape[3] = (unstridedResult - 1) / stride[2] + 1;
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
        -: 1144:  }
        -: 1145:
    #####: 1146:  inferredReturnShapes.push_back(ShapedTypeComponents(outputShape));
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1147:  return success();
branch  0 never executed
branch  1 never executed
        -: 1148:}
        -: 1149:
function _ZN4mlir4tosa8Conv3DOp6verifyEv called 0 returned 0% blocks executed 0%
    #####: 1150:LogicalResult Conv3DOp::verify() { return verifyConvOp(*this); }
call    0 never executed
call    1 never executed
call    2 never executed
        -: 1151:
function _ZN4mlir4tosa11AvgPool2dOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####: 1152:LogicalResult AvgPool2dOp::inferReturnTypeComponents(
        -: 1153:    MLIRContext *context, ::llvm::Optional<Location> location,
        -: 1154:    ValueShapeRange operands, DictionaryAttr attributes, RegionRange regions,
        -: 1155:    SmallVectorImpl<ShapedTypeComponents> &inferredReturnShapes) {
    #####: 1156:  return poolingInferReturnTypes(operands, attributes, inferredReturnShapes);
call    0 never executed
call    1 never executed
        -: 1157:}
        -: 1158:
function _ZN4mlir4tosa11MaxPool2dOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####: 1159:LogicalResult MaxPool2dOp::inferReturnTypeComponents(
        -: 1160:    MLIRContext *context, ::llvm::Optional<Location> location,
        -: 1161:    ValueShapeRange operands, DictionaryAttr attributes, RegionRange regions,
        -: 1162:    SmallVectorImpl<ShapedTypeComponents> &inferredReturnShapes) {
    #####: 1163:  return poolingInferReturnTypes(operands, attributes, inferredReturnShapes);
call    0 never executed
call    1 never executed
        -: 1164:}
        -: 1165:
function _ZN4mlir4tosa17DepthwiseConv2DOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####: 1166:LogicalResult DepthwiseConv2DOp::inferReturnTypeComponents(
        -: 1167:    MLIRContext *context, ::llvm::Optional<Location> location,
        -: 1168:    ValueShapeRange operands, DictionaryAttr attributes, RegionRange regions,
        -: 1169:    SmallVectorImpl<ShapedTypeComponents> &inferredReturnShapes) {
    #####: 1170:  llvm::SmallVector<int64_t> outputShape(4, ShapedType::kDynamicSize);
call    0 never executed
    #####: 1171:  DepthwiseConv2DOp::Adaptor adaptor(operands.getValues(), attributes);
call    0 never executed
call    1 never executed
call    2 never executed
        -: 1172:
    #####: 1173:  int64_t inputWidth = ShapedType::kDynamicSize;
    #####: 1174:  int64_t inputHeight = ShapedType::kDynamicSize;
    #####: 1175:  int64_t inputChannels = ShapedType::kDynamicSize;
        -: 1176:
    #####: 1177:  int64_t weightWidth = ShapedType::kDynamicSize;
    #####: 1178:  int64_t weightHeight = ShapedType::kDynamicSize;
    #####: 1179:  int64_t depthChannels = ShapedType::kDynamicSize;
        -: 1180:
        -: 1181:  // Input shape describes input width/height and batch.
    #####: 1182:  ShapeAdaptor inputShape = operands.getShape(adaptor.getInput());
call    0 never executed
call    1 never executed
    #####: 1183:  if (inputShape.hasRank()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1184:    outputShape[0] = inputShape.getDimSize(0);
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1185:    inputHeight = inputShape.getDimSize(1);
call    0 never executed
    #####: 1186:    inputWidth = inputShape.getDimSize(2);
call    0 never executed
    #####: 1187:    inputChannels = inputShape.getDimSize(3);
call    0 never executed
        -: 1188:  }
        -: 1189:
        -: 1190:  // Weight shapes describes the filter width/height and the output channels.
    #####: 1191:  ShapeAdaptor weightShape = operands.getShape(adaptor.getWeight());
call    0 never executed
call    1 never executed
    #####: 1192:  if (weightShape.hasRank()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1193:    weightHeight = weightShape.getDimSize(0);
call    0 never executed
    #####: 1194:    weightWidth = weightShape.getDimSize(1);
call    0 never executed
    #####: 1195:    inputChannels = ShapedType::isDynamic(inputChannels)
branch  0 never executed
branch  1 never executed
    #####: 1196:                        ? weightShape.getDimSize(2)
branch  0 never executed
branch  1 never executed
call    2 never executed
        -: 1197:                        : inputChannels;
    #####: 1198:    depthChannels = weightShape.getDimSize(3);
call    0 never executed
        -: 1199:  }
        -: 1200:
        -: 1201:  // If both inputChannels and depthChannels are available we can determine
        -: 1202:  // the output channels.
    #####: 1203:  if (!ShapedType::isDynamic(inputChannels) &&
branch  0 never executed
branch  1 never executed
    #####: 1204:      !ShapedType::isDynamic(depthChannels)) {
branch  0 never executed
branch  1 never executed
    #####: 1205:    outputShape[3] = inputChannels * depthChannels;
branch  0 never executed
branch  1 never executed
        -: 1206:  }
        -: 1207:
        -: 1208:  // Bias shape can describe the output channels.
    #####: 1209:  ShapeAdaptor biasShape = operands.getShape(adaptor.getBias());
call    0 never executed
call    1 never executed
    #####: 1210:  if (biasShape.hasRank()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1211:    outputShape[3] = ShapedType::isDynamic(outputShape[3])
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1212:                         ? biasShape.getDimSize(0)
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####: 1213:                         : outputShape[3];
branch  0 never executed
branch  1 never executed
        -: 1214:  }
        -: 1215:
    #####: 1216:  llvm::SmallVector<int64_t> dilation;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1217:  llvm::SmallVector<int64_t> padding;
branch  0 never executed
branch  1 never executed
    #####: 1218:  llvm::SmallVector<int64_t> stride;
branch  0 never executed
branch  1 never executed
        -: 1219:
    #####: 1220:  getI64Values(adaptor.getDilation(), dilation);
call    0 never executed
call    1 never executed
    #####: 1221:  getI64Values(adaptor.getPad(), padding);
call    0 never executed
call    1 never executed
    #####: 1222:  getI64Values(adaptor.getStride(), stride);
call    0 never executed
call    1 never executed
        -: 1223:
    #####: 1224:  if (!ShapedType::isDynamic(inputHeight) &&
branch  0 never executed
branch  1 never executed
    #####: 1225:      !ShapedType::isDynamic(weightHeight)) {
branch  0 never executed
branch  1 never executed
    #####: 1226:    int64_t inputSize = inputHeight + padding[0] + padding[1];
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1227:    int64_t filterSize = (weightHeight - 1) * dilation[0] + 1;
branch  0 never executed
branch  1 never executed
    #####: 1228:    int64_t unstridedResult = inputSize - filterSize + 1;
    #####: 1229:    outputShape[1] = (unstridedResult - 1) / stride[0] + 1;
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
        -: 1230:  }
        -: 1231:
    #####: 1232:  if (!ShapedType::isDynamic(inputWidth) &&
branch  0 never executed
branch  1 never executed
    #####: 1233:      !ShapedType::isDynamic(weightWidth)) {
branch  0 never executed
branch  1 never executed
    #####: 1234:    int64_t inputSize = inputWidth + padding[2] + padding[3];
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1235:    int64_t filterSize = (weightWidth - 1) * dilation[1] + 1;
branch  0 never executed
branch  1 never executed
    #####: 1236:    int64_t unstridedResult = inputSize - filterSize + 1;
    #####: 1237:    outputShape[2] = (unstridedResult - 1) / stride[1] + 1;
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
        -: 1238:  }
        -: 1239:
    #####: 1240:  inferredReturnShapes.push_back(ShapedTypeComponents(outputShape));
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1241:  return success();
branch  0 never executed
branch  1 never executed
        -: 1242:}
        -: 1243:
function _ZN4mlir4tosa17DepthwiseConv2DOp6verifyEv called 0 returned 0% blocks executed 0%
    #####: 1244:LogicalResult DepthwiseConv2DOp::verify() { return verifyConvOp(*this); }
call    0 never executed
call    1 never executed
call    2 never executed
        -: 1245:
function _ZN4mlir4tosa17TransposeConv2DOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####: 1246:LogicalResult TransposeConv2DOp::inferReturnTypeComponents(
        -: 1247:    MLIRContext *context, ::llvm::Optional<Location> location,
        -: 1248:    ValueShapeRange operands, DictionaryAttr attributes, RegionRange regions,
        -: 1249:    SmallVectorImpl<ShapedTypeComponents> &inferredReturnShapes) {
    #####: 1250:  TransposeConv2DOp::Adaptor adaptor(operands.getValues(), attributes);
call    0 never executed
call    1 never executed
call    2 never executed
    #####: 1251:  llvm::SmallVector<int64_t> outputShape;
call    0 never executed
    #####: 1252:  getI64Values(adaptor.getOutShape(), outputShape);
call    0 never executed
call    1 never executed
    #####: 1253:  outputShape = ConvertToMlirShape(outputShape);
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
        -: 1254:
    #####: 1255:  int64_t inputWidth = ShapedType::kDynamicSize;
    #####: 1256:  int64_t inputHeight = ShapedType::kDynamicSize;
    #####: 1257:  int64_t weightWidth = ShapedType::kDynamicSize;
    #####: 1258:  int64_t weightHeight = ShapedType::kDynamicSize;
        -: 1259:
        -: 1260:  // Input shape describes input width/height and batch.
    #####: 1261:  ShapeAdaptor inputShape = operands.getShape(adaptor.getInput());
call    0 never executed
call    1 never executed
    #####: 1262:  if (inputShape.hasRank()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1263:    outputShape[0] = ShapedType::isDynamic(outputShape[0])
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1264:                         ? inputShape.getDimSize(0)
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####: 1265:                         : outputShape[0];
branch  0 never executed
branch  1 never executed
    #####: 1266:    inputHeight = inputShape.getDimSize(1);
call    0 never executed
    #####: 1267:    inputWidth = inputShape.getDimSize(2);
call    0 never executed
        -: 1268:  }
        -: 1269:
        -: 1270:  // Weight shapes describes the filter width/height and the output channels.
    #####: 1271:  ShapeAdaptor weightShape = operands.getShape(adaptor.getFilter());
call    0 never executed
call    1 never executed
    #####: 1272:  if (weightShape.hasRank()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1273:    outputShape[3] = ShapedType::isDynamic(outputShape[3])
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1274:                         ? weightShape.getDimSize(0)
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####: 1275:                         : outputShape[3];
branch  0 never executed
branch  1 never executed
    #####: 1276:    weightHeight = weightShape.getDimSize(1);
call    0 never executed
    #####: 1277:    weightWidth = weightShape.getDimSize(2);
call    0 never executed
        -: 1278:  }
        -: 1279:
        -: 1280:  // Bias shape can describe the output channels.
    #####: 1281:  ShapeAdaptor biasShape = operands.getShape(adaptor.getInput());
call    0 never executed
call    1 never executed
    #####: 1282:  if (biasShape.hasRank()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1283:    outputShape[3] = ShapedType::isDynamic(outputShape[3])
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1284:                         ? biasShape.getDimSize(0)
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####: 1285:                         : outputShape[3];
branch  0 never executed
branch  1 never executed
        -: 1286:  }
        -: 1287:
    #####: 1288:  llvm::SmallVector<int64_t> padding;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1289:  llvm::SmallVector<int64_t> stride;
branch  0 never executed
branch  1 never executed
        -: 1290:
    #####: 1291:  getI64Values(adaptor.getOutPad(), padding);
call    0 never executed
call    1 never executed
    #####: 1292:  getI64Values(adaptor.getStride(), stride);
call    0 never executed
call    1 never executed
        -: 1293:
    #####: 1294:  if (!ShapedType::isDynamic(inputHeight) &&
branch  0 never executed
branch  1 never executed
    #####: 1295:      !ShapedType::isDynamic(weightHeight)) {
branch  0 never executed
branch  1 never executed
    #####: 1296:    int64_t calculateSize =
    #####: 1297:        (inputHeight - 1) * stride[0] - padding[0] - padding[1] + weightHeight;
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
    #####: 1298:    outputShape[1] =
branch  0 never executed
branch  1 never executed
    #####: 1299:        ShapedType::isDynamic(outputShape[1]) ? calculateSize : outputShape[1];
branch  0 never executed
branch  1 never executed
        -: 1300:  }
        -: 1301:
    #####: 1302:  if (!ShapedType::isDynamic(inputWidth) &&
branch  0 never executed
branch  1 never executed
    #####: 1303:      !ShapedType::isDynamic(weightWidth)) {
branch  0 never executed
branch  1 never executed
    #####: 1304:    int64_t calculateSize =
    #####: 1305:        (inputWidth - 1) * stride[1] - padding[2] - padding[3] + weightWidth;
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
    #####: 1306:    outputShape[2] =
branch  0 never executed
branch  1 never executed
    #####: 1307:        ShapedType::isDynamic(outputShape[2]) ? calculateSize : outputShape[2];
branch  0 never executed
branch  1 never executed
        -: 1308:  }
        -: 1309:
    #####: 1310:  inferredReturnShapes.push_back(ShapedTypeComponents(outputShape));
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1311:  return success();
branch  0 never executed
branch  1 never executed
        -: 1312:}
        -: 1313:
function _ZN4mlir4tosa4IfOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####: 1314:LogicalResult IfOp::inferReturnTypeComponents(
        -: 1315:    MLIRContext *context, ::llvm::Optional<Location> location,
        -: 1316:    ValueShapeRange operands, DictionaryAttr attributes, RegionRange regions,
        -: 1317:    SmallVectorImpl<ShapedTypeComponents> &inferredReturnShapes) {
    #####: 1318:  llvm::SmallVector<tosa::YieldOp> yieldOps;
    #####: 1319:  for (Region *region : regions) {
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####: 1320:    for (auto &block : *region)
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1321:      if (auto returnOp = dyn_cast<tosa::YieldOp>(block.getTerminator()))
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1322:        yieldOps.push_back(returnOp);
call    0 never executed
        -: 1323:  }
        -: 1324:
    #####: 1325:  if (yieldOps.empty())
branch  0 never executed
branch  1 never executed
    #####: 1326:    return failure();
branch  0 never executed
branch  1 never executed
        -: 1327:
        -: 1328:  // Get the initial type information for the yield op.
    #####: 1329:  llvm::SmallVector<ValueKnowledge> resultKnowledge;
call    0 never executed
    #####: 1330:  resultKnowledge.reserve(yieldOps.front().getNumOperands());
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1331:  for (auto operand : yieldOps.front().getOperands()) {
branch  0 never executed
branch  1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
call    5 never executed
    #####: 1332:    resultKnowledge.push_back(
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1333:        ValueKnowledge::getKnowledgeFromType(operand.getType()));
call    0 never executed
        -: 1334:  }
        -: 1335:
    #####: 1336:  for (auto yieldOp : yieldOps) {
branch  0 never executed
branch  1 never executed
    #####: 1337:    if (resultKnowledge.size() != yieldOp.getNumOperands())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1338:      return failure();
        -: 1339:
    #####: 1340:    for (const auto &it : llvm::enumerate(yieldOp.getOperands())) {
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
call    4 never executed
    #####: 1341:      int32_t index = it.index();
call    0 never executed
    #####: 1342:      auto meet = ValueKnowledge::meet(
call    0 never executed
    #####: 1343:          resultKnowledge[index],
branch  0 never executed
branch  1 never executed
    #####: 1344:          ValueKnowledge::getKnowledgeFromType(it.value().getType()));
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1345:      if (!meet)
branch  0 never executed
branch  1 never executed
    #####: 1346:        continue;
branch  0 never executed
branch  1 never executed
    #####: 1347:      resultKnowledge[index] = meet;
branch  0 never executed
branch  1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
        -: 1348:    }
        -: 1349:  }
        -: 1350:
    #####: 1351:  for (const ValueKnowledge &result : resultKnowledge) {
branch  0 never executed
branch  1 never executed
    #####: 1352:    inferredReturnShapes.push_back(result.getShapedTypeComponents());
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
        -: 1353:  }
        -: 1354:
    #####: 1355:  return success();
call    0 never executed
        -: 1356:}
        -: 1357:
function _ZN4mlir4tosa7WhileOp25inferReturnTypeComponentsEPNS_11MLIRContextEN4llvm8OptionalINS_8LocationEEENS_15ValueShapeRangeENS_14DictionaryAttrENS_11RegionRangeERNS4_15SmallVectorImplINS_20ShapedTypeComponentsEEE called 0 returned 0% blocks executed 0%
    #####: 1358:LogicalResult WhileOp::inferReturnTypeComponents(
        -: 1359:    MLIRContext *context, ::llvm::Optional<Location> location,
        -: 1360:    ValueShapeRange operands, DictionaryAttr attributes, RegionRange regions,
        -: 1361:    SmallVectorImpl<ShapedTypeComponents> &inferredReturnShapes) {
    #####: 1362:  llvm::SmallVector<tosa::YieldOp> yieldOps;
call    0 never executed
    #####: 1363:  for (auto &block : *regions[1])
call    0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
    #####: 1364:    if (auto returnOp = dyn_cast<tosa::YieldOp>(block.getTerminator()))
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####: 1365:      yieldOps.push_back(returnOp);
call    0 never executed
        -: 1366:
        -: 1367:  // TOSA's while must have a tosa.yield as its terminator. If not found this
        -: 1368:  // tosa.while is invalid.
    #####: 1369:  if (yieldOps.empty())
branch  0 never executed
branch  1 never executed
    #####: 1370:    return failure();
branch  0 never executed
branch  1 never executed
        -: 1371:
        -: 1372:  // Get the initial type information from the operand types.
    #####: 1373:  llvm::SmallVector<ValueKnowledge> resultKnowledge;
call    0 never executed
    #####: 1374:  resultKnowledge.reserve(yieldOps.front().getNumOperands());
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1375:  for (auto operand : yieldOps.front().getOperands()) {
branch  0 never executed
branch  1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
call    5 never executed
    #####: 1376:    resultKnowledge.push_back(
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1377:        ValueKnowledge::getKnowledgeFromType(operand.getType()));
call    0 never executed
        -: 1378:  }
        -: 1379:
    #####: 1380:  for (auto yieldOp : yieldOps) {
branch  0 never executed
branch  1 never executed
    #####: 1381:    if (resultKnowledge.size() != yieldOp.getNumOperands())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1382:      return failure();
        -: 1383:
    #####: 1384:    for (const auto &it : llvm::enumerate(yieldOp.getOperands())) {
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
    #####: 1385:      int32_t index = it.index();
call    0 never executed
    #####: 1386:      if (auto meet = ValueKnowledge::meet(
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####: 1387:              resultKnowledge[index],
branch  0 never executed
branch  1 never executed
    #####: 1388:              ValueKnowledge::getKnowledgeFromType(it.value().getType()))) {
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
call    6 never executed
    #####: 1389:        resultKnowledge[index] = meet;
branch  0 never executed
branch  1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
        -: 1390:      }
        -: 1391:    }
        -: 1392:  }
        -: 1393:
    #####: 1394:  for (const ValueKnowledge &result : resultKnowledge) {
branch  0 never executed
branch  1 never executed
    #####: 1395:    inferredReturnShapes.push_back(result.getShapedTypeComponents());
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
        -: 1396:  }
        -: 1397:
    #####: 1398:  return success();
call    0 never executed
        -: 1399:}
        -: 1400:
        -: 1401://===----------------------------------------------------------------------===//
        -: 1402:// TOSA Attribute Definitions.
        -: 1403://===----------------------------------------------------------------------===//
        -: 1404:
        -: 1405:#define GET_ATTRDEF_CLASSES
        -: 1406:#include "mlir/Dialect/Tosa/IR/TosaAttributes.cpp.inc"
        -: 1407:
        -: 1408://===----------------------------------------------------------------------===//
        -: 1409:// TOSA Operator Definitions.
        -: 1410://===----------------------------------------------------------------------===//
        -: 1411:
        -: 1412:#define GET_OP_CLASSES
        -: 1413:#include "mlir/Dialect/Tosa/IR/TosaOps.cpp.inc"
