        -:    0:Source:/data/xcy/llvm-project-fdbc55a5-1/mlir/lib/Dialect/Linalg/Transforms/Tiling.cpp
        -:    0:Graph:../tools/mlir/lib/Dialect/Linalg/Transforms/CMakeFiles/obj.MLIRLinalgTransforms.dir/Tiling.cpp.gcno
        -:    0:Data:../tools/mlir/lib/Dialect/Linalg/Transforms/CMakeFiles/obj.MLIRLinalgTransforms.dir/Tiling.cpp.gcda
        -:    0:Runs:325547
        -:    1://===- Tiling.cpp - Implementation of linalg Tiling -----------------------===//
        -:    2://
        -:    3:// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
        -:    4:// See https://llvm.org/LICENSE.txt for license information.
        -:    5:// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
        -:    6://
        -:    7://===----------------------------------------------------------------------===//
        -:    8://
        -:    9:// This file implements the linalg dialect Tiling pass.
        -:   10://
        -:   11://===----------------------------------------------------------------------===//
        -:   12:
        -:   13:#include "mlir/Dialect/Linalg/Passes.h"
        -:   14:
        -:   15:#include "mlir/Dialect/Affine/IR/AffineOps.h"
        -:   16:#include "mlir/Dialect/Arith/Utils/Utils.h"
        -:   17:#include "mlir/Dialect/ControlFlow/IR/ControlFlowOps.h"
        -:   18:#include "mlir/Dialect/Func/IR/FuncOps.h"
        -:   19:#include "mlir/Dialect/Linalg/IR/Linalg.h"
        -:   20:#include "mlir/Dialect/Linalg/Transforms/Transforms.h"
        -:   21:#include "mlir/Dialect/MemRef/IR/MemRef.h"
        -:   22:#include "mlir/Dialect/SCF/Transforms/Transforms.h"
        -:   23:#include "mlir/Dialect/Tensor/IR/Tensor.h"
        -:   24:#include "mlir/Dialect/Utils/IndexingUtils.h"
        -:   25:#include "mlir/IR/AffineExpr.h"
        -:   26:#include "mlir/IR/AffineMap.h"
        -:   27:#include "mlir/Transforms/FoldUtils.h"
        -:   28:#include "mlir/Transforms/GreedyPatternRewriteDriver.h"
        -:   29:#include "llvm/Support/CommandLine.h"
        -:   30:#include <utility>
        -:   31:
        -:   32:namespace mlir {
        -:   33:#define GEN_PASS_DEF_LINALGTILINGPASS
        -:   34:#include "mlir/Dialect/Linalg/Passes.h.inc"
        -:   35:} // namespace mlir
        -:   36:
        -:   37:using namespace mlir;
        -:   38:using namespace mlir::linalg;
        -:   39:using namespace mlir::scf;
        -:   40:
        -:   41:#define DEBUG_TYPE "linalg-tiling"
        -:   42:
function _ZL6isZeroN4mlir12OpFoldResultE called 0 returned 0% blocks executed 0%
    #####:   43:static bool isZero(OpFoldResult v) {
    #####:   44:  if (!v)
branch  0 never executed
branch  1 never executed
        -:   45:    return false;
    #####:   46:  if (auto attr = v.dyn_cast<Attribute>()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
    #####:   47:    IntegerAttr intAttr = attr.dyn_cast<IntegerAttr>();
call    0 never executed
    #####:   48:    return intAttr && intAttr.getValue().isZero();
branch  0 never executed
branch  1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
branch  6 never executed
branch  7 never executed
branch  8 never executed
        -:   49:  }
    #####:   50:  if (auto cst = v.get<Value>().getDefiningOp<arith::ConstantIndexOp>())
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:   51:    return cst.value() == 0;
call    0 never executed
    #####:   52:  return false;
        -:   53:}
        -:   54:
        -:   55:std::tuple<SmallVector<Range, 4>, LoopIndexToRangeIndexMap>
function _ZN4mlir6linalg19makeTiledLoopRangesERNS_12RewriterBaseENS_8LocationENS_9AffineMapEN4llvm8ArrayRefINS_12OpFoldResultEEES8_ called 0 returned 0% blocks executed 0%
    #####:   56:mlir::linalg::makeTiledLoopRanges(RewriterBase &b, Location loc, AffineMap map,
        -:   57:                                  ArrayRef<OpFoldResult> allShapeSizes,
        -:   58:                                  ArrayRef<OpFoldResult> allTileSizes) {
    #####:   59:  assert(allTileSizes.size() == map.getNumResults());
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
        -:   60:  // Apply `map` to get shape sizes in loop order.
    #####:   61:  SmallVector<OpFoldResult> shapeSizes =
    #####:   62:      makeComposedFoldedMultiResultAffineApply(b, loc, map, allShapeSizes);
call    0 never executed
    #####:   63:  SmallVector<OpFoldResult> tileSizes(allTileSizes.begin(), allTileSizes.end());
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:   64:
        -:   65:  // Traverse the tile sizes, which are in loop order, erase zeros everywhere.
    #####:   66:  LoopIndexToRangeIndexMap loopIndexToRangeIndex;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:   67:  for (int idx = 0, e = tileSizes.size(), zerosCount = 0; idx < e; ++idx) {
branch  0 never executed
branch  1 never executed
    #####:   68:    if (isZero(tileSizes[idx - zerosCount])) {
branch  0 never executed
branch  1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
    #####:   69:      shapeSizes.erase(shapeSizes.begin() + idx - zerosCount);
call    0 never executed
    #####:   70:      tileSizes.erase(tileSizes.begin() + idx - zerosCount);
call    0 never executed
    #####:   71:      ++zerosCount;
    #####:   72:      continue;
        -:   73:    }
    #####:   74:    loopIndexToRangeIndex[idx] = idx - zerosCount;
call    0 never executed
        -:   75:  }
        -:   76:
        -:   77:  // Create a new range with the applied tile sizes.
    #####:   78:  SmallVector<Range, 4> res;
call    0 never executed
    #####:   79:  for (unsigned idx = 0, e = tileSizes.size(); idx < e; ++idx)
branch  0 never executed
branch  1 never executed
    #####:   80:    res.push_back(Range{b.getIndexAttr(0), shapeSizes[idx], tileSizes[idx]});
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
call    6 never executed
    #####:   81:  return std::make_tuple(res, loopIndexToRangeIndex);
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:   82:}
        -:   83:
function _ZN4mlir6linalg17transformIndexOpsERNS_12RewriterBaseENS0_8LinalgOpERN4llvm15SmallVectorImplINS_5ValueEEERKNS4_8DenseMapIiiNS4_12DenseMapInfoIivEENS4_6detail12DenseMapPairIiiEEEE called 0 returned 0% blocks executed 0%
    #####:   84:void mlir::linalg::transformIndexOps(
        -:   85:    RewriterBase &b, LinalgOp op, SmallVectorImpl<Value> &ivs,
        -:   86:    const LoopIndexToRangeIndexMap &loopIndexToRangeIndex) {
    #####:   87:  SmallVector<Value> allIvs(op.getNumLoops(), nullptr);
call    0 never executed
call    1 never executed
call    2 never executed
    #####:   88:  for (auto &en : enumerate(allIvs)) {
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:   89:    auto rangeIndex = loopIndexToRangeIndex.find(en.index());
call    0 never executed
    #####:   90:    if (rangeIndex == loopIndexToRangeIndex.end())
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:   91:      continue;
    #####:   92:    en.value() = ivs[rangeIndex->second];
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:   93:  }
    #####:   94:  offsetIndices(b, op, getAsOpFoldResult(allIvs));
call    0 never executed
call    1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
branch  6 never executed
    #####:   95:}
        -:   96:
        -:   97:/// Asserts that the given index-typed value is strictly positive. If the value
        -:   98:/// is an attribute, asserts at compile time, otherwise emits an assertion
        -:   99:/// checked at runtime.
function _ZL28emitIsPositiveIndexAssertionRN4mlir20ImplicitLocOpBuilderENS_12OpFoldResultE called 0 returned 0% blocks executed 0%
    #####:  100:static void emitIsPositiveIndexAssertion(ImplicitLocOpBuilder &b,
        -:  101:                                         OpFoldResult value) {
    #####:  102:  if (auto attr = value.dyn_cast<Attribute>()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  103:    assert(attr.cast<IntegerAttr>().getValue().isStrictlyPositive() &&
call    0 never executed
call    1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
call    5 never executed
        -:  104:           "expected strictly positive tile size and divisor");
    #####:  105:    return;
        -:  106:  }
        -:  107:
    #####:  108:  Value zero = b.create<arith::ConstantIndexOp>(0);
call    0 never executed
call    1 never executed
    #####:  109:  Value condition = b.create<arith::CmpIOp>(arith::CmpIPredicate::sgt,
call    0 never executed
    #####:  110:                                            value.get<Value>(), zero);
call    0 never executed
call    1 never executed
    #####:  111:  b.create<cf::AssertOp>(
        -:  112:      condition,
    #####:  113:      b.getStringAttr("expected strictly positive tile size and divisor"));
call    0 never executed
call    1 never executed
call    2 never executed
        -:  114:}
        -:  115:
        -:  116:FailureOr<MultiSizeSpecification>
function _ZN4mlir6linalg21computeMultiTileSizesERNS_9OpBuilderENS0_8LinalgOpEjNS_12OpFoldResultES4_b called 0 returned 0% blocks executed 0%
    #####:  117:mlir::linalg::computeMultiTileSizes(OpBuilder &builder, LinalgOp op,
        -:  118:                                    unsigned dimension, OpFoldResult targetSize,
        -:  119:                                    OpFoldResult divisor, bool emitAssertions) {
        -:  120:  // Bail out on dimension overflow.
    #####:  121:  if (dimension >= op.getNumLoops())
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  122:    return failure();
        -:  123:
        -:  124:  // The code below works only on values.
    #####:  125:  Location loc = op.getLoc();
branch  0 never executed
branch  1 never executed
    #####:  126:  ImplicitLocOpBuilder b(loc, builder);
branch  0 never executed
branch  1 never executed
    #####:  127:  if (emitAssertions) {
branch  0 never executed
branch  1 never executed
    #####:  128:    emitIsPositiveIndexAssertion(b, targetSize);
call    0 never executed
    #####:  129:    emitIsPositiveIndexAssertion(b, divisor);
call    0 never executed
        -:  130:  }
    #####:  131:  Value targetSizeValue =
    #####:  132:      getValueOrCreateConstantIndexOp(builder, loc, targetSize);
call    0 never executed
    #####:  133:  Value divisorValue = getValueOrCreateConstantIndexOp(builder, loc, divisor);
call    0 never executed
        -:  134:
        -:  135:  // Find the trip count of the iteration space dimension for which the tile
        -:  136:  // sizes are computed.
    #####:  137:  SmallVector<OpFoldResult> allShapes =
    #####:  138:      op.createFlatListOfOperandDims(b, b.getLoc());
call    0 never executed
    #####:  139:  AffineMap shapesToLoops = op.getShapesToLoopsMap();
call    0 never executed
    #####:  140:  SmallVector<OpFoldResult> loopRanges =
call    0 never executed
        -:  141:      makeComposedFoldedMultiResultAffineApply(b, op.getLoc(), shapesToLoops,
    #####:  142:                                               allShapes);
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  143:  Value tripCount =
    #####:  144:      getValueOrCreateConstantIndexOp(b, op.getLoc(), loopRanges[dimension]);
branch  0 never executed
branch  1 never executed
call    2 never executed
        -:  145:
        -:  146:  // Compute the tile sizes and the respective numbers of tiles.
    #####:  147:  AffineExpr s0 = b.getAffineSymbolExpr(0);
call    0 never executed
    #####:  148:  AffineExpr s1 = b.getAffineSymbolExpr(1);
call    0 never executed
    #####:  149:  AffineExpr s2 = b.getAffineSymbolExpr(2);
call    0 never executed
    #####:  150:  auto apply = [&](AffineExpr expr, ValueRange values) -> Value {
    #####:  151:    return makeComposedAffineApply(b, b.getLoc(), expr, values);
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
call    5 never executed
branch  6 never executed
branch  7 never executed
call    8 never executed
    #####:  152:  };
    #####:  153:  Value a = apply(s0.floorDiv(s1), {tripCount, divisorValue});
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  154:  Value t = apply((s0 + s1 - 1).floorDiv(s1), {targetSizeValue, divisorValue});
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
    #####:  155:  Value d = apply((s0 + s1 - 1).floorDiv(s1), {a, t});
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
    #####:  156:  Value s = apply(s0.floorDiv(s1) * s2, {a, d, divisorValue});
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:  157:  Value v = apply(s0 % s1, {a, d});
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  158:  Value u = apply(s0 - s1, {d, v});
call    0 never executed
call    1 never executed
call    2 never executed
        -:  159:
    #####:  160:  MultiSizeSpecification spec;
    #####:  161:  spec.lowTileSize = s;
    #####:  162:  spec.highTileSize = apply(s0 + s1, {s, divisorValue});
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  163:  spec.lowTripCount = u;
    #####:  164:  spec.highTripCount = v;
        -:  165:
        -:  166:  // If requested, emit the check that the tile sizes are computed correctly.
        -:  167:  // For example, for iteration dimension size of 15 and the target size 8 it is
        -:  168:  // impossible to find two tile sizes both divisible by 8 that fully cover the
        -:  169:  // original space dimension.
    #####:  170:  if (emitAssertions) {
branch  0 never executed
branch  1 never executed
    #####:  171:    AffineExpr s3 = builder.getAffineSymbolExpr(3);
call    0 never executed
    #####:  172:    Value coveredSize =
    #####:  173:        apply(s0 * s1 + s2 * s3, {spec.lowTileSize, spec.lowTripCount,
call    0 never executed
    #####:  174:                                  spec.highTileSize, spec.highTripCount});
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:  175:    Value equals = b.create<arith::CmpIOp>(arith::CmpIPredicate::eq,
call    0 never executed
    #####:  176:                                           coveredSize, tripCount);
call    0 never executed
    #####:  177:    b.create<cf::AssertOp>(
    #####:  178:        equals, builder.getStringAttr(
    #####:  179:                    "could not compute dynamic multi-size tile shapes"));
call    0 never executed
call    1 never executed
call    2 never executed
        -:  180:  }
        -:  181:
    #####:  182:  return spec;
branch  0 never executed
branch  1 never executed
        -:  183:}
        -:  184:
        -:  185:/// Returns true if the maximum tile offset `tileSize * numThreads-1` is less
        -:  186:/// than `iterationSize`.
function _ZL30canOmitTileOffsetInBoundsCheckN4mlir12OpFoldResultES0_S0_ called 0 returned 0% blocks executed 0%
    #####:  187:static bool canOmitTileOffsetInBoundsCheck(OpFoldResult tileSize,
        -:  188:                                           OpFoldResult numThreads,
        -:  189:                                           OpFoldResult iterationSize) {
    #####:  190:  Optional<int64_t> tileSizeConst = getConstantIntValue(tileSize);
call    0 never executed
    #####:  191:  Optional<int64_t> numThreadsConst = getConstantIntValue(numThreads);
call    0 never executed
    #####:  192:  Optional<int64_t> iterSizeConst = getConstantIntValue(iterationSize);
call    0 never executed
    #####:  193:  if (!tileSizeConst || !numThreadsConst || !iterSizeConst)
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
        -:  194:    return false;
    #####:  195:  return *tileSizeConst * (*numThreadsConst - 1) < *iterSizeConst;
        -:  196:}
        -:  197:
        -:  198:/// Build an `affine_max` of all the `vals`.
function _ZL8buildMaxRN4mlir9OpBuilderENS_8LocationEN4llvm8ArrayRefINS_12OpFoldResultEEE called 0 returned 0% blocks executed 0%
    #####:  199:static OpFoldResult buildMax(OpBuilder &b, Location loc,
        -:  200:                             ArrayRef<OpFoldResult> vals) {
    #####:  201:  return makeComposedFoldedAffineMax(
call    0 never executed
    #####:  202:      b, loc, AffineMap::getMultiDimIdentityMap(vals.size(), loc.getContext()),
    #####:  203:      vals);
call    0 never executed
call    1 never executed
        -:  204:}
        -:  205:
        -:  206:/// Build an `affine_min` of all the `vals`.
function _ZL8buildMinRN4mlir9OpBuilderENS_8LocationEN4llvm8ArrayRefINS_12OpFoldResultEEE called 0 returned 0% blocks executed 0%
    #####:  207:static OpFoldResult buildMin(OpBuilder &b, Location loc,
        -:  208:                             ArrayRef<OpFoldResult> vals) {
    #####:  209:  return makeComposedFoldedAffineMin(
call    0 never executed
    #####:  210:      b, loc, AffineMap::getMultiDimIdentityMap(vals.size(), loc.getContext()),
    #####:  211:      vals);
call    0 never executed
call    1 never executed
        -:  212:}
        -:  213:
        -:  214:/// Rewrite a TilingInterface `op` to a tiled `scf.foreach_thread`. The
        -:  215:/// tiling is specified by the number of tiles/threads `numThreads` and the
        -:  216:/// optional nominal tile size `nominalTileSizes`. If `nominalTilSizes` is
        -:  217:/// not specified, then  it is derived from `numThreads` as `ceilDiv(dimSize[i],
        -:  218:/// numThreads[i])`. If non-empty, the `threadDimMapping` is added as an
        -:  219:/// attribute to the resulting `scf.foreach_thread`. A zero tile sizes indicate
        -:  220:/// that the dimension is not tiled, and can be thought of as tiling by the full
        -:  221:/// size of data.
        -:  222:/// It is the user's responsibility to ensure that `numThreads` is a valid
        -:  223:/// tiling specification (i.e. that only tiles parallel dimensions, e.g. in the
        -:  224:/// Linalg case). If `omitTileOffsetBoundsCheck` is true, then the function will
        -:  225:/// assume that `tileSize[i] * (numThread[i] -1) <= dimSize[i]` holds.
function _ZL25tileToForeachThreadOpImplRN4mlir12RewriterBaseENS_15TilingInterfaceEN4llvm8ArrayRefINS_12OpFoldResultEEENS3_8OptionalIS6_EENS4_IlEEb called 0 returned 0% blocks executed 0%
    #####:  226:static FailureOr<ForeachThreadTilingResult> tileToForeachThreadOpImpl(
        -:  227:    RewriterBase &b, TilingInterface op, ArrayRef<OpFoldResult> numThreads,
        -:  228:    Optional<ArrayRef<OpFoldResult>> nominalTileSizes,
        -:  229:    ArrayRef<int64_t> threadDimMapping, bool omitTileOffsetBoundsCheck) {
    #####:  230:  Location loc = op->getLoc();
call    0 never executed
    #####:  231:  OpBuilder::InsertionGuard g(b);
call    0 never executed
    #####:  232:  SmallVector<Range> loopRanges = op.getIterationDomain(b);
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  233:  if (loopRanges.empty())
branch  0 never executed
branch  1 never executed
    #####:  234:    return op->emitOpError("expected non-empty loop ranges");
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  235:  auto hasStrideOne = [](Range r) { return !isConstantIntValue(r.stride, 1); };
    #####:  236:  if (llvm::any_of(loopRanges, hasStrideOne))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  237:    return op->emitOpError("only stride-1 supported atm");
call    0 never executed
call    1 never executed
call    2 never executed
        -:  238:
        -:  239:  // Gather destination tensors.
    #####:  240:  SmallVector<Value> dest;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  241:  if (failed(tensor::getOrCreateDestinations(b, loc, op, dest)))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  242:    return op->emitOpError("failed to get destination tensors");
call    0 never executed
call    1 never executed
call    2 never executed
        -:  243:
    #####:  244:  SmallVector<OpFoldResult> nonZeroNumThreads =
    #####:  245:      llvm::to_vector(llvm::make_filter_range(numThreads, [](OpFoldResult ofr) {
    #####:  246:        return !isConstantIntValue(ofr, 0);
call    0 never executed
    #####:  247:      }));
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  248:  SmallVector<Value> materializedNonZeroNumThreads =
    #####:  249:      llvm::to_vector(llvm::map_range(nonZeroNumThreads, [&](OpFoldResult ofr) {
    #####:  250:        return getValueOrCreateConstantIndexOp(b, loc, ofr);
call    0 never executed
    #####:  251:      }));
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  252:
    #####:  253:  Operation *tiledOp = nullptr;
        -:  254:
        -:  255:  // Create the ForeachThreadOp. We don't use the lambda body-builder
        -:  256:  // version because we require the use of RewriterBase in the body, so we
        -:  257:  // manually move the insertion point to the body below.
    #####:  258:  scf::ForeachThreadOp foreachThreadOp = b.create<scf::ForeachThreadOp>(
    #####:  259:      loc, dest, ValueRange(materializedNonZeroNumThreads), threadDimMapping);
call    0 never executed
call    1 never executed
        -:  260:
        -:  261:  // Fill out the ForeachThreadOp body.
    #####:  262:  b.setInsertionPointToStart(foreachThreadOp.getBody(0));
call    0 never executed
call    1 never executed
    #####:  263:  ValueRange threadIds = foreachThreadOp.getThreadIndices();
call    0 never executed
    #####:  264:  int64_t nLoops = loopRanges.size();
branch  0 never executed
branch  1 never executed
    #####:  265:  SmallVector<OpFoldResult> tiledOffsets, tiledSizes;
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
    #####:  266:  tiledOffsets.reserve(nLoops);
branch  0 never executed
branch  1 never executed
    #####:  267:  tiledSizes.reserve(nLoops);
branch  0 never executed
branch  1 never executed
    #####:  268:  for (unsigned loopIdx = 0, threadIdIdx = 0; loopIdx < nLoops; ++loopIdx) {
branch  0 never executed
branch  1 never executed
    #####:  269:    bool overflow = loopIdx >= numThreads.size();
branch  0 never executed
branch  1 never executed
    #####:  270:    bool isZero = !overflow && isConstantIntValue(numThreads[loopIdx], 0);
branch  0 never executed
branch  1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
        -:  271:    // Degenerate case: take the whole domain.
    #####:  272:    if (overflow || isZero) {
branch  0 never executed
branch  1 never executed
    #####:  273:      tiledOffsets.push_back(loopRanges[loopIdx].offset);
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  274:      tiledSizes.push_back(loopRanges[loopIdx].size);
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  275:      continue;
        -:  276:    }
        -:  277:
        -:  278:    // Tiled case: compute the offset and size.
    #####:  279:    AffineExpr i, j, m, n, o;
    #####:  280:    bindDims(b.getContext(), i, j);
call    0 never executed
    #####:  281:    bindSymbols(b.getContext(), m, n, o);
call    0 never executed
    #####:  282:    OpFoldResult size = loopRanges[loopIdx].size;
branch  0 never executed
branch  1 never executed
    #####:  283:    OpFoldResult offset = loopRanges[loopIdx].offset;
call    0 never executed
    #####:  284:    OpFoldResult threadId = threadIds[threadIdIdx];
call    0 never executed
call    1 never executed
        -:  285:    // Symbolic fixed max size per thread.
        -:  286:    // TODO: floor + 0/1 depending on case for better load-balancing.
    #####:  287:    OpFoldResult tileSizePerThread =
branch  0 never executed
branch  1 never executed
    #####:  288:        nominalTileSizes.has_value()
    #####:  289:            ? (*nominalTileSizes)[loopIdx]
branch  0 never executed
branch  1 never executed
        -:  290:            : makeComposedFoldedAffineApply(
        -:  291:                  b, loc, m.ceilDiv(n),
    #####:  292:                  ArrayRef<OpFoldResult>{size, nonZeroNumThreads[threadIdIdx]});
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
call    4 never executed
call    5 never executed
        -:  293:
        -:  294:    // Dynamic offset shifted by threadId * maxSizePerThread.
    #####:  295:    OpFoldResult offsetPerThread = makeComposedFoldedAffineApply(
    #####:  296:        b, loc, i + j * m, {offset, threadId, tileSizePerThread});
call    0 never executed
call    1 never executed
call    2 never executed
        -:  297:    // Dynamic upper-bound depending on the threadId.
    #####:  298:    OpFoldResult residualTileSize = makeComposedFoldedAffineApply(
    #####:  299:        b, loc, i + j * m - n,
call    0 never executed
call    1 never executed
    #####:  300:        {offset, nonZeroNumThreads[threadIdIdx], tileSizePerThread, size});
branch  0 never executed
branch  1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
    #####:  301:    if (!isConstantIntValue(residualTileSize, 0)) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  302:      OpFoldResult sizeMinusOffsetPerThread = makeComposedFoldedAffineApply(
    #####:  303:          b, loc, -i + m, {offsetPerThread, size});
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  304:      tileSizePerThread =
    #####:  305:          buildMin(b, loc, {sizeMinusOffsetPerThread, tileSizePerThread});
call    0 never executed
        -:  306:    }
        -:  307:
    #####:  308:    tiledOffsets.push_back(offsetPerThread);
call    0 never executed
        -:  309:    // TODO: if tileSizePerThread <= 0 early exit.
    #####:  310:    if (!omitTileOffsetBoundsCheck &&
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####:  311:        !canOmitTileOffsetInBoundsCheck(tileSizePerThread,
    #####:  312:                                        nonZeroNumThreads[threadIdIdx], size))
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  313:      tileSizePerThread =
    #####:  314:          buildMax(b, loc, {b.getIndexAttr(0), tileSizePerThread});
call    0 never executed
call    1 never executed
call    2 never executed
        -:  315:
    #####:  316:    tiledSizes.push_back(tileSizePerThread);
call    0 never executed
    #####:  317:    ++threadIdIdx;
        -:  318:  }
        -:  319:
        -:  320:  // Clone the tileable op and update its destination operands to use the output
        -:  321:  // bbArgs of the ForeachThreadOp.
    #####:  322:  ArrayRef<BlockArgument> destBbArgs =
    #####:  323:      foreachThreadOp.getOutputBlockArguments();
call    0 never executed
    #####:  324:  Operation *clonedOp = b.clone(*op.getOperation());
call    0 never executed
    #####:  325:  auto destinationStyleOp = dyn_cast<DestinationStyleOpInterface>(clonedOp);
call    0 never executed
    #####:  326:  if (destinationStyleOp) {
branch  0 never executed
branch  1 never executed
    #####:  327:    for (OpOperand *outOperand : destinationStyleOp.getDpsInitOperands()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  328:      auto *it = llvm::find(dest, outOperand->get());
branch  0 never executed
branch  1 never executed
    #####:  329:      assert(it != dest.end() && "dest operand not found in dest");
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  330:      unsigned destNum = std::distance(dest.begin(), it);
branch  0 never executed
branch  1 never executed
    #####:  331:      outOperand->set(destBbArgs[destNum]);
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
        -:  332:    }
        -:  333:  }
        -:  334:
        -:  335:  // Tile the cloned op and delete the clone.
    #####:  336:  SmallVector<Operation *> tiledOps =
    #####:  337:      cast<TilingInterface>(clonedOp).getTiledImplementation(b, tiledOffsets,
call    0 never executed
call    1 never executed
    #####:  338:                                                             tiledSizes);
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  339:  b.eraseOp(clonedOp);
call    0 never executed
    #####:  340:  assert(tiledOps.size() == 1 && "expected a single produced tiled op");
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  341:  tiledOp = tiledOps.front();
call    0 never executed
        -:  342:
    #####:  343:  auto tilingInterfaceOp = dyn_cast<TilingInterface>(tiledOp);
call    0 never executed
    #####:  344:  assert(tilingInterfaceOp && "Tiled op does not implement TilingInterface");
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  345:  OpBuilder::InsertPoint insertPt = b.saveInsertionPoint();
branch  0 never executed
branch  1 never executed
    #####:  346:  for (auto it : llvm::zip(llvm::seq(unsigned(0), unsigned(dest.size())),
    #####:  347:                           tilingInterfaceOp->getResults(), destBbArgs)) {
branch  0 never executed
branch  1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
    #####:  348:    b.setInsertionPoint(insertPt.getBlock(), insertPt.getPoint());
call    0 never executed
    #####:  349:    SmallVector<OpFoldResult> resultOffsets, resultSizes;
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
    #####:  350:    if (failed(op.getResultTilePosition(b, std::get<0>(it), tiledOffsets,
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  351:                                        tiledSizes, resultOffsets,
        -:  352:                                        resultSizes)))
    #####:  353:      return op->emitOpError("output offsets couldn't be calculated");
call    0 never executed
call    1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
    #####:  354:    SmallVector<OpFoldResult> strides(resultSizes.size(), b.getIndexAttr(1));
call    0 never executed
call    1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
    #####:  355:    b.setInsertionPointToEnd(foreachThreadOp.getTerminator().getBody());
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  356:    b.create<tensor::ParallelInsertSliceOp>(loc, std::get<1>(it),
        -:  357:                                            std::get<2>(it), resultOffsets,
    #####:  358:                                            resultSizes, strides);
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  359:  }
    #####:  360:  return ForeachThreadTilingResult{foreachThreadOp, tiledOp};
        -:  361:}
        -:  362:
        -:  363:FailureOr<ForeachThreadTilingResult>
function _ZN4mlir6linalg21tileToForeachThreadOpERNS_12RewriterBaseENS_15TilingInterfaceEN4llvm8ArrayRefINS_12OpFoldResultEEENS5_IlEE called 0 returned 0% blocks executed 0%
    #####:  364:linalg::tileToForeachThreadOp(RewriterBase &b, TilingInterface op,
        -:  365:                              ArrayRef<OpFoldResult> numThreads,
        -:  366:                              ArrayRef<int64_t> threadDimMapping) {
    #####:  367:  return tileToForeachThreadOpImpl(b, op, numThreads, /*nominalTileSizes=*/None,
call    0 never executed
        -:  368:                                   threadDimMapping,
    #####:  369:                                   /*omitTileOffsetBoundsCheck=*/false);
call    0 never executed
        -:  370:}
        -:  371:
        -:  372:FailureOr<ForeachThreadTilingResult>
function _ZN4mlir6linalg35tileToForeachThreadOpUsingTileSizesERNS_12RewriterBaseENS_15TilingInterfaceEN4llvm8ArrayRefINS_12OpFoldResultEEENS5_IlEE called 0 returned 0% blocks executed 0%
    #####:  373:linalg::tileToForeachThreadOpUsingTileSizes(
        -:  374:    RewriterBase &b, TilingInterface op, ArrayRef<OpFoldResult> tileSizes,
        -:  375:    ArrayRef<int64_t> threadDimMapping) {
    #####:  376:  SmallVector<Range> loopRanges = op.getIterationDomain(b);
call    0 never executed
    #####:  377:  unsigned nLoops = loopRanges.size();
branch  0 never executed
branch  1 never executed
    #####:  378:  SmallVector<OpFoldResult> numThreads;
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####:  379:  numThreads.reserve(nLoops);
branch  0 never executed
branch  1 never executed
    #####:  380:  AffineExpr s0, s1;
    #####:  381:  bindSymbols(b.getContext(), s0, s1);
call    0 never executed
    #####:  382:  AffineExpr divExpr = s0.ceilDiv(s1);
call    0 never executed
    #####:  383:  for (const auto &it : llvm::zip(tileSizes, loopRanges)) {
branch  0 never executed
branch  1 never executed
    #####:  384:    OpFoldResult numTiles = std::get<0>(it);
    #####:  385:    if (!isConstantIntValue(numTiles, 0))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  386:      numTiles = makeComposedFoldedAffineApply(
call    0 never executed
    #####:  387:          b, op.getLoc(), divExpr, {std::get<1>(it).size, std::get<0>(it)});
call    0 never executed
    #####:  388:    numThreads.push_back(numTiles);
call    0 never executed
        -:  389:  }
    #####:  390:  return tileToForeachThreadOpImpl(b, op, numThreads,
call    0 never executed
        -:  391:                                   /*nominalTileSizes=*/tileSizes,
        -:  392:                                   threadDimMapping,
    #####:  393:                                   /*omitTileOffsetBoundsCheck=*/true);
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  394:}
        -:  395:
        -:  396:// Insert a tile `source` into the destination tensor `dest`. The position at
        -:  397:// which the tile is inserted (as well as size of tile) is taken from a given
        -:  398:// ExtractSliceOp `sliceOp`.
function _ZL21insertSliceIntoTensorRN4mlir9OpBuilderENS_8LocationENS_6tensor14ExtractSliceOpENS_5ValueES5_ called 0 returned 0% blocks executed 0%
    #####:  399:static Value insertSliceIntoTensor(OpBuilder &b, Location loc,
        -:  400:                                   tensor::ExtractSliceOp sliceOp, Value source,
        -:  401:                                   Value dest) {
    #####:  402:  return b.create<tensor::InsertSliceOp>(
    #####:  403:      loc, sliceOp.getSource().getType(), source, dest, sliceOp.getOffsets(),
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  404:      sliceOp.getSizes(), sliceOp.getStrides(), sliceOp.getStaticOffsets(),
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  405:      sliceOp.getStaticSizes(), sliceOp.getStaticStrides());
call    0 never executed
call    1 never executed
call    2 never executed
        -:  406:}
        -:  407:
        -:  408:template <typename LoopTy>
        -:  409:static FailureOr<TiledLinalgOp>
    #####:  410:tileLinalgOpImpl(RewriterBase &b, LinalgOp op, ArrayRef<OpFoldResult> tileSizes,
        -:  411:                 const LinalgTilingOptions &options) {
    #####:  412:  auto nLoops = op.getNumLoops();
        -:  413:  // Initial tile sizes may be too big, only take the first nLoops.
    #####:  414:  tileSizes = tileSizes.take_front(nLoops);
        -:  415:
    #####:  416:  if (llvm::all_of(tileSizes, isZero)) {
    #####:  417:    TiledLinalgOp tiledOp;
    #####:  418:    tiledOp.op = cast<LinalgOp>(b.clone(*op.getOperation()));
    #####:  419:    tiledOp.tensorResults.assign(tiledOp.op->result_begin(),
        -:  420:                                 tiledOp.op->result_end());
    #####:  421:    return tiledOp;
        -:  422:  }
        -:  423:
        -:  424:  // 1. Build the tiled loop ranges.
    #####:  425:  SmallVector<OpFoldResult> allShapeSizes =
        -:  426:      op.createFlatListOfOperandDims(b, op.getLoc());
    #####:  427:  AffineMap shapeSizesToLoopsMap = op.getShapesToLoopsMap();
    #####:  428:  if (!shapeSizesToLoopsMap)
    #####:  429:    return failure();
        -:  430:
    #####:  431:  auto [loopRanges, loopIndexToRangeIndex] = makeTiledLoopRanges(
        -:  432:      b, op.getLoc(), shapeSizesToLoopsMap, allShapeSizes, tileSizes);
        -:  433:
    #####:  434:  SmallVector<StringRef, 4> iteratorTypes;
    #####:  435:  for (const auto &attr : enumerate(op.getIteratorTypesArray())) {
    #####:  436:    if (loopIndexToRangeIndex.count(attr.index()))
    #####:  437:      iteratorTypes.push_back(attr.value());
        -:  438:  }
        -:  439:  // If interchangeVector is empty, use the identity. Build the permutation map
        -:  440:  // otherwise.
        -:  441:  auto invPermutationMap =
    #####:  442:      AffineMap::getMultiDimIdentityMap(tileSizes.size(), b.getContext());
    #####:  443:  if (!options.interchangeVector.empty()) {
        -:  444:    // Based on the pruned iterations (due to zero tile size), recompute the
        -:  445:    // interchange vector.
    #####:  446:    SmallVector<unsigned, 4> interchangeVector;
    #####:  447:    interchangeVector.reserve(options.interchangeVector.size());
    #####:  448:    for (auto pos : options.interchangeVector) {
    #####:  449:      auto it = loopIndexToRangeIndex.find(pos);
    #####:  450:      if (it == loopIndexToRangeIndex.end())
    #####:  451:        continue;
    #####:  452:      interchangeVector.push_back(it->second);
        -:  453:    }
        -:  454:    // Interchange vector is guaranteed to be a permutation,
        -:  455:    // `inversePermutation` must succeed.
    #####:  456:    invPermutationMap = inversePermutation(
        -:  457:        AffineMap::getPermutationMap(interchangeVector, b.getContext()));
    #####:  458:    assert(invPermutationMap);
    #####:  459:    SmallVector<int64_t> permutation(interchangeVector.begin(),
        -:  460:                                     interchangeVector.end());
    #####:  461:    applyPermutationToVector(loopRanges, permutation);
    #####:  462:    applyPermutationToVector(iteratorTypes, permutation);
        -:  463:  }
        -:  464:
        -:  465:  // Handle distribution. Create a vector of the same size of loops that are to
        -:  466:  // be tiled.
    #####:  467:  SmallVector<linalg::ProcInfo> procInfo;
    #####:  468:  if (options.distribution) {
    #####:  469:    procInfo.resize(
        -:  470:        iteratorTypes.size(),
        -:  471:        linalg::ProcInfo{nullptr, nullptr, linalg::DistributionMethod::None});
        -:  472:    // Collect loop ranges of tiled loopss, loops that are parallel.
    #####:  473:    SmallVector<Range> parallelLoopRanges;
    #####:  474:    for (const auto &iteratorType : llvm::enumerate(iteratorTypes)) {
    #####:  475:      if (!isParallelIterator(iteratorType.value()))
        -:  476:        break;
    #####:  477:      parallelLoopRanges.push_back(loopRanges[iteratorType.index()]);
        -:  478:    }
    #####:  479:    auto returnedProcInfo =
    #####:  480:        options.distribution->procInfo(b, op.getLoc(), parallelLoopRanges);
    #####:  481:    unsigned procIdIdx = 0;
        -:  482:    // Update the distribution information for the loops.
    #####:  483:    for (const auto &iteratorType : llvm::enumerate(iteratorTypes)) {
    #####:  484:      if (!isParallelIterator(iteratorType.value()))
        -:  485:        break;
    #####:  486:      procInfo[iteratorType.index()] = returnedProcInfo[procIdIdx++];
        -:  487:    }
        -:  488:  }
        -:  489:
        -:  490:  // 2. Create the tiled loops.
    #####:  491:  LinalgOp res = op;
    #####:  492:  SmallVector<Value, 4> ivs, tensorResults;
    #####:  493:  auto tiledLoopBodyBuilder =
    #####:  494:      [&](OpBuilder &builder, Location loc, ValueRange localIvs,
        -:  495:          ValueRange operandValuesToUse) -> scf::ValueVector {
    #####:  496:    ivs.assign(localIvs.begin(), localIvs.end());
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
branch  4 never executed
branch  5 never executed
        -:  497:
        -:  498:    // When an `interchangeVector` is present, it has been applied to the
        -:  499:    // loop ranges and the iterator types. Apply its inverse to the
        -:  500:    // resulting loop `ivs` to match the op definition.
    #####:  501:    SmallVector<Value, 4> interchangedIvs;
    #####:  502:    if (!options.interchangeVector.empty())
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####:  503:      interchangedIvs = applyMapToValues(b, loc, invPermutationMap, ivs);
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
call    4 never executed
call    5 never executed
branch  6 never executed
branch  7 never executed
        -:  504:    else
    #####:  505:      interchangedIvs.assign(ivs.begin(), ivs.end());
call    0 never executed
call    1 never executed
        -:  506:
        -:  507:    // Tile the `operandValuesToUse` that either match the `op` operands
        -:  508:    // themselves or the tile loop arguments forwarding them.
    #####:  509:    assert(operandValuesToUse.size() ==
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
call    4 never executed
branch  5 never executed
branch  6 never executed
branch  7 never executed
branch  8 never executed
call    9 never executed
        -:  510:               static_cast<size_t>(op->getNumOperands()) &&
        -:  511:           "expect the number of operands and inputs and outputs to match");
    #####:  512:    SmallVector<Value> valuesToTile = operandValuesToUse;
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####:  513:    SmallVector<OpFoldResult> sizeBounds =
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
call    4 never executed
call    5 never executed
branch  6 never executed
branch  7 never executed
        -:  514:        makeComposedFoldedMultiResultAffineApply(b, loc, shapeSizesToLoopsMap,
        -:  515:                                                 allShapeSizes);
    #####:  516:    SmallVector<Value> tiledOperands = makeTiledShapes(
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
branch  4 never executed
branch  5 never executed
call    6 never executed
branch  7 never executed
branch  8 never executed
call    9 never executed
call   10 never executed
call   11 never executed
call   12 never executed
branch 13 never executed
branch 14 never executed
call   15 never executed
branch 16 never executed
branch 17 never executed
        -:  517:        b, loc, op, valuesToTile, getAsOpFoldResult(interchangedIvs), tileSizes,
        -:  518:        sizeBounds,
        -:  519:        /*omitPartialTileCheck=*/false);
        -:  520:
    #####:  521:    SmallVector<Type> resultTensorTypes =
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
call    4 never executed
call    5 never executed
branch  6 never executed
branch  7 never executed
        -:  522:        getTensorOutputTypes(op, tiledOperands);
    #####:  523:    res = op.clone(b, loc, resultTensorTypes, tiledOperands);
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
call    5 never executed
    #####:  524:    tensorResults =
branch  0 never executed
branch  1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
branch  5 never executed
branch  6 never executed
call    7 never executed
branch  8 never executed
branch  9 never executed
call   10 never executed
call   11 never executed
call   12 never executed
branch 13 never executed
branch 14 never executed
call   15 never executed
        -:  525:        insertSlicesBack(builder, loc, op, tiledOperands, res->getResults());
    #####:  526:    return scf::ValueVector(tensorResults.begin(), tensorResults.end());
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
branch  4 never executed
branch  5 never executed
        -:  527:  };
    #####:  528:  GenerateLoopNest<LoopTy>::doit(b, op.getLoc(), loopRanges, op, iteratorTypes,
        -:  529:                                 tiledLoopBodyBuilder, procInfo);
        -:  530:
        -:  531:  // 3. Transform IndexOp results w.r.t. the tiling.
    #####:  532:  transformIndexOps(b, res, ivs, loopIndexToRangeIndex);
        -:  533:
        -:  534:  // 4. Gather the newly created loops and return them with the new op.
    #####:  535:  SmallVector<Operation *, 8> loops;
    #####:  536:  loops.reserve(ivs.size());
    #####:  537:  for (auto iv : ivs) {
    #####:  538:    if (iv.isa<BlockArgument>()) {
    #####:  539:      loops.push_back(iv.cast<BlockArgument>().getOwner()->getParentOp());
    #####:  540:      assert(loops.back() && "no owner found for induction variable!");
        -:  541:    } else {
        -:  542:      // TODO: Instead of doing this, try to recover the ops used instead of the
        -:  543:      // loop.
    #####:  544:      loops.push_back(nullptr);
        -:  545:    }
        -:  546:  }
        -:  547:
        -:  548:  // 5. Get the tensor results from the outermost loop if available. Otherwise
        -:  549:  // use the previously captured `tensorResults`.
    #####:  550:  Operation *outermostLoop = nullptr;
    #####:  551:  for (Operation *loop : loops)
    #####:  552:    if ((outermostLoop = loop))
        -:  553:      break;
        -:  554:
        -:  555:  return TiledLinalgOp{
    #####:  556:      res, loops, outermostLoop ? outermostLoop->getResults() : tensorResults};
        -:  557:}
------------------
_Z16tileLinalgOpImplIN4mlir3scf10ParallelOpEENS0_9FailureOrINS0_6linalg13TiledLinalgOpEEERNS0_12RewriterBaseENS4_8LinalgOpEN4llvm8ArrayRefINS0_12OpFoldResultEEERKNS4_19LinalgTilingOptionsE:
function _Z16tileLinalgOpImplIN4mlir3scf10ParallelOpEENS0_9FailureOrINS0_6linalg13TiledLinalgOpEEERNS0_12RewriterBaseENS4_8LinalgOpEN4llvm8ArrayRefINS0_12OpFoldResultEEERKNS4_19LinalgTilingOptionsE called 0 returned 0% blocks executed 0%
    #####:  410:tileLinalgOpImpl(RewriterBase &b, LinalgOp op, ArrayRef<OpFoldResult> tileSizes,
        -:  411:                 const LinalgTilingOptions &options) {
    #####:  412:  auto nLoops = op.getNumLoops();
call    0 never executed
        -:  413:  // Initial tile sizes may be too big, only take the first nLoops.
    #####:  414:  tileSizes = tileSizes.take_front(nLoops);
branch  0 never executed
branch  1 never executed
call    2 never executed
        -:  415:
    #####:  416:  if (llvm::all_of(tileSizes, isZero)) {
branch  0 never executed
branch  1 never executed
    #####:  417:    TiledLinalgOp tiledOp;
    #####:  418:    tiledOp.op = cast<LinalgOp>(b.clone(*op.getOperation()));
call    0 never executed
call    1 never executed
    #####:  419:    tiledOp.tensorResults.assign(tiledOp.op->result_begin(),
branch  0 never executed
branch  1 never executed
call    2 never executed
call    3 never executed
        -:  420:                                 tiledOp.op->result_end());
    #####:  421:    return tiledOp;
call    0 never executed
        -:  422:  }
        -:  423:
        -:  424:  // 1. Build the tiled loop ranges.
    #####:  425:  SmallVector<OpFoldResult> allShapeSizes =
call    0 never executed
        -:  426:      op.createFlatListOfOperandDims(b, op.getLoc());
    #####:  427:  AffineMap shapeSizesToLoopsMap = op.getShapesToLoopsMap();
call    0 never executed
    #####:  428:  if (!shapeSizesToLoopsMap)
branch  0 never executed
branch  1 never executed
    #####:  429:    return failure();
        -:  430:
    #####:  431:  auto [loopRanges, loopIndexToRangeIndex] = makeTiledLoopRanges(
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
        -:  432:      b, op.getLoc(), shapeSizesToLoopsMap, allShapeSizes, tileSizes);
        -:  433:
    #####:  434:  SmallVector<StringRef, 4> iteratorTypes;
call    0 never executed
    #####:  435:  for (const auto &attr : enumerate(op.getIteratorTypesArray())) {
call    0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
branch  6 never executed
call    7 never executed
    #####:  436:    if (loopIndexToRangeIndex.count(attr.index()))
call    0 never executed
    #####:  437:      iteratorTypes.push_back(attr.value());
call    0 never executed
        -:  438:  }
        -:  439:  // If interchangeVector is empty, use the identity. Build the permutation map
        -:  440:  // otherwise.
        -:  441:  auto invPermutationMap =
    #####:  442:      AffineMap::getMultiDimIdentityMap(tileSizes.size(), b.getContext());
call    0 never executed
    #####:  443:  if (!options.interchangeVector.empty()) {
branch  0 never executed
branch  1 never executed
        -:  444:    // Based on the pruned iterations (due to zero tile size), recompute the
        -:  445:    // interchange vector.
    #####:  446:    SmallVector<unsigned, 4> interchangeVector;
    #####:  447:    interchangeVector.reserve(options.interchangeVector.size());
branch  0 never executed
branch  1 never executed
    #####:  448:    for (auto pos : options.interchangeVector) {
branch  0 never executed
branch  1 never executed
    #####:  449:      auto it = loopIndexToRangeIndex.find(pos);
call    0 never executed
    #####:  450:      if (it == loopIndexToRangeIndex.end())
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  451:        continue;
    #####:  452:      interchangeVector.push_back(it->second);
call    0 never executed
call    1 never executed
        -:  453:    }
        -:  454:    // Interchange vector is guaranteed to be a permutation,
        -:  455:    // `inversePermutation` must succeed.
    #####:  456:    invPermutationMap = inversePermutation(
call    0 never executed
call    1 never executed
        -:  457:        AffineMap::getPermutationMap(interchangeVector, b.getContext()));
    #####:  458:    assert(invPermutationMap);
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  459:    SmallVector<int64_t> permutation(interchangeVector.begin(),
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
        -:  460:                                     interchangeVector.end());
    #####:  461:    applyPermutationToVector(loopRanges, permutation);
call    0 never executed
call    1 never executed
    #####:  462:    applyPermutationToVector(iteratorTypes, permutation);
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  463:  }
        -:  464:
        -:  465:  // Handle distribution. Create a vector of the same size of loops that are to
        -:  466:  // be tiled.
    #####:  467:  SmallVector<linalg::ProcInfo> procInfo;
branch  0 never executed
branch  1 never executed
    #####:  468:  if (options.distribution) {
branch  0 never executed
branch  1 never executed
    #####:  469:    procInfo.resize(
call    0 never executed
        -:  470:        iteratorTypes.size(),
        -:  471:        linalg::ProcInfo{nullptr, nullptr, linalg::DistributionMethod::None});
        -:  472:    // Collect loop ranges of tiled loopss, loops that are parallel.
    #####:  473:    SmallVector<Range> parallelLoopRanges;
    #####:  474:    for (const auto &iteratorType : llvm::enumerate(iteratorTypes)) {
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  475:      if (!isParallelIterator(iteratorType.value()))
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  476:        break;
    #####:  477:      parallelLoopRanges.push_back(loopRanges[iteratorType.index()]);
branch  0 never executed
branch  1 never executed
call    2 never executed
        -:  478:    }
    #####:  479:    auto returnedProcInfo =
branch  0 never executed
branch  1 never executed
    #####:  480:        options.distribution->procInfo(b, op.getLoc(), parallelLoopRanges);
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####:  481:    unsigned procIdIdx = 0;
        -:  482:    // Update the distribution information for the loops.
    #####:  483:    for (const auto &iteratorType : llvm::enumerate(iteratorTypes)) {
branch  0 never executed
branch  1 never executed
    #####:  484:      if (!isParallelIterator(iteratorType.value()))
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  485:        break;
    #####:  486:      procInfo[iteratorType.index()] = returnedProcInfo[procIdIdx++];
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
call    4 never executed
        -:  487:    }
        -:  488:  }
        -:  489:
        -:  490:  // 2. Create the tiled loops.
    #####:  491:  LinalgOp res = op;
call    0 never executed
    #####:  492:  SmallVector<Value, 4> ivs, tensorResults;
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####:  493:  auto tiledLoopBodyBuilder =
call    0 never executed
        -:  494:      [&](OpBuilder &builder, Location loc, ValueRange localIvs,
        -:  495:          ValueRange operandValuesToUse) -> scf::ValueVector {
        -:  496:    ivs.assign(localIvs.begin(), localIvs.end());
        -:  497:
        -:  498:    // When an `interchangeVector` is present, it has been applied to the
        -:  499:    // loop ranges and the iterator types. Apply its inverse to the
        -:  500:    // resulting loop `ivs` to match the op definition.
        -:  501:    SmallVector<Value, 4> interchangedIvs;
        -:  502:    if (!options.interchangeVector.empty())
        -:  503:      interchangedIvs = applyMapToValues(b, loc, invPermutationMap, ivs);
        -:  504:    else
        -:  505:      interchangedIvs.assign(ivs.begin(), ivs.end());
        -:  506:
        -:  507:    // Tile the `operandValuesToUse` that either match the `op` operands
        -:  508:    // themselves or the tile loop arguments forwarding them.
        -:  509:    assert(operandValuesToUse.size() ==
        -:  510:               static_cast<size_t>(op->getNumOperands()) &&
        -:  511:           "expect the number of operands and inputs and outputs to match");
        -:  512:    SmallVector<Value> valuesToTile = operandValuesToUse;
        -:  513:    SmallVector<OpFoldResult> sizeBounds =
        -:  514:        makeComposedFoldedMultiResultAffineApply(b, loc, shapeSizesToLoopsMap,
        -:  515:                                                 allShapeSizes);
        -:  516:    SmallVector<Value> tiledOperands = makeTiledShapes(
        -:  517:        b, loc, op, valuesToTile, getAsOpFoldResult(interchangedIvs), tileSizes,
        -:  518:        sizeBounds,
        -:  519:        /*omitPartialTileCheck=*/false);
        -:  520:
        -:  521:    SmallVector<Type> resultTensorTypes =
        -:  522:        getTensorOutputTypes(op, tiledOperands);
        -:  523:    res = op.clone(b, loc, resultTensorTypes, tiledOperands);
        -:  524:    tensorResults =
        -:  525:        insertSlicesBack(builder, loc, op, tiledOperands, res->getResults());
        -:  526:    return scf::ValueVector(tensorResults.begin(), tensorResults.end());
        -:  527:  };
    #####:  528:  GenerateLoopNest<LoopTy>::doit(b, op.getLoc(), loopRanges, op, iteratorTypes,
call    0 never executed
        -:  529:                                 tiledLoopBodyBuilder, procInfo);
        -:  530:
        -:  531:  // 3. Transform IndexOp results w.r.t. the tiling.
    #####:  532:  transformIndexOps(b, res, ivs, loopIndexToRangeIndex);
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  533:
        -:  534:  // 4. Gather the newly created loops and return them with the new op.
    #####:  535:  SmallVector<Operation *, 8> loops;
branch  0 never executed
branch  1 never executed
    #####:  536:  loops.reserve(ivs.size());
branch  0 never executed
branch  1 never executed
    #####:  537:  for (auto iv : ivs) {
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  538:    if (iv.isa<BlockArgument>()) {
branch  0 never executed
branch  1 never executed
    #####:  539:      loops.push_back(iv.cast<BlockArgument>().getOwner()->getParentOp());
call    0 never executed
call    1 never executed
    #####:  540:      assert(loops.back() && "no owner found for induction variable!");
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
        -:  541:    } else {
        -:  542:      // TODO: Instead of doing this, try to recover the ops used instead of the
        -:  543:      // loop.
    #####:  544:      loops.push_back(nullptr);
call    0 never executed
        -:  545:    }
        -:  546:  }
        -:  547:
        -:  548:  // 5. Get the tensor results from the outermost loop if available. Otherwise
        -:  549:  // use the previously captured `tensorResults`.
    #####:  550:  Operation *outermostLoop = nullptr;
    #####:  551:  for (Operation *loop : loops)
branch  0 never executed
branch  1 never executed
    #####:  552:    if ((outermostLoop = loop))
branch  0 never executed
branch  1 never executed
        -:  553:      break;
        -:  554:
        -:  555:  return TiledLinalgOp{
    #####:  556:      res, loops, outermostLoop ? outermostLoop->getResults() : tensorResults};
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
call    4 never executed
call    5 never executed
call    6 never executed
branch  7 never executed
branch  8 never executed
        -:  557:}
------------------
_Z16tileLinalgOpImplIN4mlir3scf5ForOpEENS0_9FailureOrINS0_6linalg13TiledLinalgOpEEERNS0_12RewriterBaseENS4_8LinalgOpEN4llvm8ArrayRefINS0_12OpFoldResultEEERKNS4_19LinalgTilingOptionsE:
function _Z16tileLinalgOpImplIN4mlir3scf5ForOpEENS0_9FailureOrINS0_6linalg13TiledLinalgOpEEERNS0_12RewriterBaseENS4_8LinalgOpEN4llvm8ArrayRefINS0_12OpFoldResultEEERKNS4_19LinalgTilingOptionsE called 0 returned 0% blocks executed 0%
    #####:  410:tileLinalgOpImpl(RewriterBase &b, LinalgOp op, ArrayRef<OpFoldResult> tileSizes,
        -:  411:                 const LinalgTilingOptions &options) {
    #####:  412:  auto nLoops = op.getNumLoops();
call    0 never executed
        -:  413:  // Initial tile sizes may be too big, only take the first nLoops.
    #####:  414:  tileSizes = tileSizes.take_front(nLoops);
branch  0 never executed
branch  1 never executed
call    2 never executed
        -:  415:
    #####:  416:  if (llvm::all_of(tileSizes, isZero)) {
branch  0 never executed
branch  1 never executed
    #####:  417:    TiledLinalgOp tiledOp;
    #####:  418:    tiledOp.op = cast<LinalgOp>(b.clone(*op.getOperation()));
call    0 never executed
call    1 never executed
    #####:  419:    tiledOp.tensorResults.assign(tiledOp.op->result_begin(),
branch  0 never executed
branch  1 never executed
call    2 never executed
call    3 never executed
        -:  420:                                 tiledOp.op->result_end());
    #####:  421:    return tiledOp;
call    0 never executed
        -:  422:  }
        -:  423:
        -:  424:  // 1. Build the tiled loop ranges.
    #####:  425:  SmallVector<OpFoldResult> allShapeSizes =
call    0 never executed
        -:  426:      op.createFlatListOfOperandDims(b, op.getLoc());
    #####:  427:  AffineMap shapeSizesToLoopsMap = op.getShapesToLoopsMap();
call    0 never executed
    #####:  428:  if (!shapeSizesToLoopsMap)
branch  0 never executed
branch  1 never executed
    #####:  429:    return failure();
        -:  430:
    #####:  431:  auto [loopRanges, loopIndexToRangeIndex] = makeTiledLoopRanges(
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
        -:  432:      b, op.getLoc(), shapeSizesToLoopsMap, allShapeSizes, tileSizes);
        -:  433:
    #####:  434:  SmallVector<StringRef, 4> iteratorTypes;
call    0 never executed
    #####:  435:  for (const auto &attr : enumerate(op.getIteratorTypesArray())) {
call    0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
branch  6 never executed
call    7 never executed
    #####:  436:    if (loopIndexToRangeIndex.count(attr.index()))
call    0 never executed
    #####:  437:      iteratorTypes.push_back(attr.value());
call    0 never executed
        -:  438:  }
        -:  439:  // If interchangeVector is empty, use the identity. Build the permutation map
        -:  440:  // otherwise.
        -:  441:  auto invPermutationMap =
    #####:  442:      AffineMap::getMultiDimIdentityMap(tileSizes.size(), b.getContext());
call    0 never executed
    #####:  443:  if (!options.interchangeVector.empty()) {
branch  0 never executed
branch  1 never executed
        -:  444:    // Based on the pruned iterations (due to zero tile size), recompute the
        -:  445:    // interchange vector.
    #####:  446:    SmallVector<unsigned, 4> interchangeVector;
    #####:  447:    interchangeVector.reserve(options.interchangeVector.size());
branch  0 never executed
branch  1 never executed
    #####:  448:    for (auto pos : options.interchangeVector) {
branch  0 never executed
branch  1 never executed
    #####:  449:      auto it = loopIndexToRangeIndex.find(pos);
call    0 never executed
    #####:  450:      if (it == loopIndexToRangeIndex.end())
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  451:        continue;
    #####:  452:      interchangeVector.push_back(it->second);
call    0 never executed
call    1 never executed
        -:  453:    }
        -:  454:    // Interchange vector is guaranteed to be a permutation,
        -:  455:    // `inversePermutation` must succeed.
    #####:  456:    invPermutationMap = inversePermutation(
call    0 never executed
call    1 never executed
        -:  457:        AffineMap::getPermutationMap(interchangeVector, b.getContext()));
    #####:  458:    assert(invPermutationMap);
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  459:    SmallVector<int64_t> permutation(interchangeVector.begin(),
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
        -:  460:                                     interchangeVector.end());
    #####:  461:    applyPermutationToVector(loopRanges, permutation);
call    0 never executed
call    1 never executed
    #####:  462:    applyPermutationToVector(iteratorTypes, permutation);
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  463:  }
        -:  464:
        -:  465:  // Handle distribution. Create a vector of the same size of loops that are to
        -:  466:  // be tiled.
    #####:  467:  SmallVector<linalg::ProcInfo> procInfo;
branch  0 never executed
branch  1 never executed
    #####:  468:  if (options.distribution) {
branch  0 never executed
branch  1 never executed
    #####:  469:    procInfo.resize(
call    0 never executed
        -:  470:        iteratorTypes.size(),
        -:  471:        linalg::ProcInfo{nullptr, nullptr, linalg::DistributionMethod::None});
        -:  472:    // Collect loop ranges of tiled loopss, loops that are parallel.
    #####:  473:    SmallVector<Range> parallelLoopRanges;
    #####:  474:    for (const auto &iteratorType : llvm::enumerate(iteratorTypes)) {
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  475:      if (!isParallelIterator(iteratorType.value()))
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  476:        break;
    #####:  477:      parallelLoopRanges.push_back(loopRanges[iteratorType.index()]);
branch  0 never executed
branch  1 never executed
call    2 never executed
        -:  478:    }
    #####:  479:    auto returnedProcInfo =
branch  0 never executed
branch  1 never executed
    #####:  480:        options.distribution->procInfo(b, op.getLoc(), parallelLoopRanges);
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####:  481:    unsigned procIdIdx = 0;
        -:  482:    // Update the distribution information for the loops.
    #####:  483:    for (const auto &iteratorType : llvm::enumerate(iteratorTypes)) {
branch  0 never executed
branch  1 never executed
    #####:  484:      if (!isParallelIterator(iteratorType.value()))
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  485:        break;
    #####:  486:      procInfo[iteratorType.index()] = returnedProcInfo[procIdIdx++];
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
call    4 never executed
        -:  487:    }
        -:  488:  }
        -:  489:
        -:  490:  // 2. Create the tiled loops.
    #####:  491:  LinalgOp res = op;
call    0 never executed
    #####:  492:  SmallVector<Value, 4> ivs, tensorResults;
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####:  493:  auto tiledLoopBodyBuilder =
call    0 never executed
        -:  494:      [&](OpBuilder &builder, Location loc, ValueRange localIvs,
        -:  495:          ValueRange operandValuesToUse) -> scf::ValueVector {
        -:  496:    ivs.assign(localIvs.begin(), localIvs.end());
        -:  497:
        -:  498:    // When an `interchangeVector` is present, it has been applied to the
        -:  499:    // loop ranges and the iterator types. Apply its inverse to the
        -:  500:    // resulting loop `ivs` to match the op definition.
        -:  501:    SmallVector<Value, 4> interchangedIvs;
        -:  502:    if (!options.interchangeVector.empty())
        -:  503:      interchangedIvs = applyMapToValues(b, loc, invPermutationMap, ivs);
        -:  504:    else
        -:  505:      interchangedIvs.assign(ivs.begin(), ivs.end());
        -:  506:
        -:  507:    // Tile the `operandValuesToUse` that either match the `op` operands
        -:  508:    // themselves or the tile loop arguments forwarding them.
        -:  509:    assert(operandValuesToUse.size() ==
        -:  510:               static_cast<size_t>(op->getNumOperands()) &&
        -:  511:           "expect the number of operands and inputs and outputs to match");
        -:  512:    SmallVector<Value> valuesToTile = operandValuesToUse;
        -:  513:    SmallVector<OpFoldResult> sizeBounds =
        -:  514:        makeComposedFoldedMultiResultAffineApply(b, loc, shapeSizesToLoopsMap,
        -:  515:                                                 allShapeSizes);
        -:  516:    SmallVector<Value> tiledOperands = makeTiledShapes(
        -:  517:        b, loc, op, valuesToTile, getAsOpFoldResult(interchangedIvs), tileSizes,
        -:  518:        sizeBounds,
        -:  519:        /*omitPartialTileCheck=*/false);
        -:  520:
        -:  521:    SmallVector<Type> resultTensorTypes =
        -:  522:        getTensorOutputTypes(op, tiledOperands);
        -:  523:    res = op.clone(b, loc, resultTensorTypes, tiledOperands);
        -:  524:    tensorResults =
        -:  525:        insertSlicesBack(builder, loc, op, tiledOperands, res->getResults());
        -:  526:    return scf::ValueVector(tensorResults.begin(), tensorResults.end());
        -:  527:  };
    #####:  528:  GenerateLoopNest<LoopTy>::doit(b, op.getLoc(), loopRanges, op, iteratorTypes,
call    0 never executed
        -:  529:                                 tiledLoopBodyBuilder, procInfo);
        -:  530:
        -:  531:  // 3. Transform IndexOp results w.r.t. the tiling.
    #####:  532:  transformIndexOps(b, res, ivs, loopIndexToRangeIndex);
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  533:
        -:  534:  // 4. Gather the newly created loops and return them with the new op.
    #####:  535:  SmallVector<Operation *, 8> loops;
branch  0 never executed
branch  1 never executed
    #####:  536:  loops.reserve(ivs.size());
branch  0 never executed
branch  1 never executed
    #####:  537:  for (auto iv : ivs) {
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  538:    if (iv.isa<BlockArgument>()) {
branch  0 never executed
branch  1 never executed
    #####:  539:      loops.push_back(iv.cast<BlockArgument>().getOwner()->getParentOp());
call    0 never executed
call    1 never executed
    #####:  540:      assert(loops.back() && "no owner found for induction variable!");
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
        -:  541:    } else {
        -:  542:      // TODO: Instead of doing this, try to recover the ops used instead of the
        -:  543:      // loop.
    #####:  544:      loops.push_back(nullptr);
call    0 never executed
        -:  545:    }
        -:  546:  }
        -:  547:
        -:  548:  // 5. Get the tensor results from the outermost loop if available. Otherwise
        -:  549:  // use the previously captured `tensorResults`.
    #####:  550:  Operation *outermostLoop = nullptr;
    #####:  551:  for (Operation *loop : loops)
branch  0 never executed
branch  1 never executed
    #####:  552:    if ((outermostLoop = loop))
branch  0 never executed
branch  1 never executed
        -:  553:      break;
        -:  554:
        -:  555:  return TiledLinalgOp{
    #####:  556:      res, loops, outermostLoop ? outermostLoop->getResults() : tensorResults};
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
call    4 never executed
call    5 never executed
call    6 never executed
branch  7 never executed
branch  8 never executed
        -:  557:}
------------------
        -:  558:
        -:  559:template <typename LoopTy>
    #####:  560:FailureOr<TiledLinalgOp> static tileLinalgOpImpl(
        -:  561:    RewriterBase &b, LinalgOp op, const LinalgTilingOptions &options) {
    #####:  562:  OpBuilder::InsertionGuard g(b);
    #####:  563:  b.setInsertionPoint(op);
        -:  564:
    #####:  565:  if (!options.tileSizeComputationFunction)
    #####:  566:    return failure();
        -:  567:
        -:  568:  // Enforce the convention that "tiling by zero" skips tiling a particular
        -:  569:  // dimension. This convention is significantly simpler to handle instead of
        -:  570:  // adjusting affine maps to account for missing dimensions.
    #####:  571:  auto nLoops = op.getNumLoops();
    #####:  572:  SmallVector<OpFoldResult> tileSizeVector =
        -:  573:      getAsOpFoldResult(options.tileSizeComputationFunction(b, op));
    #####:  574:  if (tileSizeVector.size() < nLoops) {
    #####:  575:    tileSizeVector.append(nLoops - tileSizeVector.size(), b.getIndexAttr(0));
        -:  576:  }
        -:  577:
    #####:  578:  return tileLinalgOpImpl<LoopTy>(b, op, tileSizeVector, options);
        -:  579:}
------------------
_Z16tileLinalgOpImplIN4mlir3scf10ParallelOpEENS0_9FailureOrINS0_6linalg13TiledLinalgOpEEERNS0_12RewriterBaseENS4_8LinalgOpERKNS4_19LinalgTilingOptionsE:
function _Z16tileLinalgOpImplIN4mlir3scf10ParallelOpEENS0_9FailureOrINS0_6linalg13TiledLinalgOpEEERNS0_12RewriterBaseENS4_8LinalgOpERKNS4_19LinalgTilingOptionsE called 0 returned 0% blocks executed 0%
    #####:  560:FailureOr<TiledLinalgOp> static tileLinalgOpImpl(
        -:  561:    RewriterBase &b, LinalgOp op, const LinalgTilingOptions &options) {
    #####:  562:  OpBuilder::InsertionGuard g(b);
call    0 never executed
    #####:  563:  b.setInsertionPoint(op);
call    0 never executed
        -:  564:
    #####:  565:  if (!options.tileSizeComputationFunction)
branch  0 never executed
branch  1 never executed
    #####:  566:    return failure();
        -:  567:
        -:  568:  // Enforce the convention that "tiling by zero" skips tiling a particular
        -:  569:  // dimension. This convention is significantly simpler to handle instead of
        -:  570:  // adjusting affine maps to account for missing dimensions.
    #####:  571:  auto nLoops = op.getNumLoops();
call    0 never executed
    #####:  572:  SmallVector<OpFoldResult> tileSizeVector =
branch  0 never executed
branch  1 never executed
call    2 never executed
call    3 never executed
branch  4 never executed
branch  5 never executed
branch  6 never executed
branch  7 never executed
        -:  573:      getAsOpFoldResult(options.tileSizeComputationFunction(b, op));
    #####:  574:  if (tileSizeVector.size() < nLoops) {
branch  0 never executed
branch  1 never executed
    #####:  575:    tileSizeVector.append(nLoops - tileSizeVector.size(), b.getIndexAttr(0));
call    0 never executed
call    1 never executed
call    2 never executed
        -:  576:  }
        -:  577:
    #####:  578:  return tileLinalgOpImpl<LoopTy>(b, op, tileSizeVector, options);
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  579:}
------------------
_Z16tileLinalgOpImplIN4mlir3scf5ForOpEENS0_9FailureOrINS0_6linalg13TiledLinalgOpEEERNS0_12RewriterBaseENS4_8LinalgOpERKNS4_19LinalgTilingOptionsE:
function _Z16tileLinalgOpImplIN4mlir3scf5ForOpEENS0_9FailureOrINS0_6linalg13TiledLinalgOpEEERNS0_12RewriterBaseENS4_8LinalgOpERKNS4_19LinalgTilingOptionsE called 0 returned 0% blocks executed 0%
    #####:  560:FailureOr<TiledLinalgOp> static tileLinalgOpImpl(
        -:  561:    RewriterBase &b, LinalgOp op, const LinalgTilingOptions &options) {
    #####:  562:  OpBuilder::InsertionGuard g(b);
call    0 never executed
    #####:  563:  b.setInsertionPoint(op);
call    0 never executed
        -:  564:
    #####:  565:  if (!options.tileSizeComputationFunction)
branch  0 never executed
branch  1 never executed
    #####:  566:    return failure();
        -:  567:
        -:  568:  // Enforce the convention that "tiling by zero" skips tiling a particular
        -:  569:  // dimension. This convention is significantly simpler to handle instead of
        -:  570:  // adjusting affine maps to account for missing dimensions.
    #####:  571:  auto nLoops = op.getNumLoops();
call    0 never executed
    #####:  572:  SmallVector<OpFoldResult> tileSizeVector =
branch  0 never executed
branch  1 never executed
call    2 never executed
call    3 never executed
branch  4 never executed
branch  5 never executed
branch  6 never executed
branch  7 never executed
        -:  573:      getAsOpFoldResult(options.tileSizeComputationFunction(b, op));
    #####:  574:  if (tileSizeVector.size() < nLoops) {
branch  0 never executed
branch  1 never executed
    #####:  575:    tileSizeVector.append(nLoops - tileSizeVector.size(), b.getIndexAttr(0));
call    0 never executed
call    1 never executed
call    2 never executed
        -:  576:  }
        -:  577:
    #####:  578:  return tileLinalgOpImpl<LoopTy>(b, op, tileSizeVector, options);
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  579:}
------------------
        -:  580:
        -:  581:FailureOr<TiledLinalgOp>
function _ZN4mlir6linalg12tileLinalgOpERNS_12RewriterBaseENS0_8LinalgOpERKNS0_19LinalgTilingOptionsE called 0 returned 0% blocks executed 0%
    #####:  582:mlir::linalg::tileLinalgOp(RewriterBase &b, LinalgOp op,
        -:  583:                           const LinalgTilingOptions &options) {
    #####:  584:  switch (options.loopType) {
branch  0 never executed
branch  1 never executed
branch  2 never executed
    #####:  585:  case LinalgTilingLoopType::Loops:
    #####:  586:    return tileLinalgOpImpl<scf::ForOp>(b, op, options);
call    0 never executed
    #####:  587:  case LinalgTilingLoopType::ParallelLoops:
    #####:  588:    return tileLinalgOpImpl<scf::ParallelOp>(b, op, options);
call    0 never executed
    #####:  589:  default:;
        -:  590:  }
    #####:  591:  return failure();
        -:  592:}
        -:  593:
        -:  594:/// Generate a loop nest around a given tensor::PadOp (for tiling). `newPadOp`
        -:  595:/// and `loopNest` are output parameters that return the new (tiled)
        -:  596:/// tensor::PadOp and the loop nest.
function _ZL9tilePadOpRN4mlir12RewriterBaseENS_6tensor5PadOpERS3_RNS_3scf8LoopNestERKNS_6linalg19LinalgTilingOptionsE called 0 returned 0% blocks executed 0%
    #####:  597:static LogicalResult tilePadOp(RewriterBase &builder, tensor::PadOp op,
        -:  598:                               tensor::PadOp &newPadOp, LoopNest &loopNest,
        -:  599:                               const LinalgTilingOptions &options) {
    #####:  600:  Location loc = op.getLoc();
call    0 never executed
    #####:  601:  OpBuilder::InsertionGuard g(builder);
call    0 never executed
    #####:  602:  builder.setInsertionPoint(op);
call    0 never executed
        -:  603:
        -:  604:  // Clone tensor::PadOp so that the existing op can be replaced more easily.
    #####:  605:  newPadOp = cast<tensor::PadOp>(builder.clone(*op.getOperation()));
call    0 never executed
call    1 never executed
        -:  606:  // Get rank and tile sizes.
    #####:  607:  int64_t rank = op.getResultType().getRank();
call    0 never executed
call    1 never executed
    #####:  608:  SmallVector<OpFoldResult> tileSizes =
    #####:  609:      getAsOpFoldResult(options.tileSizeComputationFunction(builder, op));
branch  0 never executed
branch  1 never executed
call    2 never executed
call    3 never executed
branch  4 never executed
branch  5 never executed
branch  6 never executed
branch  7 never executed
        -:  610:  // Normalize untiled padding dimensions to 0.
    #####:  611:  tileSizes.append(rank - tileSizes.size(), builder.getIndexAttr(0));
call    0 never executed
call    1 never executed
call    2 never executed
        -:  612:  // Compute lower and upper bounds of the loop nest.
    #####:  613:  TilingInterface tilingInterface =
    #####:  614:      dyn_cast<TilingInterface>(op.getOperation());
call    0 never executed
    #####:  615:  SmallVector<Range> ranges = tilingInterface.getIterationDomain(builder);
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  616:  SmallVector<Value> lbs, dims, steps;
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
    #####:  617:  SmallVector<OpFoldResult> allDims;
branch  0 never executed
branch  1 never executed
    #####:  618:  for (int64_t i = 0; i < rank; ++i) {
branch  0 never executed
branch  1 never executed
    #####:  619:    allDims.push_back(ranges[i].size);
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  620:    if (!isZero(tileSizes[i])) {
branch  0 never executed
branch  1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
    #####:  621:      lbs.push_back(
call    0 never executed
    #####:  622:          getValueOrCreateConstantIndexOp(builder, loc, ranges[i].offset));
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  623:      dims.push_back(
call    0 never executed
    #####:  624:          getValueOrCreateConstantIndexOp(builder, loc, ranges[i].size));
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  625:      steps.push_back(
call    0 never executed
    #####:  626:          getValueOrCreateConstantIndexOp(builder, loc, tileSizes[i]));
branch  0 never executed
branch  1 never executed
call    2 never executed
        -:  627:    }
        -:  628:  }
    #####:  629:  SmallVector<Value> destinationTensors;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  630:  if (failed(tensor::getOrCreateDestinations(builder, loc, tilingInterface,
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  631:                                             destinationTensors)))
    #####:  632:    return failure();
        -:  633:
    #####:  634:  loopNest = mlir::scf::buildLoopNest(
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
branch  5 never executed
branch  6 never executed
        -:  635:      builder, loc, lbs, /*ubs=*/dims, steps, ValueRange(destinationTensors),
function _ZZL9tilePadOpRN4mlir12RewriterBaseENS_6tensor5PadOpERS3_RNS_3scf8LoopNestERKNS_6linalg19LinalgTilingOptionsEENKUlRNS_9OpBuilderENS_8LocationENS_10ValueRangeESF_E_clESD_SE_SF_SF_ called 0 returned 0% blocks executed 0%
    #####:  636:      [&](OpBuilder &b, Location loc, ValueRange localIvs,
        -:  637:          ValueRange iterArgs) -> scf::ValueVector {
        -:  638:        // Compute offsets and sizes of ExtractSliceOp.
    #####:  639:        SmallVector<Value> localIVVector = llvm::to_vector(localIvs);
call    0 never executed
    #####:  640:        SmallVector<OpFoldResult> offsets = computeTileOffsets(
    #####:  641:            b, loc, getAsOpFoldResult(localIVVector), tileSizes);
call    0 never executed
call    1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
branch  6 never executed
    #####:  642:        SmallVector<OpFoldResult> sizes =
    #####:  643:            computeTileSizes(b, loc, tileSizes, allDims);
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  644:        // Create ExtractSliceOp: Extract a tile from the tensor::PadOp.
        -:  645:        // Note: The tensor::PadOp is located outside of the loop nest. It is
        -:  646:        // later moved inside by ExtractSliceOfPadTensorSwapPattern.
    #####:  647:        auto map = AffineMap::getMultiDimIdentityMap(rank, b.getContext());
call    0 never executed
    #####:  648:        Value tiledOutput = makeTiledShape(
call    0 never executed
    #####:  649:            b, loc, newPadOp->getResult(0), tileSizes, map, offsets, allDims,
    #####:  650:            sizes, /*omitPartialTileCheck=*/false);
call    0 never executed
    #####:  651:        auto sliceOp = tiledOutput.getDefiningOp<tensor::ExtractSliceOp>();
call    0 never executed
    #####:  652:        assert(sliceOp && "expected ExtractSliceOp");
branch  0 never executed
branch  1 never executed
call    2 never executed
        -:  653:        // Insert the tile into the output tensor.
    #####:  654:        Value yieldValue =
    #####:  655:            insertSliceIntoTensor(b, loc, sliceOp, sliceOp, iterArgs[0]);
call    0 never executed
call    1 never executed
    #####:  656:        return scf::ValueVector({yieldValue});
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  657:      });
branch  0 never executed
branch  1 never executed
    #####:  658:  return success();
branch  0 never executed
branch  1 never executed
        -:  659:}
        -:  660:
        -:  661:namespace {
        -:  662:struct PadOpTilingPattern : public OpRewritePattern<tensor::PadOp> {
function _ZN12_GLOBAL__N_118PadOpTilingPatternC2EPN4mlir11MLIRContextENS1_6linalg19LinalgTilingOptionsE called 0 returned 0% blocks executed 0%
    #####:  663:  PadOpTilingPattern(MLIRContext *ctx, LinalgTilingOptions opt)
    #####:  664:      : OpRewritePattern<tensor::PadOp>(ctx), options(std::move(opt)) {}
call    0 never executed
call    1 never executed
call    2 never executed
        -:  665:
function _ZNK12_GLOBAL__N_118PadOpTilingPattern15matchAndRewriteEN4mlir6tensor5PadOpERNS1_15PatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  666:  LogicalResult matchAndRewrite(tensor::PadOp op,
        -:  667:                                PatternRewriter &rewriter) const override {
    #####:  668:    tensor::PadOp newPadOp;
call    0 never executed
    #####:  669:    LoopNest loopNest;
call    0 never executed
    #####:  670:    if (failed(tilePadOp(rewriter, op, newPadOp, loopNest, options)))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  671:      return failure();
        -:  672:    // Replace all uses of the original tensor::PadOp.
    #####:  673:    rewriter.replaceOp(op, loopNest.getResults()[0]);
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:  674:    return success();
branch  0 never executed
branch  1 never executed
        -:  675:  }
        -:  676:
        -:  677:  LinalgTilingOptions options;
        -:  678:};
        -:  679:} // namespace
        -:  680:
        -:  681:namespace {
        -:  682:/// Helper classes for type list expansion.
        -:  683:template <typename... OpTypes>
        -:  684:class CanonicalizationPatternList;
        -:  685:
        -:  686:template <>
        -:  687:class CanonicalizationPatternList<> {
        -:  688:public:
      978:  689:  static void insert(RewritePatternSet &patterns) {}
        -:  690:};
        -:  691:
        -:  692:template <typename OpTy, typename... OpTypes>
        -:  693:class CanonicalizationPatternList<OpTy, OpTypes...> {
        -:  694:public:
function _ZN12_GLOBAL__N_127CanonicalizationPatternListIJN4mlir6linalg6FillOpENS2_11FillRng2DOpENS2_9GenericOpENS2_5MapOpENS2_8MatmulOpENS2_16MatmulUnsignedOpENS2_8MatvecOpENS2_7Mmt4DOpENS2_16PoolingNchwMaxOpENS2_16PoolingNchwSumOpENS2_17PoolingNdhwcMaxOpENS2_17PoolingNdhwcMinOpENS2_17PoolingNdhwcSumOpENS2_16PoolingNhwcMaxOpENS2_24PoolingNhwcMaxUnsignedOpENS2_16PoolingNhwcMinOpENS2_24PoolingNhwcMinUnsignedOpENS2_16PoolingNhwcSumOpENS2_22QuantizedBatchMatmulOpENS2_17QuantizedMatmulOpENS2_8ReduceOpENS2_11TransposeOpENS2_8VecmatOpEEE6insertERNS1_17RewritePatternSetE called 978 returned 100% blocks executed 100%
     3905:  695:  static void insert(RewritePatternSet &patterns) {
      978:  696:    OpTy::getCanonicalizationPatterns(patterns, patterns.getContext());
call    0 returned 99%
call    1 returned 101%
      978:  697:    CanonicalizationPatternList<OpTypes...>::insert(patterns);
call    0 returned 100%
      978:  698:  }
        -:  699:};
        -:  700:} // namespace
        -:  701:
        -:  702:RewritePatternSet
function _ZN4mlir6linalg39getLinalgTilingCanonicalizationPatternsEPNS_11MLIRContextE called 1003 returned 97% blocks executed 100%
     1003:  703:mlir::linalg::getLinalgTilingCanonicalizationPatterns(MLIRContext *ctx) {
     1003:  704:  RewritePatternSet patterns(ctx);
call    0 returned 97%
     1003:  705:  populateLinalgTilingCanonicalizationPatterns(patterns);
call    0 returned 97%
      977:  706:  return patterns;
        -:  707:}
        -:  708:
function _ZN4mlir6linalg44populateLinalgTilingCanonicalizationPatternsERNS_17RewritePatternSetE called 1003 returned 97% blocks executed 100%
     1003:  709:void mlir::linalg::populateLinalgTilingCanonicalizationPatterns(
        -:  710:    RewritePatternSet &patterns) {
     1003:  711:  auto *ctx = patterns.getContext();
call    0 returned 98%
     1003:  712:  AffineApplyOp::getCanonicalizationPatterns(patterns, ctx);
call    0 returned 98%
      983:  713:  AffineForOp::getCanonicalizationPatterns(patterns, ctx);
call    0 returned 100%
      983:  714:  AffineMinOp::getCanonicalizationPatterns(patterns, ctx);
call    0 returned 101%
      989:  715:  AffineMaxOp::getCanonicalizationPatterns(patterns, ctx);
call    0 returned 101%
     1001:  716:  arith::ConstantIndexOp::getCanonicalizationPatterns(patterns, ctx);
call    0 returned 99%
        -:  717:
     1001:  718:  memref::SubViewOp::getCanonicalizationPatterns(patterns, ctx);
call    0 returned 99%
      986:  719:  memref::ViewOp::getCanonicalizationPatterns(patterns, ctx);
call    0 returned 100%
        -:  720:
      983:  721:  scf::ForOp::getCanonicalizationPatterns(patterns, ctx);
call    0 returned 100%
      981:  722:  scf::ParallelOp::getCanonicalizationPatterns(patterns, ctx);
call    0 returned 100%
        -:  723:
      980:  724:  tensor::CastOp::getCanonicalizationPatterns(patterns, ctx);
call    0 returned 99%
      975:  725:  tensor::EmptyOp::getCanonicalizationPatterns(patterns, ctx);
call    0 returned 99%
      965:  726:  tensor::ExtractSliceOp::getCanonicalizationPatterns(patterns, ctx);
call    0 returned 101%
      976:  727:  tensor::InsertSliceOp::getCanonicalizationPatterns(patterns, ctx);
call    0 returned 100%
      979:  728:  tensor::PadOp::getCanonicalizationPatterns(patterns, ctx);
call    0 returned 100%
      982:  729:  ctx->getLoadedDialect<LinalgDialect>()->getCanonicalizationPatterns(patterns);
call    0 returned 100%
call    1 returned 100%
        -:  730:
      978:  731:  CanonicalizationPatternList<
call    0 returned 100%
        -:  732:#define GET_OP_LIST
        -:  733:#include "mlir/Dialect/Linalg/IR/LinalgStructuredOps.cpp.inc"
      977:  734:      >::insert(patterns);
      977:  735:}
        -:  736:
function _ZN4mlir6linalg31populatePadTensorTilingPatternsERNS_17RewritePatternSetERKNS0_19LinalgTilingOptionsE called 0 returned 0% blocks executed 0%
    #####:  737:void mlir::linalg::populatePadTensorTilingPatterns(
        -:  738:    RewritePatternSet &patterns, const LinalgTilingOptions &options) {
    #####:  739:  auto *ctx = patterns.getContext();
call    0 never executed
    #####:  740:  patterns.add<PadOpTilingPattern>(ctx, options);
call    0 never executed
    #####:  741:}
