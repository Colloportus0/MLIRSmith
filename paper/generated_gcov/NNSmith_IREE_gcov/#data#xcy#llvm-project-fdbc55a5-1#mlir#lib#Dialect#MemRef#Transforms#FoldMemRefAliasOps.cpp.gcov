        -:    0:Source:/data/xcy/llvm-project-fdbc55a5-1/mlir/lib/Dialect/MemRef/Transforms/FoldMemRefAliasOps.cpp
        -:    0:Graph:../tools/mlir/lib/Dialect/MemRef/Transforms/CMakeFiles/obj.MLIRMemRefTransforms.dir/FoldMemRefAliasOps.cpp.gcno
        -:    0:Data:../tools/mlir/lib/Dialect/MemRef/Transforms/CMakeFiles/obj.MLIRMemRefTransforms.dir/FoldMemRefAliasOps.cpp.gcda
        -:    0:Runs:325549
        -:    1://===- FoldMemRefAliasOps.cpp - Fold memref alias ops -----===//
        -:    2://
        -:    3:// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
        -:    4:// See https://llvm.org/LICENSE.txt for license information.
        -:    5:// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
        -:    6://
        -:    7://===----------------------------------------------------------------------===//
        -:    8://
        -:    9:// This transformation pass folds loading/storing from/to subview ops into
        -:   10:// loading/storing from/to the original memref.
        -:   11://
        -:   12://===----------------------------------------------------------------------===//
        -:   13:
        -:   14:#include "mlir/Dialect/MemRef/Transforms/Passes.h"
        -:   15:
        -:   16:#include "mlir/Dialect/Affine/IR/AffineOps.h"
        -:   17:#include "mlir/Dialect/Arith/IR/Arith.h"
        -:   18:#include "mlir/Dialect/MemRef/IR/MemRef.h"
        -:   19:#include "mlir/Dialect/Utils/IndexingUtils.h"
        -:   20:#include "mlir/Dialect/Vector/IR/VectorOps.h"
        -:   21:#include "mlir/IR/BuiltinTypes.h"
        -:   22:#include "mlir/Transforms/GreedyPatternRewriteDriver.h"
        -:   23:#include "llvm/ADT/SmallBitVector.h"
        -:   24:#include "llvm/ADT/TypeSwitch.h"
        -:   25:
        -:   26:namespace mlir {
        -:   27:namespace memref {
        -:   28:#define GEN_PASS_DEF_FOLDMEMREFALIASOPS
        -:   29:#include "mlir/Dialect/MemRef/Transforms/Passes.h.inc"
        -:   30:} // namespace memref
        -:   31:} // namespace mlir
        -:   32:
        -:   33:using namespace mlir;
        -:   34:
        -:   35://===----------------------------------------------------------------------===//
        -:   36:// Utility functions
        -:   37://===----------------------------------------------------------------------===//
        -:   38:
        -:   39:/// Given the 'indices' of a load/store operation where the memref is a result
        -:   40:/// of a expand_shape op, returns the indices w.r.t to the source memref of the
        -:   41:/// expand_shape op. For example
        -:   42:///
        -:   43:/// %0 = ... : memref<12x42xf32>
        -:   44:/// %1 = memref.expand_shape %0 [[0, 1], [2]]
        -:   45:///    : memref<12x42xf32> into memref<2x6x42xf32>
        -:   46:/// %2 = load %1[%i1, %i2, %i3] : memref<2x6x42xf32
        -:   47:///
        -:   48:/// could be folded into
        -:   49:///
        -:   50:/// %2 = load %0[6 * i1 + i2, %i3] :
        -:   51:///          memref<12x42xf32>
        -:   52:static LogicalResult
function _ZL31resolveSourceIndicesExpandShapeN4mlir8LocationERNS_15PatternRewriterENS_6memref13ExpandShapeOpENS_10ValueRangeERN4llvm15SmallVectorImplINS_5ValueEEE called 0 returned 0% blocks executed 0%
    #####:   53:resolveSourceIndicesExpandShape(Location loc, PatternRewriter &rewriter,
        -:   54:                                memref::ExpandShapeOp expandShapeOp,
        -:   55:                                ValueRange indices,
        -:   56:                                SmallVectorImpl<Value> &sourceIndices) {
    #####:   57:  for (SmallVector<int64_t, 2> groups :
    #####:   58:       expandShapeOp.getReassociationIndices()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
    #####:   59:    assert(!groups.empty() && "association indices groups cannot be empty");
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:   60:    unsigned groupSize = groups.size();
call    0 never executed
    #####:   61:    SmallVector<int64_t> suffixProduct(groupSize);
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:   62:    // Calculate suffix product of dimension sizes for all dimensions of expand
        -:   63:    // shape op result.
    #####:   64:    suffixProduct[groupSize - 1] = 1;
branch  0 never executed
branch  1 never executed
    #####:   65:    for (unsigned i = groupSize - 1; i > 0; i--)
branch  0 never executed
branch  1 never executed
    #####:   66:      suffixProduct[i - 1] =
    #####:   67:          suffixProduct[i] *
branch  0 never executed
branch  1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
    #####:   68:          expandShapeOp.getType().cast<MemRefType>().getDimSize(groups[i]);
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
    #####:   69:    SmallVector<Value> dynamicIndices(groupSize);
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:   70:    for (unsigned i = 0; i < groupSize; i++)
branch  0 never executed
branch  1 never executed
    #####:   71:      dynamicIndices[i] = indices[groups[i]];
branch  0 never executed
branch  1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
        -:   72:    // Construct the expression for the index value w.r.t to expand shape op
        -:   73:    // source corresponding the indices wrt to expand shape op result.
    #####:   74:    AffineExpr srcIndexExpr = getLinearAffineExpr(suffixProduct, rewriter);
call    0 never executed
    #####:   75:    sourceIndices.push_back(rewriter.create<AffineApplyOp>(
call    0 never executed
        -:   76:        loc,
    #####:   77:        AffineMap::get(/*numDims=*/groupSize, /*numSymbols=*/0, srcIndexExpr),
branch  0 never executed
branch  1 never executed
    #####:   78:        dynamicIndices));
call    0 never executed
call    1 never executed
call    2 never executed
        -:   79:  }
    #####:   80:  return success();
        -:   81:}
        -:   82:
        -:   83:/// Given the 'indices' of a load/store operation where the memref is a result
        -:   84:/// of a collapse_shape op, returns the indices w.r.t to the source memref of
        -:   85:/// the collapse_shape op. For example
        -:   86:///
        -:   87:/// %0 = ... : memref<2x6x42xf32>
        -:   88:/// %1 = memref.collapse_shape %0 [[0, 1], [2]]
        -:   89:///    : memref<2x6x42xf32> into memref<12x42xf32>
        -:   90:/// %2 = load %1[%i1, %i2] : memref<12x42xf32>
        -:   91:///
        -:   92:/// could be folded into
        -:   93:///
        -:   94:/// %2 = load %0[%i1 / 6, %i1 % 6, %i2] :
        -:   95:///          memref<2x6x42xf32>
        -:   96:static LogicalResult
function _ZL33resolveSourceIndicesCollapseShapeN4mlir8LocationERNS_15PatternRewriterENS_6memref15CollapseShapeOpENS_10ValueRangeERN4llvm15SmallVectorImplINS_5ValueEEE called 0 returned 0% blocks executed 0%
    #####:   97:resolveSourceIndicesCollapseShape(Location loc, PatternRewriter &rewriter,
        -:   98:                                  memref::CollapseShapeOp collapseShapeOp,
        -:   99:                                  ValueRange indices,
        -:  100:                                  SmallVectorImpl<Value> &sourceIndices) {
    #####:  101:  unsigned cnt = 0;
    #####:  102:  SmallVector<Value> tmp(indices.size());
call    0 never executed
    #####:  103:  SmallVector<Value> dynamicIndices;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  104:  for (SmallVector<int64_t, 2> groups :
    #####:  105:       collapseShapeOp.getReassociationIndices()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
    #####:  106:    assert(!groups.empty() && "association indices groups cannot be empty");
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  107:    dynamicIndices.push_back(indices[cnt++]);
call    0 never executed
call    1 never executed
    #####:  108:    unsigned groupSize = groups.size();
call    0 never executed
    #####:  109:    SmallVector<int64_t> suffixProduct(groupSize);
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  110:    // Calculate suffix product for all collapse op source dimension sizes.
    #####:  111:    suffixProduct[groupSize - 1] = 1;
branch  0 never executed
branch  1 never executed
    #####:  112:    for (unsigned i = groupSize - 1; i > 0; i--)
branch  0 never executed
branch  1 never executed
    #####:  113:      suffixProduct[i - 1] =
    #####:  114:          suffixProduct[i] * collapseShapeOp.getSrcType().getDimSize(groups[i]);
branch  0 never executed
branch  1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
call    5 never executed
branch  6 never executed
branch  7 never executed
        -:  115:    // Derive the index values along all dimensions of the source corresponding
        -:  116:    // to the index wrt to collapsed shape op output.
    #####:  117:    SmallVector<AffineExpr, 4> srcIndexExpr =
    #####:  118:        getDelinearizedAffineExpr(suffixProduct, rewriter);
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  119:    for (unsigned i = 0; i < groupSize; i++)
branch  0 never executed
branch  1 never executed
    #####:  120:      sourceIndices.push_back(rewriter.create<AffineApplyOp>(
call    0 never executed
    #####:  121:          loc, AffineMap::get(/*numDims=*/1, /*numSymbols=*/0, srcIndexExpr[i]),
call    0 never executed
    #####:  122:          dynamicIndices));
branch  0 never executed
branch  1 never executed
call    2 never executed
call    3 never executed
    #####:  123:    dynamicIndices.clear();
branch  0 never executed
branch  1 never executed
        -:  124:  }
    #####:  125:  if (collapseShapeOp.getReassociationIndices().empty()) {
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  126:    auto zeroAffineMap = rewriter.getConstantAffineMap(0);
call    0 never executed
    #####:  127:    unsigned srcRank =
call    0 never executed
    #####:  128:        collapseShapeOp.getViewSource().getType().cast<MemRefType>().getRank();
call    0 never executed
call    1 never executed
    #####:  129:    for (unsigned i = 0; i < srcRank; i++)
branch  0 never executed
branch  1 never executed
    #####:  130:      sourceIndices.push_back(
call    0 never executed
    #####:  131:          rewriter.create<AffineApplyOp>(loc, zeroAffineMap, dynamicIndices));
call    0 never executed
call    1 never executed
        -:  132:  }
    #####:  133:  return success();
branch  0 never executed
branch  1 never executed
        -:  134:}
        -:  135:
        -:  136:/// Given the 'indices' of an load/store operation where the memref is a result
        -:  137:/// of a subview op, returns the indices w.r.t to the source memref of the
        -:  138:/// subview op. For example
        -:  139:///
        -:  140:/// %0 = ... : memref<12x42xf32>
        -:  141:/// %1 = subview %0[%arg0, %arg1][][%stride1, %stride2] : memref<12x42xf32> to
        -:  142:///          memref<4x4xf32, offset=?, strides=[?, ?]>
        -:  143:/// %2 = load %1[%i1, %i2] : memref<4x4xf32, offset=?, strides=[?, ?]>
        -:  144:///
        -:  145:/// could be folded into
        -:  146:///
        -:  147:/// %2 = load %0[%arg0 + %i1 * %stride1][%arg1 + %i2 * %stride2] :
        -:  148:///          memref<12x42xf32>
        -:  149:static LogicalResult
function _ZL27resolveSourceIndicesSubViewN4mlir8LocationERNS_15PatternRewriterENS_6memref9SubViewOpENS_10ValueRangeERN4llvm15SmallVectorImplINS_5ValueEEE called 0 returned 0% blocks executed 0%
    #####:  150:resolveSourceIndicesSubView(Location loc, PatternRewriter &rewriter,
        -:  151:                            memref::SubViewOp subViewOp, ValueRange indices,
        -:  152:                            SmallVectorImpl<Value> &sourceIndices) {
    #####:  153:  SmallVector<OpFoldResult> mixedOffsets = subViewOp.getMixedOffsets();
call    0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
    #####:  154:  SmallVector<OpFoldResult> mixedSizes = subViewOp.getMixedSizes();
call    0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
branch  6 never executed
    #####:  155:  SmallVector<OpFoldResult> mixedStrides = subViewOp.getMixedStrides();
call    0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
branch  6 never executed
        -:  156:
    #####:  157:  SmallVector<Value> useIndices;
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  158:  // Check if this is rank-reducing case. Then for every unit-dim size add a
        -:  159:  // zero to the indices.
    #####:  160:  unsigned resultDim = 0;
    #####:  161:  llvm::SmallBitVector unusedDims = subViewOp.getDroppedDims();
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  162:  for (auto dim : llvm::seq<unsigned>(0, subViewOp.getSourceType().getRank())) {
call    0 never executed
call    1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
call    5 never executed
    #####:  163:    if (unusedDims.test(dim))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  164:      useIndices.push_back(rewriter.create<arith::ConstantIndexOp>(loc, 0));
call    0 never executed
call    1 never executed
        -:  165:    else
    #####:  166:      useIndices.push_back(indices[resultDim++]);
call    0 never executed
call    1 never executed
        -:  167:  }
    #####:  168:  if (useIndices.size() != mixedOffsets.size())
branch  0 never executed
branch  1 never executed
    #####:  169:    return failure();
    #####:  170:  sourceIndices.resize(useIndices.size());
call    0 never executed
    #####:  171:  for (auto index : llvm::seq<size_t>(0, mixedOffsets.size())) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  172:    SmallVector<Value> dynamicOperands;
call    0 never executed
call    1 never executed
    #####:  173:    AffineExpr expr = rewriter.getAffineDimExpr(0);
call    0 never executed
    #####:  174:    unsigned numSymbols = 0;
    #####:  175:    dynamicOperands.push_back(useIndices[index]);
branch  0 never executed
branch  1 never executed
call    2 never executed
        -:  176:
        -:  177:    // Multiply the stride;
    #####:  178:    if (auto attr = mixedStrides[index].dyn_cast<Attribute>()) {
branch  0 never executed
branch  1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
    #####:  179:      expr = expr * attr.cast<IntegerAttr>().getInt();
call    0 never executed
call    1 never executed
call    2 never executed
        -:  180:    } else {
    #####:  181:      dynamicOperands.push_back(mixedStrides[index].get<Value>());
branch  0 never executed
branch  1 never executed
call    2 never executed
call    3 never executed
    #####:  182:      expr = expr * rewriter.getAffineSymbolExpr(numSymbols++);
call    0 never executed
call    1 never executed
        -:  183:    }
        -:  184:
        -:  185:    // Add the offset.
    #####:  186:    if (auto attr = mixedOffsets[index].dyn_cast<Attribute>()) {
branch  0 never executed
branch  1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
    #####:  187:      expr = expr + attr.cast<IntegerAttr>().getInt();
call    0 never executed
call    1 never executed
call    2 never executed
        -:  188:    } else {
    #####:  189:      dynamicOperands.push_back(mixedOffsets[index].get<Value>());
branch  0 never executed
branch  1 never executed
call    2 never executed
call    3 never executed
    #####:  190:      expr = expr + rewriter.getAffineSymbolExpr(numSymbols++);
call    0 never executed
call    1 never executed
        -:  191:    }
    #####:  192:    Location loc = subViewOp.getLoc();
call    0 never executed
    #####:  193:    sourceIndices[index] = rewriter.create<AffineApplyOp>(
branch  0 never executed
branch  1 never executed
    #####:  194:        loc, AffineMap::get(1, numSymbols, expr), dynamicOperands);
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
        -:  195:  }
    #####:  196:  return success();
call    0 never executed
        -:  197:}
        -:  198:
        -:  199:/// Helpers to access the memref operand for each op.
        -:  200:template <typename LoadOrStoreOpTy>
    #####:  201:static Value getMemRefOperand(LoadOrStoreOpTy op) {
    #####:  202:  return op.getMemref();
        -:  203:}
        -:  204:
    #####:  205:static Value getMemRefOperand(vector::TransferReadOp op) {
    #####:  206:  return op.getSource();
        -:  207:}
        -:  208:
    #####:  209:static Value getMemRefOperand(vector::TransferWriteOp op) {
    #####:  210:  return op.getSource();
        -:  211:}
        -:  212:
        -:  213:/// Given the permutation map of the original
        -:  214:/// `vector.transfer_read`/`vector.transfer_write` operations compute the
        -:  215:/// permutation map to use after the subview is folded with it.
function _ZL21getPermutationMapAttrPN4mlir11MLIRContextENS_6memref9SubViewOpENS_9AffineMapE called 0 returned 0% blocks executed 0%
    #####:  216:static AffineMapAttr getPermutationMapAttr(MLIRContext *context,
        -:  217:                                           memref::SubViewOp subViewOp,
        -:  218:                                           AffineMap currPermutationMap) {
    #####:  219:  llvm::SmallBitVector unusedDims = subViewOp.getDroppedDims();
call    0 never executed
    #####:  220:  SmallVector<AffineExpr> exprs;
call    0 never executed
call    1 never executed
    #####:  221:  int64_t sourceRank = subViewOp.getSourceType().getRank();
call    0 never executed
call    1 never executed
    #####:  222:  for (auto dim : llvm::seq<int64_t>(0, sourceRank)) {
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
    #####:  223:    if (unusedDims.test(dim))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  224:      continue;
    #####:  225:    exprs.push_back(getAffineDimExpr(dim, context));
call    0 never executed
call    1 never executed
        -:  226:  }
    #####:  227:  auto resultDimToSourceDimMap = AffineMap::get(sourceRank, 0, exprs, context);
call    0 never executed
    #####:  228:  return AffineMapAttr::get(
    #####:  229:      currPermutationMap.compose(resultDimToSourceDimMap));
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
        -:  230:}
        -:  231:
        -:  232://===----------------------------------------------------------------------===//
        -:  233:// Patterns
        -:  234://===----------------------------------------------------------------------===//
        -:  235:
        -:  236:namespace {
        -:  237:/// Merges subview operation with load/transferRead operation.
        -:  238:template <typename OpTy>
        -:  239:class LoadOpOfSubViewOpFolder final : public OpRewritePattern<OpTy> {
        -:  240:public:
        -:  241:  using OpRewritePattern<OpTy>::OpRewritePattern;
        -:  242:
        -:  243:  LogicalResult matchAndRewrite(OpTy loadOp,
        -:  244:                                PatternRewriter &rewriter) const override;
        -:  245:};
        -:  246:
        -:  247:/// Merges expand_shape operation with load/transferRead operation.
        -:  248:template <typename OpTy>
        -:  249:class LoadOpOfExpandShapeOpFolder final : public OpRewritePattern<OpTy> {
        -:  250:public:
        -:  251:  using OpRewritePattern<OpTy>::OpRewritePattern;
        -:  252:
        -:  253:  LogicalResult matchAndRewrite(OpTy loadOp,
        -:  254:                                PatternRewriter &rewriter) const override;
        -:  255:};
        -:  256:
        -:  257:/// Merges collapse_shape operation with load/transferRead operation.
        -:  258:template <typename OpTy>
        -:  259:class LoadOpOfCollapseShapeOpFolder final : public OpRewritePattern<OpTy> {
        -:  260:public:
        -:  261:  using OpRewritePattern<OpTy>::OpRewritePattern;
        -:  262:
        -:  263:  LogicalResult matchAndRewrite(OpTy loadOp,
        -:  264:                                PatternRewriter &rewriter) const override;
        -:  265:};
        -:  266:
        -:  267:/// Merges subview operation with store/transferWriteOp operation.
        -:  268:template <typename OpTy>
        -:  269:class StoreOpOfSubViewOpFolder final : public OpRewritePattern<OpTy> {
        -:  270:public:
        -:  271:  using OpRewritePattern<OpTy>::OpRewritePattern;
        -:  272:
        -:  273:  LogicalResult matchAndRewrite(OpTy storeOp,
        -:  274:                                PatternRewriter &rewriter) const override;
        -:  275:};
        -:  276:
        -:  277:/// Merges expand_shape operation with store/transferWriteOp operation.
        -:  278:template <typename OpTy>
        -:  279:class StoreOpOfExpandShapeOpFolder final : public OpRewritePattern<OpTy> {
        -:  280:public:
        -:  281:  using OpRewritePattern<OpTy>::OpRewritePattern;
        -:  282:
        -:  283:  LogicalResult matchAndRewrite(OpTy storeOp,
        -:  284:                                PatternRewriter &rewriter) const override;
        -:  285:};
        -:  286:
        -:  287:/// Merges collapse_shape operation with store/transferWriteOp operation.
        -:  288:template <typename OpTy>
        -:  289:class StoreOpOfCollapseShapeOpFolder final : public OpRewritePattern<OpTy> {
        -:  290:public:
        -:  291:  using OpRewritePattern<OpTy>::OpRewritePattern;
        -:  292:
        -:  293:  LogicalResult matchAndRewrite(OpTy storeOp,
        -:  294:                                PatternRewriter &rewriter) const override;
        -:  295:};
        -:  296:
        -:  297:} // namespace
        -:  298:
        -:  299:static SmallVector<Value>
function _ZL30calculateExpandedAccessIndicesN4mlir9AffineMapERKN4llvm11SmallVectorINS_5ValueELj6EEENS_8LocationERNS_15PatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  300:calculateExpandedAccessIndices(AffineMap affineMap,
        -:  301:                               const SmallVector<Value> &indices, Location loc,
        -:  302:                               PatternRewriter &rewriter) {
    #####:  303:  SmallVector<Value> expandedIndices;
call    0 never executed
    #####:  304:  for (unsigned i = 0, e = affineMap.getNumResults(); i < e; i++)
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  305:    expandedIndices.push_back(
call    0 never executed
    #####:  306:        rewriter.create<AffineApplyOp>(loc, affineMap.getSubMap({i}), indices));
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  307:  return expandedIndices;
        -:  308:}
        -:  309:
        -:  310:template <typename OpTy>
    #####:  311:LogicalResult LoadOpOfSubViewOpFolder<OpTy>::matchAndRewrite(
        -:  312:    OpTy loadOp, PatternRewriter &rewriter) const {
    #####:  313:  auto subViewOp =
    #####:  314:      getMemRefOperand(loadOp).template getDefiningOp<memref::SubViewOp>();
        -:  315:
    #####:  316:  if (!subViewOp)
    #####:  317:    return failure();
        -:  318:
    #####:  319:  SmallVector<Value> indices(loadOp.getIndices().begin(),
    #####:  320:                             loadOp.getIndices().end());
        -:  321:  // For affine ops, we need to apply the map to get the operands to get the
        -:  322:  // "actual" indices.
    #####:  323:  if (auto affineLoadOp = dyn_cast<AffineLoadOp>(loadOp.getOperation())) {
    #####:  324:    AffineMap affineMap = affineLoadOp.getAffineMap();
    #####:  325:    auto expandedIndices = calculateExpandedAccessIndices(
        -:  326:        affineMap, indices, loadOp.getLoc(), rewriter);
    #####:  327:    indices.assign(expandedIndices.begin(), expandedIndices.end());
        -:  328:  }
    #####:  329:  SmallVector<Value, 4> sourceIndices;
    #####:  330:  if (failed(resolveSourceIndicesSubView(loadOp.getLoc(), rewriter, subViewOp,
        -:  331:                                         indices, sourceIndices)))
    #####:  332:    return failure();
        -:  333:
    #####:  334:  llvm::TypeSwitch<Operation *, void>(loadOp)
    #####:  335:      .Case<AffineLoadOp, memref::LoadOp>([&](auto op) {
    #####:  336:        rewriter.replaceOpWithNewOp<decltype(op)>(loadOp, subViewOp.getSource(),
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
call    5 never executed
call    6 never executed
call    7 never executed
call    8 never executed
call    9 never executed
call   10 never executed
call   11 never executed
        -:  337:                                                  sourceIndices);
        -:  338:      })
    #####:  339:      .Case([&](vector::TransferReadOp transferReadOp) {
    #####:  340:        rewriter.replaceOpWithNewOp<vector::TransferReadOp>(
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
call    5 never executed
    #####:  341:            transferReadOp, transferReadOp.getVectorType(),
call    0 never executed
call    1 never executed
call    2 never executed
        -:  342:            subViewOp.getSource(), sourceIndices,
    #####:  343:            getPermutationMapAttr(rewriter.getContext(), subViewOp,
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
call    5 never executed
        -:  344:                                  transferReadOp.getPermutationMap()),
    #####:  345:            transferReadOp.getPadding(),
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  346:            /*mask=*/Value(), transferReadOp.getInBoundsAttr());
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
call    5 never executed
        -:  347:      })
    #####:  348:      .Default([](Operation *) { llvm_unreachable("unexpected operation."); });
    #####:  349:  return success();
        -:  350:}
------------------
_ZNK12_GLOBAL__N_123LoadOpOfSubViewOpFolderIN4mlir12AffineLoadOpEE15matchAndRewriteES2_RNS1_15PatternRewriterE:
function _ZNK12_GLOBAL__N_123LoadOpOfSubViewOpFolderIN4mlir12AffineLoadOpEE15matchAndRewriteES2_RNS1_15PatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  311:LogicalResult LoadOpOfSubViewOpFolder<OpTy>::matchAndRewrite(
call    0 never executed
        -:  312:    OpTy loadOp, PatternRewriter &rewriter) const {
    #####:  313:  auto subViewOp =
    #####:  314:      getMemRefOperand(loadOp).template getDefiningOp<memref::SubViewOp>();
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  315:
    #####:  316:  if (!subViewOp)
branch  0 never executed
branch  1 never executed
    #####:  317:    return failure();
        -:  318:
    #####:  319:  SmallVector<Value> indices(loadOp.getIndices().begin(),
call    0 never executed
call    1 never executed
    #####:  320:                             loadOp.getIndices().end());
call    0 never executed
        -:  321:  // For affine ops, we need to apply the map to get the operands to get the
        -:  322:  // "actual" indices.
    #####:  323:  if (auto affineLoadOp = dyn_cast<AffineLoadOp>(loadOp.getOperation())) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  324:    AffineMap affineMap = affineLoadOp.getAffineMap();
call    0 never executed
    #####:  325:    auto expandedIndices = calculateExpandedAccessIndices(
call    0 never executed
call    1 never executed
        -:  326:        affineMap, indices, loadOp.getLoc(), rewriter);
    #####:  327:    indices.assign(expandedIndices.begin(), expandedIndices.end());
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  328:  }
    #####:  329:  SmallVector<Value, 4> sourceIndices;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  330:  if (failed(resolveSourceIndicesSubView(loadOp.getLoc(), rewriter, subViewOp,
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  331:                                         indices, sourceIndices)))
    #####:  332:    return failure();
        -:  333:
    #####:  334:  llvm::TypeSwitch<Operation *, void>(loadOp)
call    0 never executed
        -:  335:      .Case<AffineLoadOp, memref::LoadOp>([&](auto op) {
        -:  336:        rewriter.replaceOpWithNewOp<decltype(op)>(loadOp, subViewOp.getSource(),
        -:  337:                                                  sourceIndices);
        -:  338:      })
    #####:  339:      .Case([&](vector::TransferReadOp transferReadOp) {
call    0 never executed
        -:  340:        rewriter.replaceOpWithNewOp<vector::TransferReadOp>(
        -:  341:            transferReadOp, transferReadOp.getVectorType(),
        -:  342:            subViewOp.getSource(), sourceIndices,
        -:  343:            getPermutationMapAttr(rewriter.getContext(), subViewOp,
        -:  344:                                  transferReadOp.getPermutationMap()),
        -:  345:            transferReadOp.getPadding(),
        -:  346:            /*mask=*/Value(), transferReadOp.getInBoundsAttr());
        -:  347:      })
    #####:  348:      .Default([](Operation *) { llvm_unreachable("unexpected operation."); });
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  349:  return success();
branch  0 never executed
branch  1 never executed
        -:  350:}
------------------
_ZNK12_GLOBAL__N_123LoadOpOfSubViewOpFolderIN4mlir6memref6LoadOpEE15matchAndRewriteES3_RNS1_15PatternRewriterE:
function _ZNK12_GLOBAL__N_123LoadOpOfSubViewOpFolderIN4mlir6memref6LoadOpEE15matchAndRewriteES3_RNS1_15PatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  311:LogicalResult LoadOpOfSubViewOpFolder<OpTy>::matchAndRewrite(
call    0 never executed
        -:  312:    OpTy loadOp, PatternRewriter &rewriter) const {
    #####:  313:  auto subViewOp =
    #####:  314:      getMemRefOperand(loadOp).template getDefiningOp<memref::SubViewOp>();
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  315:
    #####:  316:  if (!subViewOp)
branch  0 never executed
branch  1 never executed
    #####:  317:    return failure();
        -:  318:
    #####:  319:  SmallVector<Value> indices(loadOp.getIndices().begin(),
call    0 never executed
call    1 never executed
    #####:  320:                             loadOp.getIndices().end());
call    0 never executed
        -:  321:  // For affine ops, we need to apply the map to get the operands to get the
        -:  322:  // "actual" indices.
    #####:  323:  if (auto affineLoadOp = dyn_cast<AffineLoadOp>(loadOp.getOperation())) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  324:    AffineMap affineMap = affineLoadOp.getAffineMap();
call    0 never executed
    #####:  325:    auto expandedIndices = calculateExpandedAccessIndices(
call    0 never executed
call    1 never executed
        -:  326:        affineMap, indices, loadOp.getLoc(), rewriter);
    #####:  327:    indices.assign(expandedIndices.begin(), expandedIndices.end());
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  328:  }
    #####:  329:  SmallVector<Value, 4> sourceIndices;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  330:  if (failed(resolveSourceIndicesSubView(loadOp.getLoc(), rewriter, subViewOp,
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  331:                                         indices, sourceIndices)))
    #####:  332:    return failure();
        -:  333:
    #####:  334:  llvm::TypeSwitch<Operation *, void>(loadOp)
call    0 never executed
        -:  335:      .Case<AffineLoadOp, memref::LoadOp>([&](auto op) {
        -:  336:        rewriter.replaceOpWithNewOp<decltype(op)>(loadOp, subViewOp.getSource(),
        -:  337:                                                  sourceIndices);
        -:  338:      })
    #####:  339:      .Case([&](vector::TransferReadOp transferReadOp) {
call    0 never executed
        -:  340:        rewriter.replaceOpWithNewOp<vector::TransferReadOp>(
        -:  341:            transferReadOp, transferReadOp.getVectorType(),
        -:  342:            subViewOp.getSource(), sourceIndices,
        -:  343:            getPermutationMapAttr(rewriter.getContext(), subViewOp,
        -:  344:                                  transferReadOp.getPermutationMap()),
        -:  345:            transferReadOp.getPadding(),
        -:  346:            /*mask=*/Value(), transferReadOp.getInBoundsAttr());
        -:  347:      })
    #####:  348:      .Default([](Operation *) { llvm_unreachable("unexpected operation."); });
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  349:  return success();
branch  0 never executed
branch  1 never executed
        -:  350:}
------------------
_ZNK12_GLOBAL__N_123LoadOpOfSubViewOpFolderIN4mlir6vector14TransferReadOpEE15matchAndRewriteES3_RNS1_15PatternRewriterE:
function _ZNK12_GLOBAL__N_123LoadOpOfSubViewOpFolderIN4mlir6vector14TransferReadOpEE15matchAndRewriteES3_RNS1_15PatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  311:LogicalResult LoadOpOfSubViewOpFolder<OpTy>::matchAndRewrite(
call    0 never executed
        -:  312:    OpTy loadOp, PatternRewriter &rewriter) const {
    #####:  313:  auto subViewOp =
    #####:  314:      getMemRefOperand(loadOp).template getDefiningOp<memref::SubViewOp>();
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  315:
    #####:  316:  if (!subViewOp)
branch  0 never executed
branch  1 never executed
    #####:  317:    return failure();
        -:  318:
    #####:  319:  SmallVector<Value> indices(loadOp.getIndices().begin(),
call    0 never executed
call    1 never executed
    #####:  320:                             loadOp.getIndices().end());
call    0 never executed
        -:  321:  // For affine ops, we need to apply the map to get the operands to get the
        -:  322:  // "actual" indices.
    #####:  323:  if (auto affineLoadOp = dyn_cast<AffineLoadOp>(loadOp.getOperation())) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  324:    AffineMap affineMap = affineLoadOp.getAffineMap();
call    0 never executed
    #####:  325:    auto expandedIndices = calculateExpandedAccessIndices(
call    0 never executed
call    1 never executed
        -:  326:        affineMap, indices, loadOp.getLoc(), rewriter);
    #####:  327:    indices.assign(expandedIndices.begin(), expandedIndices.end());
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  328:  }
    #####:  329:  SmallVector<Value, 4> sourceIndices;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  330:  if (failed(resolveSourceIndicesSubView(loadOp.getLoc(), rewriter, subViewOp,
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  331:                                         indices, sourceIndices)))
    #####:  332:    return failure();
        -:  333:
    #####:  334:  llvm::TypeSwitch<Operation *, void>(loadOp)
call    0 never executed
        -:  335:      .Case<AffineLoadOp, memref::LoadOp>([&](auto op) {
        -:  336:        rewriter.replaceOpWithNewOp<decltype(op)>(loadOp, subViewOp.getSource(),
        -:  337:                                                  sourceIndices);
        -:  338:      })
    #####:  339:      .Case([&](vector::TransferReadOp transferReadOp) {
call    0 never executed
        -:  340:        rewriter.replaceOpWithNewOp<vector::TransferReadOp>(
        -:  341:            transferReadOp, transferReadOp.getVectorType(),
        -:  342:            subViewOp.getSource(), sourceIndices,
        -:  343:            getPermutationMapAttr(rewriter.getContext(), subViewOp,
        -:  344:                                  transferReadOp.getPermutationMap()),
        -:  345:            transferReadOp.getPadding(),
        -:  346:            /*mask=*/Value(), transferReadOp.getInBoundsAttr());
        -:  347:      })
    #####:  348:      .Default([](Operation *) { llvm_unreachable("unexpected operation."); });
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  349:  return success();
branch  0 never executed
branch  1 never executed
        -:  350:}
------------------
        -:  351:
        -:  352:template <typename OpTy>
    #####:  353:LogicalResult LoadOpOfExpandShapeOpFolder<OpTy>::matchAndRewrite(
        -:  354:    OpTy loadOp, PatternRewriter &rewriter) const {
    #####:  355:  auto expandShapeOp =
    #####:  356:      getMemRefOperand(loadOp).template getDefiningOp<memref::ExpandShapeOp>();
        -:  357:
    #####:  358:  if (!expandShapeOp)
    #####:  359:    return failure();
        -:  360:
    #####:  361:  SmallVector<Value> indices(loadOp.getIndices().begin(),
    #####:  362:                             loadOp.getIndices().end());
        -:  363:  // For affine ops, we need to apply the map to get the operands to get the
        -:  364:  // "actual" indices.
    #####:  365:  if (auto affineLoadOp = dyn_cast<AffineLoadOp>(loadOp.getOperation())) {
    #####:  366:    AffineMap affineMap = affineLoadOp.getAffineMap();
    #####:  367:    auto expandedIndices = calculateExpandedAccessIndices(
        -:  368:        affineMap, indices, loadOp.getLoc(), rewriter);
    #####:  369:    indices.assign(expandedIndices.begin(), expandedIndices.end());
        -:  370:  }
    #####:  371:  SmallVector<Value, 4> sourceIndices;
    #####:  372:  if (failed(resolveSourceIndicesExpandShape(
        -:  373:          loadOp.getLoc(), rewriter, expandShapeOp, indices, sourceIndices)))
    #####:  374:    return failure();
    #####:  375:  llvm::TypeSwitch<Operation *, void>(loadOp)
    #####:  376:      .Case<AffineLoadOp, memref::LoadOp>([&](auto op) {
    #####:  377:        rewriter.replaceOpWithNewOp<decltype(op)>(
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
call    5 never executed
call    6 never executed
call    7 never executed
        -:  378:            loadOp, expandShapeOp.getViewSource(), sourceIndices);
        -:  379:      })
    #####:  380:      .Default([](Operation *) { llvm_unreachable("unexpected operation."); });
    #####:  381:  return success();
        -:  382:}
------------------
_ZNK12_GLOBAL__N_127LoadOpOfExpandShapeOpFolderIN4mlir12AffineLoadOpEE15matchAndRewriteES2_RNS1_15PatternRewriterE:
function _ZNK12_GLOBAL__N_127LoadOpOfExpandShapeOpFolderIN4mlir12AffineLoadOpEE15matchAndRewriteES2_RNS1_15PatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  353:LogicalResult LoadOpOfExpandShapeOpFolder<OpTy>::matchAndRewrite(
call    0 never executed
        -:  354:    OpTy loadOp, PatternRewriter &rewriter) const {
    #####:  355:  auto expandShapeOp =
    #####:  356:      getMemRefOperand(loadOp).template getDefiningOp<memref::ExpandShapeOp>();
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  357:
    #####:  358:  if (!expandShapeOp)
branch  0 never executed
branch  1 never executed
    #####:  359:    return failure();
        -:  360:
    #####:  361:  SmallVector<Value> indices(loadOp.getIndices().begin(),
call    0 never executed
call    1 never executed
    #####:  362:                             loadOp.getIndices().end());
call    0 never executed
        -:  363:  // For affine ops, we need to apply the map to get the operands to get the
        -:  364:  // "actual" indices.
    #####:  365:  if (auto affineLoadOp = dyn_cast<AffineLoadOp>(loadOp.getOperation())) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  366:    AffineMap affineMap = affineLoadOp.getAffineMap();
call    0 never executed
    #####:  367:    auto expandedIndices = calculateExpandedAccessIndices(
call    0 never executed
call    1 never executed
        -:  368:        affineMap, indices, loadOp.getLoc(), rewriter);
    #####:  369:    indices.assign(expandedIndices.begin(), expandedIndices.end());
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  370:  }
    #####:  371:  SmallVector<Value, 4> sourceIndices;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  372:  if (failed(resolveSourceIndicesExpandShape(
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  373:          loadOp.getLoc(), rewriter, expandShapeOp, indices, sourceIndices)))
    #####:  374:    return failure();
    #####:  375:  llvm::TypeSwitch<Operation *, void>(loadOp)
call    0 never executed
        -:  376:      .Case<AffineLoadOp, memref::LoadOp>([&](auto op) {
        -:  377:        rewriter.replaceOpWithNewOp<decltype(op)>(
        -:  378:            loadOp, expandShapeOp.getViewSource(), sourceIndices);
        -:  379:      })
    #####:  380:      .Default([](Operation *) { llvm_unreachable("unexpected operation."); });
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  381:  return success();
branch  0 never executed
branch  1 never executed
        -:  382:}
------------------
_ZNK12_GLOBAL__N_127LoadOpOfExpandShapeOpFolderIN4mlir6memref6LoadOpEE15matchAndRewriteES3_RNS1_15PatternRewriterE:
function _ZNK12_GLOBAL__N_127LoadOpOfExpandShapeOpFolderIN4mlir6memref6LoadOpEE15matchAndRewriteES3_RNS1_15PatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  353:LogicalResult LoadOpOfExpandShapeOpFolder<OpTy>::matchAndRewrite(
call    0 never executed
        -:  354:    OpTy loadOp, PatternRewriter &rewriter) const {
    #####:  355:  auto expandShapeOp =
    #####:  356:      getMemRefOperand(loadOp).template getDefiningOp<memref::ExpandShapeOp>();
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  357:
    #####:  358:  if (!expandShapeOp)
branch  0 never executed
branch  1 never executed
    #####:  359:    return failure();
        -:  360:
    #####:  361:  SmallVector<Value> indices(loadOp.getIndices().begin(),
call    0 never executed
call    1 never executed
    #####:  362:                             loadOp.getIndices().end());
call    0 never executed
        -:  363:  // For affine ops, we need to apply the map to get the operands to get the
        -:  364:  // "actual" indices.
    #####:  365:  if (auto affineLoadOp = dyn_cast<AffineLoadOp>(loadOp.getOperation())) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  366:    AffineMap affineMap = affineLoadOp.getAffineMap();
call    0 never executed
    #####:  367:    auto expandedIndices = calculateExpandedAccessIndices(
call    0 never executed
call    1 never executed
        -:  368:        affineMap, indices, loadOp.getLoc(), rewriter);
    #####:  369:    indices.assign(expandedIndices.begin(), expandedIndices.end());
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  370:  }
    #####:  371:  SmallVector<Value, 4> sourceIndices;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  372:  if (failed(resolveSourceIndicesExpandShape(
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  373:          loadOp.getLoc(), rewriter, expandShapeOp, indices, sourceIndices)))
    #####:  374:    return failure();
    #####:  375:  llvm::TypeSwitch<Operation *, void>(loadOp)
call    0 never executed
        -:  376:      .Case<AffineLoadOp, memref::LoadOp>([&](auto op) {
        -:  377:        rewriter.replaceOpWithNewOp<decltype(op)>(
        -:  378:            loadOp, expandShapeOp.getViewSource(), sourceIndices);
        -:  379:      })
    #####:  380:      .Default([](Operation *) { llvm_unreachable("unexpected operation."); });
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  381:  return success();
branch  0 never executed
branch  1 never executed
        -:  382:}
------------------
        -:  383:
        -:  384:template <typename OpTy>
    #####:  385:LogicalResult LoadOpOfCollapseShapeOpFolder<OpTy>::matchAndRewrite(
        -:  386:    OpTy loadOp, PatternRewriter &rewriter) const {
    #####:  387:  auto collapseShapeOp = getMemRefOperand(loadOp)
        -:  388:                             .template getDefiningOp<memref::CollapseShapeOp>();
        -:  389:
    #####:  390:  if (!collapseShapeOp)
    #####:  391:    return failure();
        -:  392:
    #####:  393:  SmallVector<Value> indices(loadOp.getIndices().begin(),
    #####:  394:                             loadOp.getIndices().end());
        -:  395:  // For affine ops, we need to apply the map to get the operands to get the
        -:  396:  // "actual" indices.
    #####:  397:  if (auto affineLoadOp = dyn_cast<AffineLoadOp>(loadOp.getOperation())) {
    #####:  398:    AffineMap affineMap = affineLoadOp.getAffineMap();
    #####:  399:    auto expandedIndices = calculateExpandedAccessIndices(
        -:  400:        affineMap, indices, loadOp.getLoc(), rewriter);
    #####:  401:    indices.assign(expandedIndices.begin(), expandedIndices.end());
        -:  402:  }
    #####:  403:  SmallVector<Value, 4> sourceIndices;
    #####:  404:  if (failed(resolveSourceIndicesCollapseShape(
        -:  405:          loadOp.getLoc(), rewriter, collapseShapeOp, indices, sourceIndices)))
    #####:  406:    return failure();
    #####:  407:  llvm::TypeSwitch<Operation *, void>(loadOp)
    #####:  408:      .Case<AffineLoadOp, memref::LoadOp>([&](auto op) {
    #####:  409:        rewriter.replaceOpWithNewOp<decltype(op)>(
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
call    5 never executed
call    6 never executed
call    7 never executed
        -:  410:            loadOp, collapseShapeOp.getViewSource(), sourceIndices);
        -:  411:      })
    #####:  412:      .Default([](Operation *) { llvm_unreachable("unexpected operation."); });
    #####:  413:  return success();
        -:  414:}
------------------
_ZNK12_GLOBAL__N_129LoadOpOfCollapseShapeOpFolderIN4mlir12AffineLoadOpEE15matchAndRewriteES2_RNS1_15PatternRewriterE:
function _ZNK12_GLOBAL__N_129LoadOpOfCollapseShapeOpFolderIN4mlir12AffineLoadOpEE15matchAndRewriteES2_RNS1_15PatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  385:LogicalResult LoadOpOfCollapseShapeOpFolder<OpTy>::matchAndRewrite(
call    0 never executed
        -:  386:    OpTy loadOp, PatternRewriter &rewriter) const {
    #####:  387:  auto collapseShapeOp = getMemRefOperand(loadOp)
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  388:                             .template getDefiningOp<memref::CollapseShapeOp>();
        -:  389:
    #####:  390:  if (!collapseShapeOp)
branch  0 never executed
branch  1 never executed
    #####:  391:    return failure();
        -:  392:
    #####:  393:  SmallVector<Value> indices(loadOp.getIndices().begin(),
call    0 never executed
call    1 never executed
    #####:  394:                             loadOp.getIndices().end());
call    0 never executed
        -:  395:  // For affine ops, we need to apply the map to get the operands to get the
        -:  396:  // "actual" indices.
    #####:  397:  if (auto affineLoadOp = dyn_cast<AffineLoadOp>(loadOp.getOperation())) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  398:    AffineMap affineMap = affineLoadOp.getAffineMap();
call    0 never executed
    #####:  399:    auto expandedIndices = calculateExpandedAccessIndices(
call    0 never executed
call    1 never executed
        -:  400:        affineMap, indices, loadOp.getLoc(), rewriter);
    #####:  401:    indices.assign(expandedIndices.begin(), expandedIndices.end());
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  402:  }
    #####:  403:  SmallVector<Value, 4> sourceIndices;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  404:  if (failed(resolveSourceIndicesCollapseShape(
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  405:          loadOp.getLoc(), rewriter, collapseShapeOp, indices, sourceIndices)))
    #####:  406:    return failure();
    #####:  407:  llvm::TypeSwitch<Operation *, void>(loadOp)
call    0 never executed
        -:  408:      .Case<AffineLoadOp, memref::LoadOp>([&](auto op) {
        -:  409:        rewriter.replaceOpWithNewOp<decltype(op)>(
        -:  410:            loadOp, collapseShapeOp.getViewSource(), sourceIndices);
        -:  411:      })
    #####:  412:      .Default([](Operation *) { llvm_unreachable("unexpected operation."); });
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  413:  return success();
branch  0 never executed
branch  1 never executed
        -:  414:}
------------------
_ZNK12_GLOBAL__N_129LoadOpOfCollapseShapeOpFolderIN4mlir6memref6LoadOpEE15matchAndRewriteES3_RNS1_15PatternRewriterE:
function _ZNK12_GLOBAL__N_129LoadOpOfCollapseShapeOpFolderIN4mlir6memref6LoadOpEE15matchAndRewriteES3_RNS1_15PatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  385:LogicalResult LoadOpOfCollapseShapeOpFolder<OpTy>::matchAndRewrite(
call    0 never executed
        -:  386:    OpTy loadOp, PatternRewriter &rewriter) const {
    #####:  387:  auto collapseShapeOp = getMemRefOperand(loadOp)
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  388:                             .template getDefiningOp<memref::CollapseShapeOp>();
        -:  389:
    #####:  390:  if (!collapseShapeOp)
branch  0 never executed
branch  1 never executed
    #####:  391:    return failure();
        -:  392:
    #####:  393:  SmallVector<Value> indices(loadOp.getIndices().begin(),
call    0 never executed
call    1 never executed
    #####:  394:                             loadOp.getIndices().end());
call    0 never executed
        -:  395:  // For affine ops, we need to apply the map to get the operands to get the
        -:  396:  // "actual" indices.
    #####:  397:  if (auto affineLoadOp = dyn_cast<AffineLoadOp>(loadOp.getOperation())) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  398:    AffineMap affineMap = affineLoadOp.getAffineMap();
call    0 never executed
    #####:  399:    auto expandedIndices = calculateExpandedAccessIndices(
call    0 never executed
call    1 never executed
        -:  400:        affineMap, indices, loadOp.getLoc(), rewriter);
    #####:  401:    indices.assign(expandedIndices.begin(), expandedIndices.end());
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  402:  }
    #####:  403:  SmallVector<Value, 4> sourceIndices;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  404:  if (failed(resolveSourceIndicesCollapseShape(
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  405:          loadOp.getLoc(), rewriter, collapseShapeOp, indices, sourceIndices)))
    #####:  406:    return failure();
    #####:  407:  llvm::TypeSwitch<Operation *, void>(loadOp)
call    0 never executed
        -:  408:      .Case<AffineLoadOp, memref::LoadOp>([&](auto op) {
        -:  409:        rewriter.replaceOpWithNewOp<decltype(op)>(
        -:  410:            loadOp, collapseShapeOp.getViewSource(), sourceIndices);
        -:  411:      })
    #####:  412:      .Default([](Operation *) { llvm_unreachable("unexpected operation."); });
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  413:  return success();
branch  0 never executed
branch  1 never executed
        -:  414:}
------------------
        -:  415:
        -:  416:template <typename OpTy>
    #####:  417:LogicalResult StoreOpOfSubViewOpFolder<OpTy>::matchAndRewrite(
        -:  418:    OpTy storeOp, PatternRewriter &rewriter) const {
    #####:  419:  auto subViewOp =
    #####:  420:      getMemRefOperand(storeOp).template getDefiningOp<memref::SubViewOp>();
        -:  421:
    #####:  422:  if (!subViewOp)
    #####:  423:    return failure();
        -:  424:
    #####:  425:  SmallVector<Value> indices(storeOp.getIndices().begin(),
    #####:  426:                             storeOp.getIndices().end());
        -:  427:  // For affine ops, we need to apply the map to get the operands to get the
        -:  428:  // "actual" indices.
    #####:  429:  if (auto affineStoreOp = dyn_cast<AffineStoreOp>(storeOp.getOperation())) {
    #####:  430:    AffineMap affineMap = affineStoreOp.getAffineMap();
    #####:  431:    auto expandedIndices = calculateExpandedAccessIndices(
        -:  432:        affineMap, indices, storeOp.getLoc(), rewriter);
    #####:  433:    indices.assign(expandedIndices.begin(), expandedIndices.end());
        -:  434:  }
    #####:  435:  SmallVector<Value, 4> sourceIndices;
    #####:  436:  if (failed(resolveSourceIndicesSubView(storeOp.getLoc(), rewriter, subViewOp,
        -:  437:                                         indices, sourceIndices)))
    #####:  438:    return failure();
        -:  439:
    #####:  440:  llvm::TypeSwitch<Operation *, void>(storeOp)
    #####:  441:      .Case<AffineStoreOp, memref::StoreOp>([&](auto op) {
    #####:  442:        rewriter.replaceOpWithNewOp<decltype(op)>(
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
call    5 never executed
call    6 never executed
call    7 never executed
call    8 never executed
call    9 never executed
call   10 never executed
call   11 never executed
call   12 never executed
call   13 never executed
call   14 never executed
call   15 never executed
        -:  443:            storeOp, storeOp.getValue(), subViewOp.getSource(), sourceIndices);
        -:  444:      })
    #####:  445:      .Case([&](vector::TransferWriteOp op) {
    #####:  446:        rewriter.replaceOpWithNewOp<vector::TransferWriteOp>(
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
call    5 never executed
    #####:  447:            op, op.getValue(), subViewOp.getSource(), sourceIndices,
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  448:            getPermutationMapAttr(rewriter.getContext(), subViewOp,
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
call    5 never executed
        -:  449:                                  op.getPermutationMap()),
    #####:  450:            op.getInBoundsAttr());
call    0 never executed
call    1 never executed
call    2 never executed
        -:  451:      })
    #####:  452:      .Default([](Operation *) { llvm_unreachable("unexpected operation."); });
    #####:  453:  return success();
        -:  454:}
------------------
_ZNK12_GLOBAL__N_124StoreOpOfSubViewOpFolderIN4mlir13AffineStoreOpEE15matchAndRewriteES2_RNS1_15PatternRewriterE:
function _ZNK12_GLOBAL__N_124StoreOpOfSubViewOpFolderIN4mlir13AffineStoreOpEE15matchAndRewriteES2_RNS1_15PatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  417:LogicalResult StoreOpOfSubViewOpFolder<OpTy>::matchAndRewrite(
call    0 never executed
        -:  418:    OpTy storeOp, PatternRewriter &rewriter) const {
    #####:  419:  auto subViewOp =
    #####:  420:      getMemRefOperand(storeOp).template getDefiningOp<memref::SubViewOp>();
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  421:
    #####:  422:  if (!subViewOp)
branch  0 never executed
branch  1 never executed
    #####:  423:    return failure();
        -:  424:
    #####:  425:  SmallVector<Value> indices(storeOp.getIndices().begin(),
call    0 never executed
call    1 never executed
    #####:  426:                             storeOp.getIndices().end());
call    0 never executed
        -:  427:  // For affine ops, we need to apply the map to get the operands to get the
        -:  428:  // "actual" indices.
    #####:  429:  if (auto affineStoreOp = dyn_cast<AffineStoreOp>(storeOp.getOperation())) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  430:    AffineMap affineMap = affineStoreOp.getAffineMap();
call    0 never executed
    #####:  431:    auto expandedIndices = calculateExpandedAccessIndices(
call    0 never executed
call    1 never executed
        -:  432:        affineMap, indices, storeOp.getLoc(), rewriter);
    #####:  433:    indices.assign(expandedIndices.begin(), expandedIndices.end());
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  434:  }
    #####:  435:  SmallVector<Value, 4> sourceIndices;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  436:  if (failed(resolveSourceIndicesSubView(storeOp.getLoc(), rewriter, subViewOp,
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  437:                                         indices, sourceIndices)))
    #####:  438:    return failure();
        -:  439:
    #####:  440:  llvm::TypeSwitch<Operation *, void>(storeOp)
call    0 never executed
        -:  441:      .Case<AffineStoreOp, memref::StoreOp>([&](auto op) {
        -:  442:        rewriter.replaceOpWithNewOp<decltype(op)>(
        -:  443:            storeOp, storeOp.getValue(), subViewOp.getSource(), sourceIndices);
        -:  444:      })
    #####:  445:      .Case([&](vector::TransferWriteOp op) {
call    0 never executed
        -:  446:        rewriter.replaceOpWithNewOp<vector::TransferWriteOp>(
        -:  447:            op, op.getValue(), subViewOp.getSource(), sourceIndices,
        -:  448:            getPermutationMapAttr(rewriter.getContext(), subViewOp,
        -:  449:                                  op.getPermutationMap()),
        -:  450:            op.getInBoundsAttr());
        -:  451:      })
    #####:  452:      .Default([](Operation *) { llvm_unreachable("unexpected operation."); });
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  453:  return success();
branch  0 never executed
branch  1 never executed
        -:  454:}
------------------
_ZNK12_GLOBAL__N_124StoreOpOfSubViewOpFolderIN4mlir6memref7StoreOpEE15matchAndRewriteES3_RNS1_15PatternRewriterE:
function _ZNK12_GLOBAL__N_124StoreOpOfSubViewOpFolderIN4mlir6memref7StoreOpEE15matchAndRewriteES3_RNS1_15PatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  417:LogicalResult StoreOpOfSubViewOpFolder<OpTy>::matchAndRewrite(
call    0 never executed
        -:  418:    OpTy storeOp, PatternRewriter &rewriter) const {
    #####:  419:  auto subViewOp =
    #####:  420:      getMemRefOperand(storeOp).template getDefiningOp<memref::SubViewOp>();
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  421:
    #####:  422:  if (!subViewOp)
branch  0 never executed
branch  1 never executed
    #####:  423:    return failure();
        -:  424:
    #####:  425:  SmallVector<Value> indices(storeOp.getIndices().begin(),
call    0 never executed
call    1 never executed
    #####:  426:                             storeOp.getIndices().end());
call    0 never executed
        -:  427:  // For affine ops, we need to apply the map to get the operands to get the
        -:  428:  // "actual" indices.
    #####:  429:  if (auto affineStoreOp = dyn_cast<AffineStoreOp>(storeOp.getOperation())) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  430:    AffineMap affineMap = affineStoreOp.getAffineMap();
call    0 never executed
    #####:  431:    auto expandedIndices = calculateExpandedAccessIndices(
call    0 never executed
call    1 never executed
        -:  432:        affineMap, indices, storeOp.getLoc(), rewriter);
    #####:  433:    indices.assign(expandedIndices.begin(), expandedIndices.end());
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  434:  }
    #####:  435:  SmallVector<Value, 4> sourceIndices;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  436:  if (failed(resolveSourceIndicesSubView(storeOp.getLoc(), rewriter, subViewOp,
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  437:                                         indices, sourceIndices)))
    #####:  438:    return failure();
        -:  439:
    #####:  440:  llvm::TypeSwitch<Operation *, void>(storeOp)
call    0 never executed
        -:  441:      .Case<AffineStoreOp, memref::StoreOp>([&](auto op) {
        -:  442:        rewriter.replaceOpWithNewOp<decltype(op)>(
        -:  443:            storeOp, storeOp.getValue(), subViewOp.getSource(), sourceIndices);
        -:  444:      })
    #####:  445:      .Case([&](vector::TransferWriteOp op) {
call    0 never executed
        -:  446:        rewriter.replaceOpWithNewOp<vector::TransferWriteOp>(
        -:  447:            op, op.getValue(), subViewOp.getSource(), sourceIndices,
        -:  448:            getPermutationMapAttr(rewriter.getContext(), subViewOp,
        -:  449:                                  op.getPermutationMap()),
        -:  450:            op.getInBoundsAttr());
        -:  451:      })
    #####:  452:      .Default([](Operation *) { llvm_unreachable("unexpected operation."); });
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  453:  return success();
branch  0 never executed
branch  1 never executed
        -:  454:}
------------------
_ZNK12_GLOBAL__N_124StoreOpOfSubViewOpFolderIN4mlir6vector15TransferWriteOpEE15matchAndRewriteES3_RNS1_15PatternRewriterE:
function _ZNK12_GLOBAL__N_124StoreOpOfSubViewOpFolderIN4mlir6vector15TransferWriteOpEE15matchAndRewriteES3_RNS1_15PatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  417:LogicalResult StoreOpOfSubViewOpFolder<OpTy>::matchAndRewrite(
call    0 never executed
        -:  418:    OpTy storeOp, PatternRewriter &rewriter) const {
    #####:  419:  auto subViewOp =
    #####:  420:      getMemRefOperand(storeOp).template getDefiningOp<memref::SubViewOp>();
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  421:
    #####:  422:  if (!subViewOp)
branch  0 never executed
branch  1 never executed
    #####:  423:    return failure();
        -:  424:
    #####:  425:  SmallVector<Value> indices(storeOp.getIndices().begin(),
call    0 never executed
call    1 never executed
    #####:  426:                             storeOp.getIndices().end());
call    0 never executed
        -:  427:  // For affine ops, we need to apply the map to get the operands to get the
        -:  428:  // "actual" indices.
    #####:  429:  if (auto affineStoreOp = dyn_cast<AffineStoreOp>(storeOp.getOperation())) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  430:    AffineMap affineMap = affineStoreOp.getAffineMap();
call    0 never executed
    #####:  431:    auto expandedIndices = calculateExpandedAccessIndices(
call    0 never executed
call    1 never executed
        -:  432:        affineMap, indices, storeOp.getLoc(), rewriter);
    #####:  433:    indices.assign(expandedIndices.begin(), expandedIndices.end());
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  434:  }
    #####:  435:  SmallVector<Value, 4> sourceIndices;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  436:  if (failed(resolveSourceIndicesSubView(storeOp.getLoc(), rewriter, subViewOp,
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  437:                                         indices, sourceIndices)))
    #####:  438:    return failure();
        -:  439:
    #####:  440:  llvm::TypeSwitch<Operation *, void>(storeOp)
call    0 never executed
        -:  441:      .Case<AffineStoreOp, memref::StoreOp>([&](auto op) {
        -:  442:        rewriter.replaceOpWithNewOp<decltype(op)>(
        -:  443:            storeOp, storeOp.getValue(), subViewOp.getSource(), sourceIndices);
        -:  444:      })
    #####:  445:      .Case([&](vector::TransferWriteOp op) {
call    0 never executed
        -:  446:        rewriter.replaceOpWithNewOp<vector::TransferWriteOp>(
        -:  447:            op, op.getValue(), subViewOp.getSource(), sourceIndices,
        -:  448:            getPermutationMapAttr(rewriter.getContext(), subViewOp,
        -:  449:                                  op.getPermutationMap()),
        -:  450:            op.getInBoundsAttr());
        -:  451:      })
    #####:  452:      .Default([](Operation *) { llvm_unreachable("unexpected operation."); });
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  453:  return success();
branch  0 never executed
branch  1 never executed
        -:  454:}
------------------
        -:  455:
        -:  456:template <typename OpTy>
    #####:  457:LogicalResult StoreOpOfExpandShapeOpFolder<OpTy>::matchAndRewrite(
        -:  458:    OpTy storeOp, PatternRewriter &rewriter) const {
    #####:  459:  auto expandShapeOp =
    #####:  460:      getMemRefOperand(storeOp).template getDefiningOp<memref::ExpandShapeOp>();
        -:  461:
    #####:  462:  if (!expandShapeOp)
    #####:  463:    return failure();
        -:  464:
    #####:  465:  SmallVector<Value> indices(storeOp.getIndices().begin(),
    #####:  466:                             storeOp.getIndices().end());
        -:  467:  // For affine ops, we need to apply the map to get the operands to get the
        -:  468:  // "actual" indices.
    #####:  469:  if (auto affineStoreOp = dyn_cast<AffineStoreOp>(storeOp.getOperation())) {
    #####:  470:    AffineMap affineMap = affineStoreOp.getAffineMap();
    #####:  471:    auto expandedIndices = calculateExpandedAccessIndices(
        -:  472:        affineMap, indices, storeOp.getLoc(), rewriter);
    #####:  473:    indices.assign(expandedIndices.begin(), expandedIndices.end());
        -:  474:  }
    #####:  475:  SmallVector<Value, 4> sourceIndices;
    #####:  476:  if (failed(resolveSourceIndicesExpandShape(
        -:  477:          storeOp.getLoc(), rewriter, expandShapeOp, indices, sourceIndices)))
    #####:  478:    return failure();
    #####:  479:  llvm::TypeSwitch<Operation *, void>(storeOp)
    #####:  480:      .Case<AffineStoreOp, memref::StoreOp>([&](auto op) {
    #####:  481:        rewriter.replaceOpWithNewOp<decltype(op)>(storeOp, storeOp.getValue(),
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
call    5 never executed
call    6 never executed
call    7 never executed
call    8 never executed
call    9 never executed
call   10 never executed
call   11 never executed
        -:  482:                                                  expandShapeOp.getViewSource(),
        -:  483:                                                  sourceIndices);
        -:  484:      })
    #####:  485:      .Default([](Operation *) { llvm_unreachable("unexpected operation."); });
    #####:  486:  return success();
        -:  487:}
------------------
_ZNK12_GLOBAL__N_128StoreOpOfExpandShapeOpFolderIN4mlir13AffineStoreOpEE15matchAndRewriteES2_RNS1_15PatternRewriterE:
function _ZNK12_GLOBAL__N_128StoreOpOfExpandShapeOpFolderIN4mlir13AffineStoreOpEE15matchAndRewriteES2_RNS1_15PatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  457:LogicalResult StoreOpOfExpandShapeOpFolder<OpTy>::matchAndRewrite(
call    0 never executed
        -:  458:    OpTy storeOp, PatternRewriter &rewriter) const {
    #####:  459:  auto expandShapeOp =
    #####:  460:      getMemRefOperand(storeOp).template getDefiningOp<memref::ExpandShapeOp>();
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  461:
    #####:  462:  if (!expandShapeOp)
branch  0 never executed
branch  1 never executed
    #####:  463:    return failure();
        -:  464:
    #####:  465:  SmallVector<Value> indices(storeOp.getIndices().begin(),
call    0 never executed
call    1 never executed
    #####:  466:                             storeOp.getIndices().end());
call    0 never executed
        -:  467:  // For affine ops, we need to apply the map to get the operands to get the
        -:  468:  // "actual" indices.
    #####:  469:  if (auto affineStoreOp = dyn_cast<AffineStoreOp>(storeOp.getOperation())) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  470:    AffineMap affineMap = affineStoreOp.getAffineMap();
call    0 never executed
    #####:  471:    auto expandedIndices = calculateExpandedAccessIndices(
call    0 never executed
call    1 never executed
        -:  472:        affineMap, indices, storeOp.getLoc(), rewriter);
    #####:  473:    indices.assign(expandedIndices.begin(), expandedIndices.end());
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  474:  }
    #####:  475:  SmallVector<Value, 4> sourceIndices;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  476:  if (failed(resolveSourceIndicesExpandShape(
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  477:          storeOp.getLoc(), rewriter, expandShapeOp, indices, sourceIndices)))
    #####:  478:    return failure();
    #####:  479:  llvm::TypeSwitch<Operation *, void>(storeOp)
call    0 never executed
        -:  480:      .Case<AffineStoreOp, memref::StoreOp>([&](auto op) {
        -:  481:        rewriter.replaceOpWithNewOp<decltype(op)>(storeOp, storeOp.getValue(),
        -:  482:                                                  expandShapeOp.getViewSource(),
        -:  483:                                                  sourceIndices);
        -:  484:      })
    #####:  485:      .Default([](Operation *) { llvm_unreachable("unexpected operation."); });
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  486:  return success();
branch  0 never executed
branch  1 never executed
        -:  487:}
------------------
_ZNK12_GLOBAL__N_128StoreOpOfExpandShapeOpFolderIN4mlir6memref7StoreOpEE15matchAndRewriteES3_RNS1_15PatternRewriterE:
function _ZNK12_GLOBAL__N_128StoreOpOfExpandShapeOpFolderIN4mlir6memref7StoreOpEE15matchAndRewriteES3_RNS1_15PatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  457:LogicalResult StoreOpOfExpandShapeOpFolder<OpTy>::matchAndRewrite(
call    0 never executed
        -:  458:    OpTy storeOp, PatternRewriter &rewriter) const {
    #####:  459:  auto expandShapeOp =
    #####:  460:      getMemRefOperand(storeOp).template getDefiningOp<memref::ExpandShapeOp>();
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  461:
    #####:  462:  if (!expandShapeOp)
branch  0 never executed
branch  1 never executed
    #####:  463:    return failure();
        -:  464:
    #####:  465:  SmallVector<Value> indices(storeOp.getIndices().begin(),
call    0 never executed
call    1 never executed
    #####:  466:                             storeOp.getIndices().end());
call    0 never executed
        -:  467:  // For affine ops, we need to apply the map to get the operands to get the
        -:  468:  // "actual" indices.
    #####:  469:  if (auto affineStoreOp = dyn_cast<AffineStoreOp>(storeOp.getOperation())) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  470:    AffineMap affineMap = affineStoreOp.getAffineMap();
call    0 never executed
    #####:  471:    auto expandedIndices = calculateExpandedAccessIndices(
call    0 never executed
call    1 never executed
        -:  472:        affineMap, indices, storeOp.getLoc(), rewriter);
    #####:  473:    indices.assign(expandedIndices.begin(), expandedIndices.end());
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  474:  }
    #####:  475:  SmallVector<Value, 4> sourceIndices;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  476:  if (failed(resolveSourceIndicesExpandShape(
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  477:          storeOp.getLoc(), rewriter, expandShapeOp, indices, sourceIndices)))
    #####:  478:    return failure();
    #####:  479:  llvm::TypeSwitch<Operation *, void>(storeOp)
call    0 never executed
        -:  480:      .Case<AffineStoreOp, memref::StoreOp>([&](auto op) {
        -:  481:        rewriter.replaceOpWithNewOp<decltype(op)>(storeOp, storeOp.getValue(),
        -:  482:                                                  expandShapeOp.getViewSource(),
        -:  483:                                                  sourceIndices);
        -:  484:      })
    #####:  485:      .Default([](Operation *) { llvm_unreachable("unexpected operation."); });
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  486:  return success();
branch  0 never executed
branch  1 never executed
        -:  487:}
------------------
        -:  488:
        -:  489:template <typename OpTy>
    #####:  490:LogicalResult StoreOpOfCollapseShapeOpFolder<OpTy>::matchAndRewrite(
        -:  491:    OpTy storeOp, PatternRewriter &rewriter) const {
    #####:  492:  auto collapseShapeOp = getMemRefOperand(storeOp)
        -:  493:                             .template getDefiningOp<memref::CollapseShapeOp>();
        -:  494:
    #####:  495:  if (!collapseShapeOp)
    #####:  496:    return failure();
        -:  497:
    #####:  498:  SmallVector<Value> indices(storeOp.getIndices().begin(),
    #####:  499:                             storeOp.getIndices().end());
        -:  500:  // For affine ops, we need to apply the map to get the operands to get the
        -:  501:  // "actual" indices.
    #####:  502:  if (auto affineStoreOp = dyn_cast<AffineStoreOp>(storeOp.getOperation())) {
    #####:  503:    AffineMap affineMap = affineStoreOp.getAffineMap();
    #####:  504:    auto expandedIndices = calculateExpandedAccessIndices(
        -:  505:        affineMap, indices, storeOp.getLoc(), rewriter);
    #####:  506:    indices.assign(expandedIndices.begin(), expandedIndices.end());
        -:  507:  }
    #####:  508:  SmallVector<Value, 4> sourceIndices;
    #####:  509:  if (failed(resolveSourceIndicesCollapseShape(
        -:  510:          storeOp.getLoc(), rewriter, collapseShapeOp, indices, sourceIndices)))
    #####:  511:    return failure();
    #####:  512:  llvm::TypeSwitch<Operation *, void>(storeOp)
    #####:  513:      .Case<AffineStoreOp, memref::StoreOp>([&](auto op) {
    #####:  514:        rewriter.replaceOpWithNewOp<decltype(op)>(
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
call    5 never executed
call    6 never executed
call    7 never executed
call    8 never executed
call    9 never executed
call   10 never executed
call   11 never executed
        -:  515:            storeOp, storeOp.getValue(), collapseShapeOp.getViewSource(),
        -:  516:            sourceIndices);
        -:  517:      })
    #####:  518:      .Default([](Operation *) { llvm_unreachable("unexpected operation."); });
    #####:  519:  return success();
        -:  520:}
------------------
_ZNK12_GLOBAL__N_130StoreOpOfCollapseShapeOpFolderIN4mlir13AffineStoreOpEE15matchAndRewriteES2_RNS1_15PatternRewriterE:
function _ZNK12_GLOBAL__N_130StoreOpOfCollapseShapeOpFolderIN4mlir13AffineStoreOpEE15matchAndRewriteES2_RNS1_15PatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  490:LogicalResult StoreOpOfCollapseShapeOpFolder<OpTy>::matchAndRewrite(
call    0 never executed
        -:  491:    OpTy storeOp, PatternRewriter &rewriter) const {
    #####:  492:  auto collapseShapeOp = getMemRefOperand(storeOp)
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  493:                             .template getDefiningOp<memref::CollapseShapeOp>();
        -:  494:
    #####:  495:  if (!collapseShapeOp)
branch  0 never executed
branch  1 never executed
    #####:  496:    return failure();
        -:  497:
    #####:  498:  SmallVector<Value> indices(storeOp.getIndices().begin(),
call    0 never executed
call    1 never executed
    #####:  499:                             storeOp.getIndices().end());
call    0 never executed
        -:  500:  // For affine ops, we need to apply the map to get the operands to get the
        -:  501:  // "actual" indices.
    #####:  502:  if (auto affineStoreOp = dyn_cast<AffineStoreOp>(storeOp.getOperation())) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  503:    AffineMap affineMap = affineStoreOp.getAffineMap();
call    0 never executed
    #####:  504:    auto expandedIndices = calculateExpandedAccessIndices(
call    0 never executed
call    1 never executed
        -:  505:        affineMap, indices, storeOp.getLoc(), rewriter);
    #####:  506:    indices.assign(expandedIndices.begin(), expandedIndices.end());
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  507:  }
    #####:  508:  SmallVector<Value, 4> sourceIndices;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  509:  if (failed(resolveSourceIndicesCollapseShape(
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  510:          storeOp.getLoc(), rewriter, collapseShapeOp, indices, sourceIndices)))
    #####:  511:    return failure();
    #####:  512:  llvm::TypeSwitch<Operation *, void>(storeOp)
call    0 never executed
        -:  513:      .Case<AffineStoreOp, memref::StoreOp>([&](auto op) {
        -:  514:        rewriter.replaceOpWithNewOp<decltype(op)>(
        -:  515:            storeOp, storeOp.getValue(), collapseShapeOp.getViewSource(),
        -:  516:            sourceIndices);
        -:  517:      })
    #####:  518:      .Default([](Operation *) { llvm_unreachable("unexpected operation."); });
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  519:  return success();
branch  0 never executed
branch  1 never executed
        -:  520:}
------------------
_ZNK12_GLOBAL__N_130StoreOpOfCollapseShapeOpFolderIN4mlir6memref7StoreOpEE15matchAndRewriteES3_RNS1_15PatternRewriterE:
function _ZNK12_GLOBAL__N_130StoreOpOfCollapseShapeOpFolderIN4mlir6memref7StoreOpEE15matchAndRewriteES3_RNS1_15PatternRewriterE called 0 returned 0% blocks executed 0%
    #####:  490:LogicalResult StoreOpOfCollapseShapeOpFolder<OpTy>::matchAndRewrite(
call    0 never executed
        -:  491:    OpTy storeOp, PatternRewriter &rewriter) const {
    #####:  492:  auto collapseShapeOp = getMemRefOperand(storeOp)
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  493:                             .template getDefiningOp<memref::CollapseShapeOp>();
        -:  494:
    #####:  495:  if (!collapseShapeOp)
branch  0 never executed
branch  1 never executed
    #####:  496:    return failure();
        -:  497:
    #####:  498:  SmallVector<Value> indices(storeOp.getIndices().begin(),
call    0 never executed
call    1 never executed
    #####:  499:                             storeOp.getIndices().end());
call    0 never executed
        -:  500:  // For affine ops, we need to apply the map to get the operands to get the
        -:  501:  // "actual" indices.
    #####:  502:  if (auto affineStoreOp = dyn_cast<AffineStoreOp>(storeOp.getOperation())) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  503:    AffineMap affineMap = affineStoreOp.getAffineMap();
call    0 never executed
    #####:  504:    auto expandedIndices = calculateExpandedAccessIndices(
call    0 never executed
call    1 never executed
        -:  505:        affineMap, indices, storeOp.getLoc(), rewriter);
    #####:  506:    indices.assign(expandedIndices.begin(), expandedIndices.end());
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  507:  }
    #####:  508:  SmallVector<Value, 4> sourceIndices;
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  509:  if (failed(resolveSourceIndicesCollapseShape(
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  510:          storeOp.getLoc(), rewriter, collapseShapeOp, indices, sourceIndices)))
    #####:  511:    return failure();
    #####:  512:  llvm::TypeSwitch<Operation *, void>(storeOp)
call    0 never executed
        -:  513:      .Case<AffineStoreOp, memref::StoreOp>([&](auto op) {
        -:  514:        rewriter.replaceOpWithNewOp<decltype(op)>(
        -:  515:            storeOp, storeOp.getValue(), collapseShapeOp.getViewSource(),
        -:  516:            sourceIndices);
        -:  517:      })
    #####:  518:      .Default([](Operation *) { llvm_unreachable("unexpected operation."); });
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  519:  return success();
branch  0 never executed
branch  1 never executed
        -:  520:}
------------------
        -:  521:
function _ZN4mlir6memref33populateFoldMemRefAliasOpPatternsERNS_17RewritePatternSetE called 0 returned 0% blocks executed 0%
     856*:  522:void memref::populateFoldMemRefAliasOpPatterns(RewritePatternSet &patterns) {
     856*:  523:  patterns.add<LoadOpOfSubViewOpFolder<AffineLoadOp>,
        -:  524:               LoadOpOfSubViewOpFolder<memref::LoadOp>,
        -:  525:               LoadOpOfSubViewOpFolder<vector::TransferReadOp>,
        -:  526:               StoreOpOfSubViewOpFolder<AffineStoreOp>,
        -:  527:               StoreOpOfSubViewOpFolder<memref::StoreOp>,
        -:  528:               StoreOpOfSubViewOpFolder<vector::TransferWriteOp>,
        -:  529:               LoadOpOfExpandShapeOpFolder<AffineLoadOp>,
        -:  530:               LoadOpOfExpandShapeOpFolder<memref::LoadOp>,
        -:  531:               StoreOpOfExpandShapeOpFolder<AffineStoreOp>,
        -:  532:               StoreOpOfExpandShapeOpFolder<memref::StoreOp>,
        -:  533:               LoadOpOfCollapseShapeOpFolder<AffineLoadOp>,
        -:  534:               LoadOpOfCollapseShapeOpFolder<memref::LoadOp>,
        -:  535:               StoreOpOfCollapseShapeOpFolder<AffineStoreOp>,
        -:  536:               StoreOpOfCollapseShapeOpFolder<memref::StoreOp>>(
    #####:  537:      patterns.getContext());
call    0 never executed
    #####:  538:}
        -:  539:
        -:  540://===----------------------------------------------------------------------===//
        -:  541:// Pass registration
        -:  542://===----------------------------------------------------------------------===//
        -:  543:
        -:  544:namespace {
        -:  545:
  326589*:  546:struct FoldMemRefAliasOpsPass final
call    0 never executed
call    1 returned 100%
        -:  547:    : public memref::impl::FoldMemRefAliasOpsBase<FoldMemRefAliasOpsPass> {
        -:  548:  void runOnOperation() override;
        -:  549:};
        -:  550:
        -:  551:} // namespace
        -:  552:
function _ZN12_GLOBAL__N_122FoldMemRefAliasOpsPass14runOnOperationEv called 856 returned 100% blocks executed 92%
      856:  553:void FoldMemRefAliasOpsPass::runOnOperation() {
      856:  554:  RewritePatternSet patterns(&getContext());
call    0 returned 100%
call    1 returned 100%
      856:  555:  memref::populateFoldMemRefAliasOpPatterns(patterns);
call    0 returned 100%
      856:  556:  (void)applyPatternsAndFoldGreedily(getOperation()->getRegions(),
     1712:  557:                                     std::move(patterns));
call    0 returned 100%
branch  1 taken 0% (fallthrough)
branch  2 taken 100%
branch  3 taken 100% (fallthrough)
branch  4 taken 0%
call    5 returned 100%
call    6 returned 100%
call    7 returned 100%
      856:  558:}
        -:  559:
function _ZN4mlir6memref28createFoldMemRefAliasOpsPassEv called 326589 returned 100% blocks executed 100%
   326589:  560:std::unique_ptr<Pass> memref::createFoldMemRefAliasOpsPass() {
   326589:  561:  return std::make_unique<FoldMemRefAliasOpsPass>();
call    0 returned 100%
        -:  562:}
