        -:    0:Source:/data/xcy/llvm-project-fdbc55a5-1/mlir/lib/Dialect/GPU/Transforms/KernelOutlining.cpp
        -:    0:Graph:../tools/mlir/lib/Dialect/GPU/CMakeFiles/obj.MLIRGPUTransforms.dir/Transforms/KernelOutlining.cpp.gcno
        -:    0:Data:../tools/mlir/lib/Dialect/GPU/CMakeFiles/obj.MLIRGPUTransforms.dir/Transforms/KernelOutlining.cpp.gcda
        -:    0:Runs:325546
        -:    1://===- KernelOutlining.cpp - Implementation of GPU kernel outlining -------===//
        -:    2://
        -:    3:// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
        -:    4:// See https://llvm.org/LICENSE.txt for license information.
        -:    5:// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
        -:    6://
        -:    7://===----------------------------------------------------------------------===//
        -:    8://
        -:    9:// This file implements the GPU dialect kernel outlining pass.
        -:   10://
        -:   11://===----------------------------------------------------------------------===//
        -:   12:
        -:   13:#include "mlir/Dialect/GPU/Transforms/Passes.h"
        -:   14:
        -:   15:#include "mlir/AsmParser/AsmParser.h"
        -:   16:#include "mlir/Dialect/Arith/IR/Arith.h"
        -:   17:#include "mlir/Dialect/ControlFlow/IR/ControlFlowOps.h"
        -:   18:#include "mlir/Dialect/DLTI/DLTI.h"
        -:   19:#include "mlir/Dialect/Func/IR/FuncOps.h"
        -:   20:#include "mlir/Dialect/GPU/IR/GPUDialect.h"
        -:   21:#include "mlir/Dialect/GPU/Transforms/Utils.h"
        -:   22:#include "mlir/Dialect/MemRef/IR/MemRef.h"
        -:   23:#include "mlir/IR/BlockAndValueMapping.h"
        -:   24:#include "mlir/IR/Builders.h"
        -:   25:#include "mlir/IR/Matchers.h"
        -:   26:#include "mlir/IR/SymbolTable.h"
        -:   27:#include "mlir/Support/LLVM.h"
        -:   28:#include "mlir/Transforms/RegionUtils.h"
        -:   29:
        -:   30:namespace mlir {
        -:   31:#define GEN_PASS_DEF_GPULAUNCHSINKINDEXCOMPUTATIONS
        -:   32:#define GEN_PASS_DEF_GPUKERNELOUTLINING
        -:   33:#include "mlir/Dialect/GPU/Transforms/Passes.h.inc"
        -:   34:} // namespace mlir
        -:   35:
        -:   36:using namespace mlir;
        -:   37:
        -:   38:template <typename OpTy>
    #####:   39:static void createForAllDimensions(OpBuilder &builder, Location loc,
        -:   40:                                   SmallVectorImpl<Value> &values) {
    #####:   41:  for (auto dim : {gpu::Dimension::x, gpu::Dimension::y, gpu::Dimension::z})
    #####:   42:    values.push_back(builder.create<OpTy>(loc, builder.getIndexType(), dim));
    #####:   43:}
------------------
_Z22createForAllDimensionsIN4mlir3gpu10BlockDimOpEEvRNS0_9OpBuilderENS0_8LocationERN4llvm15SmallVectorImplINS0_5ValueEEE:
function _Z22createForAllDimensionsIN4mlir3gpu10BlockDimOpEEvRNS0_9OpBuilderENS0_8LocationERN4llvm15SmallVectorImplINS0_5ValueEEE called 0 returned 0% blocks executed 0%
    #####:   39:static void createForAllDimensions(OpBuilder &builder, Location loc,
        -:   40:                                   SmallVectorImpl<Value> &values) {
    #####:   41:  for (auto dim : {gpu::Dimension::x, gpu::Dimension::y, gpu::Dimension::z})
branch  0 never executed
branch  1 never executed
    #####:   42:    values.push_back(builder.create<OpTy>(loc, builder.getIndexType(), dim));
call    0 never executed
call    1 never executed
call    2 never executed
    #####:   43:}
------------------
_Z22createForAllDimensionsIN4mlir3gpu9GridDimOpEEvRNS0_9OpBuilderENS0_8LocationERN4llvm15SmallVectorImplINS0_5ValueEEE:
function _Z22createForAllDimensionsIN4mlir3gpu9GridDimOpEEvRNS0_9OpBuilderENS0_8LocationERN4llvm15SmallVectorImplINS0_5ValueEEE called 0 returned 0% blocks executed 0%
    #####:   39:static void createForAllDimensions(OpBuilder &builder, Location loc,
        -:   40:                                   SmallVectorImpl<Value> &values) {
    #####:   41:  for (auto dim : {gpu::Dimension::x, gpu::Dimension::y, gpu::Dimension::z})
branch  0 never executed
branch  1 never executed
    #####:   42:    values.push_back(builder.create<OpTy>(loc, builder.getIndexType(), dim));
call    0 never executed
call    1 never executed
call    2 never executed
    #####:   43:}
------------------
_Z22createForAllDimensionsIN4mlir3gpu10ThreadIdOpEEvRNS0_9OpBuilderENS0_8LocationERN4llvm15SmallVectorImplINS0_5ValueEEE:
function _Z22createForAllDimensionsIN4mlir3gpu10ThreadIdOpEEvRNS0_9OpBuilderENS0_8LocationERN4llvm15SmallVectorImplINS0_5ValueEEE called 0 returned 0% blocks executed 0%
    #####:   39:static void createForAllDimensions(OpBuilder &builder, Location loc,
        -:   40:                                   SmallVectorImpl<Value> &values) {
    #####:   41:  for (auto dim : {gpu::Dimension::x, gpu::Dimension::y, gpu::Dimension::z})
branch  0 never executed
branch  1 never executed
    #####:   42:    values.push_back(builder.create<OpTy>(loc, builder.getIndexType(), dim));
call    0 never executed
call    1 never executed
call    2 never executed
    #####:   43:}
------------------
_Z22createForAllDimensionsIN4mlir3gpu9BlockIdOpEEvRNS0_9OpBuilderENS0_8LocationERN4llvm15SmallVectorImplINS0_5ValueEEE:
function _Z22createForAllDimensionsIN4mlir3gpu9BlockIdOpEEvRNS0_9OpBuilderENS0_8LocationERN4llvm15SmallVectorImplINS0_5ValueEEE called 0 returned 0% blocks executed 0%
    #####:   39:static void createForAllDimensions(OpBuilder &builder, Location loc,
        -:   40:                                   SmallVectorImpl<Value> &values) {
    #####:   41:  for (auto dim : {gpu::Dimension::x, gpu::Dimension::y, gpu::Dimension::z})
branch  0 never executed
branch  1 never executed
    #####:   42:    values.push_back(builder.create<OpTy>(loc, builder.getIndexType(), dim));
call    0 never executed
call    1 never executed
call    2 never executed
    #####:   43:}
------------------
        -:   44:
        -:   45:/// Adds operations generating block/thread ids and grid/block dimensions at the
        -:   46:/// beginning of the `launchFuncOpBody` region. Add mapping from argument in
        -:   47:/// entry block of `launchOpBody`, to the corresponding result value of the
        -:   48:/// added operations.
function _ZL24injectGpuIndexOperationsN4mlir8LocationERNS_6RegionES2_RNS_20BlockAndValueMappingE called 0 returned 0% blocks executed 0%
    #####:   49:static void injectGpuIndexOperations(Location loc, Region &launchFuncOpBody,
        -:   50:                                     Region &launchOpBody,
        -:   51:                                     BlockAndValueMapping &map) {
    #####:   52:  OpBuilder builder(loc->getContext());
call    0 never executed
call    1 never executed
    #####:   53:  Block &firstBlock = launchOpBody.front();
call    0 never executed
    #####:   54:  builder.setInsertionPointToStart(&launchFuncOpBody.front());
call    0 never executed
call    1 never executed
    #####:   55:  SmallVector<Value, 12> indexOps;
call    0 never executed
    #####:   56:  createForAllDimensions<gpu::BlockIdOp>(builder, loc, indexOps);
call    0 never executed
    #####:   57:  createForAllDimensions<gpu::ThreadIdOp>(builder, loc, indexOps);
call    0 never executed
    #####:   58:  createForAllDimensions<gpu::GridDimOp>(builder, loc, indexOps);
call    0 never executed
    #####:   59:  createForAllDimensions<gpu::BlockDimOp>(builder, loc, indexOps);
call    0 never executed
        -:   60:  // Replace the leading 12 function args with the respective thread/block index
        -:   61:  // operations. Iterate backwards since args are erased and indices change.
    #####:   62:  for (const auto &indexOp : enumerate(indexOps))
branch  0 never executed
branch  1 never executed
    #####:   63:    map.map(firstBlock.getArgument(indexOp.index()), indexOp.value());
call    0 never executed
call    1 never executed
    #####:   64:}
        -:   65:
        -:   66:/// Identifies operations that are beneficial to sink into kernels. These
        -:   67:/// operations may not have side-effects, as otherwise sinking (and hence
        -:   68:/// duplicating them) is not legal.
function _ZL26isLikelyAnIndexComputationPN4mlir9OperationE called 0 returned 0% blocks executed 0%
    #####:   69:static bool isLikelyAnIndexComputation(Operation *op) {
    #####:   70:  return matchPattern(op, m_Constant()) ||
call    0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
    #####:   71:         isa<memref::DimOp, arith::SelectOp, arith::CmpIOp>(op);
call    0 never executed
        -:   72:}
        -:   73:
        -:   74:/// For a given operation `op`, computes whether it is beneficial to sink the
        -:   75:/// operation into the kernel. An operation can be sunk if doing so does not
        -:   76:/// introduce new kernel arguments. Whether a value is already available in the
        -:   77:/// kernel (and hence does not introduce new arguments) is checked by
        -:   78:/// querying `existingDependencies` and `availableValues`.
        -:   79:/// If an operand is not yet available, we recursively check whether it can be
        -:   80:/// made available by siking its defining op.
        -:   81:/// Operations that are indentified for sinking are added to `beneficiaryOps` in
        -:   82:/// the order they should appear in the kernel. Furthermore, `availableValues`
        -:   83:/// is updated with results that will be available after sinking the identified
        -:   84:/// ops.
function _ZL21extractBeneficiaryOpsPN4mlir9OperationERKN4llvm9SetVectorINS_5ValueESt6vectorIS4_SaIS4_EENS2_8DenseSetIS4_NS2_12DenseMapInfoIS4_vEEEEEERNS3_IS1_S5_IS1_SaIS1_EENS8_IS1_NS9_IS1_vEEEEEERNS2_15SmallPtrSetImplIS4_EENS2_12function_refIFbS1_EEE called 0 returned 0% blocks executed 0%
    #####:   85:static bool extractBeneficiaryOps(
        -:   86:    Operation *op, const SetVector<Value> &existingDependencies,
        -:   87:    SetVector<Operation *> &beneficiaryOps,
        -:   88:    llvm::SmallPtrSetImpl<Value> &availableValues,
        -:   89:    llvm::function_ref<bool(Operation *)> isSinkingBeneficiary) {
    #####:   90:  if (beneficiaryOps.count(op))
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:   91:    return true;
        -:   92:
    #####:   93:  if (!isSinkingBeneficiary(op))
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:   94:    return false;
        -:   95:
    #####:   96:  for (Value operand : op->getOperands()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
call    3 never executed
        -:   97:    // It is already visible in the kernel, keep going.
    #####:   98:    if (availableValues.count(operand))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:   99:      continue;
        -:  100:    // Else check whether it can be made available via sinking or already is a
        -:  101:    // dependency.
    #####:  102:    Operation *definingOp = operand.getDefiningOp();
call    0 never executed
    #####:  103:    if ((!definingOp || !extractBeneficiaryOps(definingOp, existingDependencies,
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  104:                                               beneficiaryOps, availableValues,
    #####:  105:                                               isSinkingBeneficiary)) &&
branch  0 never executed
branch  1 never executed
    #####:  106:        !existingDependencies.count(operand))
branch  0 never executed
branch  1 never executed
    #####:  107:      return false;
        -:  108:  }
        -:  109:  // We will sink the operation, mark its results as now available.
    #####:  110:  beneficiaryOps.insert(op);
call    0 never executed
    #####:  111:  for (Value result : op->getResults())
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
call    4 never executed
    #####:  112:    availableValues.insert(result);
call    0 never executed
    #####:  113:  return true;
        -:  114:}
        -:  115:
function _ZN4mlir26sinkOperationsIntoLaunchOpENS_3gpu8LaunchOpEN4llvm12function_refIFbPNS_9OperationEEEE called 0 returned 0% blocks executed 0%
    #####:  116:LogicalResult mlir::sinkOperationsIntoLaunchOp(
        -:  117:    gpu::LaunchOp launchOp,
        -:  118:    llvm::function_ref<bool(Operation *)> isSinkingBeneficiary) {
    #####:  119:  assert(isSinkingBeneficiary);
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  120:  Region &launchOpBody = launchOp.getBody();
call    0 never executed
        -:  121:
        -:  122:  // Identify uses from values defined outside of the scope of the launch
        -:  123:  // operation.
    #####:  124:  SetVector<Value> sinkCandidates;
call    0 never executed
call    1 never executed
    #####:  125:  getUsedValuesDefinedAbove(launchOpBody, sinkCandidates);
call    0 never executed
        -:  126:
    #####:  127:  SetVector<Operation *> toBeSunk;
call    0 never executed
    #####:  128:  llvm::SmallPtrSet<Value, 4> availableValues;
call    0 never executed
call    1 never executed
    #####:  129:  for (Value operand : sinkCandidates) {
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  130:    Operation *operandOp = operand.getDefiningOp();
call    0 never executed
    #####:  131:    if (!operandOp)
branch  0 never executed
branch  1 never executed
    #####:  132:      continue;
    #####:  133:    extractBeneficiaryOps(operandOp, sinkCandidates, toBeSunk, availableValues,
call    0 never executed
        -:  134:                          isSinkingBeneficiary);
        -:  135:  }
        -:  136:
        -:  137:  // Insert operations so that the defs get cloned before uses.
    #####:  138:  BlockAndValueMapping map;
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:  139:  OpBuilder builder(launchOpBody);
call    0 never executed
    #####:  140:  for (Operation *op : toBeSunk) {
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  141:    Operation *clonedOp = builder.clone(*op, map);
call    0 never executed
        -:  142:    // Only replace uses within the launch op.
    #####:  143:    for (auto pair : llvm::zip(op->getResults(), clonedOp->getResults()))
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
    #####:  144:      replaceAllUsesInRegionWith(std::get<0>(pair), std::get<1>(pair),
call    0 never executed
call    1 never executed
        -:  145:                                 launchOp.getBody());
        -:  146:  }
    #####:  147:  return success();
call    0 never executed
        -:  148:}
        -:  149:
        -:  150:/// Outline the `gpu.launch` operation body into a kernel function. Replace
        -:  151:/// `gpu.terminator` operations by `gpu.return` in the generated function.
function _ZL21outlineKernelFuncImplN4mlir3gpu8LaunchOpEN4llvm9StringRefERNS2_9SetVectorINS_5ValueESt6vectorIS5_SaIS5_EENS2_8DenseSetIS5_NS2_12DenseMapInfoIS5_vEEEEEE called 0 returned 0% blocks executed 0%
    #####:  152:static gpu::GPUFuncOp outlineKernelFuncImpl(gpu::LaunchOp launchOp,
        -:  153:                                            StringRef kernelFnName,
        -:  154:                                            SetVector<Value> &operands) {
    #####:  155:  Location loc = launchOp.getLoc();
call    0 never executed
        -:  156:  // Create a builder with no insertion point, insertion will happen separately
        -:  157:  // due to symbol table manipulation.
    #####:  158:  OpBuilder builder(launchOp.getContext());
call    0 never executed
call    1 never executed
    #####:  159:  Region &launchOpBody = launchOp.getBody();
call    0 never executed
        -:  160:
        -:  161:  // Identify uses from values defined outside of the scope of the launch
        -:  162:  // operation.
    #####:  163:  getUsedValuesDefinedAbove(launchOpBody, operands);
call    0 never executed
        -:  164:
        -:  165:  // Create the gpu.func operation.
    #####:  166:  SmallVector<Type, 4> kernelOperandTypes;
branch  0 never executed
branch  1 never executed
    #####:  167:  kernelOperandTypes.reserve(operands.size());
branch  0 never executed
branch  1 never executed
    #####:  168:  for (Value operand : operands) {
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  169:    kernelOperandTypes.push_back(operand.getType());
call    0 never executed
        -:  170:  }
    #####:  171:  FunctionType type =
call    0 never executed
    #####:  172:      FunctionType::get(launchOp.getContext(), kernelOperandTypes, {});
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:  173:  auto outlinedFunc = builder.create<gpu::GPUFuncOp>(loc, kernelFnName, type);
call    0 never executed
    #####:  174:  outlinedFunc->setAttr(gpu::GPUDialect::getKernelFuncAttrName(),
call    0 never executed
call    1 never executed
    #####:  175:                        builder.getUnitAttr());
call    0 never executed
    #####:  176:  BlockAndValueMapping map;
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  177:
        -:  178:  // Map the arguments corresponding to the launch parameters like blockIdx,
        -:  179:  // threadIdx, etc.
    #####:  180:  Region &outlinedFuncBody = outlinedFunc.getBody();
call    0 never executed
    #####:  181:  injectGpuIndexOperations(loc, outlinedFuncBody, launchOpBody, map);
call    0 never executed
        -:  182:
        -:  183:  // Map arguments from gpu.launch region to the arguments of the gpu.func
        -:  184:  // operation.
    #####:  185:  Block &entryBlock = outlinedFuncBody.front();
call    0 never executed
    #####:  186:  for (const auto &operand : enumerate(operands))
branch  0 never executed
branch  1 never executed
    #####:  187:    map.map(operand.value(), entryBlock.getArgument(operand.index()));
call    0 never executed
call    1 never executed
        -:  188:
        -:  189:  // Clone the region of the gpu.launch operation into the gpu.func operation.
        -:  190:  // TODO: If cloneInto can be modified such that if a mapping for
        -:  191:  // a block exists, that block will be used to clone operations into (at the
        -:  192:  // end of the block), instead of creating a new block, this would be much
        -:  193:  // cleaner.
    #####:  194:  launchOpBody.cloneInto(&outlinedFuncBody, map);
call    0 never executed
        -:  195:
        -:  196:  // Branch from entry of the gpu.func operation to the block that is cloned
        -:  197:  // from the entry block of the gpu.launch operation.
    #####:  198:  Block &launchOpEntry = launchOpBody.front();
call    0 never executed
    #####:  199:  Block *clonedLaunchOpEntry = map.lookup(&launchOpEntry);
call    0 never executed
    #####:  200:  builder.setInsertionPointToEnd(&entryBlock);
call    0 never executed
    #####:  201:  builder.create<cf::BranchOp>(loc, clonedLaunchOpEntry);
call    0 never executed
        -:  202:
function _ZZL21outlineKernelFuncImplN4mlir3gpu8LaunchOpEN4llvm9StringRefERNS2_9SetVectorINS_5ValueESt6vectorIS5_SaIS5_EENS2_8DenseSetIS5_NS2_12DenseMapInfoIS5_vEEEEEEENKUlNS0_12TerminatorOpEE_clESF_.isra.0 called 0 returned 0% blocks executed 0%
    #####:  203:  outlinedFunc.walk([](gpu::TerminatorOp op) {
call    0 never executed
    #####:  204:    OpBuilder replacer(op);
call    0 never executed
    #####:  205:    replacer.create<gpu::ReturnOp>(op.getLoc());
call    0 never executed
    #####:  206:    op.erase();
call    0 never executed
    #####:  207:  });
    #####:  208:  return outlinedFunc;
call    0 never executed
        -:  209:}
        -:  210:
function _ZN4mlir17outlineKernelFuncENS_3gpu8LaunchOpEN4llvm9StringRefERNS2_15SmallVectorImplINS_5ValueEEE called 0 returned 0% blocks executed 0%
    #####:  211:gpu::GPUFuncOp mlir::outlineKernelFunc(gpu::LaunchOp launchOp,
        -:  212:                                       StringRef kernelFnName,
        -:  213:                                       llvm::SmallVectorImpl<Value> &operands) {
    #####:  214:  DenseSet<Value> inputOperandSet;
call    0 never executed
    #####:  215:  inputOperandSet.insert(operands.begin(), operands.end());
    #####:  216:  SetVector<Value> operandSet(operands.begin(), operands.end());
call    0 never executed
call    1 never executed
    #####:  217:  auto funcOp = outlineKernelFuncImpl(launchOp, kernelFnName, operandSet);
call    0 never executed
    #####:  218:  for (auto operand : operandSet) {
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  219:    if (!inputOperandSet.count(operand))
call    0 never executed
    #####:  220:      operands.push_back(operand);
call    0 never executed
        -:  221:  }
    #####:  222:  return funcOp;
call    0 never executed
        -:  223:}
        -:  224:
        -:  225:/// Replace `gpu.launch` operations with an `gpu.launch_func` operation
        -:  226:/// launching `kernelFunc`. The kernel func contains the body of the
        -:  227:/// `gpu.launch` with constant region arguments inlined.
function _ZL21convertToLaunchFuncOpN4mlir3gpu8LaunchOpENS0_9GPUFuncOpENS_10ValueRangeE called 0 returned 0% blocks executed 0%
    #####:  228:static void convertToLaunchFuncOp(gpu::LaunchOp launchOp,
        -:  229:                                  gpu::GPUFuncOp kernelFunc,
        -:  230:                                  ValueRange operands) {
    #####:  231:  OpBuilder builder(launchOp);
call    0 never executed
        -:  232:  // The launch op has an optional dynamic shared memory size. If it doesn't
        -:  233:  // exist, we use zero.
    #####:  234:  Value asyncToken = launchOp.getAsyncToken();
call    0 never executed
    #####:  235:  auto launchFunc = builder.create<gpu::LaunchFuncOp>(
    #####:  236:      launchOp.getLoc(), kernelFunc, launchOp.getGridSizeOperandValues(),
call    0 never executed
    #####:  237:      launchOp.getBlockSizeOperandValues(),
call    0 never executed
    #####:  238:      launchOp.getDynamicSharedMemorySize(), operands,
    #####:  239:      asyncToken ? asyncToken.getType() : nullptr,
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  240:      launchOp.getAsyncDependencies());
call    0 never executed
call    1 never executed
    #####:  241:  launchOp.replaceAllUsesWith(launchFunc);
branch  0 never executed
branch  1 never executed
    #####:  242:  launchOp.erase();
call    0 never executed
    #####:  243:}
        -:  244:
        -:  245:namespace {
        -:  246:/// Pass that moves ops which are likely an index computation into gpu.launch
        -:  247:/// body.
  326594*:  248:class GpuLaunchSinkIndexComputationsPass
call    0 never executed
call    1 returned 100%
        -:  249:    : public impl::GpuLaunchSinkIndexComputationsBase<
        -:  250:          GpuLaunchSinkIndexComputationsPass> {
        -:  251:public:
function _ZN12_GLOBAL__N_134GpuLaunchSinkIndexComputationsPass14runOnOperationEv called 851 returned 100% blocks executed 67%
      851:  252:  void runOnOperation() override {
      851:  253:    Operation *op = getOperation();
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
function _ZZN12_GLOBAL__N_134GpuLaunchSinkIndexComputationsPass14runOnOperationEvENKUlN4mlir3gpu8LaunchOpEE_clES3_.isra.0 called 0 returned 0% blocks executed 0%
     851*:  254:    if (op->walk([](gpu::LaunchOp launch) {
call    0 returned 100%
branch  1 taken 0% (fallthrough)
branch  2 taken 100%
        -:  255:            // Pull in instructions that can be sunk
    #####:  256:            if (failed(sinkOperationsIntoLaunchOp(launch,
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  257:                                                  isLikelyAnIndexComputation)))
    #####:  258:              return WalkResult::interrupt();
        -:  259:
    #####:  260:            return WalkResult::advance();
      851:  261:          }).wasInterrupted())
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
    #####:  262:      signalPassFailure();
call    0 never executed
      851:  263:  }
        -:  264:};
        -:  265:
        -:  266:/// Pass that moves the kernel of each LaunchOp into its separate nested module.
        -:  267:///
        -:  268:/// This pass moves the kernel code of each LaunchOp into a function created
        -:  269:/// inside a nested module. It also creates an external function of the same
        -:  270:/// name in the parent module.
        -:  271:///
        -:  272:/// The gpu.modules are intended to be compiled to a cubin blob independently in
        -:  273:/// a separate pass. The external functions can then be annotated with the
        -:  274:/// symbol of the cubin accessor function.
        -:  275:class GpuKernelOutliningPass
        -:  276:    : public impl::GpuKernelOutliningBase<GpuKernelOutliningPass> {
        -:  277:public:
function _ZN12_GLOBAL__N_122GpuKernelOutliningPassC2EN4llvm9StringRefE called 326626 returned 100% blocks executed 36%
   326626:  278:  GpuKernelOutliningPass(StringRef dlStr) {
call    0 returned 100%
call    1 returned 100%
call    2 returned 100%
  326626*:  279:    if (!dlStr.empty() && !dataLayoutStr.hasValue())
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
branch  2 never executed
branch  3 never executed
    #####:  280:      dataLayoutStr = dlStr.str();
branch  0 never executed
branch  1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
   326626:  281:  }
        -:  282:
function _ZN12_GLOBAL__N_122GpuKernelOutliningPassC2ERKS0_ called 0 returned 0% blocks executed 0%
    #####:  283:  GpuKernelOutliningPass(const GpuKernelOutliningPass &other)
    #####:  284:      : GpuKernelOutliningBase(other), dataLayoutSpec(other.dataLayoutSpec) {
call    0 never executed
call    1 never executed
    #####:  285:    dataLayoutStr = other.dataLayoutStr.getValue();
call    0 never executed
    #####:  286:  }
        -:  287:
function _ZN12_GLOBAL__N_122GpuKernelOutliningPass10initializeEPN4mlir11MLIRContextE called 968 returned 100% blocks executed 27%
      968:  288:  LogicalResult initialize(MLIRContext *context) override {
        -:  289:    // Initialize the data layout specification from the data layout string.
      968:  290:    if (!dataLayoutStr.empty()) {
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
    #####:  291:      Attribute resultAttr = mlir::parseAttribute(dataLayoutStr, context);
call    0 never executed
    #####:  292:      if (!resultAttr)
branch  0 never executed
branch  1 never executed
    #####:  293:        return failure();
        -:  294:
    #####:  295:      dataLayoutSpec = resultAttr.dyn_cast<DataLayoutSpecInterface>();
call    0 never executed
    #####:  296:      if (!dataLayoutSpec)
branch  0 never executed
branch  1 never executed
    #####:  297:        return failure();
        -:  298:    }
        -:  299:
      968:  300:    return success();
        -:  301:  }
        -:  302:
function _ZN12_GLOBAL__N_122GpuKernelOutliningPass14runOnOperationEv called 900 returned 100% blocks executed 70%
      900:  303:  void runOnOperation() override {
     1800:  304:    SymbolTable symbolTable(getOperation());
call    0 returned 100%
call    1 returned 100%
      900:  305:    bool modified = false;
     2964:  306:    for (auto func : getOperation().getOps<func::FuncOp>()) {
call    0 returned 100%
call    1 returned 100%
branch  2 taken 53% (fallthrough)
branch  3 taken 47%
call    4 returned 100%
call    5 returned 100%
        -:  307:      // Insert just after the function.
     1165:  308:      Block::iterator insertPt(func->getNextNode());
branch  0 taken 13% (fallthrough)
branch  1 taken 87%
call    2 returned 100%
function _ZZN12_GLOBAL__N_122GpuKernelOutliningPass14runOnOperationEvENKUlN4mlir3gpu8LaunchOpEE_clES3_ called 0 returned 0% blocks executed 0%
    1032*:  309:      auto funcWalkResult = func.walk([&](gpu::LaunchOp op) {
    #####:  310:        SetVector<Value> operands;
call    0 never executed
    #####:  311:        std::string kernelFnName =
    #####:  312:            Twine(op->getParentOfType<func::FuncOp>().getName(), "_kernel")
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  313:                .str();
call    0 never executed
call    1 never executed
        -:  314:
    #####:  315:        gpu::GPUFuncOp outlinedFunc =
call    0 never executed
    #####:  316:            outlineKernelFuncImpl(op, kernelFnName, operands);
call    0 never executed
        -:  317:
        -:  318:        // Create nested module and insert outlinedFunc. The module will
        -:  319:        // originally get the same name as the function, but may be renamed on
        -:  320:        // insertion into the parent module.
    #####:  321:        auto kernelModule = createKernelModule(outlinedFunc, symbolTable);
call    0 never executed
    #####:  322:        symbolTable.insert(kernelModule, insertPt);
call    0 never executed
        -:  323:
        -:  324:        // Potentially changes signature, pulling in constants.
    #####:  325:        convertToLaunchFuncOp(op, outlinedFunc, operands.getArrayRef());
call    0 never executed
call    1 never executed
    #####:  326:        modified = true;
    #####:  327:        return WalkResult::advance();
branch  0 never executed
branch  1 never executed
     1032:  328:      });
call    0 returned 100%
     1032:  329:      if (funcWalkResult.wasInterrupted())
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
    #####:  330:        return signalPassFailure();
call    0 never executed
call    1 never executed
        -:  331:    }
        -:  332:
        -:  333:    // If any new module was inserted in this module, annotate this module as
        -:  334:    // a container module.
      900:  335:    if (modified)
branch  0 taken 0% (fallthrough)
branch  1 taken 100%
    #####:  336:      getOperation()->setAttr(gpu::GPUDialect::getContainerModuleAttrName(),
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  337:                              UnitAttr::get(&getContext()));
call    0 never executed
call    1 never executed
        -:  338:  }
        -:  339:
        -:  340:private:
        -:  341:  /// Returns a gpu.module containing kernelFunc and all callees (recursive).
function _ZN12_GLOBAL__N_122GpuKernelOutliningPass18createKernelModuleEN4mlir3gpu9GPUFuncOpERKNS1_11SymbolTableE called 0 returned 0% blocks executed 0%
    #####:  342:  gpu::GPUModuleOp createKernelModule(gpu::GPUFuncOp kernelFunc,
        -:  343:                                      const SymbolTable &parentSymbolTable) {
        -:  344:    // TODO: This code cannot use an OpBuilder because it must be inserted into
        -:  345:    // a SymbolTable by the caller. SymbolTable needs to be refactored to
        -:  346:    // prevent manual building of Ops with symbols in code using SymbolTables
        -:  347:    // and then this needs to use the OpBuilder.
    #####:  348:    auto *context = getOperation().getContext();
call    0 never executed
call    1 never executed
    #####:  349:    OpBuilder builder(context);
call    0 never executed
    #####:  350:    auto kernelModule = builder.create<gpu::GPUModuleOp>(kernelFunc.getLoc(),
    #####:  351:                                                         kernelFunc.getName());
call    0 never executed
call    1 never executed
        -:  352:
        -:  353:    // If a valid data layout spec was provided, attach it to the kernel module.
        -:  354:    // Otherwise, the default data layout will be used.
    #####:  355:    if (dataLayoutSpec)
branch  0 never executed
branch  1 never executed
    #####:  356:      kernelModule->setAttr(DLTIDialect::kDataLayoutAttrName, dataLayoutSpec);
call    0 never executed
        -:  357:
    #####:  358:    SymbolTable symbolTable(kernelModule);
call    0 never executed
    #####:  359:    symbolTable.insert(kernelFunc);
call    0 never executed
        -:  360:
    #####:  361:    SmallVector<Operation *, 8> symbolDefWorklist = {kernelFunc};
call    0 never executed
call    1 never executed
    #####:  362:    while (!symbolDefWorklist.empty()) {
branch  0 never executed
branch  1 never executed
    #####:  363:      if (Optional<SymbolTable::UseRange> symbolUses =
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  364:              SymbolTable::getSymbolUses(symbolDefWorklist.pop_back_val())) {
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  365:        for (SymbolTable::SymbolUse symbolUse : *symbolUses) {
branch  0 never executed
branch  1 never executed
call    2 never executed
    #####:  366:          StringRef symbolName =
    #####:  367:              symbolUse.getSymbolRef().cast<FlatSymbolRefAttr>().getValue();
call    0 never executed
call    1 never executed
    #####:  368:          if (symbolTable.lookup(symbolName))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  369:            continue;
        -:  370:
    #####:  371:          Operation *symbolDefClone =
    #####:  372:              parentSymbolTable.lookup(symbolName)->clone();
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  373:          symbolDefWorklist.push_back(symbolDefClone);
call    0 never executed
    #####:  374:          symbolTable.insert(symbolDefClone);
call    0 never executed
        -:  375:        }
        -:  376:      }
        -:  377:    }
        -:  378:
    #####:  379:    return kernelModule;
branch  0 never executed
branch  1 never executed
        -:  380:  }
        -:  381:
        -:  382:  Option<std::string> dataLayoutStr{
        -:  383:      *this, "data-layout-str",
        -:  384:      llvm::cl::desc("String containing the data layout specification to be "
        -:  385:                     "attached to the GPU kernel module")};
        -:  386:
        -:  387:  DataLayoutSpecInterface dataLayoutSpec;
        -:  388:};
        -:  389:
        -:  390:} // namespace
        -:  391:
function _ZN4mlir39createGpuLauchSinkIndexComputationsPassEv called 326594 returned 100% blocks executed 100%
   326594:  392:std::unique_ptr<Pass> mlir::createGpuLauchSinkIndexComputationsPass() {
   326594:  393:  return std::make_unique<GpuLaunchSinkIndexComputationsPass>();
call    0 returned 100%
        -:  394:}
        -:  395:
        -:  396:std::unique_ptr<OperationPass<ModuleOp>>
function _ZN4mlir28createGpuKernelOutliningPassEN4llvm9StringRefE called 326626 returned 100% blocks executed 100%
   326626:  397:mlir::createGpuKernelOutliningPass(StringRef dataLayoutStr) {
   326626:  398:  return std::make_unique<GpuKernelOutliningPass>(dataLayoutStr);
call    0 returned 100%
        -:  399:}
