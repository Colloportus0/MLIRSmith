        -:    0:Source:/data/xcy/llvm-project-fdbc55a5-1/mlir/lib/Dialect/NVGPU/IR/NVGPUDialect.cpp
        -:    0:Graph:../tools/mlir/lib/Dialect/NVGPU/IR/CMakeFiles/obj.MLIRNVGPUDialect.dir/NVGPUDialect.cpp.gcno
        -:    0:Data:../tools/mlir/lib/Dialect/NVGPU/IR/CMakeFiles/obj.MLIRNVGPUDialect.dir/NVGPUDialect.cpp.gcda
        -:    0:Runs:325549
        -:    1://===- NVGPUDialect.cpp - MLIR NVGPU ops implementation -------------------===//
        -:    2://
        -:    3:// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
        -:    4:// See https://llvm.org/LICENSE.txt for license information.
        -:    5:// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
        -:    6://
        -:    7://===----------------------------------------------------------------------===//
        -:    8://
        -:    9:// This file implements the NVGPU dialect and its operations.
        -:   10://
        -:   11://===----------------------------------------------------------------------===//
        -:   12:
        -:   13:#include "mlir/Dialect/NVGPU/IR/NVGPUDialect.h"
        -:   14:#include "mlir/Dialect/GPU/IR/GPUDialect.h"
        -:   15:#include "mlir/IR/Builders.h"
        -:   16:#include "mlir/IR/DialectImplementation.h"
        -:   17:#include "mlir/IR/OpImplementation.h"
        -:   18:#include "mlir/IR/TypeUtilities.h"
        -:   19:#include "llvm/ADT/TypeSwitch.h"
        -:   20:
        -:   21:using namespace mlir;
        -:   22:using namespace mlir::nvgpu;
        -:   23:
function _ZN4mlir5nvgpu12NVGPUDialect10initializeEv called 0 returned 0% blocks executed 0%
    1035*:   24:void nvgpu::NVGPUDialect::initialize() {
    1035*:   25:  addTypes<
        -:   26:#define GET_TYPEDEF_LIST
        -:   27:#include "mlir/Dialect/NVGPU/IR/NVGPUTypes.cpp.inc"
    1035*:   28:      >();
call    0 returned 100%
call    1 never executed
    1035*:   29:  addOperations<
        -:   30:#define GET_OP_LIST
        -:   31:#include "mlir/Dialect/NVGPU/IR/NVGPU.cpp.inc"
    1035*:   32:      >();
call    0 returned 100%
call    1 never executed
    #####:   33:}
        -:   34:
        -:   35://===----------------------------------------------------------------------===//
        -:   36:// NVGPU_DeviceAsyncCopyOp
        -:   37://===----------------------------------------------------------------------===//
        -:   38:
        -:   39:/// Return true if the last dimension of the MemRefType has unit stride. Also
        -:   40:/// return true for memrefs with no strides.
function _ZL25isLastMemrefDimUnitStrideN4mlir10MemRefTypeE called 0 returned 0% blocks executed 0%
    #####:   41:static bool isLastMemrefDimUnitStride(MemRefType type) {
    #####:   42:  int64_t offset;
    #####:   43:  SmallVector<int64_t> strides;
call    0 never executed
    #####:   44:  if (failed(getStridesAndOffset(type, strides, offset))) {
call    0 never executed
        -:   45:    return false;
        -:   46:  }
    #####:   47:  return strides.back() == 1;
call    0 never executed
        -:   48:}
        -:   49:
function _ZN4mlir5nvgpu17DeviceAsyncCopyOp6verifyEv called 0 returned 0% blocks executed 0%
    #####:   50:LogicalResult DeviceAsyncCopyOp::verify() {
    #####:   51:  auto srcMemref = getSrc().getType().cast<MemRefType>();
call    0 never executed
call    1 never executed
call    2 never executed
    #####:   52:  auto dstMemref = getDst().getType().cast<MemRefType>();
call    0 never executed
call    1 never executed
call    2 never executed
    #####:   53:  unsigned workgroupAddressSpace = gpu::GPUDialect::getWorkgroupAddressSpace();
call    0 never executed
    #####:   54:  if (!isLastMemrefDimUnitStride(srcMemref))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:   55:    return emitError("source memref most minor dim must have unit stride");
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:   56:  if (!isLastMemrefDimUnitStride(dstMemref))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:   57:    return emitError("destination memref most minor dim must have unit stride");
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:   58:  if (dstMemref.getMemorySpaceAsInt() != workgroupAddressSpace)
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:   59:    return emitError("destination memref must have memory space ")
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:   60:           << workgroupAddressSpace;
call    0 never executed
    #####:   61:  if (dstMemref.getElementType() != srcMemref.getElementType())
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:   62:    return emitError("source and destination must have the same element type");
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:   63:  if (size_t(srcMemref.getRank()) != getSrcIndices().size())
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:   64:    return emitOpError() << "expected " << srcMemref.getRank()
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
call    5 never executed
    #####:   65:                         << " source indices, got " << getSrcIndices().size();
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:   66:  if (size_t(dstMemref.getRank()) != getDstIndices().size())
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
    #####:   67:    return emitOpError() << "expected " << dstMemref.getRank()
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
call    5 never executed
    #####:   68:                         << " destination indices, got "
call    0 never executed
    #####:   69:                         << getDstIndices().size();
call    0 never executed
call    1 never executed
call    2 never executed
    #####:   70:  return success();
        -:   71:}
        -:   72:
        -:   73://===----------------------------------------------------------------------===//
        -:   74:// NVGPU_MmaSyncOp
        -:   75://===----------------------------------------------------------------------===//
function _ZN4mlir5nvgpu9MmaSyncOp5buildERNS_9OpBuilderERNS_14OperationStateENS_5ValueES6_S6_NS_9ArrayAttrE called 0 returned 0% blocks executed 0%
    #####:   76:void MmaSyncOp::build(::mlir::OpBuilder &odsBuilder,
        -:   77:                      ::mlir::OperationState &odsState, Value matrixA,
        -:   78:                      Value matrixB, Value matrixC, ArrayAttr mmaShape) {
    #####:   79:  build(odsBuilder, odsState, matrixC.getType(), matrixA, matrixB, matrixC,
call    0 never executed
        -:   80:        mmaShape, UnitAttr());
    #####:   81:}
        -:   82:
function _ZN4mlir5nvgpu9MmaSyncOp6verifyEv called 0 returned 0% blocks executed 0%
    #####:   83:LogicalResult MmaSyncOp::verify() {
        -:   84:
        -:   85:  // Fundamental tensor core mma.sync op
        -:   86:  // For F32 (TF32), F16, S8, and S4 data types fundamental tensor core
        -:   87:  // operation is of shape: 8-by-8-by-128b. F64 is an exception. The
        -:   88:  // verification for mma.sync covering various shapes and data types is based
        -:   89:  // on the fundamental tensor core operionation.
    #####:   90:  constexpr int kThreads = 32; // 32 threads per warp
    #####:   91:  int64_t shapeM = 8;
    #####:   92:  int64_t shapeN = 8;
    #####:   93:  int64_t shapeK; // set based on data type (128b for all data types except F64)
        -:   94:
        -:   95:  // Number of elements A, B, and C per thread per fundamental tensor core tile
    #####:   96:  int64_t numElementA;    // set based on data type (32b except F64)
    #####:   97:  int64_t numElementB;    // set based on data type (32b except F64)
    #####:   98:  int64_t numElementC{2}; // two accumulator elements per fundamental tile
        -:   99:
        -:  100:  // nvgpu.mma.sync vector operands (per thread)
    #####:  101:  auto aVector = getMatrixA().getType().cast<VectorType>();
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  102:  auto bVector = getMatrixB().getType().cast<VectorType>();
call    0 never executed
call    1 never executed
call    2 never executed
    #####:  103:  auto cVector = getMatrixC().getType().cast<VectorType>();
call    0 never executed
call    1 never executed
call    2 never executed
        -:  104:
        -:  105:  // vector shapes
    #####:  106:  ArrayRef<int64_t> aShape = aVector.getShape();
call    0 never executed
    #####:  107:  ArrayRef<int64_t> bShape = bVector.getShape();
call    0 never executed
    #####:  108:  ArrayRef<int64_t> cShape = cVector.getShape();
call    0 never executed
        -:  109:
        -:  110:  // vector element type
    #####:  111:  Type aType = aVector.getElementType();
call    0 never executed
        -:  112:
        -:  113:  // tensor float32 (TF32) enabled
    #####:  114:  bool tf32Enabled = getOperation()->hasAttr(getTf32EnabledAttrName());
call    0 never executed
call    1 never executed
        -:  115:
        -:  116:  // nvgpu.mma.sync shape (per 32 threads or per warp)
    #####:  117:  int64_t m = getMmaShape()[0].cast<IntegerAttr>().getInt();
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:  118:  int64_t n = getMmaShape()[1].cast<IntegerAttr>().getInt();
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:  119:  int64_t k = getMmaShape()[2].cast<IntegerAttr>().getInt();
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
        -:  120:
    #####:  121:  if (aType.isF64()) {
call    0 never executed
branch  1 never executed
branch  2 never executed
        -:  122:    // exception to 8-by-8-128b fundamental tensor core tile size
    #####:  123:    shapeK = 4;
    #####:  124:    numElementA = 1;
    #####:  125:    numElementB = 1;
    #####:  126:  } else if (aType.isF32() || aType.isBF16() || aType.isF16() ||
call    0 never executed
call    1 never executed
branch  2 never executed
branch  3 never executed
call    4 never executed
branch  5 never executed
branch  6 never executed
branch  7 never executed
branch  8 never executed
    #####:  127:             aType.isInteger(8) || aType.isInteger(4)) {
branch  0 never executed
branch  1 never executed
call    2 never executed
call    3 never executed
branch  4 never executed
branch  5 never executed
        -:  128:    // 8-by-8-128b fundamental tensor core tile size
    #####:  129:    int operandBitwidth = aType.getIntOrFloatBitWidth();
call    0 never executed
    #####:  130:    shapeK = 128 / operandBitwidth;     // 128b wide shapeK
    #####:  131:    numElementA = 32 / operandBitwidth; // 32b wide operand A
    #####:  132:    numElementB = 32 / operandBitwidth; // 32b wide operand B
        -:  133:  } else {
    #####:  134:    return emitError() << "expected input data type (i4,i8,f16,bf16,tf32,f64) "
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:  135:                          "supported by nvgpu.mma.sync";
call    0 never executed
        -:  136:  }
        -:  137:
        -:  138:  //
        -:  139:  // Basic verification
        -:  140:  //
        -:  141:
        -:  142:  // verify warp-wide size for vector a
    #####:  143:  if (aShape[0] * aShape[1] * kThreads != m * k)
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
    #####:  144:    return emitOpError() << "expected " << m * k
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
call    5 never executed
    #####:  145:                         << " warp-wide matrix A elements";
call    0 never executed
        -:  146:
        -:  147:  // verify warp-wide size for vector b
    #####:  148:  if (bShape[0] * bShape[1] * kThreads != k * n)
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
    #####:  149:    return emitOpError() << "expected " << k * n
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
call    5 never executed
    #####:  150:                         << " warp-wide matrix B elements";
call    0 never executed
        -:  151:
        -:  152:  // verify warp-wide size for vector c
    #####:  153:  if (cShape[0] * cShape[1] * kThreads != m * n)
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
branch  4 never executed
branch  5 never executed
    #####:  154:    return emitOpError() << "expected " << m * n
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
call    5 never executed
    #####:  155:                         << " warp-wide matrix C elements";
call    0 never executed
        -:  156:
        -:  157:  // verify tf32 tensor cores are enabled for only F32 datatype
    #####:  158:  if (tf32Enabled && !(aType.isF32()))
branch  0 never executed
branch  1 never executed
call    2 never executed
branch  3 never executed
branch  4 never executed
    #####:  159:    return emitOpError() << "expected tf32 tensor cores only for F32 operands";
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
        -:  160:
        -:  161:  //
        -:  162:  // Extended verification
        -:  163:  //
        -:  164:
        -:  165:  // tiles of fundamental tensor core operations
    #####:  166:  int64_t mTile = m / shapeM;
    #####:  167:  int64_t nTile = n / shapeN;
    #####:  168:  int64_t kTile = k / shapeK;
        -:  169:
        -:  170:  // verify shape of aVector
    #####:  171:  if ((aShape[0] != mTile * kTile) || (aShape[1] != numElementA))
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####:  172:    return emitOpError() << "expected matrix A to be shaped (" << mTile * kTile
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
call    5 never executed
    #####:  173:                         << " x " << numElementA << ")";
call    0 never executed
call    1 never executed
call    2 never executed
        -:  174:
        -:  175:  // verify shape of bVector
    #####:  176:  if ((bShape[0] != kTile * nTile) || (bShape[1] != numElementB))
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####:  177:    return emitOpError() << "expected matrix B to be shaped (" << kTile * nTile
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
call    5 never executed
    #####:  178:                         << " x " << numElementB << ")";
call    0 never executed
call    1 never executed
call    2 never executed
        -:  179:
        -:  180:  // verify shape of cVector
    #####:  181:  if ((cShape[0] != mTile * nTile) || (cShape[1] != numElementC))
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####:  182:    return emitOpError() << "expected matrix C to be shaped (" << mTile * nTile
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
call    5 never executed
    #####:  183:                         << " x " << numElementC << ")";
call    0 never executed
call    1 never executed
call    2 never executed
        -:  184:
    #####:  185:  return success();
        -:  186:}
        -:  187:
        -:  188://===----------------------------------------------------------------------===//
        -:  189:// NVGPU_LdMatrixOp
        -:  190://===----------------------------------------------------------------------===//
function _ZN4mlir5nvgpu10LdMatrixOp6verifyEv called 0 returned 0% blocks executed 0%
    #####:  191:LogicalResult LdMatrixOp::verify() {
        -:  192:
        -:  193:  // ldmatrix reads data from source in shared memory
    #####:  194:  auto srcMemref = getSrcMemref().getType().cast<MemRefType>();
call    0 never executed
call    1 never executed
call    2 never executed
        -:  195:
        -:  196:  // ldmatrix writes data to result/destination in vector registers
    #####:  197:  auto resVector = getRes().getType().cast<VectorType>();
call    0 never executed
call    1 never executed
call    2 never executed
        -:  198:
        -:  199:  // vector register shape, element type, and bitwidth
    #####:  200:  ArrayRef<int64_t> resShape = resVector.getShape();
call    0 never executed
    #####:  201:  Type resType = resVector.getElementType();
call    0 never executed
    #####:  202:  int64_t elementBitWidth = resType.getIntOrFloatBitWidth();
call    0 never executed
        -:  203:
        -:  204:  // ldmatrix loads 32 bits into vector registers per 8-by-8 tile per thread
    #####:  205:  int64_t numElementsPer32b = 32 / elementBitWidth;
        -:  206:
        -:  207:  // number of 8-by-8 tiles
    #####:  208:  int64_t numTiles = getNumTiles();
call    0 never executed
        -:  209:
        -:  210:  // transpose elements in vector registers at 16b granularity when true
    #####:  211:  bool isTranspose = getTranspose();
call    0 never executed
        -:  212:
        -:  213:  // address space id for shared memory
    #####:  214:  unsigned smemAddressSpace = gpu::GPUDialect::getWorkgroupAddressSpace();
call    0 never executed
        -:  215:
        -:  216:  //
        -:  217:  // verification
        -:  218:  //
        -:  219:
    #####:  220:  if (!(srcMemref.getMemorySpaceAsInt() == smemAddressSpace))
call    0 never executed
branch  1 never executed
branch  2 never executed
    #####:  221:    return emitError()
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:  222:           << "expected nvgpu.ldmatrix srcMemref must have memory space "
call    0 never executed
    #####:  223:           << smemAddressSpace;
call    0 never executed
    #####:  224:  if (elementBitWidth > 32)
branch  0 never executed
branch  1 never executed
    #####:  225:    return emitError() << "nvgpu.ldmatrix works for 32b or lower";
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
    #####:  226:  if (isTranspose && !(elementBitWidth == 16))
branch  0 never executed
branch  1 never executed
    #####:  227:    return emitError()
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:  228:           << "nvgpu.ldmatrix transpose works only at 16b granularity";
call    0 never executed
    #####:  229:  if (!(resShape[1] == numElementsPer32b))
branch  0 never executed
branch  1 never executed
branch  2 never executed
branch  3 never executed
    #####:  230:    return emitError() << "expected vector register shape[1] = "
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
call    4 never executed
    #####:  231:                       << numElementsPer32b;
call    0 never executed
    #####:  232:  if (!(resShape[0] == numTiles))
branch  0 never executed
branch  1 never executed
    #####:  233:    return emitError()
call    0 never executed
call    1 never executed
call    2 never executed
call    3 never executed
    #####:  234:           << "expected vector register shape[0] and numTiles to match";
call    0 never executed
        -:  235:
    #####:  236:  return success();
        -:  237:}
        -:  238:
        -:  239://===----------------------------------------------------------------------===//
        -:  240:// TableGen'd dialect, type, and op definitions
        -:  241://===----------------------------------------------------------------------===//
        -:  242:
        -:  243:#include "mlir/Dialect/NVGPU/IR/NVGPUDialect.cpp.inc"
        -:  244:
        -:  245:#define GET_OP_CLASSES
        -:  246:#include "mlir/Dialect/NVGPU/IR/NVGPU.cpp.inc"
        -:  247:
        -:  248:#define GET_TYPEDEF_CLASSES
        -:  249:#include "mlir/Dialect/NVGPU/IR/NVGPUTypes.cpp.inc"
